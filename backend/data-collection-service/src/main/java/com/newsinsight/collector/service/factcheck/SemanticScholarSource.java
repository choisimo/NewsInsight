package com.newsinsight.collector.service.factcheck;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.newsinsight.collector.config.TrustScoreConfig;
import com.newsinsight.collector.service.FactVerificationService.SourceEvidence;
import com.newsinsight.collector.service.RateLimitRetryService;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.http.MediaType;
import org.springframework.stereotype.Component;
import org.springframework.web.reactive.function.client.WebClient;
import org.springframework.web.reactive.function.client.WebClientResponseException;
import reactor.core.publisher.Flux;

import java.net.URLEncoder;
import java.nio.charset.StandardCharsets;
import java.time.Duration;
import java.util.ArrayList;
import java.util.List;

/**
 * Semantic Scholar APIë¥¼ í†µí•œ í•™ìˆ  ë…¼ë¬¸ ê²€ìƒ‰
 * 
 * Semantic ScholarëŠ” AI ê¸°ë°˜ì˜ í•™ìˆ  ê²€ìƒ‰ ì—”ì§„ìœ¼ë¡œ,
 * ë…¼ë¬¸ ê°„ì˜ ì¸ìš© ê´€ê³„ì™€ ì˜í–¥ë ¥ì„ ë¶„ì„í•˜ì—¬ ë” ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
 * 
 * API ë¬¸ì„œ: https://api.semanticscholar.org/api-docs/
 * 
 * íŠ¹ì§•:
 * - API í‚¤ ì—†ì´ ë¶„ë‹¹ 100íšŒ ìš”ì²­ ê°€ëŠ¥
 * - ì¸ìš© ê´€ê³„ ë¶„ì„
 * - ì˜í–¥ë ¥ ìˆëŠ” ì¸ìš©(influential citations) ì œê³µ
 * - ì´ˆë¡ ë° TLDR ìš”ì•½ ì œê³µ
 * - 429 Too Many Requests ì‹œ IP rotationì„ í†µí•´ ì¬ì‹œë„
 */
@Component
@RequiredArgsConstructor
@Slf4j
public class SemanticScholarSource implements FactCheckSource {

    private final WebClient webClient;
    private final ObjectMapper objectMapper;
    private final TrustScoreConfig trustScoreConfig;
    private final RateLimitRetryService rateLimitRetryService;

    @Value("${collector.fact-check.semantic-scholar.enabled:true}")
    private boolean enabled;

    @Value("${collector.fact-check.semantic-scholar.api-key:}")
    private String apiKey;

    @Value("${collector.fact-check.timeout-seconds:15}")
    private int timeoutSeconds;

    private static final String API_BASE = "https://api.semanticscholar.org/graph/v1/paper/search";
    private static final String FIELDS = "title,abstract,year,citationCount,influentialCitationCount,authors,url,tldr";

    @Override
    public String getSourceId() {
        return "semantic_scholar";
    }

    @Override
    public String getSourceName() {
        return "Semantic Scholar (í•™ìˆ  ë…¼ë¬¸)";
    }

    @Override
    public double getTrustScore() {
        // TrustScoreConfigì— semantic scholar ì„¤ì •ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        try {
            return trustScoreConfig.getFactCheck().getOpenalex(); // OpenAlexì™€ ë™ì¼í•œ ìˆ˜ì¤€
        } catch (Exception e) {
            return 0.85; // ê¸°ë³¸ í•™ìˆ  ì‹ ë¢°ë„
        }
    }

    @Override
    public SourceType getSourceType() {
        return SourceType.ACADEMIC;
    }

    @Override
    public boolean isAvailable() {
        return enabled;
    }

    @Override
    public Flux<SourceEvidence> fetchEvidence(String topic, String language) {
        if (!enabled) {
            return Flux.empty();
        }

        return Flux.defer(() -> {
            try {
                String encodedQuery = URLEncoder.encode(topic, StandardCharsets.UTF_8);
                String url = String.format(
                        "%s?query=%s&limit=5&fields=%s",
                        API_BASE, encodedQuery, FIELDS
                );

                log.debug("Fetching Semantic Scholar evidence for topic: {}", topic);

                // ë¨¼ì € ì¼ë°˜ ìš”ì²­ ì‹œë„, 429 ì—ëŸ¬ ì‹œ í”„ë¡ì‹œë¥¼ í†µí•´ ì¬ì‹œë„
                String response = executeRequestWithRetry(url);

                if (response == null || response.isBlank()) {
                    log.debug("No response from Semantic Scholar for topic: {}", topic);
                    return Flux.empty();
                }

                return Flux.fromIterable(parseResponse(response, topic));
            } catch (Exception e) {
                log.warn("Semantic Scholar API call failed for topic '{}': {}", topic, e.getMessage());
                return Flux.empty();
            }
        });
    }

    /**
     * ìš”ì²­ ì‹¤í–‰ - 429 ì—ëŸ¬ ì‹œ IP rotationì„ í†µí•´ ì¬ì‹œë„
     */
    private String executeRequestWithRetry(String url) {
        try {
            // 1ì°¨ ì‹œë„: ì¼ë°˜ ìš”ì²­
            WebClient.RequestHeadersSpec<?> request = webClient.get()
                    .uri(url)
                    .accept(MediaType.APPLICATION_JSON);

            // API í‚¤ê°€ ìˆìœ¼ë©´ í—¤ë”ì— ì¶”ê°€ (ë” ë†’ì€ rate limit)
            if (apiKey != null && !apiKey.isBlank()) {
                request = webClient.get()
                        .uri(url)
                        .accept(MediaType.APPLICATION_JSON)
                        .header("x-api-key", apiKey);
            }

            return request
                    .retrieve()
                    .bodyToMono(String.class)
                    .timeout(Duration.ofSeconds(timeoutSeconds))
                    .block();
                    
        } catch (Exception e) {
            // 429 ë˜ëŠ” 403 ì—ëŸ¬ì¸ ê²½ìš° í”„ë¡ì‹œë¥¼ í†µí•´ ì¬ì‹œë„
            if (isRateLimitError(e)) {
                log.info("Rate limit hit for Semantic Scholar, attempting proxy retry for: {}", url);
                return retryWithProxy(url);
            }
            throw e;
        }
    }

    /**
     * í”„ë¡ì‹œë¥¼ í†µí•œ ì¬ì‹œë„
     */
    private String retryWithProxy(String url) {
        try {
            String[] headers = apiKey != null && !apiKey.isBlank() 
                    ? new String[]{"x-api-key", apiKey, "Accept", "application/json"}
                    : new String[]{"Accept", "application/json"};
            
            String response = rateLimitRetryService.executeWithRetryBlocking(url, headers);
            
            if (response != null) {
                log.info("Semantic Scholar proxy retry succeeded for: {}", url);
            }
            return response;
        } catch (Exception e) {
            log.warn("Semantic Scholar proxy retry failed: {}", e.getMessage());
            return null;
        }
    }

    /**
     * Rate limit ì—ëŸ¬ì¸ì§€ í™•ì¸
     */
    private boolean isRateLimitError(Throwable e) {
        if (e instanceof WebClientResponseException wce) {
            int statusCode = wce.getStatusCode().value();
            return statusCode == 429 || statusCode == 403;
        }
        String message = e.getMessage();
        if (message != null) {
            message = message.toLowerCase();
            return message.contains("429") || 
                   message.contains("403") || 
                   message.contains("too many requests") ||
                   message.contains("rate limit");
        }
        return false;
    }

    @Override
    public Flux<SourceEvidence> verifyClaimAgainstSource(String claim, String language) {
        // í•™ìˆ  ê²€ìƒ‰ì— ì í•©í•˜ë„ë¡ í‚¤ì›Œë“œ ì¶”ì¶œ
        String[] words = claim.split("[\\s,\\.!?]+");
        String searchQuery = String.join(" ", 
                java.util.Arrays.stream(words)
                        .filter(w -> w.length() > 3)
                        .filter(w -> !isCommonWord(w))
                        .limit(6)
                        .toList());
        
        if (searchQuery.isBlank()) {
            searchQuery = claim.length() > 60 ? claim.substring(0, 60) : claim;
        }
        
        return fetchEvidence(searchQuery, language);
    }

    private boolean isCommonWord(String word) {
        return List.of("that", "this", "with", "from", "have", "been", "were", "will",
                "ì´ê²ƒ", "ì €ê²ƒ", "ê·¸ê²ƒ", "ìˆëŠ”", "ì—†ëŠ”", "í•˜ëŠ”", "ë˜ëŠ”").contains(word.toLowerCase());
    }

    private List<SourceEvidence> parseResponse(String response, String query) {
        List<SourceEvidence> evidenceList = new ArrayList<>();
        
        if (response == null || response.isBlank()) {
            return evidenceList;
        }

        try {
            JsonNode root = objectMapper.readTree(response);
            JsonNode data = root.path("data");

            if (data.isArray()) {
                for (JsonNode paper : data) {
                    try {
                        String title = paper.path("title").asText("");
                        if (title.isBlank()) continue;

                        String paperAbstract = paper.path("abstract").asText("");
                        String tldr = paper.path("tldr").path("text").asText("");
                        int year = paper.path("year").asInt(0);
                        int citationCount = paper.path("citationCount").asInt(0);
                        int influentialCount = paper.path("influentialCitationCount").asInt(0);
                        String paperUrl = paper.path("url").asText("");

                        // ì €ì ì¶”ì¶œ
                        String authors = extractAuthors(paper.path("authors"));

                        // ë°œì·Œë¬¸ êµ¬ì„± - TLDRì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
                        StringBuilder excerpt = new StringBuilder();
                        excerpt.append("ğŸ“„ ").append(title);
                        if (year > 0) {
                            excerpt.append(" (").append(year).append(")");
                        }
                        excerpt.append("\n");
                        
                        if (!authors.isBlank()) {
                            excerpt.append("ì €ì: ").append(authors).append("\n");
                        }
                        
                        excerpt.append("ì¸ìš©: ").append(citationCount).append("íšŒ");
                        if (influentialCount > 0) {
                            excerpt.append(" (ì˜í–¥ë ¥ ìˆëŠ” ì¸ìš©: ").append(influentialCount).append("íšŒ)");
                        }
                        
                        // TLDRì´ ìˆìœ¼ë©´ ì¶”ê°€ (ê°„ê²°í•œ ìš”ì•½)
                        if (!tldr.isBlank()) {
                            excerpt.append("\n\nğŸ“ ìš”ì•½: ").append(tldr);
                        } else if (!paperAbstract.isBlank()) {
                            // ì´ˆë¡ ì¶”ê°€ (ìµœëŒ€ 300ì)
                            String shortAbstract = paperAbstract.length() > 300 
                                    ? paperAbstract.substring(0, 300) + "..." 
                                    : paperAbstract;
                            excerpt.append("\n\n").append(shortAbstract);
                        }

                        // ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚° (ì¸ìš© ìˆ˜ ë° ì˜í–¥ë ¥ ê¸°ë°˜)
                        double relevance = calculateRelevance(query, title, paperAbstract, citationCount, influentialCount);

                        evidenceList.add(SourceEvidence.builder()
                                .sourceType("academic")
                                .sourceName(getSourceName())
                                .url(paperUrl)
                                .excerpt(truncate(excerpt.toString(), 600))
                                .relevanceScore(relevance)
                                .stance("neutral")
                                .build());
                    } catch (Exception e) {
                        log.debug("Failed to parse Semantic Scholar paper: {}", e.getMessage());
                    }
                }
            }
        } catch (Exception e) {
            log.warn("Failed to parse Semantic Scholar response: {}", e.getMessage());
        }

        return evidenceList;
    }

    private String extractAuthors(JsonNode authorsNode) {
        if (!authorsNode.isArray() || authorsNode.isEmpty()) {
            return "";
        }

        List<String> authorNames = new ArrayList<>();
        for (JsonNode author : authorsNode) {
            String name = author.path("name").asText("");
            if (!name.isBlank()) {
                authorNames.add(name);
                if (authorNames.size() >= 3) break;
            }
        }

        if (authorNames.isEmpty()) return "";
        if (authorNames.size() < 3) return String.join(", ", authorNames);
        return authorNames.get(0) + " ì™¸ " + (authorsNode.size() - 1) + "ëª…";
    }

    private double calculateRelevance(String query, String title, String abstractText, 
                                      int citationCount, int influentialCount) {
        double score = 0.5; // ê¸°ë³¸ ì ìˆ˜

        // ì œëª©/ì´ˆë¡ê³¼ ì¿¼ë¦¬ ë§¤ì¹­
        String lowerQuery = query.toLowerCase();
        String lowerTitle = title.toLowerCase();
        String lowerAbstract = abstractText != null ? abstractText.toLowerCase() : "";

        String[] queryWords = lowerQuery.split("\\s+");
        int matches = 0;
        for (String word : queryWords) {
            if (word.length() > 2) {
                if (lowerTitle.contains(word)) matches += 2;
                if (lowerAbstract.contains(word)) matches++;
            }
        }
        score += Math.min(0.3, matches * 0.05);

        // ì¸ìš© ìˆ˜ ê¸°ë°˜ ë³´ë„ˆìŠ¤ (ë§ì´ ì¸ìš©ëœ ë…¼ë¬¸ì€ ë” ì‹ ë¢°í•  ìˆ˜ ìˆìŒ)
        if (citationCount > 100) score += 0.1;
        else if (citationCount > 50) score += 0.07;
        else if (citationCount > 10) score += 0.05;

        // ì˜í–¥ë ¥ ìˆëŠ” ì¸ìš© ë³´ë„ˆìŠ¤
        if (influentialCount > 10) score += 0.1;
        else if (influentialCount > 5) score += 0.05;

        return Math.min(1.0, Math.max(0.3, score));
    }

    private String truncate(String text, int maxLength) {
        if (text == null) return "";
        if (text.length() <= maxLength) return text;
        return text.substring(0, maxLength) + "...";
    }
}
