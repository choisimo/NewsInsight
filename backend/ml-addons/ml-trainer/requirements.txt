# ML Training Service Dependencies
fastapi>=0.109.0
uvicorn>=0.27.0
httpx>=0.26.0
pydantic>=2.5.0
python-multipart>=0.0.6

# ML/DL Core
torch>=2.1.0
transformers>=4.36.0
datasets>=2.16.0
accelerate>=0.25.0
peft>=0.7.0
trl>=0.7.0

# Korean NLP
# kobert-tokenizer is part of kobert-transformers
# For Korean BERT models, use transformers directly with klue/bert-base
konlpy>=0.6.0

# Monitoring & Logging
structlog>=23.2.0
prometheus-client>=0.19.0

# Data Processing
pandas>=2.1.0
numpy>=1.26.0
scikit-learn>=1.3.0

# Huggingface Hub (for model upload/download)
huggingface-hub>=0.20.0

# Environment
python-dotenv>=1.0.0

# Database (for storing training results)
asyncpg>=0.29.0
sqlalchemy>=2.0.0

# Redis (for state persistence)
redis>=5.0.0

# Utilities
aiofiles>=23.2.0
tenacity>=8.2.0
