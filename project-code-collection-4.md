# Project Code Snapshot

Generated at 2025-12-21T10:30:23.565Z

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/entity/search/DraftSearch.java

```java
package com.newsinsight.collector.entity.search;

import jakarta.persistence.*;
import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;
import org.hibernate.annotations.CreationTimestamp;
import org.hibernate.annotations.JdbcTypeCode;
import org.hibernate.annotations.UpdateTimestamp;
import org.hibernate.type.SqlTypes;

import java.time.LocalDateTime;
import java.util.Map;

/**
 * Entity for storing user's draft/unsaved searches.
 * Captures search inputs that haven't been executed yet,
 * enabling "Continue Work" feature for incomplete searches.
 */
@Entity
@Table(name = "draft_searches", indexes = {
        @Index(name = "idx_draft_search_user_id", columnList = "user_id"),
        @Index(name = "idx_draft_search_session_id", columnList = "session_id"),
        @Index(name = "idx_draft_search_created_at", columnList = "created_at"),
        @Index(name = "idx_draft_search_executed", columnList = "executed")
})
@Data
@Builder
@NoArgsConstructor
@AllArgsConstructor
public class DraftSearch {

    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    /**
     * Search query entered by user
     */
    @Column(nullable = false, length = 1024)
    private String query;

    /**
     * Type of search intended
     */
    @Enumerated(EnumType.STRING)
    @Column(name = "search_type", length = 32)
    @Builder.Default
    private SearchType searchType = SearchType.UNIFIED;

    /**
     * User ID
     */
    @Column(name = "user_id", length = 64)
    private String userId;

    /**
     * Session ID for anonymous users
     */
    @Column(name = "session_id", length = 64)
    private String sessionId;

    /**
     * Time window selected (1d, 7d, 30d, etc.)
     */
    @Column(name = "time_window", length = 16)
    private String timeWindow;

    /**
     * Search mode (standard, deep, fact-check, etc.)
     */
    @Column(name = "search_mode", length = 32)
    private String searchMode;

    /**
     * Additional options/parameters
     */
    @JdbcTypeCode(SqlTypes.JSON)
    @Column(name = "options", columnDefinition = "jsonb")
    private Map<String, Object> options;

    /**
     * Whether this draft has been executed
     */
    @Column(name = "executed")
    @Builder.Default
    private Boolean executed = false;

    /**
     * When the draft was executed
     */
    @Column(name = "executed_at")
    private LocalDateTime executedAt;

    /**
     * Reference to the executed search history
     */
    @Column(name = "search_history_id")
    private Long searchHistoryId;

    /**
     * Project ID if associated with a project
     */
    @Column(name = "project_id")
    private Long projectId;

    /**
     * Source page/context where the draft was created
     */
    @Column(name = "source_context", length = 128)
    private String sourceContext;

    @CreationTimestamp
    @Column(name = "created_at", updatable = false)
    private LocalDateTime createdAt;

    @UpdateTimestamp
    @Column(name = "updated_at")
    private LocalDateTime updatedAt;

    /**
     * Mark draft as executed
     */
    public void markExecuted(Long searchHistoryId) {
        this.executed = true;
        this.executedAt = LocalDateTime.now();
        this.searchHistoryId = searchHistoryId;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/entity/search/SearchHistory.java

```java
package com.newsinsight.collector.entity.search;

import jakarta.persistence.*;
import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;
import org.hibernate.annotations.CreationTimestamp;
import org.hibernate.annotations.JdbcTypeCode;
import org.hibernate.annotations.UpdateTimestamp;
import org.hibernate.type.SqlTypes;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Map;

/**
 * Entity representing a search history record.
 * Stores the search query, results, and metadata for all search types
 * (unified search, deep search, fact check, browser agent).
 */
@Entity
@Table(name = "search_history", indexes = {
        @Index(name = "idx_search_history_type", columnList = "search_type"),
        @Index(name = "idx_search_history_query", columnList = "query"),
        @Index(name = "idx_search_history_created_at", columnList = "created_at"),
        @Index(name = "idx_search_history_user_id", columnList = "user_id"),
        @Index(name = "idx_search_history_parent_id", columnList = "parent_search_id"),
        @Index(name = "idx_search_history_completion_status", columnList = "completion_status"),
        @Index(name = "idx_search_history_project_id", columnList = "project_id")
})
@Data
@Builder
@NoArgsConstructor
@AllArgsConstructor
public class SearchHistory {

    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    /**
     * External reference ID (e.g., jobId from search job)
     */
    @Column(name = "external_id", length = 64, unique = true)
    private String externalId;

    /**
     * Type of search performed
     */
    @Enumerated(EnumType.STRING)
    @Column(name = "search_type", nullable = false, length = 32)
    private SearchType searchType;

    /**
     * The search query or topic
     */
    @Column(nullable = false, length = 1024)
    private String query;

    /**
     * Time window for search (e.g., 1d, 7d, 30d)
     */
    @Column(length = 16)
    private String timeWindow;

    /**
     * Optional user ID for multi-user scenarios
     */
    @Column(name = "user_id", length = 64)
    private String userId;

    /**
     * Session ID for grouping searches
     */
    @Column(name = "session_id", length = 64)
    private String sessionId;

    /**
     * Parent search ID for derived/drilldown searches
     */
    @Column(name = "parent_search_id")
    private Long parentSearchId;

    /**
     * Depth level for drilldown searches (0 = original, 1+ = drilldown)
     */
    @Column(name = "depth_level")
    @Builder.Default
    private Integer depthLevel = 0;

    /**
     * Total number of results found
     */
    @Column(name = "result_count")
    @Builder.Default
    private Integer resultCount = 0;

    /**
     * Search results stored as JSON
     * Contains list of search result items with their analysis data
     */
    @JdbcTypeCode(SqlTypes.JSON)
    @Column(name = "results", columnDefinition = "jsonb")
    private List<Map<String, Object>> results;

    /**
     * AI summary/response stored as JSON
     */
    @JdbcTypeCode(SqlTypes.JSON)
    @Column(name = "ai_summary", columnDefinition = "jsonb")
    private Map<String, Object> aiSummary;

    /**
     * URLs discovered during search (for auto-collection)
     */
    @JdbcTypeCode(SqlTypes.JSON)
    @Column(name = "discovered_urls", columnDefinition = "jsonb")
    private List<String> discoveredUrls;

    /**
     * Fact check results (for FACT_CHECK type)
     */
    @JdbcTypeCode(SqlTypes.JSON)
    @Column(name = "fact_check_results", columnDefinition = "jsonb")
    private List<Map<String, Object>> factCheckResults;

    /**
     * Overall credibility score (0-100)
     */
    @Column(name = "credibility_score")
    private Double credibilityScore;

    /**
     * Stance distribution (pro, con, neutral counts)
     */
    @JdbcTypeCode(SqlTypes.JSON)
    @Column(name = "stance_distribution", columnDefinition = "jsonb")
    private Map<String, Object> stanceDistribution;

    /**
     * Additional metadata
     */
    @JdbcTypeCode(SqlTypes.JSON)
    @Column(columnDefinition = "jsonb")
    private Map<String, Object> metadata;

    /**
     * Whether this search has been bookmarked/starred
     */
    @Column
    @Builder.Default
    private Boolean bookmarked = false;

    /**
     * User-provided tags for organization
     */
    @JdbcTypeCode(SqlTypes.JSON)
    @Column(columnDefinition = "jsonb")
    private List<String> tags;

    /**
     * User notes about this search
     */
    @Column(columnDefinition = "text")
    private String notes;

    /**
     * Search duration in milliseconds
     */
    @Column(name = "duration_ms")
    private Long durationMs;

    /**
     * Error message if search failed
     */
    @Column(name = "error_message", length = 2048)
    private String errorMessage;

    /**
     * Whether the search completed successfully
     */
    @Column
    @Builder.Default
    private Boolean success = true;

    // ============ New fields for improved tracking ============

    /**
     * Completion status for "Continue Work" feature
     */
    @Enumerated(EnumType.STRING)
    @Column(name = "completion_status", length = 32)
    @Builder.Default
    private CompletionStatus completionStatus = CompletionStatus.IN_PROGRESS;

    /**
     * Whether the user has viewed the results
     */
    @Column(name = "viewed")
    @Builder.Default
    private Boolean viewed = false;

    /**
     * When the user viewed the results
     */
    @Column(name = "viewed_at")
    private LocalDateTime viewedAt;

    /**
     * Whether a report has been generated for this search
     */
    @Column(name = "report_generated")
    @Builder.Default
    private Boolean reportGenerated = false;

    /**
     * Phase where failure occurred (for debugging)
     * e.g., "db_search", "web_crawl", "ai_analysis"
     */
    @Column(name = "failure_phase", length = 64)
    private String failurePhase;

    /**
     * Detailed failure information
     */
    @JdbcTypeCode(SqlTypes.JSON)
    @Column(name = "failure_details", columnDefinition = "jsonb")
    private Map<String, Object> failureDetails;

    /**
     * Partial results saved before failure
     */
    @JdbcTypeCode(SqlTypes.JSON)
    @Column(name = "partial_results", columnDefinition = "jsonb")
    private List<Map<String, Object>> partialResults;

    /**
     * Progress percentage (0-100) for long-running searches
     */
    @Column(name = "progress")
    @Builder.Default
    private Integer progress = 0;

    /**
     * Current phase description for UI display
     */
    @Column(name = "current_phase", length = 128)
    private String currentPhase;

    /**
     * Project ID for project-based organization
     */
    @Column(name = "project_id")
    private Long projectId;

    @CreationTimestamp
    @Column(name = "created_at", updatable = false)
    private LocalDateTime createdAt;

    @UpdateTimestamp
    @Column(name = "updated_at")
    private LocalDateTime updatedAt;

    // ============ Enums ============

    /**
     * Completion status for tracking search progress
     */
    public enum CompletionStatus {
        /** Search input saved but not executed */
        DRAFT,
        /** Search is currently running */
        IN_PROGRESS,
        /** Some sources succeeded, some failed */
        PARTIAL,
        /** Search completed successfully */
        COMPLETED,
        /** Search failed */
        FAILED,
        /** Search was cancelled by user */
        CANCELLED
    }

    // ============ Helper methods ============

    /**
     * Convenience method to check if this is a derived search
     */
    public boolean isDerivedSearch() {
        return parentSearchId != null && parentSearchId > 0;
    }

    /**
     * Get result count safely
     */
    public int getResultCountSafe() {
        if (results != null) {
            return results.size();
        }
        return resultCount != null ? resultCount : 0;
    }

    /**
     * Check if this search needs to be continued
     */
    public boolean needsContinuation() {
        if (completionStatus == null) {
            return !Boolean.TRUE.equals(success);
        }
        return completionStatus == CompletionStatus.DRAFT
                || completionStatus == CompletionStatus.IN_PROGRESS
                || completionStatus == CompletionStatus.PARTIAL
                || completionStatus == CompletionStatus.FAILED;
    }

    /**
     * Check if this search is actionable (should show in "Continue Work")
     */
    public boolean isActionable() {
        // Exclude completed searches that have been viewed
        if (completionStatus == CompletionStatus.COMPLETED && Boolean.TRUE.equals(viewed)) {
            return false;
        }
        // Exclude bookmarked or report-generated searches
        if (Boolean.TRUE.equals(bookmarked) || Boolean.TRUE.equals(reportGenerated)) {
            return false;
        }
        return needsContinuation() || (completionStatus == CompletionStatus.COMPLETED && !Boolean.TRUE.equals(viewed));
    }

    /**
     * Mark as viewed
     */
    public void markViewed() {
        this.viewed = true;
        this.viewedAt = LocalDateTime.now();
    }

    /**
     * Mark as completed
     */
    public void markCompleted() {
        this.completionStatus = CompletionStatus.COMPLETED;
        this.success = true;
        this.progress = 100;
    }

    /**
     * Mark as failed with details
     */
    public void markFailed(String phase, String errorMessage, Map<String, Object> details) {
        this.completionStatus = CompletionStatus.FAILED;
        this.success = false;
        this.failurePhase = phase;
        this.errorMessage = errorMessage;
        this.failureDetails = details;
    }

    /**
     * Update progress
     */
    public void updateProgress(int progress, String phase) {
        this.progress = Math.min(100, Math.max(0, progress));
        this.currentPhase = phase;
        if (this.completionStatus == CompletionStatus.DRAFT) {
            this.completionStatus = CompletionStatus.IN_PROGRESS;
        }
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/entity/search/SearchTemplate.java

```java
package com.newsinsight.collector.entity.search;

import jakarta.persistence.*;
import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;
import org.hibernate.annotations.CreationTimestamp;
import org.hibernate.annotations.JdbcTypeCode;
import org.hibernate.annotations.UpdateTimestamp;
import org.hibernate.type.SqlTypes;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Map;

/**
 * Entity representing a saved search template.
 * Templates allow users to save search configurations with selected items
 * for reuse in SmartSearch.
 */
@Entity
@Table(name = "search_template", indexes = {
        @Index(name = "idx_search_template_user_id", columnList = "user_id"),
        @Index(name = "idx_search_template_mode", columnList = "mode"),
        @Index(name = "idx_search_template_created_at", columnList = "created_at")
})
@Data
@Builder
@NoArgsConstructor
@AllArgsConstructor
public class SearchTemplate {

    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    /**
     * Template name (user-defined)
     */
    @Column(nullable = false, length = 256)
    private String name;

    /**
     * Search query associated with this template
     */
    @Column(nullable = false, length = 1024)
    private String query;

    /**
     * Search mode (unified, deep, factcheck)
     */
    @Column(nullable = false, length = 32)
    private String mode;

    /**
     * User ID who created this template
     */
    @Column(name = "user_id", length = 64)
    private String userId;

    /**
     * Selected items stored as JSON array
     * Each item contains: id, type, title, url, snippet, source, stance, verificationStatus
     */
    @JdbcTypeCode(SqlTypes.JSON)
    @Column(name = "items", columnDefinition = "jsonb")
    private List<Map<String, Object>> items;

    /**
     * Optional description for the template
     */
    @Column(columnDefinition = "text")
    private String description;

    /**
     * Whether this template is marked as favorite
     */
    @Column
    @Builder.Default
    private Boolean favorite = false;

    /**
     * Tags for categorization
     */
    @JdbcTypeCode(SqlTypes.JSON)
    @Column(columnDefinition = "jsonb")
    private List<String> tags;

    /**
     * Additional metadata
     */
    @JdbcTypeCode(SqlTypes.JSON)
    @Column(columnDefinition = "jsonb")
    private Map<String, Object> metadata;

    /**
     * Reference to original search history (if created from a search)
     */
    @Column(name = "source_search_id")
    private Long sourceSearchId;

    /**
     * Number of times this template has been used
     */
    @Column(name = "use_count")
    @Builder.Default
    private Integer useCount = 0;

    /**
     * Last time this template was used
     */
    @Column(name = "last_used_at")
    private LocalDateTime lastUsedAt;

    @CreationTimestamp
    @Column(name = "created_at", updatable = false)
    private LocalDateTime createdAt;

    @UpdateTimestamp
    @Column(name = "updated_at")
    private LocalDateTime updatedAt;

    /**
     * Increment use count and update last used timestamp
     */
    public void recordUsage() {
        this.useCount = (this.useCount != null ? this.useCount : 0) + 1;
        this.lastUsedAt = LocalDateTime.now();
    }

    /**
     * Get item count safely
     */
    public int getItemCount() {
        return items != null ? items.size() : 0;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/entity/search/SearchType.java

```java
package com.newsinsight.collector.entity.search;

/**
 * Types of searches that can be performed and stored.
 */
public enum SearchType {
    /** Unified parallel search (DB + Web + AI) */
    UNIFIED,
    
    /** Deep AI search with crawl agents */
    DEEP_SEARCH,
    
    /** Fact verification search */
    FACT_CHECK,
    
    /** Browser agent research */
    BROWSER_AGENT
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/entity/settings/LlmProviderSettings.java

```java
package com.newsinsight.collector.entity.settings;

import jakarta.persistence.*;
import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;
import org.hibernate.annotations.CreationTimestamp;
import org.hibernate.annotations.UpdateTimestamp;

import java.time.LocalDateTime;

/**
 * LLM Provider 설정 엔티티.
 * 
 * 관리자(전역) 설정과 사용자별 설정을 통합 관리.
 * - userId가 null이면 전역(관리자) 설정
 * - userId가 있으면 해당 사용자의 개인 설정
 * 
 * 사용자 설정이 존재하면 전역 설정보다 우선 적용됨.
 */
@Entity
@Table(name = "llm_provider_settings", 
    uniqueConstraints = {
        @UniqueConstraint(name = "uk_llm_provider_user", columnNames = {"provider_type", "user_id"})
    },
    indexes = {
        @Index(name = "idx_llm_settings_user", columnList = "user_id"),
        @Index(name = "idx_llm_settings_provider", columnList = "provider_type"),
        @Index(name = "idx_llm_settings_enabled", columnList = "enabled")
    }
)
@Data
@Builder
@NoArgsConstructor
@AllArgsConstructor
public class LlmProviderSettings {

    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    /**
     * LLM 제공자 타입
     */
    @Enumerated(EnumType.STRING)
    @Column(name = "provider_type", nullable = false, length = 30)
    private LlmProviderType providerType;

    /**
     * 사용자 ID (null = 전역/관리자 설정)
     */
    @Column(name = "user_id", length = 100)
    private String userId;

    /**
     * API 키 (암호화 저장 권장)
     */
    @Column(name = "api_key", columnDefinition = "TEXT")
    private String apiKey;

    /**
     * 기본 모델명
     * 예: gpt-4o, claude-3-5-sonnet-20241022, gemini-1.5-pro
     */
    @Column(name = "default_model", length = 100)
    private String defaultModel;

    /**
     * API Base URL (커스텀 엔드포인트용)
     */
    @Column(name = "base_url", length = 500)
    private String baseUrl;

    /**
     * 활성화 여부
     */
    @Column(name = "enabled", nullable = false)
    @Builder.Default
    private Boolean enabled = true;

    /**
     * 우선순위 (낮을수록 먼저 사용, fallback 체인용)
     */
    @Column(name = "priority")
    @Builder.Default
    private Integer priority = 100;

    /**
     * 최대 토큰 수
     */
    @Column(name = "max_tokens")
    @Builder.Default
    private Integer maxTokens = 4096;

    /**
     * Temperature (0.0 ~ 2.0)
     */
    @Column(name = "temperature")
    @Builder.Default
    private Double temperature = 0.7;

    /**
     * 요청 타임아웃 (밀리초)
     */
    @Column(name = "timeout_ms")
    @Builder.Default
    private Integer timeoutMs = 60000;

    /**
     * 분당 최대 요청 수 (Rate limiting)
     */
    @Column(name = "max_requests_per_minute")
    @Builder.Default
    private Integer maxRequestsPerMinute = 60;

    /**
     * Azure OpenAI 전용: Deployment Name
     */
    @Column(name = "azure_deployment_name", length = 100)
    private String azureDeploymentName;

    /**
     * Azure OpenAI 전용: API Version
     */
    @Column(name = "azure_api_version", length = 20)
    private String azureApiVersion;

    /**
     * 마지막 테스트 성공 시간
     */
    @Column(name = "last_tested_at")
    private LocalDateTime lastTestedAt;

    /**
     * 마지막 테스트 결과
     */
    @Column(name = "last_test_success")
    private Boolean lastTestSuccess;

    /**
     * 생성일시
     */
    @CreationTimestamp
    @Column(name = "created_at", nullable = false, updatable = false)
    private LocalDateTime createdAt;

    /**
     * 수정일시
     */
    @UpdateTimestamp
    @Column(name = "updated_at")
    private LocalDateTime updatedAt;

    // === Helper Methods ===

    /**
     * 전역(관리자) 설정인지 확인
     */
    public boolean isGlobal() {
        return userId == null || userId.isBlank();
    }

    /**
     * 사용자별 설정인지 확인
     */
    public boolean isUserSpecific() {
        return userId != null && !userId.isBlank();
    }

    /**
     * API 키 마스킹 (표시용)
     */
    public String getMaskedApiKey() {
        if (apiKey == null || apiKey.length() < 8) {
            return "****";
        }
        return apiKey.substring(0, 4) + "****" + apiKey.substring(apiKey.length() - 4);
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/entity/settings/LlmProviderType.java

```java
package com.newsinsight.collector.entity.settings;

/**
 * LLM Provider 종류
 */
public enum LlmProviderType {
    OPENAI("OpenAI", "https://api.openai.com/v1"),
    ANTHROPIC("Anthropic", "https://api.anthropic.com"),
    GOOGLE("Google AI", "https://generativelanguage.googleapis.com"),
    OPENROUTER("OpenRouter", "https://openrouter.ai/api/v1"),
    OLLAMA("Ollama", "http://localhost:11434"),
    AZURE_OPENAI("Azure OpenAI", null),
    CUSTOM("Custom", null);

    private final String displayName;
    private final String defaultBaseUrl;

    LlmProviderType(String displayName, String defaultBaseUrl) {
        this.displayName = displayName;
        this.defaultBaseUrl = defaultBaseUrl;
    }

    public String getDisplayName() {
        return displayName;
    }

    public String getDefaultBaseUrl() {
        return defaultBaseUrl;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/entity/workspace/WorkspaceFile.java

```java
package com.newsinsight.collector.entity.workspace;

import jakarta.persistence.*;
import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;
import org.hibernate.annotations.CreationTimestamp;
import org.hibernate.annotations.JdbcTypeCode;
import org.hibernate.annotations.UpdateTimestamp;
import org.hibernate.type.SqlTypes;

import java.time.LocalDateTime;
import java.util.Map;
import java.util.UUID;

/**
 * Entity representing a file stored in user's workspace.
 * File metadata is stored in PostgreSQL, actual file content on local disk/S3.
 */
@Entity
@Table(name = "workspace_files", indexes = {
        @Index(name = "idx_workspace_file_session_id", columnList = "session_id"),
        @Index(name = "idx_workspace_file_user_id", columnList = "user_id"),
        @Index(name = "idx_workspace_file_project_id", columnList = "project_id"),
        @Index(name = "idx_workspace_file_file_type", columnList = "file_type"),
        @Index(name = "idx_workspace_file_status", columnList = "status"),
        @Index(name = "idx_workspace_file_created_at", columnList = "created_at")
})
@Data
@Builder
@NoArgsConstructor
@AllArgsConstructor
public class WorkspaceFile {

    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    /**
     * Unique file identifier (UUID for secure access)
     */
    @Column(name = "file_uuid", nullable = false, unique = true, length = 36)
    @Builder.Default
    private String fileUuid = UUID.randomUUID().toString();

    /**
     * Session ID for anonymous users
     */
    @Column(name = "session_id", length = 64)
    private String sessionId;

    /**
     * User ID for authenticated users (optional)
     */
    @Column(name = "user_id", length = 64)
    private String userId;

    /**
     * Associated project ID (optional)
     */
    @Column(name = "project_id")
    private Long projectId;

    /**
     * Original file name
     */
    @Column(name = "original_name", nullable = false, length = 512)
    private String originalName;

    /**
     * Stored file name (UUID-based for uniqueness)
     */
    @Column(name = "stored_name", nullable = false, length = 128)
    private String storedName;

    /**
     * File extension (e.g., pdf, xlsx, csv)
     */
    @Column(name = "extension", length = 32)
    private String extension;

    /**
     * MIME type
     */
    @Column(name = "mime_type", length = 128)
    private String mimeType;

    /**
     * File size in bytes
     */
    @Column(name = "file_size", nullable = false)
    private Long fileSize;

    /**
     * File type category
     */
    @Enumerated(EnumType.STRING)
    @Column(name = "file_type", length = 32)
    @Builder.Default
    private FileType fileType = FileType.OTHER;

    /**
     * Storage location type
     */
    @Enumerated(EnumType.STRING)
    @Column(name = "storage_type", length = 32)
    @Builder.Default
    private StorageType storageType = StorageType.LOCAL;

    /**
     * Storage path (relative path for local, key for S3)
     */
    @Column(name = "storage_path", nullable = false, length = 1024)
    private String storagePath;

    /**
     * File status
     */
    @Enumerated(EnumType.STRING)
    @Column(name = "status", length = 32)
    @Builder.Default
    private FileStatus status = FileStatus.ACTIVE;

    /**
     * File description
     */
    @Column(name = "description", length = 1024)
    private String description;

    /**
     * File checksum (SHA-256)
     */
    @Column(name = "checksum", length = 64)
    private String checksum;

    /**
     * Download count
     */
    @Column(name = "download_count")
    @Builder.Default
    private Integer downloadCount = 0;

    /**
     * Last accessed time
     */
    @Column(name = "last_accessed_at")
    private LocalDateTime lastAccessedAt;

    /**
     * Expiration time (for temporary files)
     */
    @Column(name = "expires_at")
    private LocalDateTime expiresAt;

    /**
     * Additional metadata
     */
    @JdbcTypeCode(SqlTypes.JSON)
    @Column(name = "metadata", columnDefinition = "jsonb")
    private Map<String, Object> metadata;

    @CreationTimestamp
    @Column(name = "created_at", updatable = false)
    private LocalDateTime createdAt;

    @UpdateTimestamp
    @Column(name = "updated_at")
    private LocalDateTime updatedAt;

    // ============ Enums ============

    public enum FileType {
        /** Document files (PDF, DOC, TXT) */
        DOCUMENT,
        /** Spreadsheet files (XLSX, CSV) */
        SPREADSHEET,
        /** Image files (PNG, JPG, GIF) */
        IMAGE,
        /** Data files (JSON, XML) */
        DATA,
        /** Archive files (ZIP, TAR) */
        ARCHIVE,
        /** Report files (generated reports) */
        REPORT,
        /** Other files */
        OTHER
    }

    public enum StorageType {
        /** Local file system storage */
        LOCAL,
        /** AWS S3 storage */
        S3,
        /** Google Cloud Storage */
        GCS
    }

    public enum FileStatus {
        /** File is active and accessible */
        ACTIVE,
        /** File is being uploaded */
        UPLOADING,
        /** File is being processed */
        PROCESSING,
        /** File has been archived */
        ARCHIVED,
        /** File is scheduled for deletion */
        PENDING_DELETE,
        /** File has been deleted */
        DELETED
    }

    // ============ Helper methods ============

    /**
     * Check if file is owned by session
     */
    public boolean isOwnedBySession(String sessionId) {
        return this.sessionId != null && this.sessionId.equals(sessionId);
    }

    /**
     * Check if file is owned by user
     */
    public boolean isOwnedByUser(String userId) {
        return this.userId != null && this.userId.equals(userId);
    }

    /**
     * Check if file is accessible by session or user
     */
    public boolean isAccessibleBy(String sessionId, String userId) {
        if (sessionId != null && isOwnedBySession(sessionId)) {
            return true;
        }
        if (userId != null && isOwnedByUser(userId)) {
            return true;
        }
        return false;
    }

    /**
     * Increment download count
     */
    public void incrementDownloadCount() {
        this.downloadCount = (this.downloadCount == null ? 0 : this.downloadCount) + 1;
        this.lastAccessedAt = LocalDateTime.now();
    }

    /**
     * Mark as deleted
     */
    public void markDeleted() {
        this.status = FileStatus.DELETED;
    }

    /**
     * Check if file is expired
     */
    public boolean isExpired() {
        return this.expiresAt != null && LocalDateTime.now().isAfter(this.expiresAt);
    }

    /**
     * Get human-readable file size
     */
    public String getHumanReadableSize() {
        if (fileSize == null) return "0 B";
        
        long bytes = fileSize;
        if (bytes < 1024) return bytes + " B";
        if (bytes < 1024 * 1024) return String.format("%.1f KB", bytes / 1024.0);
        if (bytes < 1024 * 1024 * 1024) return String.format("%.1f MB", bytes / (1024.0 * 1024));
        return String.format("%.1f GB", bytes / (1024.0 * 1024 * 1024));
    }

    /**
     * Determine file type from extension
     */
    public static FileType determineFileType(String extension) {
        if (extension == null) return FileType.OTHER;
        
        String ext = extension.toLowerCase();
        return switch (ext) {
            case "pdf", "doc", "docx", "txt", "rtf", "odt" -> FileType.DOCUMENT;
            case "xls", "xlsx", "csv", "ods" -> FileType.SPREADSHEET;
            case "png", "jpg", "jpeg", "gif", "bmp", "svg", "webp" -> FileType.IMAGE;
            case "json", "xml", "yaml", "yml" -> FileType.DATA;
            case "zip", "tar", "gz", "rar", "7z" -> FileType.ARCHIVE;
            default -> FileType.OTHER;
        };
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/exception/ChatExceptionHandler.java

```java
package com.newsinsight.collector.exception;

import lombok.extern.slf4j.Slf4j;
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.ExceptionHandler;
import org.springframework.web.bind.annotation.RestControllerAdvice;

import java.time.LocalDateTime;
import java.util.HashMap;
import java.util.Map;

/**
 * 채팅 서비스 전역 예외 핸들러
 */
@RestControllerAdvice(basePackages = "com.newsinsight.collector.controller")
@Slf4j
public class ChatExceptionHandler {

    @ExceptionHandler(SessionException.class)
    public ResponseEntity<Map<String, Object>> handleSessionException(SessionException ex) {
        log.error("Session error: {}", ex.getMessage(), ex);
        
        Map<String, Object> response = createErrorResponse(
                ex.getErrorCode(),
                ex.getMessage(),
                ex.getSessionId(),
                HttpStatus.BAD_REQUEST.value()
        );
        
        return ResponseEntity.status(HttpStatus.BAD_REQUEST).body(response);
    }

    @ExceptionHandler(SyncException.class)
    public ResponseEntity<Map<String, Object>> handleSyncException(SyncException ex) {
        log.error("Sync error: {}", ex.getMessage(), ex);
        
        Map<String, Object> response = createErrorResponse(
                ex.getErrorCode(),
                ex.getMessage(),
                ex.getSessionId(),
                HttpStatus.INTERNAL_SERVER_ERROR.value()
        );
        
        return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).body(response);
    }

    @ExceptionHandler(VectorEmbeddingException.class)
    public ResponseEntity<Map<String, Object>> handleVectorEmbeddingException(VectorEmbeddingException ex) {
        log.error("Vector embedding error: {}", ex.getMessage(), ex);
        
        Map<String, Object> response = createErrorResponse(
                ex.getErrorCode(),
                ex.getMessage(),
                ex.getSessionId(),
                HttpStatus.SERVICE_UNAVAILABLE.value()
        );
        
        return ResponseEntity.status(HttpStatus.SERVICE_UNAVAILABLE).body(response);
    }

    @ExceptionHandler(ChatServiceException.class)
    public ResponseEntity<Map<String, Object>> handleChatServiceException(ChatServiceException ex) {
        log.error("Chat service error: {}", ex.getMessage(), ex);
        
        Map<String, Object> response = createErrorResponse(
                ex.getErrorCode(),
                ex.getMessage(),
                ex.getSessionId(),
                HttpStatus.INTERNAL_SERVER_ERROR.value()
        );
        
        return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).body(response);
    }

    @ExceptionHandler(Exception.class)
    public ResponseEntity<Map<String, Object>> handleGenericException(Exception ex) {
        log.error("Unexpected error: {}", ex.getMessage(), ex);
        
        Map<String, Object> response = createErrorResponse(
                "INTERNAL_ERROR",
                "An unexpected error occurred",
                null,
                HttpStatus.INTERNAL_SERVER_ERROR.value()
        );
        
        return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).body(response);
    }

    private Map<String, Object> createErrorResponse(String errorCode, String message, String sessionId, int status) {
        Map<String, Object> response = new HashMap<>();
        response.put("success", false);
        response.put("error", errorCode);
        response.put("message", message);
        response.put("status", status);
        response.put("timestamp", LocalDateTime.now().toString());
        
        if (sessionId != null) {
            response.put("sessionId", sessionId);
        }
        
        return response;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/exception/ChatServiceException.java

```java
package com.newsinsight.collector.exception;

/**
 * 채팅 서비스 관련 예외 기본 클래스
 */
public class ChatServiceException extends RuntimeException {
    
    private final String errorCode;
    private final String sessionId;

    public ChatServiceException(String message) {
        super(message);
        this.errorCode = "CHAT_ERROR";
        this.sessionId = null;
    }

    public ChatServiceException(String message, Throwable cause) {
        super(message, cause);
        this.errorCode = "CHAT_ERROR";
        this.sessionId = null;
    }

    public ChatServiceException(String errorCode, String message) {
        super(message);
        this.errorCode = errorCode;
        this.sessionId = null;
    }

    public ChatServiceException(String errorCode, String message, String sessionId) {
        super(message);
        this.errorCode = errorCode;
        this.sessionId = sessionId;
    }

    public ChatServiceException(String errorCode, String message, String sessionId, Throwable cause) {
        super(message, cause);
        this.errorCode = errorCode;
        this.sessionId = sessionId;
    }

    public String getErrorCode() {
        return errorCode;
    }

    public String getSessionId() {
        return sessionId;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/exception/SessionException.java

```java
package com.newsinsight.collector.exception;

/**
 * 세션 관련 예외
 */
public class SessionException extends ChatServiceException {

    public SessionException(String message) {
        super("SESSION_ERROR", message);
    }

    public SessionException(String message, String sessionId) {
        super("SESSION_ERROR", message, sessionId);
    }

    public SessionException(String message, String sessionId, Throwable cause) {
        super("SESSION_ERROR", message, sessionId, cause);
    }

    /**
     * 세션을 찾을 수 없을 때
     */
    public static SessionException notFound(String sessionId) {
        return new SessionException("Session not found: " + sessionId, sessionId);
    }

    /**
     * 세션이 만료되었을 때
     */
    public static SessionException expired(String sessionId) {
        return new SessionException("Session has expired: " + sessionId, sessionId);
    }

    /**
     * 세션이 이미 종료되었을 때
     */
    public static SessionException alreadyClosed(String sessionId) {
        return new SessionException("Session is already closed: " + sessionId, sessionId);
    }

    /**
     * 세션 생성 실패
     */
    public static SessionException creationFailed(String sessionId, Throwable cause) {
        return new SessionException("Failed to create session: " + sessionId, sessionId, cause);
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/exception/SyncException.java

```java
package com.newsinsight.collector.exception;

/**
 * 동기화 관련 예외
 */
public class SyncException extends ChatServiceException {

    public SyncException(String message) {
        super("SYNC_ERROR", message);
    }

    public SyncException(String message, String sessionId) {
        super("SYNC_ERROR", message, sessionId);
    }

    public SyncException(String message, String sessionId, Throwable cause) {
        super("SYNC_ERROR", message, sessionId, cause);
    }

    /**
     * RDB 동기화 실패
     */
    public static SyncException rdbSyncFailed(String sessionId, Throwable cause) {
        return new SyncException("Failed to sync session to RDB: " + sessionId, sessionId, cause);
    }

    /**
     * 벡터 DB 임베딩 실패
     */
    public static SyncException embeddingFailed(String sessionId, Throwable cause) {
        return new SyncException("Failed to embed session to vector DB: " + sessionId, sessionId, cause);
    }

    /**
     * 동기화 타임아웃
     */
    public static SyncException timeout(String sessionId) {
        return new SyncException("Sync operation timed out for session: " + sessionId, sessionId);
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/exception/VectorEmbeddingException.java

```java
package com.newsinsight.collector.exception;

/**
 * 벡터 임베딩 관련 예외
 */
public class VectorEmbeddingException extends ChatServiceException {

    public VectorEmbeddingException(String message) {
        super("VECTOR_ERROR", message);
    }

    public VectorEmbeddingException(String message, Throwable cause) {
        super("VECTOR_ERROR", message, null, cause);
    }

    public VectorEmbeddingException(String message, String sessionId, Throwable cause) {
        super("VECTOR_ERROR", message, sessionId, cause);
    }

    /**
     * 벡터 DB 연결 실패
     */
    public static VectorEmbeddingException connectionFailed(Throwable cause) {
        return new VectorEmbeddingException("Failed to connect to vector DB", cause);
    }

    /**
     * 임베딩 생성 실패
     */
    public static VectorEmbeddingException embeddingGenerationFailed(String messageId, Throwable cause) {
        return new VectorEmbeddingException("Failed to generate embedding for message: " + messageId, cause);
    }

    /**
     * 벡터 저장 실패
     */
    public static VectorEmbeddingException storageFailed(String embeddingId, Throwable cause) {
        return new VectorEmbeddingException("Failed to store embedding: " + embeddingId, cause);
    }

    /**
     * 검색 실패
     */
    public static VectorEmbeddingException searchFailed(Throwable cause) {
        return new VectorEmbeddingException("Vector search failed", cause);
    }

    /**
     * 벡터 DB 비활성화
     */
    public static VectorEmbeddingException disabled() {
        return new VectorEmbeddingException("Vector DB is disabled");
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/mapper/EntityMapper.java

```java
package com.newsinsight.collector.mapper;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.core.type.TypeReference;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.newsinsight.collector.dto.*;
import com.newsinsight.collector.entity.CollectedData;
import com.newsinsight.collector.entity.CollectionJob;
import com.newsinsight.collector.entity.DataSource;
import com.newsinsight.collector.entity.SourceType;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.stereotype.Component;

import java.util.Collections;
import java.util.Map;

@Component
public class EntityMapper {

    private static final Logger log = LoggerFactory.getLogger(EntityMapper.class);
    private static final TypeReference<Map<String, Object>> MAP_TYPE = new TypeReference<>() {};

    private final ObjectMapper objectMapper;

    public EntityMapper(ObjectMapper objectMapper) {
        this.objectMapper = objectMapper;
    }

    public DataSourceDTO toDTO(DataSource source) {
        return new DataSourceDTO(
                source.getId(),
                source.getName(),
                source.getUrl(),
                source.getSourceType(),
                source.getIsActive(),
                source.getLastCollected(),
                source.getCollectionFrequency(),
                parseJson(source.getMetadataJson()),
                source.getCreatedAt(),
                source.getUpdatedAt(),
                BrowserAgentConfigDto.fromEntity(source.getBrowserAgentConfig())
        );
    }

    // Alias method for DataSource
    public DataSourceDTO toDataSourceDTO(DataSource source) {
        return toDTO(source);
    }

    public CollectionJobDTO toDTO(CollectionJob job) {
        return new CollectionJobDTO(
                job.getId(),
                job.getSourceId(),
                job.getStatus(),
                job.getStartedAt(),
                job.getCompletedAt(),
                job.getItemsCollected(),
                job.getErrorMessage(),
                job.getCreatedAt()
        );
    }

    // Alias method for CollectionJob
    public CollectionJobDTO toCollectionJobDTO(CollectionJob job) {
        return toDTO(job);
    }

    public CollectedDataDTO toDTO(CollectedData data) {
        return new CollectedDataDTO(
                data.getId(),
                data.getSourceId(),
                data.getTitle(),
                data.getContent(),
                data.getUrl(),
                data.getPublishedDate(),
                data.getCollectedAt(),
                data.getContentHash(),
                parseJson(data.getMetadataJson()),
                data.getProcessed()
        );
    }

    // Alias method for CollectedData
    public CollectedDataDTO toCollectedDataDTO(CollectedData data) {
        return toDTO(data);
    }

    public DataSource toEntity(DataSourceCreateRequest request) {
        DataSource.DataSourceBuilder builder = DataSource.builder()
                .name(request.name())
                .url(request.url())
                .sourceType(request.sourceType())
                .collectionFrequency(request.collectionFrequency())
                .metadataJson(toJson(request.metadata()))
                .isActive(true);

        // Set browser agent config if applicable
        if (request.sourceType() == SourceType.BROWSER_AGENT && request.browserAgentConfig() != null) {
            builder.browserAgentConfig(request.browserAgentConfig().toEntity());
        }

        return builder.build();
    }

    // Alias method for DataSourceCreateRequest
    public DataSource toDataSource(DataSourceCreateRequest request) {
        return toEntity(request);
    }

    public void updateEntity(DataSource source, DataSourceUpdateRequest request) {
        if (request.name() != null) {
            source.setName(request.name());
        }
        if (request.url() != null) {
            source.setUrl(request.url());
        }
        if (request.isActive() != null) {
            source.setIsActive(request.isActive());
        }
        if (request.collectionFrequency() != null) {
            source.setCollectionFrequency(request.collectionFrequency());
        }
        if (request.metadata() != null) {
            source.setMetadataJson(toJson(request.metadata()));
        }
        // Update browser agent config if provided
        if (request.browserAgentConfig() != null) {
            source.setBrowserAgentConfig(request.browserAgentConfig().toEntity());
        }
    }

    // Alias method for updating DataSource from request
    public void updateDataSourceFromRequest(DataSourceUpdateRequest request, DataSource source) {
        updateEntity(source, request);
    }

    private Map<String, Object> parseJson(String json) {
        if (json == null || json.isBlank()) {
            return Collections.emptyMap();
        }
        try {
            return objectMapper.readValue(json, MAP_TYPE);
        } catch (JsonProcessingException e) {
            log.warn("Failed to parse metadata JSON. Returning empty map. Data: {}", json, e);
            return Collections.emptyMap();
        }
    }

    private String toJson(Map<String, Object> map) {
        if (map == null || map.isEmpty()) {
            return null;
        }
        try {
            return objectMapper.writeValueAsString(map);
        } catch (JsonProcessingException e) {
            log.warn("Failed to serialize metadata map. Returning null. Data: {}", map, e);
            return null;
        }
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/mongo/AiResponseDocument.java

```java
package com.newsinsight.collector.mongo;

import org.springframework.data.annotation.Id;
import org.springframework.data.mongodb.core.index.Indexed;
import org.springframework.data.mongodb.core.mapping.Document;

import java.time.Instant;
import java.util.Map;

@Document(collection = "ai_responses")
public class AiResponseDocument {

    @Id
    private String id; // requestId

    private String status;
    private String completedAt;
    private String providerId;
    private String modelId;
    private String text;
    private Map<String, Object> raw;

    @Indexed(expireAfterSeconds = 604800) // 7 days
    private Instant createdAt;

    public AiResponseDocument() {
    }

    public AiResponseDocument(String id,
                              String status,
                              String completedAt,
                              String providerId,
                              String modelId,
                              String text,
                              Map<String, Object> raw,
                              Instant createdAt) {
        this.id = id;
        this.status = status;
        this.completedAt = completedAt;
        this.providerId = providerId;
        this.modelId = modelId;
        this.text = text;
        this.raw = raw;
        this.createdAt = createdAt;
    }

    public String getId() {
        return id;
    }

    public void setId(String id) {
        this.id = id;
    }

    public String getStatus() {
        return status;
    }

    public void setStatus(String status) {
        this.status = status;
    }

    public String getCompletedAt() {
        return completedAt;
    }

    public void setCompletedAt(String completedAt) {
        this.completedAt = completedAt;
    }

    public String getProviderId() {
        return providerId;
    }

    public void setProviderId(String providerId) {
        this.providerId = providerId;
    }

    public String getModelId() {
        return modelId;
    }

    public void setModelId(String modelId) {
        this.modelId = modelId;
    }

    public String getText() {
        return text;
    }

    public void setText(String text) {
        this.text = text;
    }

    public Map<String, Object> getRaw() {
        return raw;
    }

    public void setRaw(Map<String, Object> raw) {
        this.raw = raw;
    }

    public Instant getCreatedAt() {
        return createdAt;
    }

    public void setCreatedAt(Instant createdAt) {
        this.createdAt = createdAt;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/mongo/AiResponseRepository.java

```java
package com.newsinsight.collector.mongo;

import org.springframework.data.mongodb.repository.MongoRepository;

public interface AiResponseRepository extends MongoRepository<AiResponseDocument, String> {
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/AiJobRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.ai.AiJob;
import com.newsinsight.collector.entity.ai.AiJobStatus;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Modifying;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Optional;

@Repository
public interface AiJobRepository extends JpaRepository<AiJob, String> {

    /**
     * Find jobs by overall status
     */
    Page<AiJob> findByOverallStatus(AiJobStatus status, Pageable pageable);

    /**
     * Find jobs by topic containing the search term
     */
    Page<AiJob> findByTopicContainingIgnoreCase(String topic, Pageable pageable);

    /**
     * Find jobs by status list
     */
    List<AiJob> findByOverallStatusIn(List<AiJobStatus> statuses);

    /**
     * Find jobs by status and created before a given time (for timeout/cleanup)
     */
    @Query("SELECT j FROM AiJob j WHERE j.overallStatus IN :statuses AND j.createdAt < :before")
    List<AiJob> findByStatusInAndCreatedAtBefore(
            @Param("statuses") List<AiJobStatus> statuses,
            @Param("before") LocalDateTime before
    );

    /**
     * Find job with sub-tasks eagerly loaded
     */
    @Query("SELECT j FROM AiJob j LEFT JOIN FETCH j.subTasks WHERE j.id = :jobId")
    Optional<AiJob> findByIdWithSubTasks(@Param("jobId") String jobId);

    /**
     * Find recent jobs by topic
     */
    @Query("SELECT j FROM AiJob j WHERE LOWER(j.topic) = LOWER(:topic) ORDER BY j.createdAt DESC")
    List<AiJob> findRecentByTopic(@Param("topic") String topic, Pageable pageable);

    /**
     * Count jobs by status
     */
    long countByOverallStatus(AiJobStatus status);

    /**
     * Mark timed out jobs (PENDING or IN_PROGRESS older than cutoff)
     */
    @Modifying
    @Query("UPDATE AiJob j SET j.overallStatus = 'TIMEOUT', j.completedAt = CURRENT_TIMESTAMP " +
            "WHERE j.overallStatus IN ('PENDING', 'IN_PROGRESS') AND j.createdAt < :before")
    int markTimedOutJobs(@Param("before") LocalDateTime before);

    /**
     * Delete old completed/failed/cancelled jobs
     */
    @Modifying
    @Query("DELETE FROM AiJob j WHERE j.overallStatus IN ('COMPLETED', 'FAILED', 'PARTIAL_SUCCESS', 'TIMEOUT', 'CANCELLED') " +
            "AND j.completedAt < :before")
    int deleteOldJobs(@Param("before") LocalDateTime before);

    /**
     * Find jobs created within a time range
     */
    Page<AiJob> findByCreatedAtBetween(LocalDateTime start, LocalDateTime end, Pageable pageable);

    /**
     * Get statistics: count by status
     */
    @Query("SELECT j.overallStatus, COUNT(j) FROM AiJob j GROUP BY j.overallStatus")
    List<Object[]> getStatusCounts();

    /**
     * Find active (non-terminal) jobs
     */
    @Query("SELECT j FROM AiJob j WHERE j.overallStatus IN ('PENDING', 'IN_PROGRESS')")
    List<AiJob> findActiveJobs();
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/AiSubTaskRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.ai.AiProvider;
import com.newsinsight.collector.entity.ai.AiSubTask;
import com.newsinsight.collector.entity.ai.AiTaskStatus;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Modifying;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Optional;

@Repository
public interface AiSubTaskRepository extends JpaRepository<AiSubTask, String> {

    /**
     * Find all sub-tasks for a job
     */
    List<AiSubTask> findByAiJobId(String jobId);

    /**
     * Find sub-tasks by job ID and status
     */
    List<AiSubTask> findByAiJobIdAndStatus(String jobId, AiTaskStatus status);

    /**
     * Find sub-tasks by provider
     */
    List<AiSubTask> findByProviderId(AiProvider providerId);

    /**
     * Find sub-tasks by status
     */
    Page<AiSubTask> findByStatus(AiTaskStatus status, Pageable pageable);

    /**
     * Find sub-task by job ID and provider ID
     */
    Optional<AiSubTask> findByAiJobIdAndProviderId(String jobId, AiProvider providerId);

    /**
     * Count sub-tasks by job ID and status
     */
    long countByAiJobIdAndStatus(String jobId, AiTaskStatus status);

    /**
     * Count sub-tasks by job ID
     */
    long countByAiJobId(String jobId);

    /**
     * Get status distribution for a job
     */
    @Query("SELECT t.status, COUNT(t) FROM AiSubTask t WHERE t.aiJob.id = :jobId GROUP BY t.status")
    List<Object[]> getStatusDistributionByJobId(@Param("jobId") String jobId);

    /**
     * Find pending tasks older than cutoff (for timeout)
     */
    @Query("SELECT t FROM AiSubTask t WHERE t.status IN ('PENDING', 'IN_PROGRESS') AND t.createdAt < :before")
    List<AiSubTask> findPendingTasksOlderThan(@Param("before") LocalDateTime before);

    /**
     * Mark timed out sub-tasks
     */
    @Modifying
    @Query("UPDATE AiSubTask t SET t.status = 'TIMEOUT', t.completedAt = CURRENT_TIMESTAMP " +
            "WHERE t.status IN ('PENDING', 'IN_PROGRESS') AND t.createdAt < :before")
    int markTimedOutTasks(@Param("before") LocalDateTime before);

    /**
     * Delete sub-tasks by job IDs
     */
    @Modifying
    @Query("DELETE FROM AiSubTask t WHERE t.aiJob.id IN :jobIds")
    int deleteByJobIds(@Param("jobIds") List<String> jobIds);

    /**
     * Check if all sub-tasks for a job are in terminal state
     */
    @Query("SELECT COUNT(t) = 0 FROM AiSubTask t WHERE t.aiJob.id = :jobId AND t.status IN ('PENDING', 'IN_PROGRESS')")
    boolean areAllTasksTerminal(@Param("jobId") String jobId);

    /**
     * Check if any sub-task for a job completed successfully
     */
    @Query("SELECT COUNT(t) > 0 FROM AiSubTask t WHERE t.aiJob.id = :jobId AND t.status = 'COMPLETED'")
    boolean hasCompletedTask(@Param("jobId") String jobId);

    /**
     * Check if all sub-tasks for a job completed successfully
     */
    @Query("SELECT COUNT(t) = (SELECT COUNT(t2) FROM AiSubTask t2 WHERE t2.aiJob.id = :jobId) " +
            "FROM AiSubTask t WHERE t.aiJob.id = :jobId AND t.status = 'COMPLETED'")
    boolean areAllTasksCompleted(@Param("jobId") String jobId);
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/ArticleAnalysisRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.analysis.ArticleAnalysis;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.util.List;
import java.util.Optional;

@Repository
public interface ArticleAnalysisRepository extends JpaRepository<ArticleAnalysis, Long> {

    Optional<ArticleAnalysis> findByArticleId(Long articleId);

    List<ArticleAnalysis> findByArticleIdIn(List<Long> articleIds);

    @Query("SELECT a FROM ArticleAnalysis a WHERE a.fullyAnalyzed = false")
    List<ArticleAnalysis> findIncompleteAnalyses();

    @Query("SELECT a FROM ArticleAnalysis a WHERE a.reliabilityScore >= :minScore")
    List<ArticleAnalysis> findByReliabilityScoreGreaterThanEqual(@Param("minScore") Double minScore);

    @Query("SELECT a FROM ArticleAnalysis a WHERE a.misinfoRisk = :risk")
    List<ArticleAnalysis> findByMisinfoRisk(@Param("risk") String risk);

    @Query("SELECT a.articleId FROM ArticleAnalysis a WHERE a.articleId IN :articleIds")
    List<Long> findAnalyzedArticleIds(@Param("articleIds") List<Long> articleIds);

    boolean existsByArticleId(Long articleId);
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/ArticleDiscussionRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.analysis.ArticleDiscussion;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.stereotype.Repository;

import java.util.List;
import java.util.Optional;

@Repository
public interface ArticleDiscussionRepository extends JpaRepository<ArticleDiscussion, Long> {

    Optional<ArticleDiscussion> findByArticleId(Long articleId);

    List<ArticleDiscussion> findByArticleIdIn(List<Long> articleIds);

    boolean existsByArticleId(Long articleId);
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/BrowserJobHistoryRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.browser.BrowserJobHistory;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Modifying;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Optional;

/**
 * Repository for BrowserJobHistory entity.
 * Manages browser automation job history persistence.
 */
@Repository
public interface BrowserJobHistoryRepository extends JpaRepository<BrowserJobHistory, Long> {

    /**
     * Find by job ID
     */
    Optional<BrowserJobHistory> findByJobId(String jobId);

    /**
     * Find by user ID
     */
    Page<BrowserJobHistory> findByUserIdOrderByCreatedAtDesc(String userId, Pageable pageable);

    /**
     * Find by session ID
     */
    Page<BrowserJobHistory> findBySessionIdOrderByCreatedAtDesc(String sessionId, Pageable pageable);

    /**
     * Find by status
     */
    Page<BrowserJobHistory> findByStatus(BrowserJobHistory.BrowserJobStatus status, Pageable pageable);

    /**
     * Find by user and status
     */
    Page<BrowserJobHistory> findByUserIdAndStatus(
            String userId,
            BrowserJobHistory.BrowserJobStatus status,
            Pageable pageable
    );

    /**
     * Find active jobs (PENDING, RUNNING, WAITING_HUMAN)
     */
    @Query("""
            SELECT b FROM BrowserJobHistory b 
            WHERE b.status IN ('PENDING', 'RUNNING', 'WAITING_HUMAN')
            ORDER BY b.createdAt DESC
            """)
    List<BrowserJobHistory> findActiveJobs();

    /**
     * Find active jobs by user
     */
    @Query("""
            SELECT b FROM BrowserJobHistory b 
            WHERE b.userId = :userId 
            AND b.status IN ('PENDING', 'RUNNING', 'WAITING_HUMAN')
            ORDER BY b.createdAt DESC
            """)
    List<BrowserJobHistory> findActiveJobsByUser(@Param("userId") String userId);

    /**
     * Find by project ID
     */
    Page<BrowserJobHistory> findByProjectIdOrderByCreatedAtDesc(Long projectId, Pageable pageable);

    /**
     * Find by related search history ID
     */
    List<BrowserJobHistory> findBySearchHistoryIdOrderByCreatedAtDesc(Long searchHistoryId);

    /**
     * Update job status
     */
    @Modifying
    @Query("""
            UPDATE BrowserJobHistory b 
            SET b.status = :status, b.updatedAt = :updatedAt 
            WHERE b.jobId = :jobId
            """)
    void updateStatus(
            @Param("jobId") String jobId,
            @Param("status") BrowserJobHistory.BrowserJobStatus status,
            @Param("updatedAt") LocalDateTime updatedAt
    );

    /**
     * Count jobs by status
     */
    long countByStatus(BrowserJobHistory.BrowserJobStatus status);

    /**
     * Count jobs by user and status
     */
    long countByUserIdAndStatus(String userId, BrowserJobHistory.BrowserJobStatus status);

    /**
     * Find jobs completed within time range
     */
    Page<BrowserJobHistory> findByStatusAndCompletedAtAfter(
            BrowserJobHistory.BrowserJobStatus status,
            LocalDateTime after,
            Pageable pageable
    );

    /**
     * Delete old completed jobs (cleanup)
     */
    @Modifying
    @Query("""
            DELETE FROM BrowserJobHistory b 
            WHERE b.status IN ('COMPLETED', 'FAILED', 'CANCELLED', 'TIMEOUT') 
            AND b.completedAt < :before
            """)
    void deleteOldCompletedJobs(@Param("before") LocalDateTime before);

    /**
     * Get statistics by status
     */
    @Query("""
            SELECT b.status as status, COUNT(b) as count, AVG(b.durationMs) as avgDuration
            FROM BrowserJobHistory b
            WHERE b.createdAt > :after
            GROUP BY b.status
            """)
    List<BrowserJobStats> getStatsByStatus(@Param("after") LocalDateTime after);

    interface BrowserJobStats {
        BrowserJobHistory.BrowserJobStatus getStatus();
        Long getCount();
        Double getAvgDuration();
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/ChatHistoryRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.chat.ChatHistory;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Query;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;

/**
 * 채팅 이력 리포지토리 (PostgreSQL)
 */
@Repository
public interface ChatHistoryRepository extends JpaRepository<ChatHistory, Long> {

    /**
     * 세션 ID로 메시지 조회
     */
    List<ChatHistory> findBySessionIdOrderByCreatedAtAsc(String sessionId);

    /**
     * 사용자 ID로 메시지 조회
     */
    List<ChatHistory> findByUserIdOrderByCreatedAtDesc(String userId);

    /**
     * 메시지 ID 존재 여부 확인
     */
    boolean existsByMessageId(String messageId);

    /**
     * 특정 기간 내 메시지 조회
     */
    List<ChatHistory> findByCreatedAtBetween(LocalDateTime start, LocalDateTime end);

    /**
     * 임베딩이 필요한 메시지 조회 (assistant 메시지만)
     */
    @Query("SELECT ch FROM ChatHistory ch WHERE ch.role = 'assistant' AND ch.embeddingId IS NULL")
    List<ChatHistory> findMessagesNeedingEmbedding();
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/CollectedDataRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.CollectedData;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Optional;

@Repository
public interface CollectedDataRepository extends JpaRepository<CollectedData, Long> {

    Optional<CollectedData> findByContentHash(String contentHash);

    List<CollectedData> findBySourceIdOrderByCollectedAtDesc(Long sourceId);

    Page<CollectedData> findBySourceId(Long sourceId, Pageable pageable);

    List<CollectedData> findByProcessedFalse();

    Page<CollectedData> findByProcessedFalse(Pageable pageable);

    Page<CollectedData> findByProcessed(Boolean processed, Pageable pageable);

    long countByProcessedFalse();

    @Query("SELECT COUNT(cd) FROM CollectedData cd WHERE cd.collectedAt >= :startDate")
    long countCollectedSince(@Param("startDate") LocalDateTime startDate);

    @Query("SELECT COUNT(cd) FROM CollectedData cd WHERE cd.sourceId = :sourceId")
    long countBySourceId(@Param("sourceId") Long sourceId);

    /**
     * Full-Text Search with date filter using PostgreSQL tsvector.
     * Uses plainto_tsquery for natural language queries (handles Korean well).
     * Falls back to LIKE for very short queries (1-2 chars).
     * Results are ranked by FTS relevance, then by date.
     */
    @Query(value = """
        SELECT * FROM collected_data cd
        WHERE (
            :query IS NULL OR :query = '' OR
            CASE 
                WHEN LENGTH(:query) <= 2 THEN 
                    LOWER(cd.title) LIKE LOWER(CONCAT('%', :query, '%')) 
                    OR LOWER(cd.content) LIKE LOWER(CONCAT('%', :query, '%'))
                ELSE 
                    cd.search_vector @@ plainto_tsquery('simple', :query)
            END
        )
        AND ((cd.published_date IS NOT NULL AND cd.published_date >= :since)
          OR (cd.published_date IS NULL AND cd.collected_at >= :since))
        ORDER BY 
            CASE WHEN :query IS NOT NULL AND :query != '' AND LENGTH(:query) > 2 
                 THEN ts_rank(cd.search_vector, plainto_tsquery('simple', :query)) 
                 ELSE 0 END DESC,
            COALESCE(cd.published_date, cd.collected_at) DESC
        """,
        countQuery = """
        SELECT COUNT(*) FROM collected_data cd
        WHERE (
            :query IS NULL OR :query = '' OR
            CASE 
                WHEN LENGTH(:query) <= 2 THEN 
                    LOWER(cd.title) LIKE LOWER(CONCAT('%', :query, '%')) 
                    OR LOWER(cd.content) LIKE LOWER(CONCAT('%', :query, '%'))
                ELSE 
                    cd.search_vector @@ plainto_tsquery('simple', :query)
            END
        )
        AND ((cd.published_date IS NOT NULL AND cd.published_date >= :since)
          OR (cd.published_date IS NULL AND cd.collected_at >= :since))
        """,
        nativeQuery = true)
    Page<CollectedData> searchByQueryAndSince(@Param("query") String query,
                                              @Param("since") LocalDateTime since,
                                              Pageable pageable);

    /**
     * Full-Text Search without date filter.
     * Uses plainto_tsquery for natural language queries.
     * Falls back to LIKE for very short queries (1-2 chars).
     */
    @Query(value = """
        SELECT * FROM collected_data cd
        WHERE (
            :query IS NULL OR :query = '' OR
            CASE 
                WHEN LENGTH(:query) <= 2 THEN 
                    LOWER(cd.title) LIKE LOWER(CONCAT('%', :query, '%')) 
                    OR LOWER(cd.content) LIKE LOWER(CONCAT('%', :query, '%'))
                ELSE 
                    cd.search_vector @@ plainto_tsquery('simple', :query)
            END
        )
        ORDER BY 
            CASE WHEN :query IS NOT NULL AND :query != '' AND LENGTH(:query) > 2 
                 THEN ts_rank(cd.search_vector, plainto_tsquery('simple', :query)) 
                 ELSE 0 END DESC,
            COALESCE(cd.published_date, cd.collected_at) DESC
        """,
        countQuery = """
        SELECT COUNT(*) FROM collected_data cd
        WHERE (
            :query IS NULL OR :query = '' OR
            CASE 
                WHEN LENGTH(:query) <= 2 THEN 
                    LOWER(cd.title) LIKE LOWER(CONCAT('%', :query, '%')) 
                    OR LOWER(cd.content) LIKE LOWER(CONCAT('%', :query, '%'))
                ELSE 
                    cd.search_vector @@ plainto_tsquery('simple', :query)
            END
        )
        """,
        nativeQuery = true)
    Page<CollectedData> searchByQuery(@Param("query") String query,
                                      Pageable pageable);

    /**
     * Full-Text Search with custom date range (start and end date).
     * Uses plainto_tsquery for natural language queries (handles Korean well).
     * Falls back to LIKE for very short queries (1-2 chars).
     * Results are ranked by FTS relevance, then by date.
     * 
     * @param query Search query
     * @param since Start date (inclusive)
     * @param until End date (inclusive)
     * @param pageable Pagination info
     * @return Page of matching articles within the date range
     */
    @Query(value = """
        SELECT * FROM collected_data cd
        WHERE (
            :query IS NULL OR :query = '' OR
            CASE 
                WHEN LENGTH(:query) <= 2 THEN 
                    LOWER(cd.title) LIKE LOWER(CONCAT('%', :query, '%')) 
                    OR LOWER(cd.content) LIKE LOWER(CONCAT('%', :query, '%'))
                ELSE 
                    cd.search_vector @@ plainto_tsquery('simple', :query)
            END
        )
        AND ((cd.published_date IS NOT NULL AND cd.published_date >= :since AND cd.published_date <= :until)
          OR (cd.published_date IS NULL AND cd.collected_at >= :since AND cd.collected_at <= :until))
        ORDER BY 
            CASE WHEN :query IS NOT NULL AND :query != '' AND LENGTH(:query) > 2 
                 THEN ts_rank(cd.search_vector, plainto_tsquery('simple', :query)) 
                 ELSE 0 END DESC,
            COALESCE(cd.published_date, cd.collected_at) DESC
        """,
        countQuery = """
        SELECT COUNT(*) FROM collected_data cd
        WHERE (
            :query IS NULL OR :query = '' OR
            CASE 
                WHEN LENGTH(:query) <= 2 THEN 
                    LOWER(cd.title) LIKE LOWER(CONCAT('%', :query, '%')) 
                    OR LOWER(cd.content) LIKE LOWER(CONCAT('%', :query, '%'))
                ELSE 
                    cd.search_vector @@ plainto_tsquery('simple', :query)
            END
        )
        AND ((cd.published_date IS NOT NULL AND cd.published_date >= :since AND cd.published_date <= :until)
          OR (cd.published_date IS NULL AND cd.collected_at >= :since AND cd.collected_at <= :until))
        """,
        nativeQuery = true)
    Page<CollectedData> searchByQueryAndDateRange(@Param("query") String query,
                                                  @Param("since") LocalDateTime since,
                                                  @Param("until") LocalDateTime until,
                                                  Pageable pageable);

    boolean existsByContentHash(String contentHash);
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/CollectionJobRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.CollectionJob;
import com.newsinsight.collector.entity.CollectionJob.JobStatus;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Optional;

@Repository
public interface CollectionJobRepository extends JpaRepository<CollectionJob, Long> {

    List<CollectionJob> findBySourceIdOrderByCreatedAtDesc(Long sourceId);

    Page<CollectionJob> findBySourceId(Long sourceId, Pageable pageable);

    List<CollectionJob> findByStatus(JobStatus status);

    Page<CollectionJob> findByStatus(JobStatus status, Pageable pageable);

    Optional<CollectionJob> findFirstBySourceIdAndStatusOrderByCreatedAtDesc(
        Long sourceId, JobStatus status);

    @Query("SELECT cj FROM CollectionJob cj WHERE cj.status = :status " +
           "AND cj.startedAt < :threshold")
    List<CollectionJob> findStaleJobs(
        @Param("status") JobStatus status,
        @Param("threshold") LocalDateTime threshold);

    @Query("SELECT cj FROM CollectionJob cj WHERE cj.createdAt >= :startDate " +
           "ORDER BY cj.createdAt DESC")
    List<CollectionJob> findRecentJobs(@Param("startDate") LocalDateTime startDate);

    List<CollectionJob> findByStatusAndCompletedAtBefore(JobStatus status, LocalDateTime completedAt);

    long countByStatus(JobStatus status);
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/CrawlEvidenceRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.CrawlEvidence;
import com.newsinsight.collector.entity.EvidenceStance;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Modifying;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.util.List;

@Repository
public interface CrawlEvidenceRepository extends JpaRepository<CrawlEvidence, Long> {

    /**
     * Find all evidence for a job
     */
    List<CrawlEvidence> findByJobId(String jobId);

    /**
     * Find evidence by job ID with pagination
     */
    Page<CrawlEvidence> findByJobId(String jobId, Pageable pageable);

    /**
     * Find evidence by job ID and stance
     */
    List<CrawlEvidence> findByJobIdAndStance(String jobId, EvidenceStance stance);

    /**
     * Count evidence by job ID
     */
    long countByJobId(String jobId);

    /**
     * Count evidence by stance for a job
     */
    long countByJobIdAndStance(String jobId, EvidenceStance stance);

    /**
     * Delete all evidence for a job
     */
    @Modifying
    @Query("DELETE FROM CrawlEvidence e WHERE e.jobId = :jobId")
    int deleteByJobId(@Param("jobId") String jobId);

    /**
     * Delete evidence for multiple jobs
     */
    @Modifying
    @Query("DELETE FROM CrawlEvidence e WHERE e.jobId IN :jobIds")
    int deleteByJobIdIn(@Param("jobIds") List<String> jobIds);

    /**
     * Search evidence by snippet content
     */
    @Query("SELECT e FROM CrawlEvidence e WHERE e.jobId = :jobId AND " +
            "(LOWER(e.snippet) LIKE LOWER(CONCAT('%', :keyword, '%')) OR " +
            "LOWER(e.title) LIKE LOWER(CONCAT('%', :keyword, '%')))")
    List<CrawlEvidence> searchByKeyword(
            @Param("jobId") String jobId,
            @Param("keyword") String keyword
    );

    /**
     * Get stance distribution for a job
     */
    @Query("SELECT e.stance, COUNT(e) FROM CrawlEvidence e WHERE e.jobId = :jobId GROUP BY e.stance")
    List<Object[]> getStanceDistribution(@Param("jobId") String jobId);
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/CrawlJobRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.CrawlJob;
import com.newsinsight.collector.entity.CrawlJobStatus;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Modifying;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;

@Repository
public interface CrawlJobRepository extends JpaRepository<CrawlJob, String> {

    /**
     * Find jobs by status
     */
    Page<CrawlJob> findByStatus(CrawlJobStatus status, Pageable pageable);

    /**
     * Find jobs by topic containing the search term
     */
    Page<CrawlJob> findByTopicContainingIgnoreCase(String topic, Pageable pageable);

    /**
     * Find pending jobs older than a given time (for timeout handling)
     */
    @Query("SELECT j FROM CrawlJob j WHERE j.status IN :statuses AND j.createdAt < :before")
    List<CrawlJob> findByStatusInAndCreatedAtBefore(
            @Param("statuses") List<CrawlJobStatus> statuses,
            @Param("before") LocalDateTime before
    );

    /**
     * Find recent jobs by topic
     */
    @Query("SELECT j FROM CrawlJob j WHERE LOWER(j.topic) = LOWER(:topic) ORDER BY j.createdAt DESC")
    List<CrawlJob> findRecentByTopic(@Param("topic") String topic, Pageable pageable);

    /**
     * Count jobs by status
     */
    long countByStatus(CrawlJobStatus status);

    /**
     * Mark timed out jobs
     */
    @Modifying
    @Query("UPDATE CrawlJob j SET j.status = 'TIMEOUT', j.completedAt = CURRENT_TIMESTAMP " +
            "WHERE j.status IN ('PENDING', 'IN_PROGRESS') AND j.createdAt < :before")
    int markTimedOutJobs(@Param("before") LocalDateTime before);

    /**
     * Delete old completed/failed jobs
     */
    @Modifying
    @Query("DELETE FROM CrawlJob j WHERE j.status IN ('COMPLETED', 'FAILED', 'TIMEOUT', 'CANCELLED') " +
            "AND j.completedAt < :before")
    int deleteOldJobs(@Param("before") LocalDateTime before);

    /**
     * Find jobs created within a time range
     */
    Page<CrawlJob> findByCreatedAtBetween(LocalDateTime start, LocalDateTime end, Pageable pageable);
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/CrawlTargetRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.autocrawl.CrawlTarget;
import com.newsinsight.collector.entity.autocrawl.CrawlTargetStatus;
import com.newsinsight.collector.entity.autocrawl.DiscoverySource;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Modifying;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Optional;

/**
 * 자동 크롤링 대상 URL 저장소.
 * 검색, 기사 분석 등에서 발견된 URL의 크롤링 대기열을 관리합니다.
 */
@Repository
public interface CrawlTargetRepository extends JpaRepository<CrawlTarget, Long> {
       

    /**
     * URL 해시로 기존 대상 조회 (중복 체크용)
     */
    Optional<CrawlTarget> findByUrlHash(String urlHash);

    /**
     * URL 해시 존재 여부 (빠른 중복 체크)
     */
    boolean existsByUrlHash(String urlHash);

    /**
     * 상태별 대상 조회
     */
    List<CrawlTarget> findByStatus(CrawlTargetStatus status);

    Page<CrawlTarget> findByStatus(CrawlTargetStatus status, Pageable pageable);

    /**
     * 대기 중인 대상을 우선순위 순으로 조회 (크롤링 큐)
     * 재시도 백오프 시간이 지난 대상만 포함
     */
    @Query("SELECT ct FROM CrawlTarget ct " +
           "WHERE ct.status = :status " +
           "AND (ct.nextAttemptAfter IS NULL OR ct.nextAttemptAfter <= :now) " +
           "ORDER BY ct.priority DESC, ct.discoveredAt ASC")
    List<CrawlTarget> findPendingTargetsOrderByPriority(
            @Param("status") CrawlTargetStatus status,
            @Param("now") LocalDateTime now,
            Pageable pageable);

    /**
     * PENDING 상태의 대상 중 크롤링 가능한 대상 조회 (우선순위 순)
     */
    default List<CrawlTarget> findReadyToCrawl(int limit) {
        return findPendingTargetsOrderByPriority(
                CrawlTargetStatus.PENDING,
                LocalDateTime.now(),
                Pageable.ofSize(limit));
    }

    /**
     * 도메인별 대상 조회
     */
    List<CrawlTarget> findByDomain(String domain);

    /**
     * 발견 출처별 대상 조회
     */
    List<CrawlTarget> findByDiscoverySource(DiscoverySource source);

    Page<CrawlTarget> findByDiscoverySource(DiscoverySource source, Pageable pageable);

    /**
     * 특정 기간 내 발견된 대상 조회
     */
    List<CrawlTarget> findByDiscoveredAtAfter(LocalDateTime since);

    /**
     * 키워드 관련 대상 조회 (LIKE 검색)
     */
    @Query("SELECT ct FROM CrawlTarget ct WHERE ct.relatedKeywords LIKE %:keyword%")
    List<CrawlTarget> findByRelatedKeywordsContaining(@Param("keyword") String keyword);

    /**
     * 상태별 카운트
     */
    long countByStatus(CrawlTargetStatus status);

    /**
     * 발견 출처별 카운트
     */
    long countByDiscoverySource(DiscoverySource source);

    /**
     * 오래된 완료/실패 대상 정리
     */
    @Modifying
    @Query("DELETE FROM CrawlTarget ct WHERE ct.status IN :statuses AND ct.updatedAt < :before")
    int deleteOldTargets(@Param("statuses") List<CrawlTargetStatus> statuses, 
                         @Param("before") LocalDateTime before);

    /**
     * 오래 대기 중인 대상 정리 (7일 이상 PENDING인 경우)
     */
    @Modifying
    @Query("UPDATE CrawlTarget ct SET ct.status = 'EXPIRED' " +
           "WHERE ct.status = 'PENDING' AND ct.discoveredAt < :before")
    int expireOldPendingTargets(@Param("before") LocalDateTime before);

    /**
     * IN_PROGRESS 상태로 오래 멈춘 대상 복구 (타임아웃)
     */
    @Modifying
    @Query("UPDATE CrawlTarget ct SET ct.status = 'PENDING', ct.retryCount = ct.retryCount + 1 " +
           "WHERE ct.status = 'IN_PROGRESS' AND ct.lastAttemptAt < :timeout")
    int recoverStuckTargets(@Param("timeout") LocalDateTime timeout);

    /**
     * 도메인별 대기 중 대상 수 (도메인별 rate limiting용)
     */
    @Query("SELECT ct.domain, COUNT(ct) FROM CrawlTarget ct " +
           "WHERE ct.status = 'PENDING' GROUP BY ct.domain ORDER BY COUNT(ct) DESC")
    List<Object[]> countPendingByDomain();

    /**
     * 최근 N일간 발견된 대상 통계
     */
    @Query("SELECT ct.discoverySource, COUNT(ct) FROM CrawlTarget ct " +
           "WHERE ct.discoveredAt > :since GROUP BY ct.discoverySource")
    List<Object[]> getDiscoveryStatsSince(@Param("since") LocalDateTime since);

    /**
     * 최근 N일간 완료된 대상 통계
     */
    @Query("SELECT DATE(ct.completedAt), COUNT(ct) FROM CrawlTarget ct " +
           "WHERE ct.status = 'COMPLETED' AND ct.completedAt > :since " +
           "GROUP BY DATE(ct.completedAt) ORDER BY DATE(ct.completedAt)")
    List<Object[]> getCompletedStatsByDateSince(@Param("since") LocalDateTime since);
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/DataSourceRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.DataSource;
import com.newsinsight.collector.entity.SourceType;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Query;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Optional;

@Repository
public interface DataSourceRepository extends JpaRepository<DataSource, Long> {

    List<DataSource> findByIsActiveTrue();

    List<DataSource> findBySourceType(SourceType sourceType);

    List<DataSource> findByIsActiveTrueAndSourceType(SourceType sourceType);

    /**
     * Find active web search sources ordered by priority.
     * Lower priority number = higher priority.
     */
    @Query("SELECT ds FROM DataSource ds WHERE ds.isActive = true " +
           "AND ds.sourceType = 'WEB_SEARCH' " +
           "AND ds.searchUrlTemplate IS NOT NULL " +
           "ORDER BY ds.searchPriority ASC")
    List<DataSource> findActiveWebSearchSources();

    Optional<DataSource> findByName(String name);

    Optional<DataSource> findByUrl(String url);

    @Query("SELECT ds FROM DataSource ds WHERE ds.isActive = true " +
           "AND (ds.lastCollected IS NULL OR ds.lastCollected < :threshold)")
    List<DataSource> findDueForCollection(LocalDateTime threshold);

    long countByIsActiveTrue();
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/DraftSearchRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.search.DraftSearch;
import com.newsinsight.collector.entity.search.SearchType;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Modifying;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;

/**
 * Repository for DraftSearch entity.
 * Manages draft/unsaved search persistence.
 */
@Repository
public interface DraftSearchRepository extends JpaRepository<DraftSearch, Long> {

    /**
     * Find unexecuted drafts by user
     */
    List<DraftSearch> findByUserIdAndExecutedFalseOrderByCreatedAtDesc(String userId);

    /**
     * Find unexecuted drafts by session
     */
    List<DraftSearch> findBySessionIdAndExecutedFalseOrderByCreatedAtDesc(String sessionId);

    /**
     * Find drafts by user or session (for anonymous users)
     */
    @Query("""
            SELECT d FROM DraftSearch d 
            WHERE (d.userId = :userId OR d.sessionId = :sessionId)
            AND d.executed = false
            ORDER BY d.createdAt DESC
            """)
    List<DraftSearch> findUnexecutedDrafts(
            @Param("userId") String userId,
            @Param("sessionId") String sessionId,
            Pageable pageable
    );

    /**
     * Find drafts by search type
     */
    Page<DraftSearch> findBySearchTypeAndExecutedFalse(SearchType searchType, Pageable pageable);

    /**
     * Find drafts for a project
     */
    List<DraftSearch> findByProjectIdAndExecutedFalseOrderByCreatedAtDesc(Long projectId);

    /**
     * Mark draft as executed
     */
    @Modifying
    @Query("""
            UPDATE DraftSearch d 
            SET d.executed = true, d.executedAt = :executedAt, d.searchHistoryId = :searchHistoryId 
            WHERE d.id = :id
            """)
    void markExecuted(
            @Param("id") Long id,
            @Param("executedAt") LocalDateTime executedAt,
            @Param("searchHistoryId") Long searchHistoryId
    );

    /**
     * Delete old executed drafts (cleanup)
     */
    @Modifying
    @Query("DELETE FROM DraftSearch d WHERE d.executed = true AND d.executedAt < :before")
    void deleteOldExecutedDrafts(@Param("before") LocalDateTime before);

    /**
     * Delete old unexecuted drafts (cleanup)
     */
    @Modifying
    @Query("DELETE FROM DraftSearch d WHERE d.executed = false AND d.createdAt < :before")
    void deleteOldUnexecutedDrafts(@Param("before") LocalDateTime before);

    /**
     * Count unexecuted drafts by user
     */
    long countByUserIdAndExecutedFalse(String userId);

    /**
     * Find recent drafts with similar query
     */
    @Query("""
            SELECT d FROM DraftSearch d 
            WHERE d.userId = :userId 
            AND LOWER(d.query) LIKE LOWER(CONCAT('%', :query, '%'))
            AND d.executed = false
            ORDER BY d.createdAt DESC
            """)
    List<DraftSearch> findSimilarDrafts(
            @Param("userId") String userId,
            @Param("query") String query,
            Pageable pageable
    );
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/FactCheckChatSessionRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.chat.FactCheckChatSession;
import org.springframework.data.mongodb.repository.MongoRepository;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Optional;

/**
 * 팩트체크 챗봇 세션 리포지토리 (MongoDB)
 */
@Repository
public interface FactCheckChatSessionRepository extends MongoRepository<FactCheckChatSession, String> {

    /**
     * 세션 ID로 조회
     */
    Optional<FactCheckChatSession> findBySessionId(String sessionId);

    /**
     * 사용자 ID로 세션 목록 조회
     */
    List<FactCheckChatSession> findByUserIdOrderByStartedAtDesc(String userId);

    /**
     * 상태별 세션 조회
     */
    List<FactCheckChatSession> findByStatus(FactCheckChatSession.SessionStatus status);

    /**
     * RDB 동기화가 필요한 세션 조회
     */
    List<FactCheckChatSession> findBySyncedToRdbFalseAndStatusIn(List<FactCheckChatSession.SessionStatus> statuses);

    /**
     * 벡터 DB 임베딩이 필요한 세션 조회
     */
    List<FactCheckChatSession> findByEmbeddedToVectorDbFalseAndStatusIn(List<FactCheckChatSession.SessionStatus> statuses);

    /**
     * 특정 시간 이후 활동이 없는 세션 조회 (만료 처리용)
     */
    List<FactCheckChatSession> findByStatusAndLastActivityAtBefore(
            FactCheckChatSession.SessionStatus status, 
            LocalDateTime dateTime
    );

    /**
     * 세션 ID 존재 여부 확인
     */
    boolean existsBySessionId(String sessionId);
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/GeneratedReportRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.report.GeneratedReport;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Modifying;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Optional;

/**
 * Repository for GeneratedReport entity.
 * Manages report persistence and retrieval.
 */
@Repository
public interface GeneratedReportRepository extends JpaRepository<GeneratedReport, Long> {

    /**
     * Find by search history ID
     */
    List<GeneratedReport> findBySearchHistoryIdOrderByCreatedAtDesc(Long searchHistoryId);

    /**
     * Find by user ID
     */
    Page<GeneratedReport> findByUserIdOrderByCreatedAtDesc(String userId, Pageable pageable);

    /**
     * Find by project ID
     */
    Page<GeneratedReport> findByProjectIdOrderByCreatedAtDesc(Long projectId, Pageable pageable);

    /**
     * Find by report type
     */
    Page<GeneratedReport> findByReportType(GeneratedReport.ReportType reportType, Pageable pageable);

    /**
     * Find by status
     */
    Page<GeneratedReport> findByStatus(GeneratedReport.ReportStatus status, Pageable pageable);

    /**
     * Find public reports
     */
    Page<GeneratedReport> findByIsPublicTrue(Pageable pageable);

    /**
     * Find by public URL
     */
    Optional<GeneratedReport> findByPublicUrl(String publicUrl);

    /**
     * Find pending reports
     */
    @Query("SELECT r FROM GeneratedReport r WHERE r.status IN ('PENDING', 'GENERATING') ORDER BY r.createdAt")
    List<GeneratedReport> findPendingReports();

    /**
     * Find expired public reports
     */
    @Query("""
            SELECT r FROM GeneratedReport r 
            WHERE r.isPublic = true 
            AND r.shareExpiresAt < :now
            """)
    List<GeneratedReport> findExpiredPublicReports(@Param("now") LocalDateTime now);

    /**
     * Update download count
     */
    @Modifying
    @Query("""
            UPDATE GeneratedReport r 
            SET r.downloadCount = r.downloadCount + 1, r.lastDownloadedAt = :downloadedAt 
            WHERE r.id = :id
            """)
    void incrementDownloadCount(@Param("id") Long id, @Param("downloadedAt") LocalDateTime downloadedAt);

    /**
     * Update status
     */
    @Modifying
    @Query("UPDATE GeneratedReport r SET r.status = :status WHERE r.id = :id")
    void updateStatus(@Param("id") Long id, @Param("status") GeneratedReport.ReportStatus status);

    /**
     * Mark as public
     */
    @Modifying
    @Query("""
            UPDATE GeneratedReport r 
            SET r.isPublic = true, r.publicUrl = :publicUrl, r.shareExpiresAt = :expiresAt 
            WHERE r.id = :id
            """)
    void makePublic(
            @Param("id") Long id,
            @Param("publicUrl") String publicUrl,
            @Param("expiresAt") LocalDateTime expiresAt
    );

    /**
     * Revoke public access
     */
    @Modifying
    @Query("UPDATE GeneratedReport r SET r.isPublic = false, r.publicUrl = null, r.shareExpiresAt = null WHERE r.id = :id")
    void revokePublicAccess(@Param("id") Long id);

    /**
     * Count by user
     */
    long countByUserId(String userId);

    /**
     * Count by project
     */
    long countByProjectId(Long projectId);

    /**
     * Delete old reports
     */
    @Modifying
    @Query("DELETE FROM GeneratedReport r WHERE r.createdAt < :before AND r.status IN ('COMPLETED', 'FAILED', 'EXPIRED')")
    void deleteOldReports(@Param("before") LocalDateTime before);

    /**
     * Get report statistics
     */
    @Query("""
            SELECT r.reportType as reportType, COUNT(r) as count, SUM(r.downloadCount) as totalDownloads
            FROM GeneratedReport r
            WHERE r.createdAt > :after
            GROUP BY r.reportType
            """)
    List<ReportStats> getStatsByType(@Param("after") LocalDateTime after);

    interface ReportStats {
        GeneratedReport.ReportType getReportType();
        Long getCount();
        Long getTotalDownloads();
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/LlmProviderSettingsRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.settings.LlmProviderSettings;
import com.newsinsight.collector.entity.settings.LlmProviderType;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Modifying;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Optional;

@Repository
public interface LlmProviderSettingsRepository extends JpaRepository<LlmProviderSettings, Long> {

    // === 전역(관리자) 설정 조회 ===

    /**
     * 전역 설정 전체 조회 (userId가 null인 것들)
     */
    @Query("SELECT s FROM LlmProviderSettings s WHERE s.userId IS NULL ORDER BY s.priority ASC")
    List<LlmProviderSettings> findAllGlobalSettings();

    /**
     * 활성화된 전역 설정만 조회
     */
    @Query("SELECT s FROM LlmProviderSettings s WHERE s.userId IS NULL AND s.enabled = true ORDER BY s.priority ASC")
    List<LlmProviderSettings> findEnabledGlobalSettings();

    /**
     * 특정 Provider의 전역 설정 조회
     */
    @Query("SELECT s FROM LlmProviderSettings s WHERE s.providerType = :providerType AND s.userId IS NULL")
    Optional<LlmProviderSettings> findGlobalByProviderType(@Param("providerType") LlmProviderType providerType);

    // === 사용자별 설정 조회 ===

    /**
     * 특정 사용자의 모든 설정 조회
     */
    List<LlmProviderSettings> findByUserIdOrderByPriorityAsc(String userId);

    /**
     * 특정 사용자의 활성화된 설정만 조회
     */
    List<LlmProviderSettings> findByUserIdAndEnabledTrueOrderByPriorityAsc(String userId);

    /**
     * 특정 사용자의 특정 Provider 설정 조회
     */
    Optional<LlmProviderSettings> findByProviderTypeAndUserId(LlmProviderType providerType, String userId);

    // === 유효(effective) 설정 조회 (사용자 설정 우선, 없으면 전역) ===

    /**
     * 특정 Provider의 유효 설정 조회 (사용자 > 전역 우선순위)
     */
    @Query("SELECT s FROM LlmProviderSettings s " +
           "WHERE s.providerType = :providerType " +
           "AND (s.userId = :userId OR s.userId IS NULL) " +
           "ORDER BY CASE WHEN s.userId IS NOT NULL THEN 0 ELSE 1 END, s.priority ASC")
    List<LlmProviderSettings> findEffectiveSettings(
            @Param("providerType") LlmProviderType providerType,
            @Param("userId") String userId
    );

    /**
     * 사용자에게 유효한 모든 활성화된 설정 조회
     * 사용자 설정이 있으면 그것을, 없으면 전역 설정 반환
     */
    @Query(value = """
        SELECT DISTINCT ON (provider_type) * FROM llm_provider_settings 
        WHERE (user_id = :userId OR user_id IS NULL) 
        AND enabled = true 
        ORDER BY provider_type, 
                 CASE WHEN user_id IS NOT NULL THEN 0 ELSE 1 END, 
                 priority ASC
        """, nativeQuery = true)
    List<LlmProviderSettings> findAllEffectiveSettingsForUser(@Param("userId") String userId);

    // === 업데이트 쿼리 ===

    @Modifying
    @Query("UPDATE LlmProviderSettings s SET s.enabled = :enabled WHERE s.id = :id")
    void updateEnabled(@Param("id") Long id, @Param("enabled") Boolean enabled);

    @Modifying
    @Query("UPDATE LlmProviderSettings s SET s.lastTestedAt = :testedAt, s.lastTestSuccess = :success WHERE s.id = :id")
    void updateTestResult(@Param("id") Long id, @Param("testedAt") LocalDateTime testedAt, @Param("success") Boolean success);

    // === 존재 여부 확인 ===

    boolean existsByProviderTypeAndUserId(LlmProviderType providerType, String userId);

    @Query("SELECT CASE WHEN COUNT(s) > 0 THEN true ELSE false END FROM LlmProviderSettings s " +
           "WHERE s.providerType = :providerType AND s.userId IS NULL")
    boolean existsGlobalByProviderType(@Param("providerType") LlmProviderType providerType);

    // === 삭제 ===

    void deleteByProviderTypeAndUserId(LlmProviderType providerType, String userId);

    @Modifying
    @Query("DELETE FROM LlmProviderSettings s WHERE s.providerType = :providerType AND s.userId IS NULL")
    void deleteGlobalByProviderType(@Param("providerType") LlmProviderType providerType);

    /**
     * 특정 사용자의 모든 설정 삭제
     */
    void deleteByUserId(String userId);
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/MlAddonExecutionRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.addon.ExecutionStatus;
import com.newsinsight.collector.entity.addon.MlAddonExecution;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.data.jpa.repository.EntityGraph;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Modifying;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Optional;

@Repository
public interface MlAddonExecutionRepository extends JpaRepository<MlAddonExecution, Long> {

    Optional<MlAddonExecution> findByRequestId(String requestId);

    @EntityGraph(attributePaths = {"addon"})
    List<MlAddonExecution> findByArticleId(Long articleId);

    List<MlAddonExecution> findByBatchId(String batchId);

    List<MlAddonExecution> findByStatus(ExecutionStatus status);

    @EntityGraph(attributePaths = {"addon"})
    Page<MlAddonExecution> findByStatus(ExecutionStatus status, Pageable pageable);

    @EntityGraph(attributePaths = {"addon"})
    Page<MlAddonExecution> findByAddonId(Long addonId, Pageable pageable);

    @EntityGraph(attributePaths = {"addon"})
    @Override
    Page<MlAddonExecution> findAll(Pageable pageable);

    @Query("SELECT e FROM MlAddonExecution e WHERE e.articleId = :articleId AND e.addon.addonKey = :addonKey")
    Optional<MlAddonExecution> findByArticleIdAndAddonKey(@Param("articleId") Long articleId, @Param("addonKey") String addonKey);

    @Query("SELECT e FROM MlAddonExecution e WHERE e.status = 'PENDING' AND e.createdAt < :cutoff")
    List<MlAddonExecution> findStaleExecutions(@Param("cutoff") LocalDateTime cutoff);

    @Modifying
    @Query("UPDATE MlAddonExecution e SET e.status = 'TIMEOUT' WHERE e.status IN ('PENDING', 'RUNNING') AND e.createdAt < :cutoff")
    int markTimedOutExecutions(@Param("cutoff") LocalDateTime cutoff);

    @Query("SELECT COUNT(e) FROM MlAddonExecution e WHERE e.addon.id = :addonId AND e.status = :status AND e.createdAt > :since")
    long countByAddonAndStatusSince(@Param("addonId") Long addonId, @Param("status") ExecutionStatus status, @Param("since") LocalDateTime since);

    @Query("SELECT AVG(e.latencyMs) FROM MlAddonExecution e WHERE e.addon.id = :addonId AND e.status = 'SUCCESS' AND e.createdAt > :since")
    Double getAverageLatency(@Param("addonId") Long addonId, @Param("since") LocalDateTime since);

    @Modifying
    @Query("DELETE FROM MlAddonExecution e WHERE e.createdAt < :cutoff")
    int deleteOldExecutions(@Param("cutoff") LocalDateTime cutoff);

    /**
     * 특정 시간 이후의 모든 실행 기록 조회 (오늘의 통계 계산용)
     */
    List<MlAddonExecution> findByCreatedAtAfter(LocalDateTime since);
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/MlAddonRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.addon.AddonCategory;
import com.newsinsight.collector.entity.addon.AddonHealthStatus;
import com.newsinsight.collector.entity.addon.MlAddon;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Modifying;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Optional;

@Repository
public interface MlAddonRepository extends JpaRepository<MlAddon, Long> {

    Optional<MlAddon> findByAddonKey(String addonKey);

    List<MlAddon> findByEnabledTrue();

    List<MlAddon> findByCategory(AddonCategory category);

    List<MlAddon> findByCategoryAndEnabledTrue(AddonCategory category);

    List<MlAddon> findByEnabledTrueOrderByPriorityAsc();

    @Query("SELECT a FROM MlAddon a WHERE a.enabled = true AND a.category IN :categories ORDER BY a.priority ASC")
    List<MlAddon> findEnabledByCategories(@Param("categories") List<AddonCategory> categories);

    @Query("SELECT a FROM MlAddon a WHERE a.enabled = true AND a.healthStatus = :status")
    List<MlAddon> findEnabledByHealthStatus(@Param("status") AddonHealthStatus status);

    @Modifying
    @Query("UPDATE MlAddon a SET a.healthStatus = :status, a.lastHealthCheck = :checkTime WHERE a.id = :id")
    void updateHealthStatus(@Param("id") Long id, @Param("status") AddonHealthStatus status, @Param("checkTime") LocalDateTime checkTime);

    @Modifying
    @Query("UPDATE MlAddon a SET a.enabled = false WHERE a.id = :id")
    void disableAddon(@Param("id") Long id);

    @Query("SELECT a FROM MlAddon a WHERE a.healthCheckUrl IS NOT NULL AND " +
           "(a.lastHealthCheck IS NULL OR a.lastHealthCheck < :cutoff)")
    List<MlAddon> findAddonsNeedingHealthCheck(@Param("cutoff") LocalDateTime cutoff);

    boolean existsByAddonKey(String addonKey);
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/ProjectActivityLogRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.project.ProjectActivityLog;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Modifying;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;

/**
 * Repository for ProjectActivityLog entity.
 */
@Repository
public interface ProjectActivityLogRepository extends JpaRepository<ProjectActivityLog, Long> {

    /**
     * Find by project ID
     */
    Page<ProjectActivityLog> findByProjectIdOrderByCreatedAtDesc(Long projectId, Pageable pageable);

    /**
     * Find by project ID and activity type
     */
    Page<ProjectActivityLog> findByProjectIdAndActivityType(
            Long projectId,
            ProjectActivityLog.ActivityType activityType,
            Pageable pageable
    );

    /**
     * Find by user ID
     */
    Page<ProjectActivityLog> findByUserIdOrderByCreatedAtDesc(String userId, Pageable pageable);

    /**
     * Find by project and user
     */
    Page<ProjectActivityLog> findByProjectIdAndUserId(Long projectId, String userId, Pageable pageable);

    /**
     * Find recent activities for project
     */
    List<ProjectActivityLog> findTop20ByProjectIdOrderByCreatedAtDesc(Long projectId);

    /**
     * Find activities within date range
     */
    Page<ProjectActivityLog> findByProjectIdAndCreatedAtBetween(
            Long projectId,
            LocalDateTime from,
            LocalDateTime to,
            Pageable pageable
    );

    /**
     * Find by entity
     */
    List<ProjectActivityLog> findByEntityTypeAndEntityIdOrderByCreatedAtDesc(String entityType, String entityId);

    /**
     * Get activity count by type
     */
    @Query("""
            SELECT a.activityType as activityType, COUNT(a) as count
            FROM ProjectActivityLog a
            WHERE a.projectId = :projectId
            AND a.createdAt > :after
            GROUP BY a.activityType
            """)
    List<ActivityTypeCount> getActivityCountByType(@Param("projectId") Long projectId, @Param("after") LocalDateTime after);

    /**
     * Get activity count by user
     */
    @Query("""
            SELECT a.userId as userId, COUNT(a) as count
            FROM ProjectActivityLog a
            WHERE a.projectId = :projectId
            AND a.createdAt > :after
            GROUP BY a.userId
            """)
    List<UserActivityCount> getActivityCountByUser(@Param("projectId") Long projectId, @Param("after") LocalDateTime after);

    /**
     * Delete old activities
     */
    @Modifying
    @Query("DELETE FROM ProjectActivityLog a WHERE a.createdAt < :before")
    void deleteOldActivities(@Param("before") LocalDateTime before);

    /**
     * Delete by project
     */
    void deleteByProjectId(Long projectId);

    interface ActivityTypeCount {
        ProjectActivityLog.ActivityType getActivityType();
        Long getCount();
    }

    interface UserActivityCount {
        String getUserId();
        Long getCount();
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/ProjectItemRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.project.ProjectItem;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Modifying;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;

/**
 * Repository for ProjectItem entity.
 */
@Repository
public interface ProjectItemRepository extends JpaRepository<ProjectItem, Long> {

    /**
     * Find by project ID
     */
    Page<ProjectItem> findByProjectIdOrderByAddedAtDesc(Long projectId, Pageable pageable);

    /**
     * Find by project ID and type
     */
    Page<ProjectItem> findByProjectIdAndItemType(Long projectId, ProjectItem.ItemType itemType, Pageable pageable);

    /**
     * Find bookmarked items
     */
    Page<ProjectItem> findByProjectIdAndBookmarkedTrue(Long projectId, Pageable pageable);

    /**
     * Find unread items
     */
    Page<ProjectItem> findByProjectIdAndIsReadFalse(Long projectId, Pageable pageable);

    /**
     * Find by importance
     */
    Page<ProjectItem> findByProjectIdAndImportanceGreaterThanEqual(Long projectId, Integer minImportance, Pageable pageable);

    /**
     * Find by category
     */
    Page<ProjectItem> findByProjectIdAndCategory(Long projectId, String category, Pageable pageable);

    /**
     * Find by source ID
     */
    List<ProjectItem> findBySourceIdAndSourceType(String sourceId, String sourceType);

    /**
     * Find by URL
     */
    List<ProjectItem> findByProjectIdAndUrl(Long projectId, String url);

    /**
     * Search by title
     */
    @Query("""
            SELECT i FROM ProjectItem i 
            WHERE i.projectId = :projectId 
            AND LOWER(i.title) LIKE LOWER(CONCAT('%', :query, '%'))
            ORDER BY i.addedAt DESC
            """)
    Page<ProjectItem> searchByTitle(@Param("projectId") Long projectId, @Param("query") String query, Pageable pageable);

    /**
     * Search by content
     */
    @Query("""
            SELECT i FROM ProjectItem i 
            WHERE i.projectId = :projectId 
            AND (LOWER(i.title) LIKE LOWER(CONCAT('%', :query, '%')) 
                 OR LOWER(i.summary) LIKE LOWER(CONCAT('%', :query, '%')))
            ORDER BY i.addedAt DESC
            """)
    Page<ProjectItem> searchByContent(@Param("projectId") Long projectId, @Param("query") String query, Pageable pageable);

    /**
     * Find by tag
     */
    @Query(value = """
            SELECT * FROM project_items 
            WHERE project_id = :projectId 
            AND tags @> :tag::jsonb
            ORDER BY added_at DESC
            """, nativeQuery = true)
    Page<ProjectItem> findByTag(@Param("projectId") Long projectId, @Param("tag") String tagJson, Pageable pageable);

    /**
     * Find items within date range
     */
    Page<ProjectItem> findByProjectIdAndPublishedAtBetween(
            Long projectId,
            LocalDateTime from,
            LocalDateTime to,
            Pageable pageable
    );

    /**
     * Find recent items added
     */
    Page<ProjectItem> findByProjectIdAndAddedAtAfter(Long projectId, LocalDateTime after, Pageable pageable);

    /**
     * Mark as read
     */
    @Modifying
    @Query("UPDATE ProjectItem i SET i.isRead = true WHERE i.id = :id")
    void markAsRead(@Param("id") Long id);

    /**
     * Mark all as read for project
     */
    @Modifying
    @Query("UPDATE ProjectItem i SET i.isRead = true WHERE i.projectId = :projectId")
    void markAllAsRead(@Param("projectId") Long projectId);

    /**
     * Toggle bookmark
     */
    @Modifying
    @Query("UPDATE ProjectItem i SET i.bookmarked = NOT i.bookmarked WHERE i.id = :id")
    void toggleBookmark(@Param("id") Long id);

    /**
     * Update importance
     */
    @Modifying
    @Query("UPDATE ProjectItem i SET i.importance = :importance WHERE i.id = :id")
    void updateImportance(@Param("id") Long id, @Param("importance") Integer importance);

    /**
     * Count by project
     */
    long countByProjectId(Long projectId);

    /**
     * Count by project and type
     */
    long countByProjectIdAndItemType(Long projectId, ProjectItem.ItemType itemType);

    /**
     * Count unread by project
     */
    long countByProjectIdAndIsReadFalse(Long projectId);

    /**
     * Get distinct categories for project
     */
    @Query("SELECT DISTINCT i.category FROM ProjectItem i WHERE i.projectId = :projectId AND i.category IS NOT NULL")
    List<String> findDistinctCategories(@Param("projectId") Long projectId);

    /**
     * Get item count by date
     */
    @Query("""
            SELECT CAST(i.addedAt AS date) as date, COUNT(i) as count
            FROM ProjectItem i
            WHERE i.projectId = :projectId
            AND i.addedAt > :after
            GROUP BY CAST(i.addedAt AS date)
            ORDER BY date DESC
            """)
    List<ItemCountByDate> getItemCountByDate(@Param("projectId") Long projectId, @Param("after") LocalDateTime after);

    /**
     * Delete by project
     */
    void deleteByProjectId(Long projectId);

    interface ItemCountByDate {
        java.sql.Date getDate();
        Long getCount();
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/ProjectMemberRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.project.ProjectMember;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Modifying;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Optional;

/**
 * Repository for ProjectMember entity.
 */
@Repository
public interface ProjectMemberRepository extends JpaRepository<ProjectMember, Long> {

    /**
     * Find by project ID
     */
    List<ProjectMember> findByProjectIdOrderByJoinedAtDesc(Long projectId);

    /**
     * Find by project ID and status
     */
    List<ProjectMember> findByProjectIdAndStatus(Long projectId, ProjectMember.MemberStatus status);

    /**
     * Find by user ID
     */
    List<ProjectMember> findByUserIdOrderByJoinedAtDesc(String userId);

    /**
     * Find by user ID and status
     */
    List<ProjectMember> findByUserIdAndStatus(String userId, ProjectMember.MemberStatus status);

    /**
     * Find specific membership
     */
    Optional<ProjectMember> findByProjectIdAndUserId(Long projectId, String userId);

    /**
     * Find by invite token
     */
    Optional<ProjectMember> findByInviteToken(String inviteToken);

    /**
     * Find pending invitations for user
     */
    List<ProjectMember> findByUserIdAndStatusOrderByJoinedAtDesc(String userId, ProjectMember.MemberStatus status);

    /**
     * Find expired invitations
     */
    @Query("""
            SELECT m FROM ProjectMember m 
            WHERE m.status = 'PENDING' 
            AND m.inviteExpiresAt < :now
            """)
    List<ProjectMember> findExpiredInvitations(@Param("now") LocalDateTime now);

    /**
     * Find members by role
     */
    List<ProjectMember> findByProjectIdAndRole(Long projectId, ProjectMember.MemberRole role);

    /**
     * Find projects where user is a member
     */
    @Query("""
            SELECT m.projectId FROM ProjectMember m 
            WHERE m.userId = :userId 
            AND m.status = 'ACTIVE'
            """)
    List<Long> findProjectIdsByUser(@Param("userId") String userId);

    /**
     * Check if user is member of project
     */
    boolean existsByProjectIdAndUserIdAndStatus(Long projectId, String userId, ProjectMember.MemberStatus status);

    /**
     * Update role
     */
    @Modifying
    @Query("UPDATE ProjectMember m SET m.role = :role WHERE m.id = :id")
    void updateRole(@Param("id") Long id, @Param("role") ProjectMember.MemberRole role);

    /**
     * Update status
     */
    @Modifying
    @Query("UPDATE ProjectMember m SET m.status = :status WHERE m.id = :id")
    void updateStatus(@Param("id") Long id, @Param("status") ProjectMember.MemberStatus status);

    /**
     * Update last active
     */
    @Modifying
    @Query("UPDATE ProjectMember m SET m.lastActiveAt = :activeAt WHERE m.projectId = :projectId AND m.userId = :userId")
    void updateLastActive(
            @Param("projectId") Long projectId,
            @Param("userId") String userId,
            @Param("activeAt") LocalDateTime activeAt
    );

    /**
     * Count members by project
     */
    long countByProjectIdAndStatus(Long projectId, ProjectMember.MemberStatus status);

    /**
     * Delete by project
     */
    void deleteByProjectId(Long projectId);

    /**
     * Delete expired invitations
     */
    @Modifying
    @Query("DELETE FROM ProjectMember m WHERE m.status = 'PENDING' AND m.inviteExpiresAt < :now")
    void deleteExpiredInvitations(@Param("now") LocalDateTime now);
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/ProjectNotificationRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.project.ProjectNotification;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Modifying;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;

/**
 * Repository for ProjectNotification entity.
 */
@Repository
public interface ProjectNotificationRepository extends JpaRepository<ProjectNotification, Long> {

    /**
     * Find by user ID ordered by created at desc
     */
    Page<ProjectNotification> findByUserIdOrderByCreatedAtDesc(String userId, Pageable pageable);

    /**
     * Find unread notifications by user ID
     */
    List<ProjectNotification> findByUserIdAndIsReadFalseOrderByCreatedAtDesc(String userId);

    /**
     * Mark notification as read
     */
    @Modifying
    @Query("UPDATE ProjectNotification n SET n.isRead = true WHERE n.id = :id")
    void markAsRead(@Param("id") Long id);

    /**
     * Mark all notifications as read for a user
     */
    @Modifying
    @Query("UPDATE ProjectNotification n SET n.isRead = true WHERE n.userId = :userId AND n.isRead = false")
    void markAllAsRead(@Param("userId") String userId);

    /**
     * Find by project ID
     */
    Page<ProjectNotification> findByProjectIdOrderByCreatedAtDesc(Long projectId, Pageable pageable);

    /**
     * Find by notification type
     */
    Page<ProjectNotification> findByProjectIdAndNotificationType(
            Long projectId,
            ProjectNotification.NotificationType notificationType,
            Pageable pageable
    );

    /**
     * Find by priority
     */
    Page<ProjectNotification> findByProjectIdAndPriority(
            Long projectId,
            ProjectNotification.NotificationPriority priority,
            Pageable pageable
    );

    /**
     * Find unread notifications for user
     */
    @Query(value = """
            SELECT * FROM project_notifications 
            WHERE project_id = :projectId 
            AND recipients @> :userIdJson::jsonb
            AND (read_by IS NULL OR NOT read_by @> :userIdJson::jsonb)
            AND (expires_at IS NULL OR expires_at > :now)
            ORDER BY created_at DESC
            """, nativeQuery = true)
    List<ProjectNotification> findUnreadForUser(
            @Param("projectId") Long projectId,
            @Param("userIdJson") String userIdJson,
            @Param("now") LocalDateTime now
    );

    /**
     * Find notifications for user across all projects
     */
    @Query(value = """
            SELECT * FROM project_notifications 
            WHERE recipients @> :userIdJson::jsonb
            AND (expires_at IS NULL OR expires_at > :now)
            ORDER BY created_at DESC
            LIMIT :limit
            """, nativeQuery = true)
    List<ProjectNotification> findForUser(
            @Param("userIdJson") String userIdJson,
            @Param("now") LocalDateTime now,
            @Param("limit") int limit
    );

    /**
     * Find unsent notifications
     */
    @Query("SELECT n FROM ProjectNotification n WHERE n.sentAt IS NULL AND n.dismissed = false ORDER BY n.createdAt")
    List<ProjectNotification> findUnsent(Pageable pageable);

    /**
     * Find expired notifications
     */
    @Query("SELECT n FROM ProjectNotification n WHERE n.expiresAt < :now")
    List<ProjectNotification> findExpired(@Param("now") LocalDateTime now);

    /**
     * Mark as sent
     */
    @Modifying
    @Query("UPDATE ProjectNotification n SET n.sentAt = :sentAt WHERE n.id = :id")
    void markAsSent(@Param("id") Long id, @Param("sentAt") LocalDateTime sentAt);

    /**
     * Dismiss notification
     */
    @Modifying
    @Query("UPDATE ProjectNotification n SET n.dismissed = true WHERE n.id = :id")
    void dismiss(@Param("id") Long id);

    /**
     * Count unread for user in project
     */
    @Query(value = """
            SELECT COUNT(*) FROM project_notifications 
            WHERE project_id = :projectId 
            AND recipients @> :userIdJson::jsonb
            AND (read_by IS NULL OR NOT read_by @> :userIdJson::jsonb)
            AND (expires_at IS NULL OR expires_at > :now)
            """, nativeQuery = true)
    long countUnreadForUser(
            @Param("projectId") Long projectId,
            @Param("userIdJson") String userIdJson,
            @Param("now") LocalDateTime now
    );

    /**
     * Delete old notifications
     */
    @Modifying
    @Query("DELETE FROM ProjectNotification n WHERE n.createdAt < :before")
    void deleteOldNotifications(@Param("before") LocalDateTime before);

    /**
     * Delete expired notifications
     */
    @Modifying
    @Query("DELETE FROM ProjectNotification n WHERE n.expiresAt < :now")
    void deleteExpiredNotifications(@Param("now") LocalDateTime now);

    /**
     * Delete by project
     */
    void deleteByProjectId(Long projectId);
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/ProjectRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.project.Project;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Modifying;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Optional;

/**
 * Repository for Project entity.
 */
@Repository
public interface ProjectRepository extends JpaRepository<Project, Long> {

    /**
     * Find by owner ID
     */
    Page<Project> findByOwnerIdOrderByLastActivityAtDesc(String ownerId, Pageable pageable);

    /**
     * Find by owner ID and status
     */
    Page<Project> findByOwnerIdAndStatus(String ownerId, Project.ProjectStatus status, Pageable pageable);

    /**
     * Find by owner ID and category
     */
    Page<Project> findByOwnerIdAndCategory(String ownerId, Project.ProjectCategory category, Pageable pageable);

    /**
     * Find default project for user
     */
    Optional<Project> findByOwnerIdAndIsDefaultTrue(String ownerId);

    /**
     * Find active projects with auto-collect enabled
     */
    @Query(value = "SELECT * FROM projects p WHERE p.status = 'ACTIVE' AND p.settings IS NOT NULL AND p.settings->>'autoCollect' = 'true'", nativeQuery = true)
    List<Project> findAutoCollectEnabledProjects();

    /**
     * Find projects needing collection (based on interval)
     */
    @Query(value = """
            SELECT * FROM projects p 
            WHERE p.status = 'ACTIVE' 
            AND p.settings->>'autoCollect' = 'true'
            AND (
                p.last_collected_at IS NULL 
                OR (
                    (p.settings->>'collectInterval' = 'hourly' AND p.last_collected_at < :hourAgo)
                    OR (p.settings->>'collectInterval' = 'daily' AND p.last_collected_at < :dayAgo)
                    OR (p.settings->>'collectInterval' = 'weekly' AND p.last_collected_at < :weekAgo)
                )
            )
            """, nativeQuery = true)
    List<Project> findProjectsNeedingCollection(
            @Param("hourAgo") LocalDateTime hourAgo,
            @Param("dayAgo") LocalDateTime dayAgo,
            @Param("weekAgo") LocalDateTime weekAgo
    );

    /**
     * Find public projects
     */
    Page<Project> findByVisibility(Project.ProjectVisibility visibility, Pageable pageable);

    /**
     * Search projects by name
     */
    @Query("SELECT p FROM Project p WHERE LOWER(p.name) LIKE LOWER(CONCAT('%', :name, '%'))")
    Page<Project> searchByName(@Param("name") String name, Pageable pageable);

    /**
     * Search projects by keyword
     */
    @Query(value = """
            SELECT * FROM projects p 
            WHERE p.keywords @> :keyword::jsonb
            """, nativeQuery = true)
    List<Project> findByKeyword(@Param("keyword") String keywordJson);

    /**
     * Update last activity
     */
    @Modifying
    @Query("UPDATE Project p SET p.lastActivityAt = :activityAt WHERE p.id = :id")
    void updateLastActivity(@Param("id") Long id, @Param("activityAt") LocalDateTime activityAt);

    /**
     * Update last collected
     */
    @Modifying
    @Query("UPDATE Project p SET p.lastCollectedAt = :collectedAt WHERE p.id = :id")
    void updateLastCollected(@Param("id") Long id, @Param("collectedAt") LocalDateTime collectedAt);

    /**
     * Update status
     */
    @Modifying
    @Query("UPDATE Project p SET p.status = :status, p.updatedAt = :updatedAt WHERE p.id = :id")
    void updateStatus(
            @Param("id") Long id,
            @Param("status") Project.ProjectStatus status,
            @Param("updatedAt") LocalDateTime updatedAt
    );

    /**
     * Count by owner
     */
    long countByOwnerId(String ownerId);

    /**
     * Count by status
     */
    long countByStatus(Project.ProjectStatus status);

    /**
     * Count active projects by owner
     */
    long countByOwnerIdAndStatus(String ownerId, Project.ProjectStatus status);

    /**
     * Find inactive projects (for cleanup suggestions)
     */
    @Query("SELECT p FROM Project p WHERE p.status = com.newsinsight.collector.entity.project.Project$ProjectStatus.ACTIVE AND p.lastActivityAt < :inactiveSince ORDER BY p.lastActivityAt ASC")
    List<Project> findInactiveProjects(@Param("inactiveSince") LocalDateTime inactiveSince, Pageable pageable);
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/SearchFeedbackRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.feedback.SearchFeedback;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;

/**
 * Repository for SearchFeedback entity.
 * Manages user feedback on search results.
 */
@Repository
public interface SearchFeedbackRepository extends JpaRepository<SearchFeedback, Long> {

    /**
     * Find by search history ID
     */
    List<SearchFeedback> findBySearchHistoryIdOrderByCreatedAtDesc(Long searchHistoryId);

    /**
     * Find by user ID
     */
    Page<SearchFeedback> findByUserIdOrderByCreatedAtDesc(String userId, Pageable pageable);

    /**
     * Find by feedback type
     */
    Page<SearchFeedback> findByFeedbackType(SearchFeedback.FeedbackType feedbackType, Pageable pageable);

    /**
     * Find unreviewed feedback
     */
    Page<SearchFeedback> findByReviewedFalseOrderByCreatedAtDesc(Pageable pageable);

    /**
     * Find feedback with low ratings
     */
    @Query("SELECT f FROM SearchFeedback f WHERE f.rating <= :maxRating ORDER BY f.createdAt DESC")
    Page<SearchFeedback> findLowRatedFeedback(@Param("maxRating") int maxRating, Pageable pageable);

    /**
     * Find positive feedback (thumbs up)
     */
    Page<SearchFeedback> findByThumbsUpTrueOrderByCreatedAtDesc(Pageable pageable);

    /**
     * Find negative feedback (thumbs down)
     */
    Page<SearchFeedback> findByThumbsUpFalseOrderByCreatedAtDesc(Pageable pageable);

    /**
     * Count feedback by search history
     */
    long countBySearchHistoryId(Long searchHistoryId);

    /**
     * Average rating by search history
     */
    @Query("SELECT AVG(f.rating) FROM SearchFeedback f WHERE f.searchHistoryId = :searchHistoryId AND f.rating IS NOT NULL")
    Double getAverageRatingBySearchHistory(@Param("searchHistoryId") Long searchHistoryId);

    /**
     * Get overall feedback statistics
     */
    @Query("""
            SELECT 
                COUNT(f) as totalCount,
                AVG(f.rating) as avgRating,
                AVG(f.usefulnessRating) as avgUsefulness,
                AVG(f.accuracyRating) as avgAccuracy,
                AVG(f.relevanceRating) as avgRelevance,
                SUM(CASE WHEN f.thumbsUp = true THEN 1 ELSE 0 END) as thumbsUpCount,
                SUM(CASE WHEN f.thumbsUp = false THEN 1 ELSE 0 END) as thumbsDownCount
            FROM SearchFeedback f
            WHERE f.createdAt > :after
            """)
    FeedbackStats getOverallStats(@Param("after") LocalDateTime after);

    /**
     * Get feedback stats by type
     */
    @Query("""
            SELECT f.feedbackType as feedbackType, COUNT(f) as count, AVG(f.rating) as avgRating
            FROM SearchFeedback f
            WHERE f.createdAt > :after
            GROUP BY f.feedbackType
            """)
    List<FeedbackTypeStats> getStatsByType(@Param("after") LocalDateTime after);

    /**
     * Find feedback not used for training
     */
    @Query("""
            SELECT f FROM SearchFeedback f 
            WHERE f.usedForTraining = false 
            AND f.reviewed = true
            ORDER BY f.createdAt
            """)
    List<SearchFeedback> findUnusedForTraining(Pageable pageable);

    interface FeedbackStats {
        Long getTotalCount();
        Double getAvgRating();
        Double getAvgUsefulness();
        Double getAvgAccuracy();
        Double getAvgRelevance();
        Long getThumbsUpCount();
        Long getThumbsDownCount();
    }

    interface FeedbackTypeStats {
        SearchFeedback.FeedbackType getFeedbackType();
        Long getCount();
        Double getAvgRating();
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/SearchHistoryRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.search.SearchHistory;
import com.newsinsight.collector.entity.search.SearchType;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Optional;

/**
 * Repository for SearchHistory entity.
 * Provides search history persistence and query operations.
 */
@Repository
public interface SearchHistoryRepository extends JpaRepository<SearchHistory, Long> {

    /**
     * Find by external ID (e.g., jobId)
     */
    Optional<SearchHistory> findByExternalId(String externalId);

    /**
     * Find by external ID containing (for jobId + suffix patterns)
     */
    List<SearchHistory> findByExternalIdContaining(String externalIdPart);

    /**
     * Find all searches by type
     */
    Page<SearchHistory> findBySearchType(SearchType searchType, Pageable pageable);

    /**
     * Find all searches by user
     */
    Page<SearchHistory> findByUserId(String userId, Pageable pageable);

    /**
     * Find searches by user and type
     */
    Page<SearchHistory> findByUserIdAndSearchType(String userId, SearchType searchType, Pageable pageable);

    /**
     * Find bookmarked searches
     */
    Page<SearchHistory> findByBookmarkedTrue(Pageable pageable);

    /**
     * Find bookmarked searches by user
     */
    Page<SearchHistory> findByUserIdAndBookmarkedTrue(String userId, Pageable pageable);

    /**
     * Find derived searches from a parent
     */
    List<SearchHistory> findByParentSearchIdOrderByCreatedAtDesc(Long parentSearchId);

    /**
     * Find searches by session
     */
    List<SearchHistory> findBySessionIdOrderByCreatedAtDesc(String sessionId);
    
    /**
     * Find searches by userId and sessionId (for anonymous user isolation)
     * This ensures that each anonymous session only sees their own data
     */
    Page<SearchHistory> findByUserIdAndSessionId(String userId, String sessionId, Pageable pageable);
    
    /**
     * Find searches by userId OR sessionId (fallback for migration)
     */
    @Query("SELECT sh FROM SearchHistory sh WHERE sh.userId = :userId OR sh.sessionId = :sessionId ORDER BY sh.createdAt DESC")
    Page<SearchHistory> findByUserIdOrSessionId(
            @Param("userId") String userId,
            @Param("sessionId") String sessionId,
            Pageable pageable
    );

    /**
     * Search by query text (case-insensitive, partial match)
     */
    @Query("SELECT sh FROM SearchHistory sh WHERE LOWER(sh.query) LIKE LOWER(CONCAT('%', :query, '%'))")
    Page<SearchHistory> searchByQuery(@Param("query") String query, Pageable pageable);

    /**
     * Search by query text and type
     */
    @Query("SELECT sh FROM SearchHistory sh WHERE LOWER(sh.query) LIKE LOWER(CONCAT('%', :query, '%')) AND sh.searchType = :searchType")
    Page<SearchHistory> searchByQueryAndType(
            @Param("query") String query,
            @Param("searchType") SearchType searchType,
            Pageable pageable
    );

    /**
     * Find recent searches within time range
     */
    Page<SearchHistory> findByCreatedAtAfter(LocalDateTime after, Pageable pageable);

    /**
     * Find recent searches by user within time range
     */
    Page<SearchHistory> findByUserIdAndCreatedAtAfter(String userId, LocalDateTime after, Pageable pageable);

    /**
     * Get search count by type
     */
    long countBySearchType(SearchType searchType);

    /**
     * Get search count by user
     */
    long countByUserId(String userId);

    /**
     * Find searches with specific tag
     */
    @Query(value = "SELECT * FROM search_history WHERE tags @> :tag::jsonb", nativeQuery = true)
    List<SearchHistory> findByTag(@Param("tag") String tagJson);

    /**
     * Delete old searches (for cleanup)
     */
    @Query("DELETE FROM SearchHistory sh WHERE sh.createdAt < :before AND sh.bookmarked = false")
    void deleteOldSearches(@Param("before") LocalDateTime before);

    /**
     * Get unique discovered URLs from recent searches
     */
    @Query(value = """
            SELECT DISTINCT jsonb_array_elements_text(discovered_urls) as url
            FROM search_history 
            WHERE discovered_urls IS NOT NULL 
            AND created_at > :after
            LIMIT :limit
            """, nativeQuery = true)
    List<String> findRecentDiscoveredUrls(@Param("after") LocalDateTime after, @Param("limit") int limit);

    /**
     * Find similar searches (by query similarity)
     */
    @Query(value = """
            SELECT * FROM search_history 
            WHERE search_type = :searchType
            AND similarity(query, :query) > 0.3
            ORDER BY similarity(query, :query) DESC
            LIMIT :limit
            """, nativeQuery = true)
    List<SearchHistory> findSimilarSearches(
            @Param("query") String query,
            @Param("searchType") String searchType,
            @Param("limit") int limit
    );

    /**
     * Get search statistics summary
     */
    @Query("""
            SELECT sh.searchType as searchType, COUNT(sh) as count, AVG(sh.resultCount) as avgResults
            FROM SearchHistory sh
            WHERE sh.createdAt > :after
            GROUP BY sh.searchType
            """)
    List<SearchStatsSummary> getSearchStatsSummary(@Param("after") LocalDateTime after);

    /**
     * Projection for search statistics
     */
    interface SearchStatsSummary {
        SearchType getSearchType();
        Long getCount();
        Double getAvgResults();
    }

    // ============ New methods for Continue Work feature ============

    /**
     * Find searches that need continuation (for "Continue Work" feature)
     * Includes: IN_PROGRESS, PARTIAL, FAILED, DRAFT, or COMPLETED but not viewed
     */
    @Query("""
            SELECT sh FROM SearchHistory sh
            WHERE (sh.userId = :userId OR sh.sessionId = :sessionId)
            AND (
                sh.completionStatus IN ('DRAFT', 'IN_PROGRESS', 'PARTIAL', 'FAILED')
                OR (sh.completionStatus = 'COMPLETED' AND sh.viewed = false)
            )
            AND sh.bookmarked = false
            AND sh.reportGenerated = false
            ORDER BY 
                CASE sh.completionStatus 
                    WHEN 'IN_PROGRESS' THEN 1
                    WHEN 'FAILED' THEN 2
                    WHEN 'DRAFT' THEN 3
                    WHEN 'PARTIAL' THEN 4
                    ELSE 5
                END,
                sh.updatedAt DESC
            """)
    List<SearchHistory> findContinueWorkItems(
            @Param("userId") String userId,
            @Param("sessionId") String sessionId,
            Pageable pageable
    );

    /**
     * Find searches by completion status
     */
    Page<SearchHistory> findByCompletionStatus(
            SearchHistory.CompletionStatus completionStatus,
            Pageable pageable
    );

    /**
     * Find searches by user and completion status
     */
    Page<SearchHistory> findByUserIdAndCompletionStatus(
            String userId,
            SearchHistory.CompletionStatus completionStatus,
            Pageable pageable
    );

    /**
     * Find unviewed completed searches
     */
    @Query("SELECT sh FROM SearchHistory sh WHERE sh.completionStatus = 'COMPLETED' AND sh.viewed = false")
    Page<SearchHistory> findUnviewedCompleted(Pageable pageable);

    /**
     * Find searches by project ID
     */
    Page<SearchHistory> findByProjectId(Long projectId, Pageable pageable);

    /**
     * Find searches by project ID and type
     */
    Page<SearchHistory> findByProjectIdAndSearchType(Long projectId, SearchType searchType, Pageable pageable);

    /**
     * Count in-progress searches by user
     */
    @Query("SELECT COUNT(sh) FROM SearchHistory sh WHERE sh.userId = :userId AND sh.completionStatus = 'IN_PROGRESS'")
    long countInProgressByUser(@Param("userId") String userId);

    /**
     * Update viewed status
     */
    @Query("UPDATE SearchHistory sh SET sh.viewed = true, sh.viewedAt = :viewedAt WHERE sh.id = :id")
    void markAsViewed(@Param("id") Long id, @Param("viewedAt") LocalDateTime viewedAt);

    /**
     * Update completion status
     */
    @Query("UPDATE SearchHistory sh SET sh.completionStatus = :status, sh.updatedAt = :updatedAt WHERE sh.id = :id")
    void updateCompletionStatus(
            @Param("id") Long id,
            @Param("status") SearchHistory.CompletionStatus status,
            @Param("updatedAt") LocalDateTime updatedAt
    );

    /**
     * Find failed searches for retry
     */
    @Query("""
            SELECT sh FROM SearchHistory sh 
            WHERE sh.completionStatus = 'FAILED' 
            AND sh.createdAt > :after
            ORDER BY sh.createdAt DESC
            """)
    List<SearchHistory> findFailedSearches(@Param("after") LocalDateTime after, Pageable pageable);
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/SearchTemplateRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.search.SearchTemplate;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Modifying;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.util.List;

/**
 * Repository for SearchTemplate entity.
 * Provides template persistence and query operations.
 */
@Repository
public interface SearchTemplateRepository extends JpaRepository<SearchTemplate, Long> {

    /**
     * Find all templates by user
     */
    Page<SearchTemplate> findByUserId(String userId, Pageable pageable);

    /**
     * Find all templates by user (list)
     */
    List<SearchTemplate> findByUserIdOrderByCreatedAtDesc(String userId);

    /**
     * Find templates by mode
     */
    Page<SearchTemplate> findByMode(String mode, Pageable pageable);

    /**
     * Find templates by user and mode
     */
    Page<SearchTemplate> findByUserIdAndMode(String userId, String mode, Pageable pageable);

    /**
     * Find favorite templates by user
     */
    List<SearchTemplate> findByUserIdAndFavoriteTrueOrderByLastUsedAtDesc(String userId);

    /**
     * Find all favorites
     */
    Page<SearchTemplate> findByFavoriteTrue(Pageable pageable);

    /**
     * Search templates by name (case-insensitive)
     */
    @Query("SELECT st FROM SearchTemplate st WHERE LOWER(st.name) LIKE LOWER(CONCAT('%', :name, '%'))")
    Page<SearchTemplate> searchByName(@Param("name") String name, Pageable pageable);

    /**
     * Search templates by name for a specific user
     */
    @Query("SELECT st FROM SearchTemplate st WHERE st.userId = :userId AND LOWER(st.name) LIKE LOWER(CONCAT('%', :name, '%'))")
    Page<SearchTemplate> searchByNameAndUserId(@Param("name") String name, @Param("userId") String userId, Pageable pageable);

    /**
     * Search templates by query text
     */
    @Query("SELECT st FROM SearchTemplate st WHERE LOWER(st.query) LIKE LOWER(CONCAT('%', :query, '%'))")
    Page<SearchTemplate> searchByQuery(@Param("query") String query, Pageable pageable);

    /**
     * Find most used templates
     */
    @Query("SELECT st FROM SearchTemplate st WHERE st.userId = :userId ORDER BY st.useCount DESC")
    List<SearchTemplate> findMostUsedByUser(@Param("userId") String userId, Pageable pageable);

    /**
     * Find recently used templates
     */
    @Query("SELECT st FROM SearchTemplate st WHERE st.userId = :userId AND st.lastUsedAt IS NOT NULL ORDER BY st.lastUsedAt DESC")
    List<SearchTemplate> findRecentlyUsedByUser(@Param("userId") String userId, Pageable pageable);

    /**
     * Find templates created from a specific search
     */
    List<SearchTemplate> findBySourceSearchId(Long sourceSearchId);

    /**
     * Count templates by user
     */
    long countByUserId(String userId);

    /**
     * Count templates by mode
     */
    long countByMode(String mode);

    /**
     * Increment use count
     */
    @Modifying
    @Query("UPDATE SearchTemplate st SET st.useCount = st.useCount + 1, st.lastUsedAt = CURRENT_TIMESTAMP WHERE st.id = :id")
    void incrementUseCount(@Param("id") Long id);

    /**
     * Check if template with name exists for user
     */
    boolean existsByUserIdAndName(String userId, String name);
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/repository/WorkspaceFileRepository.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.workspace.WorkspaceFile;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Modifying;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Optional;

/**
 * Repository for WorkspaceFile entity.
 */
@Repository
public interface WorkspaceFileRepository extends JpaRepository<WorkspaceFile, Long> {

    /**
     * Find by file UUID
     */
    Optional<WorkspaceFile> findByFileUuid(String fileUuid);

    /**
     * Find by file UUID and active status
     */
    @Query("SELECT f FROM WorkspaceFile f WHERE f.fileUuid = :fileUuid AND f.status = 'ACTIVE'")
    Optional<WorkspaceFile> findActiveByFileUuid(@Param("fileUuid") String fileUuid);

    /**
     * Find files by session ID
     */
    Page<WorkspaceFile> findBySessionIdAndStatusOrderByCreatedAtDesc(
            String sessionId, 
            WorkspaceFile.FileStatus status, 
            Pageable pageable
    );

    /**
     * Find files by user ID
     */
    Page<WorkspaceFile> findByUserIdAndStatusOrderByCreatedAtDesc(
            String userId, 
            WorkspaceFile.FileStatus status, 
            Pageable pageable
    );

    /**
     * Find files by project ID
     */
    Page<WorkspaceFile> findByProjectIdAndStatusOrderByCreatedAtDesc(
            Long projectId, 
            WorkspaceFile.FileStatus status, 
            Pageable pageable
    );

    /**
     * Find files by session ID and file type
     */
    Page<WorkspaceFile> findBySessionIdAndFileTypeAndStatus(
            String sessionId,
            WorkspaceFile.FileType fileType,
            WorkspaceFile.FileStatus status,
            Pageable pageable
    );

    /**
     * Find files by user ID and file type
     */
    Page<WorkspaceFile> findByUserIdAndFileTypeAndStatus(
            String userId,
            WorkspaceFile.FileType fileType,
            WorkspaceFile.FileStatus status,
            Pageable pageable
    );

    /**
     * Search files by name for session
     */
    @Query("SELECT f FROM WorkspaceFile f WHERE f.sessionId = :sessionId " +
           "AND f.status = 'ACTIVE' AND LOWER(f.originalName) LIKE LOWER(CONCAT('%', :name, '%'))")
    Page<WorkspaceFile> searchByNameForSession(
            @Param("sessionId") String sessionId,
            @Param("name") String name,
            Pageable pageable
    );

    /**
     * Search files by name for user
     */
    @Query("SELECT f FROM WorkspaceFile f WHERE f.userId = :userId " +
           "AND f.status = 'ACTIVE' AND LOWER(f.originalName) LIKE LOWER(CONCAT('%', :name, '%'))")
    Page<WorkspaceFile> searchByNameForUser(
            @Param("userId") String userId,
            @Param("name") String name,
            Pageable pageable
    );

    /**
     * Find expired files
     */
    @Query("SELECT f FROM WorkspaceFile f WHERE f.status = 'ACTIVE' AND f.expiresAt IS NOT NULL AND f.expiresAt < :now")
    List<WorkspaceFile> findExpiredFiles(@Param("now") LocalDateTime now);

    /**
     * Find files pending deletion
     */
    List<WorkspaceFile> findByStatus(WorkspaceFile.FileStatus status);

    /**
     * Find old session files (for cleanup)
     */
    @Query("SELECT f FROM WorkspaceFile f WHERE f.sessionId IS NOT NULL AND f.userId IS NULL " +
           "AND f.createdAt < :threshold AND f.status = 'ACTIVE'")
    List<WorkspaceFile> findOldSessionFiles(@Param("threshold") LocalDateTime threshold);

    /**
     * Update file status
     */
    @Modifying
    @Query("UPDATE WorkspaceFile f SET f.status = :status, f.updatedAt = :now WHERE f.id = :id")
    void updateStatus(
            @Param("id") Long id,
            @Param("status") WorkspaceFile.FileStatus status,
            @Param("now") LocalDateTime now
    );

    /**
     * Increment download count
     */
    @Modifying
    @Query("UPDATE WorkspaceFile f SET f.downloadCount = f.downloadCount + 1, " +
           "f.lastAccessedAt = :now WHERE f.id = :id")
    void incrementDownloadCount(@Param("id") Long id, @Param("now") LocalDateTime now);

    /**
     * Mark files as deleted for session
     */
    @Modifying
    @Query("UPDATE WorkspaceFile f SET f.status = 'DELETED', f.updatedAt = :now WHERE f.sessionId = :sessionId")
    void markDeletedBySessionId(@Param("sessionId") String sessionId, @Param("now") LocalDateTime now);

    /**
     * Transfer files from session to user (when user logs in)
     */
    @Modifying
    @Query("UPDATE WorkspaceFile f SET f.userId = :userId, f.updatedAt = :now WHERE f.sessionId = :sessionId")
    void transferSessionFilesToUser(
            @Param("sessionId") String sessionId,
            @Param("userId") String userId,
            @Param("now") LocalDateTime now
    );

    /**
     * Count files by session
     */
    long countBySessionIdAndStatus(String sessionId, WorkspaceFile.FileStatus status);

    /**
     * Count files by user
     */
    long countByUserIdAndStatus(String userId, WorkspaceFile.FileStatus status);

    /**
     * Sum file sizes by session
     */
    @Query("SELECT COALESCE(SUM(f.fileSize), 0) FROM WorkspaceFile f WHERE f.sessionId = :sessionId AND f.status = 'ACTIVE'")
    Long sumFileSizeBySessionId(@Param("sessionId") String sessionId);

    /**
     * Sum file sizes by user
     */
    @Query("SELECT COALESCE(SUM(f.fileSize), 0) FROM WorkspaceFile f WHERE f.userId = :userId AND f.status = 'ACTIVE'")
    Long sumFileSizeByUserId(@Param("userId") String userId);

    /**
     * Find by stored name
     */
    Optional<WorkspaceFile> findByStoredName(String storedName);

    /**
     * Check if file exists with same checksum for deduplication
     */
    @Query("SELECT f FROM WorkspaceFile f WHERE f.checksum = :checksum AND f.status = 'ACTIVE' " +
           "AND (f.sessionId = :sessionId OR f.userId = :userId)")
    Optional<WorkspaceFile> findByChecksumAndOwner(
            @Param("checksum") String checksum,
            @Param("sessionId") String sessionId,
            @Param("userId") String userId
    );
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/scheduler/AutoCrawlScheduler.java

```java
package com.newsinsight.collector.scheduler;

import com.newsinsight.collector.entity.autocrawl.DiscoverySource;
import com.newsinsight.collector.service.autocrawl.AutoCrawlDiscoveryService;
import com.newsinsight.collector.service.autocrawl.CrawlQueueService;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Component;

import java.util.Map;

/**
 * 자동 크롤링 스케줄러.
 * 
 * 크롤링 큐를 주기적으로 처리하고, URL 발견/정리 작업을 자동화합니다.
 * 백그라운드에서 지속적으로 실행되어 실시간 크롤링을 지원합니다.
 */
@Component
@RequiredArgsConstructor
@Slf4j
@ConditionalOnProperty(name = "autocrawl.enabled", havingValue = "true", matchIfMissing = false)
public class AutoCrawlScheduler {

    private final CrawlQueueService crawlQueueService;
    private final AutoCrawlDiscoveryService autoCrawlDiscoveryService;

    @Value("${autocrawl.batch-size:10}")
    private int batchSize;

    @Value("${autocrawl.cleanup-days:7}")
    private int cleanupDays;

    @Value("${autocrawl.expire-pending-days:7}")
    private int expirePendingDays;

    // ========================================
    // 크롤링 큐 처리
    // ========================================

    /**
     * 크롤링 큐 처리 (30초마다)
     * 대기 중인 대상을 우선순위에 따라 크롤러로 분배
     */
    @Scheduled(fixedDelayString = "${autocrawl.queue-interval-ms:30000}")
    public void processQueue() {
        try {
            int dispatched = crawlQueueService.processQueue(batchSize);
            if (dispatched > 0) {
                log.info("[AutoCrawl] Dispatched {} targets for crawling", dispatched);
            }
        } catch (Exception e) {
            log.error("[AutoCrawl] Error processing queue: {}", e.getMessage(), e);
        }
    }

    /**
     * 멈춘 작업 복구 (5분마다)
     * IN_PROGRESS 상태로 오래 방치된 대상을 PENDING으로 복구
     */
    @Scheduled(fixedDelayString = "${autocrawl.recovery-interval-ms:300000}")
    public void recoverStuckTargets() {
        try {
            int recovered = crawlQueueService.recoverStuckTargets();
            if (recovered > 0) {
                log.warn("[AutoCrawl] Recovered {} stuck targets", recovered);
            }
        } catch (Exception e) {
            log.error("[AutoCrawl] Error recovering stuck targets: {}", e.getMessage(), e);
        }
    }

    // ========================================
    // 정리 작업
    // ========================================

    /**
     * 오래된 완료/실패 대상 정리 (매일 새벽 3시)
     */
    @Scheduled(cron = "${autocrawl.cleanup-cron:0 0 3 * * *}")
    public void cleanupOldTargets() {
        try {
            log.info("[AutoCrawl] Starting daily cleanup...");
            
            // 완료/실패 대상 정리
            int cleaned = crawlQueueService.cleanupOldTargets(cleanupDays);
            
            // 오래 대기 중인 대상 만료
            int expired = crawlQueueService.expireOldPendingTargets(expirePendingDays);
            
            log.info("[AutoCrawl] Daily cleanup complete: cleaned={}, expired={}", cleaned, expired);
        } catch (Exception e) {
            log.error("[AutoCrawl] Error during cleanup: {}", e.getMessage(), e);
        }
    }

    // ========================================
    // 통계 로깅
    // ========================================

    /**
     * 큐 상태 로깅 (10분마다)
     */
    @Scheduled(fixedDelayString = "${autocrawl.stats-interval-ms:600000}")
    public void logQueueStats() {
        try {
            CrawlQueueService.QueueStats stats = crawlQueueService.getQueueStats();
            
            log.info("[AutoCrawl Stats] pending={}, inProgress={}, completed={}, failed={}, " +
                     "sessionDispatched={}, sessionCompleted={}, sessionFailed={}",
                    stats.getPendingCount(),
                    stats.getInProgressCount(),
                    stats.getCompletedCount(),
                    stats.getFailedCount(),
                    stats.getTotalDispatched(),
                    stats.getTotalCompleted(),
                    stats.getTotalFailed());
            
            // 발견 출처별 통계
            Map<DiscoverySource, Long> discoveryStats = autoCrawlDiscoveryService.getDiscoveryStats();
            if (!discoveryStats.isEmpty()) {
                log.info("[AutoCrawl Stats] Discovery sources (last 7 days): {}", discoveryStats);
            }
            
        } catch (Exception e) {
            log.error("[AutoCrawl] Error logging stats: {}", e.getMessage(), e);
        }
    }

    // ========================================
    // 수동 제어용 메서드
    // ========================================

    /**
     * 수동으로 큐 처리 트리거
     */
    public int triggerQueueProcessing(int customBatchSize) {
        log.info("[AutoCrawl] Manual queue processing triggered with batch size: {}", customBatchSize);
        return crawlQueueService.processQueue(customBatchSize);
    }

    /**
     * 수동으로 정리 트리거
     */
    public void triggerCleanup() {
        log.info("[AutoCrawl] Manual cleanup triggered");
        cleanupOldTargets();
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/scheduler/CollectionScheduler.java

```java
package com.newsinsight.collector.scheduler;

import com.newsinsight.collector.entity.CollectionJob;
import com.newsinsight.collector.entity.CollectionJob.JobStatus;
import com.newsinsight.collector.repository.CollectionJobRepository;
import com.newsinsight.collector.service.CollectionService;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Component;

import java.util.List;

/**
 * 자동 크롤링 스케줄러.
 * 설정된 cron 주기에 따라 활성화된 모든 데이터 소스에 대해 자동으로 수집 작업을 시작합니다.
 */
@Component
@RequiredArgsConstructor
@Slf4j
public class CollectionScheduler {

    private final CollectionService collectionService;
    private final CollectionJobRepository collectionJobRepository;

    @Value("${collector.scheduling.enabled:true}")
    private boolean schedulingEnabled;

    @Value("${collector.scheduling.skip-if-running:true}")
    private boolean skipIfRunning;

    /**
     * 정기 수집 스케줄러.
     * 기본값: 매 시 정각 (0 0 * * * ?)
     * 환경변수 COLLECTION_CRON으로 조정 가능.
     */
    @Scheduled(cron = "${collector.scheduling.cron:0 0 * * * ?}")
    public void scheduledCollection() {
        if (!schedulingEnabled) {
            log.debug("Scheduled collection is disabled");
            return;
        }

        // 이미 실행 중인 작업이 있으면 스킵 (중복 실행 방지)
        if (skipIfRunning && hasRunningJobs()) {
            log.info("Skipping scheduled collection: jobs already running");
            return;
        }

        log.info("Starting scheduled collection for all active sources");
        try {
            List<CollectionJob> jobs = collectionService.startCollectionForAllActive();
            log.info("Scheduled collection started {} jobs", jobs.size());
            
            if (jobs.isEmpty()) {
                log.warn("No active data sources found for scheduled collection");
            }
        } catch (Exception e) {
            log.error("Scheduled collection failed: {}", e.getMessage(), e);
        }
    }

    /**
     * 실행 중인 수집 작업이 있는지 확인.
     */
    private boolean hasRunningJobs() {
        long runningCount = collectionJobRepository.countByStatus(JobStatus.RUNNING);
        long pendingCount = collectionJobRepository.countByStatus(JobStatus.PENDING);
        return (runningCount + pendingCount) > 0;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/scheduler/MlAddonHealthScheduler.java

```java
package com.newsinsight.collector.scheduler;

import com.newsinsight.collector.entity.addon.AddonHealthStatus;
import com.newsinsight.collector.entity.addon.MlAddon;
import com.newsinsight.collector.repository.MlAddonRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;
import org.springframework.http.ResponseEntity;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Component;
import org.springframework.transaction.annotation.Transactional;
import org.springframework.web.client.RestClientException;
import org.springframework.web.client.RestTemplate;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.atomic.AtomicInteger;

/**
 * ML Addon Health Check Scheduler.
 * 
 * Periodically checks the health of registered ML addons and updates their status.
 * Supports automatic disabling of unhealthy addons after consecutive failures.
 */
@Component
@RequiredArgsConstructor
@Slf4j
@ConditionalOnProperty(name = "ml.addon.health-check.enabled", havingValue = "true", matchIfMissing = true)
public class MlAddonHealthScheduler {

    private final MlAddonRepository mlAddonRepository;
    private final RestTemplate restTemplate;

    @Value("${ml.addon.health-check.timeout-ms:5000}")
    private int healthCheckTimeoutMs;

    @Value("${ml.addon.health-check.max-consecutive-failures:3}")
    private int maxConsecutiveFailures;

    @Value("${ml.addon.health-check.auto-disable:false}")
    private boolean autoDisableUnhealthy;

    @Value("${ml.addon.health-check.interval-minutes:5}")
    private int healthCheckIntervalMinutes;

    // Track consecutive failures per addon
    private final Map<Long, AtomicInteger> failureCounters = new ConcurrentHashMap<>();

    /**
     * Periodic health check for all registered ML addons.
     * Default: runs every 5 minutes.
     */
    @Scheduled(fixedDelayString = "${ml.addon.health-check.interval-ms:300000}")
    @Transactional
    public void checkAddonHealth() {
        log.debug("[MlAddonHealth] Starting health check cycle...");
        
        // Get addons that need health check
        LocalDateTime cutoff = LocalDateTime.now().minusMinutes(healthCheckIntervalMinutes);
        List<MlAddon> addonsToCheck = mlAddonRepository.findAddonsNeedingHealthCheck(cutoff);
        
        if (addonsToCheck.isEmpty()) {
            log.debug("[MlAddonHealth] No addons need health check at this time");
            return;
        }
        
        log.info("[MlAddonHealth] Checking {} addons...", addonsToCheck.size());
        
        int healthy = 0;
        int unhealthy = 0;
        int degraded = 0;
        
        for (MlAddon addon : addonsToCheck) {
            try {
                AddonHealthStatus status = checkSingleAddon(addon);
                updateAddonHealth(addon, status);
                
                switch (status) {
                    case HEALTHY -> healthy++;
                    case UNHEALTHY -> unhealthy++;
                    case DEGRADED -> degraded++;
                    default -> {} // UNKNOWN - shouldn't happen after check
                }
            } catch (Exception e) {
                log.error("[MlAddonHealth] Error checking addon {}: {}", addon.getAddonKey(), e.getMessage());
                updateAddonHealth(addon, AddonHealthStatus.UNHEALTHY);
                unhealthy++;
            }
        }
        
        log.info("[MlAddonHealth] Health check complete: healthy={}, degraded={}, unhealthy={}", 
                healthy, degraded, unhealthy);
    }

    /**
     * Check health of a single addon.
     */
    private AddonHealthStatus checkSingleAddon(MlAddon addon) {
        if (addon.getHealthCheckUrl() == null || addon.getHealthCheckUrl().isBlank()) {
            log.debug("[MlAddonHealth] Addon {} has no health check URL, marking as UNKNOWN", addon.getAddonKey());
            return AddonHealthStatus.UNKNOWN;
        }
        
        try {
            long startTime = System.currentTimeMillis();
            ResponseEntity<Map> response = restTemplate.getForEntity(
                addon.getHealthCheckUrl(), 
                Map.class
            );
            long latencyMs = System.currentTimeMillis() - startTime;
            
            if (response.getStatusCode().is2xxSuccessful()) {
                // Clear failure counter on success
                failureCounters.remove(addon.getId());
                
                // Check if response indicates healthy status
                Map<?, ?> body = response.getBody();
                if (body != null) {
                    Object status = body.get("status");
                    if ("healthy".equalsIgnoreCase(String.valueOf(status)) ||
                        "ok".equalsIgnoreCase(String.valueOf(status))) {
                        
                        // Check latency for degraded status
                        if (latencyMs > addon.getTimeoutMs() / 2) {
                            log.warn("[MlAddonHealth] Addon {} responding slowly: {}ms", 
                                    addon.getAddonKey(), latencyMs);
                            return AddonHealthStatus.DEGRADED;
                        }
                        
                        log.debug("[MlAddonHealth] Addon {} is healthy ({}ms)", addon.getAddonKey(), latencyMs);
                        return AddonHealthStatus.HEALTHY;
                    }
                }
                
                // Response OK but status field not healthy
                return AddonHealthStatus.DEGRADED;
            } else {
                // Non-2xx response
                incrementFailureCounter(addon);
                return AddonHealthStatus.UNHEALTHY;
            }
            
        } catch (RestClientException e) {
            log.warn("[MlAddonHealth] Failed to reach addon {}: {}", addon.getAddonKey(), e.getMessage());
            incrementFailureCounter(addon);
            return AddonHealthStatus.UNHEALTHY;
        }
    }

    /**
     * Update addon health status in database.
     */
    @Transactional
    protected void updateAddonHealth(MlAddon addon, AddonHealthStatus status) {
        mlAddonRepository.updateHealthStatus(addon.getId(), status, LocalDateTime.now());
        
        // Check if we should auto-disable
        if (autoDisableUnhealthy && status == AddonHealthStatus.UNHEALTHY) {
            AtomicInteger counter = failureCounters.get(addon.getId());
            if (counter != null && counter.get() >= maxConsecutiveFailures) {
                log.warn("[MlAddonHealth] Auto-disabling addon {} after {} consecutive failures", 
                        addon.getAddonKey(), counter.get());
                mlAddonRepository.disableAddon(addon.getId());
                failureCounters.remove(addon.getId());
            }
        }
    }

    /**
     * Increment failure counter for an addon.
     */
    private void incrementFailureCounter(MlAddon addon) {
        failureCounters.computeIfAbsent(addon.getId(), k -> new AtomicInteger(0)).incrementAndGet();
    }

    /**
     * Manually trigger health check for a specific addon.
     */
    @Transactional
    public AddonHealthStatus checkAddonHealthNow(Long addonId) {
        MlAddon addon = mlAddonRepository.findById(addonId)
                .orElseThrow(() -> new IllegalArgumentException("Addon not found: " + addonId));
        
        AddonHealthStatus status = checkSingleAddon(addon);
        updateAddonHealth(addon, status);
        
        return status;
    }

    /**
     * Manually trigger health check for all addons.
     */
    @Transactional
    public Map<String, Integer> checkAllAddonsNow() {
        List<MlAddon> allAddons = mlAddonRepository.findByEnabledTrue();
        
        int healthy = 0;
        int unhealthy = 0;
        int degraded = 0;
        int unknown = 0;
        
        for (MlAddon addon : allAddons) {
            AddonHealthStatus status = checkSingleAddon(addon);
            updateAddonHealth(addon, status);
            
            switch (status) {
                case HEALTHY -> healthy++;
                case UNHEALTHY -> unhealthy++;
                case DEGRADED -> degraded++;
                case UNKNOWN -> unknown++;
            }
        }
        
        return Map.of(
            "healthy", healthy,
            "unhealthy", unhealthy,
            "degraded", degraded,
            "unknown", unknown,
            "total", allAddons.size()
        );
    }

    /**
     * Get current health statistics.
     */
    public Map<String, Object> getHealthStats() {
        List<MlAddon> allAddons = mlAddonRepository.findByEnabledTrue();
        
        long healthy = allAddons.stream()
                .filter(a -> a.getHealthStatus() == AddonHealthStatus.HEALTHY)
                .count();
        long unhealthy = allAddons.stream()
                .filter(a -> a.getHealthStatus() == AddonHealthStatus.UNHEALTHY)
                .count();
        long degraded = allAddons.stream()
                .filter(a -> a.getHealthStatus() == AddonHealthStatus.DEGRADED)
                .count();
        long unknown = allAddons.stream()
                .filter(a -> a.getHealthStatus() == AddonHealthStatus.UNKNOWN)
                .count();
        
        return Map.of(
            "healthy", healthy,
            "unhealthy", unhealthy,
            "degraded", degraded,
            "unknown", unknown,
            "total", allAddons.size(),
            "healthRate", allAddons.isEmpty() ? 0.0 : (double) healthy / allAddons.size()
        );
    }

    /**
     * Reset failure counter for an addon (e.g., after manual intervention).
     */
    public void resetFailureCounter(Long addonId) {
        failureCounters.remove(addonId);
        log.info("[MlAddonHealth] Reset failure counter for addon {}", addonId);
    }

    /**
     * Log health summary periodically (every hour).
     */
    @Scheduled(cron = "0 0 * * * *")
    public void logHealthSummary() {
        Map<String, Object> stats = getHealthStats();
        log.info("[MlAddonHealth] Hourly summary: healthy={}, degraded={}, unhealthy={}, unknown={}, total={}", 
                stats.get("healthy"), 
                stats.get("degraded"), 
                stats.get("unhealthy"), 
                stats.get("unknown"),
                stats.get("total"));
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/AddonOrchestratorService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.dto.addon.AddonRequest;
import com.newsinsight.collector.dto.addon.AddonResponse;
import com.newsinsight.collector.entity.CollectedData;
import com.newsinsight.collector.entity.addon.*;
import com.newsinsight.collector.entity.analysis.ArticleAnalysis;
import com.newsinsight.collector.entity.analysis.ArticleDiscussion;
import com.newsinsight.collector.repository.*;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.http.MediaType;
import org.springframework.scheduling.annotation.Async;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;
import org.springframework.web.reactive.function.client.WebClient;
import reactor.core.publisher.Mono;

import java.time.Duration;
import java.time.LocalDateTime;
import java.util.*;
import java.util.concurrent.CompletableFuture;
import java.util.stream.Collectors;

/**
 * ML Add-on Orchestrator Service.
 * 
 * 기사 분석 요청을 받아 등록된 Add-on들에게 분배하고,
 * 결과를 수집하여 ArticleAnalysis/ArticleDiscussion에 저장.
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class AddonOrchestratorService {

    private final MlAddonRepository addonRepository;
    private final MlAddonExecutionRepository executionRepository;
    private final ArticleAnalysisRepository analysisRepository;
    private final ArticleDiscussionRepository discussionRepository;
    private final CollectedDataRepository collectedDataRepository;
    private final WebClient.Builder webClientBuilder;
    private final AnalysisEventService analysisEventService;

    /**
     * 단일 기사에 대해 모든 활성화된 Add-on 실행.
     * 
     * @param articleId 분석할 기사 ID
     * @param importance 중요도 (realtime / batch)
     * @return 배치 ID
     */
    @Async
    public CompletableFuture<String> analyzeArticle(Long articleId, String importance) {
        String batchId = UUID.randomUUID().toString();
        log.info("Starting article analysis: articleId={}, batchId={}, importance={}", articleId, batchId, importance);

        // 기사 조회
        CollectedData article = collectedDataRepository.findById(articleId)
                .orElseThrow(() -> new IllegalArgumentException("Article not found: " + articleId));

        // 활성화된 Add-on 목록 조회 (우선순위 순)
        List<MlAddon> addons = addonRepository.findByEnabledTrueOrderByPriorityAsc();
        
        if (addons.isEmpty()) {
            log.warn("No enabled Add-ons found");
            return CompletableFuture.completedFuture(batchId);
        }

        // 의존성 없는 Add-on들은 병렬 실행, 의존성 있는 것들은 순차 실행
        Map<String, AddonResponse> results = new HashMap<>();
        List<MlAddon> pendingAddons = new ArrayList<>(addons);

        while (!pendingAddons.isEmpty()) {
            // 현재 실행 가능한 Add-on 찾기 (의존성이 모두 충족된 것들)
            List<MlAddon> readyAddons = pendingAddons.stream()
                    .filter(addon -> areDependenciesSatisfied(addon, results.keySet()))
                    .collect(Collectors.toList());

            if (readyAddons.isEmpty() && !pendingAddons.isEmpty()) {
                log.warn("Circular dependency or missing addon detected. Remaining: {}", 
                        pendingAddons.stream().map(MlAddon::getAddonKey).collect(Collectors.toList()));
                break;
            }

            // 병렬 실행
            List<CompletableFuture<AddonResponse>> futures = readyAddons.stream()
                    .map(addon -> executeAddon(addon, article, batchId, importance, results))
                    .collect(Collectors.toList());

            // 모든 실행 완료 대기
            CompletableFuture.allOf(futures.toArray(new CompletableFuture[0])).join();

            // 결과 수집
            for (int i = 0; i < readyAddons.size(); i++) {
                MlAddon addon = readyAddons.get(i);
                try {
                    AddonResponse response = futures.get(i).get();
                    if (response != null && "success".equals(response.getStatus())) {
                        results.put(addon.getAddonKey(), response);
                    }
                } catch (Exception e) {
                    log.error("Failed to get result for addon: {}", addon.getAddonKey(), e);
                }
            }

            pendingAddons.removeAll(readyAddons);
        }

        // 결과를 ArticleAnalysis에 저장
        saveAnalysisResults(articleId, results);

        saveDiscussionResults(articleId, results);

        log.info("Article analysis completed: articleId={}, batchId={}, addonsExecuted={}", 
                articleId, batchId, results.size());

        return CompletableFuture.completedFuture(batchId);
    }

    @Transactional
    public void saveDiscussionResults(Long articleId, Map<String, AddonResponse> results) {
        ArticleDiscussion discussion = discussionRepository.findByArticleId(articleId)
                .orElse(ArticleDiscussion.builder().articleId(articleId).build());

        List<String> analyzedBy = discussion.getAnalyzedBy() != null
                ? new ArrayList<>(discussion.getAnalyzedBy())
                : new ArrayList<>();

        boolean updated = false;

        for (Map.Entry<String, AddonResponse> entry : results.entrySet()) {
            String addonKey = entry.getKey();
            AddonResponse response = entry.getValue();

            if (response == null || response.getResults() == null) continue;

            AddonResponse.AnalysisResults r = response.getResults();
            if (r.getDiscussion() == null) continue;

            AddonResponse.DiscussionResult d = r.getDiscussion();

            if (d.getOverallSentiment() != null) discussion.setOverallSentiment(d.getOverallSentiment());
            if (d.getSentimentDistribution() != null) discussion.setSentimentDistribution(d.getSentimentDistribution());
            if (d.getStanceDistribution() != null) discussion.setStanceDistribution(d.getStanceDistribution());
            if (d.getToxicityScore() != null) discussion.setToxicityScore(d.getToxicityScore());
            if (d.getTopKeywords() != null) discussion.setTopKeywords(d.getTopKeywords());
            if (d.getTimeSeries() != null) discussion.setTimeSeries(d.getTimeSeries());

            if (d.getBotLikelihood() != null) {
                discussion.setBotLikelihoodScore(d.getBotLikelihood());
                discussion.setSuspiciousPatternDetected(d.getBotLikelihood() >= 0.7);
            }

            if (r.getRaw() != null) {
                Object totalObj = r.getRaw().get("total");
                if (totalObj instanceof Number n) {
                    discussion.setTotalCommentCount(n.intValue());
                    discussion.setAnalyzedCount(n.intValue());
                }

                Object reasonsObj = r.getRaw().get("detection_reasons");
                if (reasonsObj instanceof List<?> list) {
                    List<String> reasons = list.stream()
                            .filter(Objects::nonNull)
                            .map(Object::toString)
                            .collect(Collectors.toList());
                    discussion.setSuspiciousPatterns(reasons);
                }
            }

            analyzedBy.add(addonKey);
            updated = true;
        }

        if (!updated) return;

        discussion.setAnalyzedBy(analyzedBy.stream().distinct().collect(Collectors.toList()));
        ArticleDiscussion savedDiscussion = discussionRepository.save(discussion);

        analysisEventService.publishDiscussionComplete(articleId, savedDiscussion);
    }

    /**
     * 여러 기사 일괄 분석.
     */
    @Async
    public CompletableFuture<String> analyzeArticles(List<Long> articleIds, String importance) {
        String batchId = UUID.randomUUID().toString();
        log.info("Starting batch analysis: articleCount={}, batchId={}", articleIds.size(), batchId);

        for (Long articleId : articleIds) {
            try {
                analyzeArticle(articleId, importance).join();
            } catch (Exception e) {
                log.error("Failed to analyze article: {}", articleId, e);
            }
        }

        return CompletableFuture.completedFuture(batchId);
    }

    /**
     * 특정 카테고리의 Add-on만 실행.
     */
    @Async
    public CompletableFuture<AddonResponse> executeCategory(Long articleId, AddonCategory category) {
        List<MlAddon> addons = addonRepository.findByCategoryAndEnabledTrue(category);
        if (addons.isEmpty()) {
            log.warn("No enabled addon found for category: {}", category);
            return CompletableFuture.completedFuture(null);
        }

        CollectedData article = collectedDataRepository.findById(articleId)
                .orElseThrow(() -> new IllegalArgumentException("Article not found: " + articleId));

        // 첫 번째 활성화된 Add-on 실행
        MlAddon addon = addons.get(0);
        return executeAddon(addon, article, UUID.randomUUID().toString(), "batch", new HashMap<>());
    }

    /**
     * 개별 Add-on 실행.
     */
    private CompletableFuture<AddonResponse> executeAddon(
            MlAddon addon,
            CollectedData article,
            String batchId,
            String importance,
            Map<String, AddonResponse> previousResults
    ) {
        String requestId = UUID.randomUUID().toString();

        // 실행 기록 생성
        MlAddonExecution execution = MlAddonExecution.builder()
                .requestId(requestId)
                .batchId(batchId)
                .addon(addon)
                .articleId(article.getId())
                .importance(importance)
                .status(ExecutionStatus.PENDING)
                .build();
        executionRepository.save(execution);

        // 요청 페이로드 생성
        AddonRequest request = buildRequest(requestId, addon, article, previousResults, importance);

        // 실행 시작
        execution.markStarted();
        executionRepository.save(execution);

        // SSE 이벤트 발행: 분석 시작
        analysisEventService.publishAnalysisStarted(article.getId(), addon.getAddonKey());

        // Add-on 호출
        return callAddon(addon, request)
                .map(response -> {
                    // 성공 처리
                    execution.markSuccess(
                            response.getResults() != null ? Map.of("results", response.getResults()) : null,
                            response.getMeta() != null ? response.getMeta().getModelVersion() : null
                    );
                    addon.incrementSuccess(execution.getLatencyMs());
                    executionRepository.save(execution);
                    addonRepository.save(addon);

                    // SSE 이벤트 발행: 부분 결과
                    if (response.getResults() != null) {
                        Map<String, Object> partialResult = new HashMap<>();
                        AddonResponse.AnalysisResults r = response.getResults();
                        if (r.getSentiment() != null) {
                            partialResult.put("sentimentLabel", r.getSentiment().getLabel());
                            partialResult.put("sentimentScore", r.getSentiment().getScore());
                        }
                        if (r.getReliability() != null) {
                            partialResult.put("reliabilityScore", r.getReliability().getScore());
                            partialResult.put("reliabilityGrade", r.getReliability().getGrade());
                        }
                        if (r.getBias() != null) {
                            partialResult.put("biasLabel", r.getBias().getLabel());
                            partialResult.put("biasScore", r.getBias().getScore());
                        }
                        analysisEventService.publishPartialResult(article.getId(), addon.getAddonKey(), partialResult);
                    }

                    return response;
                })
                .onErrorResume(error -> {
                    // 실패 처리
                    execution.markFailed("EXECUTION_ERROR", error.getMessage());
                    addon.incrementFailure();
                    executionRepository.save(execution);
                    addonRepository.save(addon);
                    log.error("Addon execution failed: addon={}, error={}", addon.getAddonKey(), error.getMessage());

                    // SSE 이벤트 발행: 에러
                    analysisEventService.publishAnalysisError(article.getId(), addon.getAddonKey(), error.getMessage());

                    return Mono.empty();
                })
                .toFuture();
    }

    /**
     * Add-on HTTP 호출.
     */
    private Mono<AddonResponse> callAddon(MlAddon addon, AddonRequest request) {
        if (!addon.isHttpBased()) {
            log.warn("Non-HTTP addon not yet supported: {}", addon.getInvokeType());
            return Mono.empty();
        }

        WebClient client = webClientBuilder.build();
        
        return client.post()
                .uri(addon.getEndpointUrl())
                .contentType(MediaType.APPLICATION_JSON)
                .headers(headers -> {
                    // 인증 헤더 추가
                    if (addon.getAuthType() == AddonAuthType.API_KEY && addon.getAuthCredentials() != null) {
                        headers.set("X-API-Key", addon.getAuthCredentials());
                    } else if (addon.getAuthType() == AddonAuthType.BEARER_TOKEN && addon.getAuthCredentials() != null) {
                        headers.setBearerAuth(addon.getAuthCredentials());
                    }
                })
                .bodyValue(request)
                .retrieve()
                .bodyToMono(AddonResponse.class)
                .timeout(Duration.ofMillis(addon.getTimeoutMs()))
                .doOnSubscribe(s -> log.debug("Calling addon: {} at {}", addon.getAddonKey(), addon.getEndpointUrl()))
                .doOnSuccess(r -> log.debug("Addon response received: {}", addon.getAddonKey()));
    }

    /**
     * 요청 페이로드 생성.
     */
    private AddonRequest buildRequest(
            String requestId,
            MlAddon addon,
            CollectedData article,
            Map<String, AddonResponse> previousResults,
            String importance
    ) {
        return AddonRequest.builder()
                .requestId(requestId)
                .addonId(addon.getAddonKey())
                .task("article_analysis")
                .inputSchemaVersion(addon.getInputSchemaVersion())
                .article(AddonRequest.ArticleInput.builder()
                        .id(article.getId())
                        .title(article.getTitle())
                        .content(article.getContent())
                        .url(article.getUrl())
                        .publishedAt(article.getPublishedDate() != null ? article.getPublishedDate().toString() : null)
                        .build())
                .context(AddonRequest.AnalysisContext.builder()
                        .language("ko")
                        .country("KR")
                        .previousResults(previousResults.entrySet().stream()
                                .collect(Collectors.toMap(
                                        Map.Entry::getKey,
                                        e -> e.getValue().getResults()
                                )))
                        .build())
                .options(AddonRequest.ExecutionOptions.builder()
                        .importance(importance)
                        .timeoutMs(addon.getTimeoutMs())
                        .build())
                .build();
    }

    /**
     * 의존성 충족 여부 확인.
     */
    private boolean areDependenciesSatisfied(MlAddon addon, Set<String> completedAddons) {
        if (addon.getDependsOn() == null || addon.getDependsOn().isEmpty()) {
            return true;
        }
        return completedAddons.containsAll(addon.getDependsOn());
    }

    /**
     * 분석 결과를 ArticleAnalysis에 저장.
     */
    @Transactional
    public void saveAnalysisResults(Long articleId, Map<String, AddonResponse> results) {
        ArticleAnalysis analysis = analysisRepository.findByArticleId(articleId)
                .orElse(ArticleAnalysis.builder().articleId(articleId).build());

        List<String> analyzedBy = new ArrayList<>();
        Map<String, Boolean> analysisStatus = new HashMap<>();

        for (Map.Entry<String, AddonResponse> entry : results.entrySet()) {
            String addonKey = entry.getKey();
            AddonResponse response = entry.getValue();
            
            if (response == null || response.getResults() == null) continue;

            analyzedBy.add(addonKey);
            analysisStatus.put(addonKey, true);

            AddonResponse.AnalysisResults r = response.getResults();

            // 감정 분석 결과 저장
            if (r.getSentiment() != null) {
                analysis.setSentimentScore(r.getSentiment().getScore());
                analysis.setSentimentLabel(r.getSentiment().getLabel());
                analysis.setSentimentDistribution(r.getSentiment().getDistribution());
            }

            // 신뢰도 결과 저장
            if (r.getReliability() != null) {
                analysis.setReliabilityScore(r.getReliability().getScore());
                analysis.setReliabilityGrade(r.getReliability().getGrade());
                analysis.setReliabilityFactors(r.getReliability().getFactors());
            }

            // 편향도 결과 저장
            if (r.getBias() != null) {
                analysis.setBiasLabel(r.getBias().getLabel());
                analysis.setBiasScore(r.getBias().getScore());
                analysis.setBiasDetails(r.getBias().getDetails());
            }

            // 팩트체크 결과 저장
            if (r.getFactcheck() != null) {
                analysis.setFactcheckStatus(r.getFactcheck().getStatus());
                analysis.setFactcheckNotes(r.getFactcheck().getNotes());
            }

            // 요약 결과 저장
            if (r.getSummary() != null) {
                analysis.setSummary(r.getSummary().getAbstractiveSummary());
                analysis.setKeySentences(r.getSummary().getExtractiveSentences());
            }

            // 주제 분류 결과 저장
            if (r.getTopics() != null) {
                analysis.setTopics(r.getTopics().getLabels());
                analysis.setTopicScores(r.getTopics().getScores());
            }

            // 허위정보 결과 저장
            if (r.getMisinformation() != null) {
                analysis.setMisinfoRisk(r.getMisinformation().getRiskLevel());
                analysis.setMisinfoScore(r.getMisinformation().getScore());
            }

            // 독성 분석 결과 저장
            if (r.getToxicity() != null) {
                analysis.setToxicityScore(r.getToxicity().getScore());
            }
        }

        analysis.setAnalyzedBy(analyzedBy);
        analysis.setAnalysisStatus(analysisStatus);
        analysis.setFullyAnalyzed(!results.isEmpty());

        ArticleAnalysis savedAnalysis = analysisRepository.save(analysis);
        log.info("Saved analysis results for article: {}, addons: {}", articleId, analyzedBy);

        // SSE 이벤트 발행: 분석 완료
        analysisEventService.publishAnalysisComplete(articleId, savedAnalysis);
    }

    /**
     * Add-on 헬스체크 실행.
     */
    @Async
    public void runHealthChecks() {
        LocalDateTime cutoff = LocalDateTime.now().minusMinutes(5);
        List<MlAddon> addons = addonRepository.findAddonsNeedingHealthCheck(cutoff);

        for (MlAddon addon : addons) {
            try {
                WebClient client = webClientBuilder.build();
                client.get()
                        .uri(addon.getHealthCheckUrl())
                        .retrieve()
                        .toBodilessEntity()
                        .timeout(Duration.ofSeconds(10))
                        .subscribe(
                                response -> {
                                    addonRepository.updateHealthStatus(addon.getId(), AddonHealthStatus.HEALTHY, LocalDateTime.now());
                                    log.debug("Health check passed: {}", addon.getAddonKey());
                                },
                                error -> {
                                    addonRepository.updateHealthStatus(addon.getId(), AddonHealthStatus.UNHEALTHY, LocalDateTime.now());
                                    log.warn("Health check failed: {}", addon.getAddonKey());
                                }
                        );
            } catch (Exception e) {
                log.error("Health check error for addon: {}", addon.getAddonKey(), e);
            }
        }
    }

    /**
     * 특정 Add-on으로 직접 분석 실행 (커스텀 입력, 기사 ID 없이).
     * 프론트엔드에서 직접 호출 시 사용.
     * 
     * @param addon 실행할 Add-on
     * @param articleData 기사 데이터 (title, content, url 등)
     * @param requestId 요청 ID
     * @param importance 중요도
     * @return 분석 결과
     */
    public AddonResponse executeAddonDirect(
            MlAddon addon,
            Map<String, Object> articleData,
            String requestId,
            String importance
    ) {
        log.info("Direct addon execution: addon={}, requestId={}", addon.getAddonKey(), requestId);
        
        // 요청 페이로드 생성
        AddonRequest request = AddonRequest.builder()
                .requestId(requestId)
                .addonId(addon.getAddonKey())
                .task("direct_analysis")
                .inputSchemaVersion(addon.getInputSchemaVersion())
                .article(AddonRequest.ArticleInput.builder()
                        .id(articleData.get("id") != null ? Long.parseLong(articleData.get("id").toString()) : null)
                        .title((String) articleData.get("title"))
                        .content((String) articleData.get("content"))
                        .url((String) articleData.get("url"))
                        .source((String) articleData.get("source"))
                        .publishedAt((String) articleData.get("publishedAt"))
                        .build())
                .context(AddonRequest.AnalysisContext.builder()
                        .language("ko")
                        .country("KR")
                        .build())
                .options(AddonRequest.ExecutionOptions.builder()
                        .importance(importance)
                        .timeoutMs(addon.getTimeoutMs())
                        .build())
                .build();
        
        // 실행 기록 생성
        MlAddonExecution execution = MlAddonExecution.builder()
                .requestId(requestId)
                .batchId(null)
                .addon(addon)
                .articleId(articleData.get("id") != null ? Long.parseLong(articleData.get("id").toString()) : null)
                .importance(importance)
                .status(ExecutionStatus.PENDING)
                .build();
        executionRepository.save(execution);
        
        execution.markStarted();
        executionRepository.save(execution);
        
        try {
            // Add-on 호출 (동기)
            AddonResponse response = callAddon(addon, request)
                    .block(Duration.ofMillis(addon.getTimeoutMs() + 5000));
            
            if (response != null && "success".equals(response.getStatus())) {
                execution.markSuccess(
                        response.getResults() != null ? Map.of("results", response.getResults()) : null,
                        response.getMeta() != null ? response.getMeta().getModelVersion() : null
                );
                addon.incrementSuccess(execution.getLatencyMs());
            } else {
                String errorMsg = response != null && response.getError() != null 
                        ? response.getError().getMessage() 
                        : "Unknown error";
                execution.markFailed("ADDON_ERROR", errorMsg);
                addon.incrementFailure();
            }
            
            executionRepository.save(execution);
            addonRepository.save(addon);
            
            return response;
        } catch (Exception e) {
            execution.markFailed("EXECUTION_ERROR", e.getMessage());
            addon.incrementFailure();
            executionRepository.save(execution);
            addonRepository.save(addon);
            log.error("Direct addon execution failed: addon={}, error={}", addon.getAddonKey(), e.getMessage());
            throw new RuntimeException("Addon execution failed: " + e.getMessage(), e);
        }
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/AiMessagingService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.dto.AiRequestMessage;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Service;

import java.time.OffsetDateTime;
import java.util.Map;
import java.util.UUID;

@Service
@RequiredArgsConstructor
@Slf4j
public class AiMessagingService {

    private final KafkaTemplate<String, AiRequestMessage> aiRequestKafkaTemplate;

    @Value("${collector.ai.topic.request:newsinsight.ai.requests}")
    private String requestTopic;

    @Value("${collector.ai.default-provider-id:openai}")
    private String defaultProviderId;

    @Value("${collector.ai.default-model-id:gpt-4.1}")
    private String defaultModelId;

    public String sendAnalysisRequest(String query, String window, String message, Map<String, Object> context) {
        String requestId = UUID.randomUUID().toString();
        String type = "ARTICLE_ANALYSIS";
        String effectiveWindow = (window == null || window.isBlank()) ? "7d" : window;
        AiRequestMessage payload = new AiRequestMessage(
                requestId,
                type,
                query,
                effectiveWindow,
                message,
                context,
                defaultProviderId,
                defaultModelId,
                null,
                null,
                "collector-service"
        );
        aiRequestKafkaTemplate.send(requestTopic, requestId, payload);
        log.info("Sent AI analysis request {} to topic {} at {}", requestId, requestTopic, OffsetDateTime.now());
        return requestId;
    }

    public String sendAnalysisRequestWithRole(
            String query,
            String window,
            String message,
            Map<String, Object> context,
            String agentRole,
            String outputSchema
    ) {
        String requestId = UUID.randomUUID().toString();
        String type = "ARTICLE_ANALYSIS";
        String effectiveWindow = (window == null || window.isBlank()) ? "7d" : window;
        AiRequestMessage payload = new AiRequestMessage(
                requestId,
                type,
                query,
                effectiveWindow,
                message,
                context,
                defaultProviderId,
                defaultModelId,
                agentRole,
                outputSchema,
                "collector-service"
        );
        aiRequestKafkaTemplate.send(requestTopic, requestId, payload);
        log.info("Sent AI analysis request {} (role={}) to topic {} at {}", requestId, agentRole, requestTopic, OffsetDateTime.now());
        return requestId;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/AiProviderFallbackService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.client.AIDoveClient;
import com.newsinsight.collector.client.OpenAICompatibleClient;
import com.newsinsight.collector.client.PerplexityClient;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;
import reactor.core.publisher.Flux;
import reactor.core.publisher.Mono;

import java.time.Duration;
import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.function.Supplier;

/**
 * AI Provider Fallback Chain Service.
 * Provides resilient AI completion by trying multiple providers in sequence.
 * 
 * Fallback order:
 * 1. Perplexity (if enabled) - Best for fact-checking with online search
 * 2. OpenAI (if enabled)
 * 3. OpenRouter (if enabled)
 * 4. Azure OpenAI (if enabled)
 * 5. AI Dove (if enabled) - n8n webhook
 * 6. Ollama (local) - Last resort
 * 7. Custom endpoint (if enabled)
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class AiProviderFallbackService {

    private final PerplexityClient perplexityClient;
    private final OpenAICompatibleClient openAICompatibleClient;
    private final AIDoveClient aiDoveClient;

    /**
     * Stream completion using fallback chain.
     * Tries each available provider in order until one succeeds.
     * 
     * @param prompt The prompt to send
     * @return Flux of response chunks
     */
    public Flux<String> streamCompletionWithFallback(String prompt) {
        List<ProviderAttempt> providers = buildProviderChain(prompt);
        
        if (providers.isEmpty()) {
            log.error("No AI providers are available");
            return Flux.just("AI 분석을 수행할 수 없습니다. 설정된 AI 제공자가 없습니다.");
        }

        log.info("AI fallback chain initialized with {} providers: {}", 
                providers.size(), 
                providers.stream().map(ProviderAttempt::name).toList());

        return tryProvidersInSequence(providers, 0);
    }

    /**
     * Get completion (non-streaming) using fallback chain.
     * Collects all chunks into a single string.
     * 
     * @param prompt The prompt to send
     * @return Mono of complete response
     */
    public Mono<String> getCompletionWithFallback(String prompt) {
        return streamCompletionWithFallback(prompt)
                .collectList()
                .map(chunks -> String.join("", chunks));
    }

    /**
     * Check which providers are currently available
     */
    public List<String> getAvailableProviders() {
        List<String> available = new ArrayList<>();
        
        if (perplexityClient.isEnabled()) {
            available.add("Perplexity");
        }
        if (openAICompatibleClient.isOpenAIEnabled()) {
            available.add("OpenAI");
        }
        if (openAICompatibleClient.isOpenRouterEnabled()) {
            available.add("OpenRouter");
        }
        if (openAICompatibleClient.isAzureEnabled()) {
            available.add("Azure OpenAI");
        }
        if (aiDoveClient.isEnabled()) {
            available.add("AI Dove");
        }
        if (openAICompatibleClient.isOllamaEnabled()) {
            available.add("Ollama");
        }
        if (openAICompatibleClient.isCustomEnabled()) {
            available.add("Custom");
        }
        
        return available;
    }

    /**
     * Check if any AI provider is available
     */
    public boolean isAnyProviderAvailable() {
        return perplexityClient.isEnabled() 
                || openAICompatibleClient.isEnabled()
                || aiDoveClient.isEnabled();
    }

    /**
     * Build the provider chain based on availability
     */
    private List<ProviderAttempt> buildProviderChain(String prompt) {
        List<ProviderAttempt> chain = new ArrayList<>();

        // 1. Perplexity - Best for fact-checking with online search capabilities
        if (perplexityClient.isEnabled()) {
            chain.add(new ProviderAttempt(
                    "Perplexity",
                    () -> perplexityClient.streamCompletion(prompt)
            ));
        }

        // 2. OpenAI
        if (openAICompatibleClient.isOpenAIEnabled()) {
            chain.add(new ProviderAttempt(
                    "OpenAI",
                    () -> openAICompatibleClient.streamFromOpenAI(prompt)
            ));
        }

        // 3. OpenRouter - Access to multiple models
        if (openAICompatibleClient.isOpenRouterEnabled()) {
            chain.add(new ProviderAttempt(
                    "OpenRouter",
                    () -> openAICompatibleClient.streamFromOpenRouter(prompt)
            ));
        }

        // 4. Azure OpenAI
        if (openAICompatibleClient.isAzureEnabled()) {
            chain.add(new ProviderAttempt(
                    "Azure OpenAI",
                    () -> openAICompatibleClient.streamFromAzure(prompt)
            ));
        }

        // 5. AI Dove (n8n webhook) - Simulated streaming
        if (aiDoveClient.isEnabled()) {
            chain.add(new ProviderAttempt(
                    "AI Dove",
                    () -> aiDoveClient.chatStream(prompt, null)
            ));
        }

        // 6. Ollama - Local LLM (always available but may not be running)
        chain.add(new ProviderAttempt(
                "Ollama",
                () -> openAICompatibleClient.streamFromOllama(prompt)
        ));

        // 7. Custom endpoint
        if (openAICompatibleClient.isCustomEnabled()) {
            chain.add(new ProviderAttempt(
                    "Custom",
                    () -> openAICompatibleClient.streamFromCustom(prompt)
            ));
        }

        return chain;
    }

    /**
     * Try providers in sequence until one succeeds
     */
    private Flux<String> tryProvidersInSequence(List<ProviderAttempt> providers, int index) {
        if (index >= providers.size()) {
            log.error("All AI providers failed");
            return Flux.just("모든 AI 제공자 연결에 실패했습니다. 나중에 다시 시도해주세요.");
        }

        ProviderAttempt current = providers.get(index);
        log.info("Attempting AI provider: {} (attempt {}/{})", current.name(), index + 1, providers.size());

        AtomicInteger chunkCount = new AtomicInteger(0);

        return current.streamSupplier().get()
                .timeout(Duration.ofSeconds(90))
                .doOnNext(chunk -> chunkCount.incrementAndGet())
                .doOnComplete(() -> {
                    if (chunkCount.get() > 0) {
                        log.info("AI provider {} completed successfully with {} chunks", 
                                current.name(), chunkCount.get());
                    }
                })
                .onErrorResume(e -> {
                    log.warn("AI provider {} failed: {}. Trying next provider...", 
                            current.name(), e.getMessage());
                    return tryProvidersInSequence(providers, index + 1);
                })
                .switchIfEmpty(Flux.defer(() -> {
                    log.warn("AI provider {} returned empty response. Trying next provider...", 
                            current.name());
                    return tryProvidersInSequence(providers, index + 1);
                }));
    }

    /**
     * Provider attempt wrapper
     */
    private record ProviderAttempt(
            String name,
            Supplier<Flux<String>> streamSupplier
    ) {}
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/AiResultConsumerService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.dto.AiResponseMessage;
import com.newsinsight.collector.mongo.AiResponseDocument;
import com.newsinsight.collector.mongo.AiResponseRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Service;

import java.time.Instant;

@Service
@RequiredArgsConstructor
@Slf4j
public class AiResultConsumerService {

    private final AiResponseRepository aiResponseRepository;

    @KafkaListener(
            topics = "${collector.ai.topic.response:newsinsight.ai.responses}",
            groupId = "${spring.application.name}-ai",
            containerFactory = "aiResponseKafkaListenerContainerFactory"
    )
    public void handleAiResponse(AiResponseMessage message) {
        log.info("Received AI response requestId={} status={} model={}",
                message.requestId(), message.status(), message.modelId());

        AiResponseDocument document = new AiResponseDocument(
                message.requestId(),
                message.status(),
                message.completedAt(),
                message.providerId(),
                message.modelId(),
                message.text(),
                message.raw(),
                Instant.now()
        );

        aiResponseRepository.save(document);
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/AnalysisEventService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.entity.analysis.ArticleAnalysis;
import com.newsinsight.collector.entity.analysis.ArticleDiscussion;
import lombok.extern.slf4j.Slf4j;
import org.springframework.http.codec.ServerSentEvent;
import org.springframework.stereotype.Service;
import reactor.core.publisher.Flux;
import reactor.core.publisher.Sinks;

import java.time.Duration;
import java.util.HashMap;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;

/**
 * SSE 서비스 - 분석 결과 실시간 업데이트 알림
 * 
 * 프론트엔드가 특정 기사 ID들을 구독하면, 해당 기사의 분석이 완료될 때 알림을 받습니다.
 * 검색 결과 페이지에서 분석 중인 기사들의 상태를 실시간으로 업데이트할 때 사용합니다.
 */
@Service
@Slf4j
public class AnalysisEventService {

    // Global sink for all analysis updates (clients filter by articleId)
    private final Sinks.Many<ServerSentEvent<Object>> globalSink;
    
    // Track which article IDs are being watched
    private final Set<Long> watchedArticleIds = ConcurrentHashMap.newKeySet();
    
    // Subscriber count for cleanup
    private int subscriberCount = 0;

    public AnalysisEventService() {
        this.globalSink = Sinks.many().multicast().onBackpressureBuffer(500);
    }

    /**
     * Subscribe to analysis updates for specific article IDs.
     * 
     * @param articleIds Set of article IDs to watch
     * @return SSE event stream
     */
    public Flux<ServerSentEvent<Object>> subscribeToAnalysisUpdates(Set<Long> articleIds) {
        if (articleIds != null && !articleIds.isEmpty()) {
            watchedArticleIds.addAll(articleIds);
        }

        // Heartbeat stream
        Flux<ServerSentEvent<Object>> heartbeat = Flux.interval(Duration.ofSeconds(20))
                .map(tick -> ServerSentEvent.builder()
                        .event("heartbeat")
                        .data(Map.of("timestamp", System.currentTimeMillis()))
                        .build());

        // Filter events by article IDs if provided
        Flux<ServerSentEvent<Object>> events = globalSink.asFlux()
                .filter(event -> {
                    if (articleIds == null || articleIds.isEmpty()) {
                        return true; // No filter, receive all
                    }
                    Object data = event.data();
                    if (data instanceof Map<?, ?> dataMap) {
                        Object articleId = dataMap.get("articleId");
                        if (articleId instanceof Long id) {
                            return articleIds.contains(id);
                        }
                    }
                    return false;
                });

        return Flux.merge(heartbeat, events)
                .doOnSubscribe(sub -> {
                    subscriberCount++;
                    log.debug("New analysis updates subscriber, total: {}", subscriberCount);
                })
                .doOnCancel(() -> {
                    subscriberCount--;
                    log.debug("Analysis updates subscriber disconnected, total: {}", subscriberCount);
                    // Clean up watched IDs if no more subscribers
                    if (subscriberCount <= 0) {
                        watchedArticleIds.clear();
                    }
                });
    }

    /**
     * Publish analysis started event.
     * 
     * @param articleId The article ID
     * @param addonKey The addon that started analysis
     */
    public void publishAnalysisStarted(Long articleId, String addonKey) {
        if (!watchedArticleIds.contains(articleId)) return;

        ServerSentEvent<Object> event = ServerSentEvent.builder()
                .event("analysis_started")
                .data(Map.of(
                        "articleId", articleId,
                        "addonKey", addonKey,
                        "timestamp", System.currentTimeMillis()
                ))
                .build();

        globalSink.tryEmitNext(event);
        log.debug("Published analysis_started for article: {}, addon: {}", articleId, addonKey);
    }

    /**
     * Publish analysis progress event.
     * 
     * @param articleId The article ID
     * @param addonKey The addon processing
     * @param progress Progress percentage (0-100)
     */
    public void publishAnalysisProgress(Long articleId, String addonKey, int progress) {
        if (!watchedArticleIds.contains(articleId)) return;

        ServerSentEvent<Object> event = ServerSentEvent.builder()
                .event("analysis_progress")
                .data(Map.of(
                        "articleId", articleId,
                        "addonKey", addonKey,
                        "progress", progress,
                        "timestamp", System.currentTimeMillis()
                ))
                .build();

        globalSink.tryEmitNext(event);
    }

    /**
     * Publish partial analysis result (single addon completed).
     * 
     * @param articleId The article ID
     * @param addonKey The addon that completed
     * @param result The partial result data
     */
    public void publishPartialResult(Long articleId, String addonKey, Map<String, Object> result) {
        if (!watchedArticleIds.contains(articleId)) return;

        ServerSentEvent<Object> event = ServerSentEvent.builder()
                .event("analysis_partial")
                .data(Map.of(
                        "articleId", articleId,
                        "addonKey", addonKey,
                        "result", result,
                        "timestamp", System.currentTimeMillis()
                ))
                .build();

        globalSink.tryEmitNext(event);
        log.debug("Published partial analysis for article: {}, addon: {}", articleId, addonKey);
    }

    /**
     * Publish full analysis complete event.
     * 
     * @param articleId The article ID
     * @param analysis The complete analysis result
     */
    public void publishAnalysisComplete(Long articleId, ArticleAnalysis analysis) {
        // Build analysis map using HashMap since we have more than 10 entries
        Map<String, Object> analysisMap = new HashMap<>();
        analysisMap.put("reliabilityScore", analysis.getReliabilityScore() != null ? analysis.getReliabilityScore() : 0);
        analysisMap.put("reliabilityGrade", analysis.getReliabilityGrade() != null ? analysis.getReliabilityGrade() : "unknown");
        analysisMap.put("reliabilityColor", analysis.getReliabilityColor());
        analysisMap.put("sentimentLabel", analysis.getSentimentLabel() != null ? analysis.getSentimentLabel() : "neutral");
        analysisMap.put("sentimentScore", analysis.getSentimentScore() != null ? analysis.getSentimentScore() : 0);
        analysisMap.put("biasLabel", analysis.getBiasLabel());
        analysisMap.put("biasScore", analysis.getBiasScore());
        analysisMap.put("factcheckStatus", analysis.getFactcheckStatus());
        analysisMap.put("misinfoRisk", analysis.getMisinfoRisk());
        analysisMap.put("riskTags", analysis.getRiskTags());
        analysisMap.put("topics", analysis.getTopics());
        analysisMap.put("summary", analysis.getSummary());
        analysisMap.put("fullyAnalyzed", analysis.getFullyAnalyzed());

        ServerSentEvent<Object> event = ServerSentEvent.builder()
                .event("analysis_complete")
                .data(Map.of(
                        "articleId", articleId,
                        "analysis", analysisMap,
                        "timestamp", System.currentTimeMillis()
                ))
                .build();

        globalSink.tryEmitNext(event);
        log.info("Published analysis_complete for article: {}", articleId);
        
        // Remove from watched list
        watchedArticleIds.remove(articleId);
    }

    /**
     * Publish discussion analysis complete event.
     * 
     * @param articleId The article ID
     * @param discussion The discussion analysis result
     */
    public void publishDiscussionComplete(Long articleId, ArticleDiscussion discussion) {
        ServerSentEvent<Object> event = ServerSentEvent.builder()
                .event("discussion_complete")
                .data(Map.of(
                        "articleId", articleId,
                        "discussion", Map.of(
                                "totalCommentCount", discussion.getTotalCommentCount() != null ? discussion.getTotalCommentCount() : 0,
                                "overallSentiment", discussion.getOverallSentiment() != null ? discussion.getOverallSentiment() : "unknown",
                                "sentimentDistribution", discussion.getSentimentDistribution() != null ? discussion.getSentimentDistribution() : Map.of(),
                                "discussionQualityScore", discussion.getDiscussionQualityScore(),
                                "stanceDistribution", discussion.getStanceDistribution(),
                                "suspiciousPatternDetected", discussion.getSuspiciousPatternDetected()
                        ),
                        "timestamp", System.currentTimeMillis()
                ))
                .build();

        globalSink.tryEmitNext(event);
        log.info("Published discussion_complete for article: {}", articleId);
    }

    /**
     * Publish analysis error event.
     * 
     * @param articleId The article ID
     * @param addonKey The addon that failed
     * @param errorMessage Error description
     */
    public void publishAnalysisError(Long articleId, String addonKey, String errorMessage) {
        if (!watchedArticleIds.contains(articleId)) return;

        ServerSentEvent<Object> event = ServerSentEvent.builder()
                .event("analysis_error")
                .data(Map.of(
                        "articleId", articleId,
                        "addonKey", addonKey != null ? addonKey : "unknown",
                        "error", errorMessage,
                        "timestamp", System.currentTimeMillis()
                ))
                .build();

        globalSink.tryEmitNext(event);
        log.warn("Published analysis_error for article: {}, addon: {}", articleId, addonKey);
    }

    /**
     * Add article IDs to watch list.
     * 
     * @param articleIds Article IDs to watch
     */
    public void watchArticles(Set<Long> articleIds) {
        if (articleIds != null) {
            watchedArticleIds.addAll(articleIds);
        }
    }

    /**
     * Remove article ID from watch list.
     * 
     * @param articleId Article ID to stop watching
     */
    public void unwatchArticle(Long articleId) {
        watchedArticleIds.remove(articleId);
    }

    /**
     * Check if an article is being watched.
     * 
     * @param articleId The article ID
     * @return true if being watched
     */
    public boolean isWatched(Long articleId) {
        return watchedArticleIds.contains(articleId);
    }

    /**
     * Get count of watched articles.
     * 
     * @return Count of watched article IDs
     */
    public int getWatchedCount() {
        return watchedArticleIds.size();
    }

    /**
     * Get subscriber count.
     * 
     * @return Number of active subscribers
     */
    public int getSubscriberCount() {
        return subscriberCount;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/AnalysisService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.dto.AnalysisResponseDto;
import com.newsinsight.collector.dto.ArticleDto;
import com.newsinsight.collector.dto.ArticlesResponseDto;
import com.newsinsight.collector.dto.KeywordDataDto;
import com.newsinsight.collector.dto.SentimentDataDto;
import com.newsinsight.collector.entity.CollectedData;
import com.newsinsight.collector.entity.DataSource;
import com.newsinsight.collector.repository.CollectedDataRepository;
import com.newsinsight.collector.repository.DataSourceRepository;
import lombok.RequiredArgsConstructor;
import org.jsoup.Jsoup;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.PageRequest;
import org.springframework.data.domain.Pageable;
import org.springframework.data.domain.Sort;
import org.springframework.stereotype.Service;

import java.time.LocalDateTime;
import java.time.OffsetDateTime;
import java.util.*;

@Service
@RequiredArgsConstructor
public class AnalysisService {

    private static final int MAX_KEYWORD_DOCS = 200;
    private static final int SNIPPET_MAX_LENGTH = 200;

    private static final Set<String> STOP_WORDS = Set.of(
            "the", "and", "or", "a", "an", "of", "to", "in", "on", "for", "with",
            "이", "그", "저", "에서", "으로", "에게", "하다", "되다"
    );

    private final CollectedDataRepository collectedDataRepository;
    private final DataSourceRepository dataSourceRepository;
    private final AiMessagingService aiMessagingService;

    public AnalysisResponseDto analyze(String query, String window) {
        LocalDateTime now = LocalDateTime.now();
        String effectiveWindow = window;
        LocalDateTime since;
        switch (window) {
            case "1d" -> since = now.minusDays(1);
            case "30d" -> since = now.minusDays(30);
            case "7d" -> since = now.minusDays(7);
            default -> {
                since = now.minusDays(7);
                effectiveWindow = "7d";
            }
        }

        String normalizedQuery = (query != null && !query.isBlank()) ? query : null;
        String message = normalizedQuery != null ? normalizedQuery : "";
        aiMessagingService.sendAnalysisRequest(normalizedQuery, window, message, Map.of());
        Page<CollectedData> page = collectedDataRepository.searchByQueryAndSince(normalizedQuery, since, Pageable.unpaged());
        long articleCount = page.getTotalElements();

        List<CollectedData> documents = page.getContent();

        double pos = 0.0;
        double neg = 0.0;
        double neu = 0.0;

        for (CollectedData data : documents) {
            Double quality = data.getQualityScore();
            if (quality == null) {
                neu += 1.0;
            } else if (quality >= 0.66) {
                pos += 1.0;
            } else if (quality <= 0.33) {
                neg += 1.0;
            } else {
                neu += 1.0;
            }
        }

        if (pos == 0.0 && neg == 0.0 && neu == 0.0) {
            neu = 1.0;
        }

        SentimentDataDto sentiments = new SentimentDataDto(pos, neg, neu);
        List<KeywordDataDto> topKeywords = extractTopKeywords(documents, query);

        String analyzedAt = OffsetDateTime.now().toString();

        return new AnalysisResponseDto(query, effectiveWindow, articleCount, sentiments, topKeywords, analyzedAt);
    }

    public ArticlesResponseDto searchArticles(String query, int limit) {
        int pageSize = limit > 0 ? limit : 50;
        PageRequest pageRequest = PageRequest.of(0, pageSize,
                Sort.by(Sort.Direction.DESC, "publishedDate")
                        .and(Sort.by(Sort.Direction.DESC, "collectedAt")));
        String normalizedQuery = (query != null && !query.isBlank()) ? query : null;
        Page<CollectedData> page = collectedDataRepository.searchByQuery(normalizedQuery, pageRequest);

        List<ArticleDto> articles = page.getContent().stream()
                .map(this::toArticleDto)
                .toList();

        return new ArticlesResponseDto(query, articles, page.getTotalElements());
    }

    private ArticleDto toArticleDto(CollectedData data) {
        String id = data.getId() != null ? data.getId().toString() : null;
        String title = data.getTitle();
        DataSource source = data.getSourceId() != null
                ? dataSourceRepository.findById(data.getSourceId()).orElse(null)
                : null;
        String sourceName = source != null ? source.getName() : "Unknown";

        String publishedAt;
        if (data.getPublishedDate() != null) {
            publishedAt = data.getPublishedDate().toString();
        } else if (data.getCollectedAt() != null) {
            publishedAt = data.getCollectedAt().toString();
        } else {
            publishedAt = null;
        }

        String url = data.getUrl();
        // 원본 콘텐츠를 보존하면서 정제된 텍스트 생성
        String rawContent = data.getContent();
        String cleanedContent = cleanContent(rawContent);
        String snippet = buildSnippetFromCleanText(cleanedContent);

        return new ArticleDto(id, title, sourceName, publishedAt, url, snippet, cleanedContent);
    }

    private List<KeywordDataDto> extractTopKeywords(List<CollectedData> documents, String query) {
        if (documents == null || documents.isEmpty()) {
            return List.of();
        }

        Map<String, Integer> freq = new HashMap<>();
        int docCount = 0;

        for (CollectedData data : documents) {
            if (docCount >= MAX_KEYWORD_DOCS) {
                break;
            }
            docCount++;

            StringBuilder sb = new StringBuilder();
            if (data.getTitle() != null) {
                sb.append(data.getTitle()).append(' ');
            }
            if (data.getContent() != null) {
                sb.append(data.getContent());
            }

            String text;
            try {
                text = Jsoup.parse(sb.toString()).text();
            } catch (Exception e) {
                text = sb.toString();
            }

            text = text.toLowerCase(Locale.ROOT);
            String[] tokens = text.split("[^\\p{L}0-9]+");
            for (String token : tokens) {
                if (token == null || token.isBlank()) continue;
                if (token.length() <= 1) continue;
                if (STOP_WORDS.contains(token)) continue;
                if (query != null && token.equalsIgnoreCase(query)) continue;

                // @CHECK 
                // token이 null이 될 수 있음 
                freq.merge(token, 1, Integer::sum);
            }
        }

        if (freq.isEmpty()) {
            return query == null || query.isBlank()
                    ? List.of()
                    : List.of(new KeywordDataDto(query, 1.0));
        }

        return freq.entrySet().stream()
                .sorted(Map.Entry.<String, Integer>comparingByValue().reversed())
                .limit(10)
                .map(e -> new KeywordDataDto(e.getKey(), e.getValue()))
                .toList();
    }

    /**
     * 이미 정제된 텍스트에서 snippet 생성 (HTML 파싱 불필요)
     */
    private String buildSnippetFromCleanText(String cleanText) {
        if (cleanText == null || cleanText.isBlank()) {
            return null;
        }

        if (cleanText.length() <= SNIPPET_MAX_LENGTH) {
            return cleanText;
        }

        // 단어 경계에서 자르기
        int cut = SNIPPET_MAX_LENGTH;
        for (int i = Math.min(SNIPPET_MAX_LENGTH - 1, cleanText.length() - 1); 
             i > SNIPPET_MAX_LENGTH * 0.6 && i >= 0; i--) {
            if (Character.isWhitespace(cleanText.charAt(i))) {
                cut = i;
                break;
            }
        }

        return cleanText.substring(0, cut).trim() + "...";
    }

    /**
     * 레거시 호환성을 위한 buildSnippet (HTML 파싱 포함)
     */
    private String buildSnippet(String content) {
        if (content == null || content.isBlank()) {
            return null;
        }

        String text;
        try {
            text = Jsoup.parse(content).text();
        } catch (Exception e) {
            text = content;
        }

        text = text.replaceAll("\\s+", " ").trim();
        if (text.isEmpty()) {
            return null;
        }

        if (text.length() <= SNIPPET_MAX_LENGTH) {
            return text;
        }

        int startIdx = Math.min(SNIPPET_MAX_LENGTH - 1, text.length() - 1);
        int cut = SNIPPET_MAX_LENGTH;
        for (int i = startIdx; i > SNIPPET_MAX_LENGTH * 0.6 && i >= 0; i--) {
            if (Character.isWhitespace(text.charAt(i))) {
                cut = i;
                break;
            }
        }

        return text.substring(0, cut).trim() + "...";
    }

    /**
     * HTML 태그를 제거하고 정리된 전체 텍스트를 반환합니다.
     * snippet과 달리 길이 제한 없이 전체 내용을 반환합니다.
     * 
     * 중요: 이 메서드는 원본 텍스트 내용을 최대한 보존하며,
     * HTML 태그만 제거하고 실제 텍스트 데이터는 변경하지 않습니다.
     *
     * @param content 원본 콘텐츠 (HTML 포함 가능)
     * @return 정리된 전체 텍스트 (원본 데이터 보존)
     */
    private String cleanContent(String content) {
        if (content == null || content.isBlank()) {
            return null;
        }

        String text;
        try {
            // Jsoup을 사용하여 HTML 태그만 제거, 텍스트 내용은 보존
            text = Jsoup.parse(content).text();
        } catch (Exception e) {
            // HTML 파싱 실패 시 원본 그대로 사용
            text = content;
        }

        // 연속 공백만 정리 (실제 텍스트 내용은 변경하지 않음)
        text = text.replaceAll("\\s+", " ").trim();
        
        return text.isEmpty() ? null : text;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/ChatSyncService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.entity.chat.ChatHistory;
import com.newsinsight.collector.entity.chat.FactCheckChatSession;
import com.newsinsight.collector.repository.ChatHistoryRepository;
import com.newsinsight.collector.repository.FactCheckChatSessionRepository;
import io.micrometer.core.instrument.Counter;
import io.micrometer.core.instrument.MeterRegistry;
import io.micrometer.core.instrument.Timer;
import jakarta.annotation.PostConstruct;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.scheduling.annotation.Async;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.time.Duration;
import java.time.LocalDateTime;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.atomic.AtomicLong;

/**
 * 채팅 동기화 서비스
 * 
 * MongoDB → RDB 동기화 (백그라운드)
 * MongoDB → 벡터 DB 임베딩 (백그라운드)
 * 
 * 개선사항:
 * - 5분 경과 조건 추가
 * - 배치 저장 지원
 * - 동시성 제어 강화
 * - 메트릭 수집
 * - 재시도 로직
 */
@Service
@Slf4j
public class ChatSyncService {

    private final FactCheckChatSessionRepository sessionRepository;
    private final ChatHistoryRepository chatHistoryRepository;
    private final VectorEmbeddingService vectorEmbeddingService;
    private final MeterRegistry meterRegistry;

    // 설정값
    @Value("${chat.sync.min-messages:10}")
    private int minMessagesForSync;

    @Value("${chat.sync.max-idle-minutes:5}")
    private int maxIdleMinutesForSync;

    @Value("${chat.sync.batch-size:50}")
    private int batchSize;

    @Value("${chat.sync.max-retry:3}")
    private int maxRetryAttempts;

    @Value("${chat.sync.session-expire-hours:24}")
    private int sessionExpireHours;

    // 메트릭
    private Counter syncSuccessCounter;
    private Counter syncErrorCounter;
    private Counter embeddingSuccessCounter;
    private Counter embeddingErrorCounter;
    private Counter sessionExpiredCounter;
    private Timer syncDurationTimer;
    private Timer embeddingDurationTimer;
    private final AtomicLong pendingSyncGauge = new AtomicLong(0);
    private final AtomicLong pendingEmbeddingGauge = new AtomicLong(0);

    // 동시성 제어 - 진행 중인 동기화 세션 추적
    private final ConcurrentHashMap<String, LocalDateTime> syncingSessionsMap = new ConcurrentHashMap<>();
    
    // 마지막 동기화 시간 추적
    private final ConcurrentHashMap<String, LocalDateTime> lastSyncTimeMap = new ConcurrentHashMap<>();

    public ChatSyncService(
            FactCheckChatSessionRepository sessionRepository,
            ChatHistoryRepository chatHistoryRepository,
            VectorEmbeddingService vectorEmbeddingService,
            MeterRegistry meterRegistry
    ) {
        this.sessionRepository = sessionRepository;
        this.chatHistoryRepository = chatHistoryRepository;
        this.vectorEmbeddingService = vectorEmbeddingService;
        this.meterRegistry = meterRegistry;
    }

    @PostConstruct
    public void initMetrics() {
        syncSuccessCounter = Counter.builder("chat.sync.rdb.success")
                .description("Number of successful RDB syncs")
                .register(meterRegistry);
        
        syncErrorCounter = Counter.builder("chat.sync.rdb.error")
                .description("Number of failed RDB syncs")
                .register(meterRegistry);
        
        embeddingSuccessCounter = Counter.builder("chat.sync.embedding.success")
                .description("Number of successful embeddings")
                .register(meterRegistry);
        
        embeddingErrorCounter = Counter.builder("chat.sync.embedding.error")
                .description("Number of failed embeddings")
                .register(meterRegistry);
        
        sessionExpiredCounter = Counter.builder("chat.sync.sessions.expired")
                .description("Number of sessions expired")
                .register(meterRegistry);
        
        syncDurationTimer = Timer.builder("chat.sync.rdb.duration")
                .description("Time taken for RDB sync")
                .register(meterRegistry);
        
        embeddingDurationTimer = Timer.builder("chat.sync.embedding.duration")
                .description("Time taken for embedding")
                .register(meterRegistry);

        meterRegistry.gauge("chat.sync.rdb.pending", pendingSyncGauge);
        meterRegistry.gauge("chat.sync.embedding.pending", pendingEmbeddingGauge);
    }

    /**
     * 동기화가 필요한 경우 스케줄링
     * 조건:
     * 1. 메시지가 minMessagesForSync개 이상
     * 2. 마지막 동기화로부터 maxIdleMinutesForSync분 경과
     */
    public void scheduleSyncIfNeeded(FactCheckChatSession session) {
        if (session.isSyncedToRdb()) {
            return;
        }

        boolean shouldSync = false;
        String reason = "";

        // 조건 1: 메시지 개수 체크
        if (session.getMessages().size() >= minMessagesForSync) {
            shouldSync = true;
            reason = "message count >= " + minMessagesForSync;
        }

        // 조건 2: 마지막 동기화로부터 시간 경과 체크
        LocalDateTime lastSync = lastSyncTimeMap.get(session.getSessionId());
        if (lastSync != null) {
            Duration elapsed = Duration.between(lastSync, LocalDateTime.now());
            if (elapsed.toMinutes() >= maxIdleMinutesForSync) {
                shouldSync = true;
                reason = "idle time >= " + maxIdleMinutesForSync + " minutes";
            }
        } else if (session.getStartedAt() != null) {
            // 최초 동기화 - 세션 시작 후 5분 경과 시
            Duration elapsed = Duration.between(session.getStartedAt(), LocalDateTime.now());
            if (elapsed.toMinutes() >= maxIdleMinutesForSync && session.getMessages().size() > 0) {
                shouldSync = true;
                reason = "first sync after " + maxIdleMinutesForSync + " minutes";
            }
        }

        if (shouldSync) {
            log.debug("Scheduling sync for session {}: {}", session.getSessionId(), reason);
            syncSessionToRdbAsync(session);
        }
    }

    /**
     * 세션을 RDB로 동기화 (비동기)
     */
    @Async("chatSyncExecutor")
    public void syncSessionToRdbAsync(FactCheckChatSession session) {
        String sessionId = session.getSessionId();
        
        // 중복 동기화 방지
        if (syncingSessionsMap.putIfAbsent(sessionId, LocalDateTime.now()) != null) {
            log.debug("Session {} is already being synced, skipping", sessionId);
            return;
        }

        try {
            syncSessionToRdbWithRetry(session);
        } finally {
            syncingSessionsMap.remove(sessionId);
        }
    }

    /**
     * 세션을 RDB로 동기화 (재시도 포함)
     */
    private void syncSessionToRdbWithRetry(FactCheckChatSession session) {
        int attempts = 0;
        Exception lastException = null;

        while (attempts < maxRetryAttempts) {
            try {
                syncSessionToRdb(session);
                return; // 성공 시 반환
            } catch (Exception e) {
                attempts++;
                lastException = e;
                log.warn("Sync attempt {} failed for session {}: {}", 
                        attempts, session.getSessionId(), e.getMessage());
                
                if (attempts < maxRetryAttempts) {
                    try {
                        // 지수 백오프
                        Thread.sleep((long) Math.pow(2, attempts) * 1000);
                    } catch (InterruptedException ie) {
                        Thread.currentThread().interrupt();
                        break;
                    }
                }
            }
        }

        log.error("Failed to sync session {} after {} attempts", 
                session.getSessionId(), maxRetryAttempts, lastException);
        syncErrorCounter.increment();
    }

    /**
     * 세션을 RDB로 동기화 (동기)
     */
    @Transactional
    public void syncSessionToRdb(FactCheckChatSession session) {
        Timer.Sample sample = Timer.start(meterRegistry);
        
        log.info("Syncing session {} to RDB ({} messages)", 
                session.getSessionId(), session.getMessages().size());

        // 배치로 저장할 메시지 수집
        List<ChatHistory> toSave = new ArrayList<>();
        
        for (FactCheckChatSession.ChatMessage message : session.getMessages()) {
            // 이미 동기화된 메시지는 건너뛰기
            if (chatHistoryRepository.existsByMessageId(message.getMessageId())) {
                continue;
            }

            // RDB 엔티티 생성
            ChatHistory chatHistory = ChatHistory.builder()
                    .sessionId(session.getSessionId())
                    .messageId(message.getMessageId())
                    .userId(session.getUserId())
                    .role(message.getRole())
                    .content(message.getContent())
                    .messageType(message.getType() != null ? message.getType().name() : null)
                    .metadata(convertMetadata(message.getMetadata()))
                    .build();

            toSave.add(chatHistory);

            // 배치 크기에 도달하면 저장
            if (toSave.size() >= batchSize) {
                chatHistoryRepository.saveAll(toSave);
                toSave.clear();
            }
        }

        // 남은 메시지 저장
        if (!toSave.isEmpty()) {
            chatHistoryRepository.saveAll(toSave);
        }

        // 동기화 완료 플래그 업데이트
        session.setSyncedToRdb(true);
        sessionRepository.save(session);

        // 마지막 동기화 시간 업데이트
        lastSyncTimeMap.put(session.getSessionId(), LocalDateTime.now());

        sample.stop(syncDurationTimer);
        syncSuccessCounter.increment();
        
        log.info("Synced {} new messages from session {} to RDB", 
                toSave.size(), session.getSessionId());

        // 벡터 임베딩 트리거
        if (!session.isEmbeddedToVectorDb()) {
            embedSessionToVectorDbAsync(session);
        }
    }

    /**
     * 세션을 벡터 DB로 임베딩 (비동기)
     */
    @Async("chatSyncExecutor")
    public void embedSessionToVectorDbAsync(FactCheckChatSession session) {
        String sessionId = session.getSessionId();
        
        try {
            embedSessionToVectorDbWithRetry(session);
        } catch (Exception e) {
            log.error("Failed to embed session {} to vector DB: {}", 
                    sessionId, e.getMessage(), e);
            embeddingErrorCounter.increment();
        }
    }

    /**
     * 세션을 벡터 DB로 임베딩 (재시도 포함)
     */
    private void embedSessionToVectorDbWithRetry(FactCheckChatSession session) {
        int attempts = 0;
        Exception lastException = null;

        while (attempts < maxRetryAttempts) {
            try {
                embedSessionToVectorDb(session);
                return;
            } catch (Exception e) {
                attempts++;
                lastException = e;
                log.warn("Embedding attempt {} failed for session {}: {}", 
                        attempts, session.getSessionId(), e.getMessage());
                
                if (attempts < maxRetryAttempts) {
                    try {
                        Thread.sleep((long) Math.pow(2, attempts) * 1000);
                    } catch (InterruptedException ie) {
                        Thread.currentThread().interrupt();
                        break;
                    }
                }
            }
        }

        log.error("Failed to embed session {} after {} attempts", 
                session.getSessionId(), maxRetryAttempts, lastException);
        embeddingErrorCounter.increment();
    }

    /**
     * 세션을 벡터 DB로 임베딩 (동기)
     */
    @Transactional
    public void embedSessionToVectorDb(FactCheckChatSession session) {
        Timer.Sample sample = Timer.start(meterRegistry);
        
        log.info("Embedding session {} to vector DB", session.getSessionId());

        // assistant 메시지만 임베딩 (팩트체크 결과)
        List<FactCheckChatSession.ChatMessage> assistantMessages = session.getMessages().stream()
                .filter(msg -> "assistant".equals(msg.getRole()))
                .filter(msg -> msg.getContent() != null && !msg.getContent().isBlank())
                .filter(msg -> msg.getType() == FactCheckChatSession.MessageType.AI_SYNTHESIS 
                        || msg.getType() == FactCheckChatSession.MessageType.VERIFICATION
                        || msg.getType() == FactCheckChatSession.MessageType.ASSESSMENT)
                .toList();

        if (assistantMessages.isEmpty()) {
            log.debug("No assistant messages to embed for session {}", session.getSessionId());
            session.setEmbeddedToVectorDb(true);
            sessionRepository.save(session);
            return;
        }

        int embeddedCount = 0;
        for (FactCheckChatSession.ChatMessage message : assistantMessages) {
            try {
                // 벡터 임베딩 생성 및 저장
                String embeddingId = vectorEmbeddingService.embedChatMessage(
                        session.getSessionId(),
                        message.getMessageId(),
                        message.getContent(),
                        message.getMetadata()
                );

                if (embeddingId != null) {
                    // RDB에 임베딩 ID 업데이트
                    updateEmbeddingIdInRdb(session.getSessionId(), message.getMessageId(), embeddingId);
                    embeddedCount++;
                }
            } catch (Exception e) {
                log.error("Failed to embed message {}: {}", message.getMessageId(), e.getMessage());
            }
        }

        // 임베딩 완료 플래그 업데이트
        session.setEmbeddedToVectorDb(true);
        sessionRepository.save(session);

        sample.stop(embeddingDurationTimer);
        embeddingSuccessCounter.increment();

        log.info("Embedded {} messages from session {} to vector DB", 
                embeddedCount, session.getSessionId());
    }

    /**
     * RDB에 임베딩 ID 업데이트
     */
    private void updateEmbeddingIdInRdb(String sessionId, String messageId, String embeddingId) {
        chatHistoryRepository.findBySessionIdOrderByCreatedAtAsc(sessionId)
                .stream()
                .filter(ch -> ch.getMessageId().equals(messageId))
                .findFirst()
                .ifPresent(ch -> {
                    ch.setEmbeddingId(embeddingId);
                    chatHistoryRepository.save(ch);
                });
    }

    /**
     * 스케줄러: 주기적으로 동기화되지 않은 세션 처리
     */
    @Scheduled(fixedDelayString = "${chat.sync.scheduler.interval:300000}") // 기본 5분마다
    public void syncPendingSessions() {
        log.debug("Running scheduled sync for pending sessions");

        List<FactCheckChatSession.SessionStatus> targetStatuses = List.of(
                FactCheckChatSession.SessionStatus.ACTIVE,
                FactCheckChatSession.SessionStatus.COMPLETED,
                FactCheckChatSession.SessionStatus.EXPIRED
        );

        // RDB 동기화 대상 조회
        List<FactCheckChatSession> unsyncedSessions = 
                sessionRepository.findBySyncedToRdbFalseAndStatusIn(targetStatuses);
        
        pendingSyncGauge.set(unsyncedSessions.size());
        log.info("Found {} sessions to sync to RDB", unsyncedSessions.size());
        
        for (FactCheckChatSession session : unsyncedSessions) {
            // 5분 이상 경과한 세션만 동기화
            if (shouldSyncNow(session)) {
                syncSessionToRdbAsync(session);
            }
        }

        // 벡터 DB 임베딩 대상 조회
        List<FactCheckChatSession> unembeddedSessions = 
                sessionRepository.findByEmbeddedToVectorDbFalseAndStatusIn(
                        List.of(FactCheckChatSession.SessionStatus.COMPLETED,
                                FactCheckChatSession.SessionStatus.EXPIRED));
        
        pendingEmbeddingGauge.set(unembeddedSessions.size());
        log.info("Found {} sessions to embed to vector DB", unembeddedSessions.size());
        
        for (FactCheckChatSession session : unembeddedSessions) {
            // RDB 동기화 완료된 세션만 임베딩
            if (session.isSyncedToRdb()) {
                embedSessionToVectorDbAsync(session);
            }
        }
    }

    /**
     * 지금 동기화해야 하는지 확인
     */
    private boolean shouldSyncNow(FactCheckChatSession session) {
        // 완료/만료 세션은 즉시 동기화
        if (session.getStatus() != FactCheckChatSession.SessionStatus.ACTIVE) {
            return true;
        }

        // 활성 세션은 마지막 활동으로부터 5분 경과 시 동기화
        if (session.getLastActivityAt() != null) {
            Duration elapsed = Duration.between(session.getLastActivityAt(), LocalDateTime.now());
            return elapsed.toMinutes() >= maxIdleMinutesForSync;
        }

        return true;
    }

    /**
     * 스케줄러: 오래된 활성 세션 만료 처리
     */
    @Scheduled(fixedDelayString = "${chat.sync.expire.interval:3600000}") // 기본 1시간마다
    public void expireInactiveSessions() {
        LocalDateTime expiryThreshold = LocalDateTime.now().minusHours(sessionExpireHours);
        
        List<FactCheckChatSession> inactiveSessions = sessionRepository
                .findByStatusAndLastActivityAtBefore(
                        FactCheckChatSession.SessionStatus.ACTIVE, 
                        expiryThreshold
                );

        log.info("Found {} inactive sessions to expire", inactiveSessions.size());
        
        for (FactCheckChatSession session : inactiveSessions) {
            session.setStatus(FactCheckChatSession.SessionStatus.EXPIRED);
            session.setEndedAt(LocalDateTime.now());
            sessionRepository.save(session);
            
            // 만료된 세션도 동기화
            syncSessionToRdbAsync(session);
            
            sessionExpiredCounter.increment();
            log.info("Expired session: {}", session.getSessionId());
        }

        // 메모리 정리 - 오래된 추적 데이터 삭제
        cleanupTrackingData();
    }

    /**
     * 스케줄러: 동기화 상태 정리 (stuck 상태 복구)
     */
    @Scheduled(fixedDelay = 600000) // 10분마다
    public void cleanupStuckSyncs() {
        LocalDateTime stuckThreshold = LocalDateTime.now().minusMinutes(10);
        
        syncingSessionsMap.entrySet().removeIf(entry -> {
            if (entry.getValue().isBefore(stuckThreshold)) {
                log.warn("Removing stuck sync for session: {}", entry.getKey());
                return true;
            }
            return false;
        });
    }

    /**
     * 오래된 추적 데이터 정리
     */
    private void cleanupTrackingData() {
        LocalDateTime cleanupThreshold = LocalDateTime.now().minusHours(sessionExpireHours * 2);
        
        lastSyncTimeMap.entrySet().removeIf(entry -> 
                entry.getValue().isBefore(cleanupThreshold));
    }

    /**
     * 메타데이터 변환 (Object → Map)
     */
    @SuppressWarnings("unchecked")
    private Map<String, Object> convertMetadata(Object metadata) {
        if (metadata == null) {
            return new HashMap<>();
        }
        if (metadata instanceof Map) {
            return (Map<String, Object>) metadata;
        }
        // 다른 타입의 경우 빈 맵 반환
        Map<String, Object> result = new HashMap<>();
        result.put("raw", metadata.toString());
        return result;
    }

    /**
     * 동기화 통계 조회
     */
    public SyncStats getSyncStats() {
        return SyncStats.builder()
                .pendingSyncCount(pendingSyncGauge.get())
                .pendingEmbeddingCount(pendingEmbeddingGauge.get())
                .activeSyncCount(syncingSessionsMap.size())
                .build();
    }

    @lombok.Data
    @lombok.Builder
    public static class SyncStats {
        private long pendingSyncCount;
        private long pendingEmbeddingCount;
        private int activeSyncCount;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/ClaimExtractionService.java

```java
package com.newsinsight.collector.service;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.newsinsight.collector.client.AIDoveClient;
import com.newsinsight.collector.dto.ClaimExtractionRequest;
import com.newsinsight.collector.dto.ClaimExtractionResponse;
import com.newsinsight.collector.dto.ClaimExtractionResponse.ExtractedClaim;
import com.newsinsight.collector.dto.CrawledPage;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.nodes.Element;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.http.MediaType;
import org.springframework.stereotype.Service;
import org.springframework.web.reactive.function.client.WebClient;
import reactor.core.publisher.Mono;
import reactor.core.scheduler.Schedulers;

import java.time.Duration;
import java.util.*;
import java.util.concurrent.atomic.AtomicInteger;

/**
 * Service for extracting verifiable claims from URLs.
 * 
 * Uses IntegratedCrawler for content extraction and AI Dove for claim analysis.
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class ClaimExtractionService {

    private final WebClient webClient;
    private final ObjectMapper objectMapper;
    private final AIDoveClient aiDoveClient;

    @Value("${collector.crawler.base-url:http://web-crawler:11235}")
    private String crawl4aiBaseUrl;

    @Value("${collector.claim-extraction.timeout-seconds:60}")
    private int timeoutSeconds;

    @Value("${collector.claim-extraction.max-claims:10}")
    private int defaultMaxClaims;

    @Value("${collector.claim-extraction.min-confidence:0.5}")
    private double defaultMinConfidence;

    /**
     * Extract claims from a URL.
     * 
     * Pipeline:
     * 1. Crawl the URL to get page content
     * 2. Send content to AI Dove with claim extraction prompt
     * 3. Parse and return structured claims
     */
    public Mono<ClaimExtractionResponse> extractClaims(ClaimExtractionRequest request) {
        long startTime = System.currentTimeMillis();
        String url = request.getUrl();
        int maxClaims = request.getMaxClaims() != null ? request.getMaxClaims() : defaultMaxClaims;
        double minConfidence = request.getMinConfidence() != null ? request.getMinConfidence() : defaultMinConfidence;

        log.info("Starting claim extraction for URL: {}", url);

        return crawlUrl(url)
                .flatMap(page -> {
                    if (page.content() == null || page.content().isBlank()) {
                        return Mono.just(ClaimExtractionResponse.builder()
                                .url(url)
                                .pageTitle(page.title())
                                .claims(Collections.emptyList())
                                .processingTimeMs(System.currentTimeMillis() - startTime)
                                .extractionSource(page.source())
                                .message("페이지에서 분석할 수 있는 콘텐츠를 찾지 못했습니다.")
                                .build());
                    }

                    return extractClaimsFromContent(page.content(), page.title(), maxClaims)
                            .map(claims -> {
                                // Filter by minimum confidence
                                List<ExtractedClaim> filteredClaims = claims.stream()
                                        .filter(c -> c.getConfidence() >= minConfidence)
                                        .toList();

                                return ClaimExtractionResponse.builder()
                                        .url(url)
                                        .pageTitle(page.title())
                                        .claims(filteredClaims)
                                        .processingTimeMs(System.currentTimeMillis() - startTime)
                                        .extractionSource(page.source())
                                        .message(filteredClaims.isEmpty() 
                                                ? "검증 가능한 주장을 찾지 못했습니다." 
                                                : null)
                                        .build();
                            });
                })
                .onErrorResume(e -> {
                    log.error("Claim extraction failed for URL {}: {}", url, e.getMessage());
                    return Mono.just(ClaimExtractionResponse.builder()
                            .url(url)
                            .claims(Collections.emptyList())
                            .processingTimeMs(System.currentTimeMillis() - startTime)
                            .message("주장 추출 실패: " + e.getMessage())
                            .build());
                });
    }

    /**
     * Crawl URL using multiple strategies with fallback
     */
    private Mono<CrawledPage> crawlUrl(String url) {
        // Try Crawl4AI first
        return crawlWithCrawl4AI(url)
                .switchIfEmpty(crawlDirect(url))
                .timeout(Duration.ofSeconds(timeoutSeconds))
                .doOnSuccess(page -> log.debug("Successfully crawled: {} using {}", url, page.source()));
    }

    /**
     * Crawl using Crawl4AI service
     */
    private Mono<CrawledPage> crawlWithCrawl4AI(String url) {
        String endpoint = crawl4aiBaseUrl + "/md";

        Map<String, Object> payload = Map.of(
                "url", url,
                "bypass_cache", true,
                "word_count_threshold", 50,
                "remove_overlay_elements", true,
                "process_iframes", true
        );

        return webClient.post()
                .uri(endpoint)
                .contentType(MediaType.APPLICATION_JSON)
                .bodyValue(payload)
                .retrieve()
                .bodyToMono(String.class)
                .timeout(Duration.ofSeconds(30))
                .map(response -> parseCrawl4AIResponse(url, response))
                .filter(page -> page.content() != null && !page.content().isBlank())
                .doOnSuccess(page -> log.debug("Crawl4AI success: {}", url))
                .onErrorResume(e -> {
                    log.debug("Crawl4AI failed for {}: {}", url, e.getMessage());
                    return Mono.empty();
                });
    }

    /**
     * Direct HTTP crawl using Jsoup
     */
    private Mono<CrawledPage> crawlDirect(String url) {
        return Mono.fromCallable(() -> {
                    Document doc = Jsoup.connect(url)
                            .userAgent("Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
                            .timeout(30000)
                            .followRedirects(true)
                            .get();

                    String title = doc.title();
                    String content = extractMainContent(doc);

                    return new CrawledPage(url, title, content, "direct", new ArrayList<>());
                })
                .subscribeOn(Schedulers.boundedElastic())
                .filter(page -> page.content() != null && page.content().length() > 100)
                .doOnSuccess(page -> log.debug("Direct crawl success: {}", url))
                .onErrorResume(e -> {
                    log.debug("Direct crawl failed for {}: {}", url, e.getMessage());
                    return Mono.empty();
                });
    }

    /**
     * Parse Crawl4AI response
     */
    private CrawledPage parseCrawl4AIResponse(String url, String response) {
        try {
            JsonNode node = objectMapper.readTree(response);
            String content = null;
            String title = null;

            if (node.has("result")) {
                JsonNode result = node.get("result");
                if (result.has("markdown")) {
                    content = result.get("markdown").asText();
                }
                if (result.has("metadata") && result.get("metadata").has("title")) {
                    title = result.get("metadata").get("title").asText();
                }
            } else if (node.has("markdown")) {
                content = node.get("markdown").asText();
            }

            // Truncate very long content
            if (content != null && content.length() > 15000) {
                content = content.substring(0, 15000) + "\n...[truncated]";
            }

            return new CrawledPage(url, title, content, "crawl4ai", new ArrayList<>());
        } catch (Exception e) {
            log.warn("Failed to parse Crawl4AI response for {}: {}", url, e.getMessage());
            return new CrawledPage(url, null, null, "crawl4ai", new ArrayList<>());
        }
    }

    /**
     * Extract main content from HTML document
     */
    private String extractMainContent(Document doc) {
        // Remove unwanted elements
        doc.select("script, style, nav, header, footer, aside, .advertisement, .ads, .sidebar, .comment, .comments").remove();

        // Try to find article content
        Element article = doc.selectFirst("article, .article, .content, .post-content, main, .main-content, .article-body, .entry-content");
        if (article != null) {
            return article.text();
        }

        // Fallback to body
        Element body = doc.body();
        return body != null ? body.text() : doc.text();
    }

    /**
     * Extract claims from content using AI Dove
     */
    private Mono<List<ExtractedClaim>> extractClaimsFromContent(String content, String title, int maxClaims) {
        if (!aiDoveClient.isEnabled()) {
            log.warn("AI Dove is disabled, cannot extract claims");
            return Mono.just(Collections.emptyList());
        }

        String prompt = buildClaimExtractionPrompt(content, title, maxClaims);

        return aiDoveClient.chat(prompt, null)
                .map(response -> parseClaimsFromAI(response.reply()))
                .onErrorResume(e -> {
                    log.error("AI claim extraction failed: {}", e.getMessage());
                    return Mono.just(Collections.emptyList());
                });
    }

    /**
     * Build prompt for claim extraction
     */
    private String buildClaimExtractionPrompt(String content, String title, int maxClaims) {
        // Truncate content if too long
        String truncatedContent = content;
        if (content.length() > 10000) {
            truncatedContent = content.substring(0, 10000) + "\n...[truncated]";
        }

        return """
                You are an expert fact-checker. Analyze the following news article and extract verifiable claims.
                
                A "verifiable claim" is a factual statement that can be confirmed or refuted through evidence.
                Do NOT include opinions, predictions, or subjective statements.
                
                For each claim, provide:
                1. The exact claim text (1-2 sentences)
                2. A confidence score (0.0-1.0) indicating how clearly stated the claim is
                3. The context where it was found (e.g., "headline", "first paragraph", "statistics section")
                4. The type of claim: "statistical" (numbers/data), "event" (something happened), "quote" (attributed statement), "general" (other factual claims)
                5. Whether it's verifiable (true/false)
                
                Return ONLY a JSON array with this structure (no other text):
                [
                  {
                    "text": "The claim text",
                    "confidence": 0.85,
                    "context": "Found in the opening paragraph",
                    "claimType": "statistical",
                    "verifiable": true
                  }
                ]
                
                Extract up to %d claims. Prioritize:
                1. Statistical claims (numbers, percentages, data)
                2. Event claims (specific things that happened)
                3. Attributed quotes (statements from named sources)
                
                Title: %s
                
                Content:
                %s
                """.formatted(maxClaims, title != null ? title : "Unknown", truncatedContent);
    }

    /**
     * Parse claims from AI response
     */
    private List<ExtractedClaim> parseClaimsFromAI(String aiResponse) {
        if (aiResponse == null || aiResponse.isBlank()) {
            return Collections.emptyList();
        }

        try {
            // Extract JSON array from response
            String json = extractJsonArray(aiResponse);
            if (json == null) {
                log.warn("No JSON array found in AI response");
                return Collections.emptyList();
            }

            JsonNode claimsArray = objectMapper.readTree(json);
            List<ExtractedClaim> claims = new ArrayList<>();
            AtomicInteger idCounter = new AtomicInteger(1);

            for (JsonNode node : claimsArray) {
                ExtractedClaim claim = ExtractedClaim.builder()
                        .id("claim-" + idCounter.getAndIncrement())
                        .text(node.has("text") ? node.get("text").asText() : "")
                        .confidence(node.has("confidence") ? node.get("confidence").asDouble() : 0.7)
                        .context(node.has("context") ? node.get("context").asText() : null)
                        .claimType(node.has("claimType") ? node.get("claimType").asText() : "general")
                        .verifiable(node.has("verifiable") ? node.get("verifiable").asBoolean() : true)
                        .build();

                // Only add claims with actual text
                if (claim.getText() != null && !claim.getText().isBlank()) {
                    claims.add(claim);
                }
            }

            log.info("Extracted {} claims from AI response", claims.size());
            return claims;
        } catch (Exception e) {
            log.warn("Failed to parse AI claims response: {}", e.getMessage());
            return Collections.emptyList();
        }
    }

    /**
     * Extract JSON array from text that may contain other content
     */
    private String extractJsonArray(String text) {
        if (text == null) return null;

        int start = text.indexOf('[');
        int end = text.lastIndexOf(']');

        if (start >= 0 && end > start) {
            return text.substring(start, end + 1);
        }
        return null;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/CollectedDataService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.config.TrustScoreConfig;
import com.newsinsight.collector.entity.CollectedData;
import com.newsinsight.collector.repository.CollectedDataRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.nio.charset.StandardCharsets;
import java.security.MessageDigest;
import java.security.NoSuchAlgorithmException;
import java.util.Optional;

@Service
@RequiredArgsConstructor
@Slf4j
public class CollectedDataService {

    private final CollectedDataRepository collectedDataRepository;
    private final TrustScoreConfig trustScoreConfig;

    /**
     * 중복 제거를 위한 SHA-256 콘텐츠 해시 계산
     */
    public String computeContentHash(String url, String title, String content) {
        try {
            MessageDigest digest = MessageDigest.getInstance("SHA-256");
            digest.update((url != null ? url : "").getBytes(StandardCharsets.UTF_8));
            digest.update((title != null ? title : "").getBytes(StandardCharsets.UTF_8));
            digest.update((content != null ? content : "").getBytes(StandardCharsets.UTF_8));
            
            byte[] hash = digest.digest();
            StringBuilder hexString = new StringBuilder();
            for (byte b : hash) {
                String hex = Integer.toHexString(0xff & b);
                if (hex.length() == 1) hexString.append('0');
                hexString.append(hex);
            }
            return hexString.toString();
        } catch (NoSuchAlgorithmException e) {
            throw new RuntimeException("SHA-256 algorithm not available", e);
        }
    }

    /**
     * 해시값으로 콘텐츠 존재 여부 확인
     */
    public boolean isDuplicate(String contentHash) {
        return collectedDataRepository.findByContentHash(contentHash).isPresent();
    }

    /**
     * 수집된 데이터 저장
     */
    @Transactional
    public CollectedData save(CollectedData data) {
        // 콘텐츠 해시가 비어있으면 계산하여 설정
        if (data.getContentHash() == null) {
            String hash = computeContentHash(data.getUrl(), data.getTitle(), data.getContent());
            data.setContentHash(hash);
        }
        
        // 중복 여부 확인
        if (isDuplicate(data.getContentHash())) {
            log.debug("Duplicate content detected: {}", data.getContentHash());
            data.setDuplicate(true);
        }
        
        return collectedDataRepository.save(data);
    }

    /**
     * 수집된 데이터 단건 조회 (ID)
     */
    public Optional<CollectedData> findById(Long id) {
        return collectedDataRepository.findById(id);
    }

    /**
     * 수집된 데이터 전체 조회 (페이지네이션)
     */
    public Page<CollectedData> findAll(Pageable pageable) {
        return collectedDataRepository.findAll(pageable);
    }

    /**
     * 미처리 데이터 조회
     */
    public Page<CollectedData> findUnprocessed(Pageable pageable) {
        return collectedDataRepository.findByProcessedFalse(pageable);
    }

    /**
     * 소스 ID 기준 데이터 조회
     */
    public Page<CollectedData> findBySourceId(Long sourceId, Pageable pageable) {
        return collectedDataRepository.findBySourceId(sourceId, pageable);
    }

    /**
     * 키워드 기반 검색 (제목 + 본문)
     */
    public Page<CollectedData> search(String query, Pageable pageable) {
        if (query == null || query.isBlank()) {
            return collectedDataRepository.findAll(pageable);
        }
        return collectedDataRepository.searchByQuery(query.trim(), pageable);
    }

    /**
     * 키워드 기반 검색 + 처리 상태 필터
     */
    public Page<CollectedData> searchWithFilter(String query, Boolean processed, Pageable pageable) {
        if (query == null || query.isBlank()) {
            if (processed == null) {
                return collectedDataRepository.findAll(pageable);
            } else if (Boolean.FALSE.equals(processed)) {
                return collectedDataRepository.findByProcessedFalse(pageable);
            } else {
                return collectedDataRepository.findByProcessed(true, pageable);
            }
        }
        
        // 검색 + 필터링: Repository에 추가 쿼리 필요하므로 여기서 후처리
        Page<CollectedData> results = collectedDataRepository.searchByQuery(query.trim(), pageable);
        if (processed == null) {
            return results;
        }
        // Note: 효율적인 구현을 위해서는 Repository에 복합 쿼리 추가 필요
        // 현재는 검색 결과 그대로 반환 (필터링은 클라이언트에서 처리)
        return results;
    }

    /**
     * 데이터 처리 완료로 마킹
     */
    @Transactional
    public boolean markAsProcessed(Long id) {
        Optional<CollectedData> dataOpt = collectedDataRepository.findById(id);
        if (dataOpt.isEmpty()) {
            return false;
        }
        
        CollectedData data = dataOpt.get();
        data.setProcessed(true);
        collectedDataRepository.save(data);
        return true;
    }

    /**
     * 전체 수집 건수 카운트
     */
    public long countTotal() {
        return collectedDataRepository.count();
    }

    /**
     * 미처리 건수 카운트
     */
    public long countUnprocessed() {
        return collectedDataRepository.countByProcessedFalse();
    }

    /**
     * QA 지표 기반 품질 점수 계산
     */
    public double calculateQualityScore(
            Boolean httpOk,
            boolean hasContent,
            boolean duplicate,
            double semanticConsistency,
            double outlierScore) {
        
        double httpScore = httpOk == null ? 0.5 : (httpOk ? 1.0 : 0.0);
        double contentScore = hasContent ? 1.0 : 0.0;
        double duplicatePenalty = duplicate ? 1.0 : 0.0;
        double outlierPenalty = Math.max(0.0, Math.min(1.0, outlierScore));
        double sem = Math.max(0.0, Math.min(1.0, semanticConsistency));
        
        double score = 0.25 * httpScore + 0.25 * contentScore + 0.3 * sem + 
                      0.2 * (1.0 - outlierPenalty) - 0.2 * duplicatePenalty;
        
        return Math.max(0.0, Math.min(1.0, score));
    }

    /**
     * URL 도메인 기반 신뢰도 점수 계산
     * Uses externalized trust score configuration.
     */
    public double calculateTrustScore(String url, Boolean httpOk, boolean inWhitelist) {
        TrustScoreConfig.DataQuality dq = trustScoreConfig.getDataQuality();
        double base = inWhitelist ? dq.getWhitelistScore() : dq.getBaseScore();
        if (Boolean.TRUE.equals(httpOk)) {
            base += dq.getHttpOkBonus();
        }
        return Math.max(0.0, Math.min(1.0, base));
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/CollectionService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.dto.BrowserTaskMessage;
import com.newsinsight.collector.dto.CollectionStatsDTO;
import com.newsinsight.collector.dto.CrawlCommandMessage;
import com.newsinsight.collector.dto.CrawlResultMessage;
import com.newsinsight.collector.entity.BrowserAgentConfig;
import com.newsinsight.collector.entity.CollectedData;
import com.newsinsight.collector.entity.CollectionJob;
import com.newsinsight.collector.entity.CollectionJob.JobStatus;
import com.newsinsight.collector.entity.DataSource;
import com.newsinsight.collector.entity.SourceType;
import com.newsinsight.collector.repository.CollectionJobRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Optional;

@Service
@RequiredArgsConstructor
@Slf4j
public class CollectionService {

    private final CollectionJobRepository collectionJobRepository;
    private final DataSourceService dataSourceService;
    private final RssFeedService rssFeedService;
    private final WebScraperService webScraperService;
    private final CollectedDataService collectedDataService;

    private final KafkaTemplate<String, CrawlCommandMessage> crawlCommandKafkaTemplate;
    private final KafkaTemplate<String, CrawlResultMessage> crawlResultKafkaTemplate;
    private final KafkaTemplate<String, BrowserTaskMessage> browserTaskKafkaTemplate;

    @Value("${collector.crawl.topic.command:newsinsight.crawl.commands}")
    private String crawlCommandTopic;

    @Value("${collector.crawl.topic.result:newsinsight.crawl.results}")
    private String crawlResultTopic;

    @Value("${collector.crawl.topic.browser-task:newsinsight.crawl.browser.tasks}")
    private String browserTaskTopic;

    @Value("${collector.browser-agent.callback-base-url:http://localhost:8081}")
    private String browserAgentCallbackBaseUrl;

    @Value("${collector.browser-agent.callback-token:}")
    private String browserAgentCallbackToken;

    /**
     * 특정 소스에 대한 수집 작업 시작
     */
    @Transactional
    public CollectionJob startCollection(Long sourceId) {
        Optional<DataSource> sourceOpt = dataSourceService.findById(sourceId);
        
        if (sourceOpt.isEmpty()) {
            throw new IllegalArgumentException("Data source not found: " + sourceId);
        }
        
        DataSource source = sourceOpt.get();
        
        if (!source.getIsActive()) {
            throw new IllegalStateException("Data source is not active: " + sourceId);
        }
        
        // 수집 작업 엔티티 생성
        CollectionJob job = CollectionJob.builder()
                .sourceId(sourceId)
                .status(JobStatus.PENDING)
                .itemsCollected(0)
                .build();
        
        job = collectionJobRepository.save(job);
        
        // 수집 작업을 비동기로 실행
        final Long jobId = job.getId();

        CrawlCommandMessage command = new CrawlCommandMessage(
                jobId,
                sourceId,
                source.getSourceType().name(),
                source.getUrl(),
                source.getName()
        );

        crawlCommandKafkaTemplate.send(crawlCommandTopic, jobId.toString(), command);
        
        return job;
    }

    /**
     * 여러 소스에 대한 수집 작업 시작
     */
    @Transactional
    public List<CollectionJob> startCollectionForSources(List<Long> sourceIds) {
        return sourceIds.stream()
                .map(this::startCollection)
                .toList();
    }

    /**
     * 활성 소스 전체에 대한 수집 작업 시작
     */
    @Transactional
    public List<CollectionJob> startCollectionForAllActive() {
        List<DataSource> activeSources = dataSourceService.findActiveSources();
        return activeSources.stream()
                .map(source -> startCollection(source.getId()))
                .toList();
    }

    /**
     * 실제 수집 로직 실행
     */
    @Transactional
    protected void executeCollection(Long jobId, DataSource source) {
        Optional<CollectionJob> jobOpt = collectionJobRepository.findById(jobId);
        
        if (jobOpt.isEmpty()) {
            log.error("Collection job not found: {}", jobId);
            return;
        }
        
        CollectionJob job = jobOpt.get();
        
        try {
            log.info("Starting collection job {} for source: {} ({})", 
                    jobId, source.getName(), source.getSourceType());
            
            // 작업 상태를 RUNNING으로 변경
            job.setStatus(JobStatus.RUNNING);
            job.setStartedAt(LocalDateTime.now());
            collectionJobRepository.save(job);
            
            // BROWSER_AGENT 타입인 경우 별도 처리
            if (source.getSourceType() == SourceType.BROWSER_AGENT) {
                executeBrowserAgentCollection(jobId, source, job);
                return;
            }
            
            // 소스 타입에 따라 데이터 수집
            List<CollectedData> collectedItems = collectFromSource(source);

            // 수집된 데이터 이벤트 발행
            int eventCount = 0;
            for (CollectedData data : collectedItems) {
                try {
                    String publishedAt = data.getPublishedDate() != null
                            ? data.getPublishedDate().toString()
                            : null;

                    CrawlResultMessage message = new CrawlResultMessage(
                            jobId,
                            data.getSourceId(),
                            data.getTitle(),
                            data.getContent(),
                            data.getUrl(),
                            publishedAt,
                            data.getMetadataJson()
                    );

                    crawlResultKafkaTemplate.send(crawlResultTopic, jobId.toString(), message);
                    eventCount++;
                } catch (Exception e) {
                    log.error("Error publishing crawl result event: {}", e.getMessage(), e);
                }
            }
            
            // 소스의 마지막 수집 시각 업데이트
            dataSourceService.updateLastCollected(source.getId(), LocalDateTime.now());
            
            // 작업 상태를 COMPLETED로 변경
            job.setStatus(JobStatus.COMPLETED);
            job.setCompletedAt(LocalDateTime.now());
            job.setItemsCollected(eventCount);
            collectionJobRepository.save(job);
            
            log.info("Completed collection job {} for source: {} - published {} crawl result events", 
                    jobId, source.getName(), eventCount);
            
        } catch (Exception e) {
            log.error("Error executing collection job {}: {}", jobId, e.getMessage(), e);
            
            // 작업 상태를 FAILED로 변경
            job.setStatus(JobStatus.FAILED);
            job.setCompletedAt(LocalDateTime.now());
            job.setErrorMessage(e.getMessage());
            collectionJobRepository.save(job);
        }
    }

    /**
     * BROWSER_AGENT 소스에 대한 비동기 수집 시작.
     * BrowserTaskMessage를 Kafka로 발행하고, 결과는 autonomous-crawler-service에서 
     * crawl.results 토픽으로 비동기 전송됨.
     */
    private void executeBrowserAgentCollection(Long jobId, DataSource source, CollectionJob job) {
        BrowserAgentConfig config = source.getEffectiveBrowserAgentConfig();
        
        String callbackUrl = browserAgentCallbackBaseUrl.endsWith("/") 
                ? browserAgentCallbackBaseUrl + "api/v1/browser-agent/callback"
                : browserAgentCallbackBaseUrl + "/api/v1/browser-agent/callback";

        BrowserTaskMessage task = BrowserTaskMessage.builder()
                .jobId(jobId)
                .sourceId(source.getId())
                .sourceName(source.getName())
                .seedUrl(source.getUrl())
                .maxDepth(config.getMaxDepth())
                .maxPages(config.getMaxPages())
                .budgetSeconds(config.getBudgetSeconds())
                .policy(config.getPolicy() != null ? config.getPolicy().getValue() : "focused_topic")
                .focusKeywords(config.getFocusKeywords())
                .customPrompt(config.getCustomPrompt())
                .captureScreenshots(config.getCaptureScreenshots())
                .extractStructured(config.getExtractStructured())
                .excludedDomains(config.getExcludedDomains())
                .callbackUrl(callbackUrl)
                .callbackToken(browserAgentCallbackToken)
                .createdAt(LocalDateTime.now())
                .build();

        browserTaskKafkaTemplate.send(browserTaskTopic, jobId.toString(), task);
        
        log.info("Published browser task for job {}: source={}, seedUrl={}, policy={}, maxDepth={}, maxPages={}",
                jobId, source.getName(), source.getUrl(), 
                config.getPolicy(), config.getMaxDepth(), config.getMaxPages());
        
        // Job은 RUNNING 상태로 유지 - 결과는 비동기로 들어옴
        // autonomous-crawler-service가 세션 완료 시 callback을 호출하거나,
        // 개별 결과를 crawl.results 토픽으로 발행
    }

    /**
     * 소스 타입에 따른 데이터 수집
     */
    private List<CollectedData> collectFromSource(DataSource source) {
        SourceType sourceType = source.getSourceType();
        
        return switch (sourceType) {
            case RSS -> rssFeedService.fetchRssFeed(source);
            case WEB -> webScraperService.scrapeWebPage(source);
            case WEB_SEARCH -> {
                log.warn("WEB_SEARCH 소스 타입은 UnifiedSearchService를 통해 처리해야 합니다: {}", source.getName());
                yield List.of();
            }
            case API -> {
                log.warn("API 소스 타입은 아직 미구현: {}", source.getName());
                yield List.of();
            }
            case WEBHOOK -> {
                log.warn("WEBHOOK 소스 타입은 수동 이벤트 기반으로, 능동 수집이 불가: {}", source.getName());
                yield List.of();
            }
            case BROWSER_AGENT -> {
                // BROWSER_AGENT는 executeBrowserAgentCollection에서 별도 처리
                log.warn("BROWSER_AGENT should be handled by executeBrowserAgentCollection: {}", source.getName());
                yield List.of();
            }
        };
    }

    /**
     * 수집 작업 단건 조회 (ID)
     */
    public Optional<CollectionJob> getJobById(Long jobId) {
        return collectionJobRepository.findById(jobId);
    }

    /**
     * 수집 작업 전체 조회 (페이지네이션)
     */
    public Page<CollectionJob> getAllJobs(Pageable pageable) {
        return collectionJobRepository.findAll(pageable);
    }

    /**
     * 상태별 수집 작업 조회
     */
    public Page<CollectionJob> getJobsByStatus(JobStatus status, Pageable pageable) {
        return collectionJobRepository.findByStatus(status, pageable);
    }

    /**
     * 수집 통계 조회
     */
    public CollectionStatsDTO getStatistics() {
        long totalSources = dataSourceService.countAll();
        long activeSources = dataSourceService.countActive();
        long totalItemsCollected = collectedDataService.countTotal();
        long unprocessedItems = collectedDataService.countUnprocessed();
        
        // 최근 수집 시각 계산
        LocalDateTime lastCollection = dataSourceService.findAll(Pageable.unpaged())
                .stream()
                .map(DataSource::getLastCollected)
                .filter(java.util.Objects::nonNull)
                .max(LocalDateTime::compareTo)
                .orElse(null);
        
        return new CollectionStatsDTO(
                totalSources,
                activeSources,
                totalItemsCollected,
                unprocessedItems, // Using unprocessed as proxy for today's count
                lastCollection
        );
    }

    /**
     * 실행 중인 수집 작업 취소
     */
    @Transactional
    public boolean cancelJob(Long jobId) {
        Optional<CollectionJob> jobOpt = collectionJobRepository.findById(jobId);
        
        if (jobOpt.isEmpty()) {
            return false;
        }
        
        CollectionJob job = jobOpt.get();
        
        if (job.getStatus() != JobStatus.RUNNING && job.getStatus() != JobStatus.PENDING) {
            return false;
        }
        
        job.setStatus(JobStatus.CANCELLED);
        job.setCompletedAt(LocalDateTime.now());
        collectionJobRepository.save(job);
        
        log.info("Cancelled collection job: {}", jobId);
        return true;
    }

    /**
     * 오래된 완료 작업 정리
     */
    @Transactional
    public int cleanupOldJobs(int daysOld) {
        LocalDateTime cutoffDate = LocalDateTime.now().minusDays(daysOld);
        List<CollectionJob> oldJobs = collectionJobRepository.findByStatusAndCompletedAtBefore(
                JobStatus.COMPLETED, cutoffDate);
        
        collectionJobRepository.deleteAll(oldJobs);
        log.info("Cleaned up {} old collection jobs", oldJobs.size());
        
        return oldJobs.size();
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/CrawlCommandConsumerService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.dto.CrawlCommandMessage;
import com.newsinsight.collector.entity.CollectionJob;
import com.newsinsight.collector.entity.CollectionJob.JobStatus;
import com.newsinsight.collector.entity.DataSource;
import com.newsinsight.collector.repository.CollectionJobRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.time.LocalDateTime;
import java.util.Optional;

/**
 * Kafka Consumer for crawl commands.
 * Validates job and source before delegating to CollectionService.
 * Failed messages will be retried and eventually sent to DLQ by KafkaConfig error handler.
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class CrawlCommandConsumerService {

    private final CollectionService collectionService;
    private final DataSourceService dataSourceService;
    private final CollectionJobRepository collectionJobRepository;

    @KafkaListener(
            topics = "${collector.crawl.topic.command:newsinsight.crawl.commands}",
            groupId = "${spring.application.name}-crawl",
            containerFactory = "crawlCommandKafkaListenerContainerFactory"
    )
    @Transactional
    public void handleCrawlCommand(CrawlCommandMessage command) {
        log.info("Processing crawl command: jobId={}, sourceId={}, sourceType={}, url={}",
                command.jobId(), command.sourceId(), command.sourceType(), command.url());

        // Validate job exists
        Optional<CollectionJob> jobOpt = collectionJobRepository.findById(command.jobId());
        if (jobOpt.isEmpty()) {
            log.error("CollectionJob not found: jobId={}, sourceId={}. Message will be sent to DLQ.",
                    command.jobId(), command.sourceId());
            throw new IllegalStateException("CollectionJob not found: " + command.jobId());
        }

        CollectionJob job = jobOpt.get();

        // Validate source exists
        Optional<DataSource> sourceOpt = dataSourceService.findById(command.sourceId());
        if (sourceOpt.isEmpty()) {
            String errorMsg = "DataSource not found: sourceId=" + command.sourceId();
            log.error("DataSource not found: jobId={}, sourceId={}. Marking job as FAILED.",
                    command.jobId(), command.sourceId());
            markJobFailed(job, errorMsg);
            return; // Don't retry - source doesn't exist
        }

        DataSource source = sourceOpt.get();

        // Validate source is active
        if (!source.getIsActive()) {
            String errorMsg = "DataSource is not active: sourceId=" + command.sourceId();
            log.warn("DataSource is inactive: jobId={}, sourceId={}. Marking job as FAILED.",
                    command.jobId(), command.sourceId());
            markJobFailed(job, errorMsg);
            return; // Don't retry - intentionally disabled
        }

        // Execute collection - exceptions here will trigger retry + DLQ
        log.info("Starting collection execution: jobId={}, source={}, type={}",
                command.jobId(), source.getName(), source.getSourceType());
        
        collectionService.executeCollection(command.jobId(), source);
        
        log.info("Completed crawl command: jobId={}, sourceId={}",
                command.jobId(), command.sourceId());
    }

    private void markJobFailed(CollectionJob job, String errorMessage) {
        job.setStatus(JobStatus.FAILED);
        job.setCompletedAt(LocalDateTime.now());
        job.setErrorMessage(errorMessage);
        collectionJobRepository.save(job);
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/CrawlResultConsumerService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.dto.CrawlResultMessage;
import com.newsinsight.collector.entity.CollectedData;
import com.newsinsight.collector.service.autocrawl.AutoCrawlIntegrationService;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Service;

import java.time.LocalDateTime;
import java.time.OffsetDateTime;
import java.time.ZonedDateTime;
import java.time.format.DateTimeFormatter;
import java.time.format.DateTimeParseException;
import java.util.List;

/**
 * Kafka Consumer for crawl results.
 * Handles idempotency via content hash deduplication in CollectedDataService.
 * 
 * Integrates with AutoCrawl to:
 * - Trigger URL discovery from collected articles
 * - Update CrawlTarget status on completion
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class CrawlResultConsumerService {

    private final CollectedDataService collectedDataService;
    private final AutoCrawlIntegrationService autoCrawlIntegrationService;

    @Value("${autocrawl.enabled:true}")
    private boolean autoCrawlEnabled;

    /**
     * Supported date formats for parsing publishedAt from various sources.
     * Order matters - more specific formats should come first.
     */
    private static final List<DateTimeFormatter> DATE_FORMATTERS = List.of(
            DateTimeFormatter.ISO_OFFSET_DATE_TIME,      // 2025-11-29T01:20:00+09:00
            DateTimeFormatter.ISO_ZONED_DATE_TIME,       // 2025-11-29T01:20:00+09:00[Asia/Seoul]
            DateTimeFormatter.ISO_LOCAL_DATE_TIME,       // 2025-11-29T01:20:00
            DateTimeFormatter.RFC_1123_DATE_TIME,        // Fri, 29 Nov 2025 01:20:00 GMT
            DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss"),
            DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ssXXX"),
            DateTimeFormatter.ofPattern("yyyy/MM/dd HH:mm:ss"),
            DateTimeFormatter.ofPattern("dd-MM-yyyy HH:mm:ss"),
            DateTimeFormatter.ofPattern("MMM dd, yyyy HH:mm:ss")
    );

    @KafkaListener(
            topics = "${collector.crawl.topic.result:newsinsight.crawl.results}",
            groupId = "${spring.application.name}-crawl-result",
            containerFactory = "crawlResultKafkaListenerContainerFactory"
    )
    public void handleCrawlResult(CrawlResultMessage message) {
        log.info("Processing crawl result: jobId={}, sourceId={}, url={}",
                message.jobId(), message.sourceId(), message.url());

        // Pre-compute content hash for idempotency check
        String contentHash = collectedDataService.computeContentHash(
                message.url(), message.title(), message.content());

        // Early duplicate detection - skip processing if already exists
        if (collectedDataService.isDuplicate(contentHash)) {
            log.info("Duplicate detected, skipping: jobId={}, url={}, hash={}",
                    message.jobId(), message.url(), contentHash.substring(0, 8));
            return;
        }

        // Parse published date with multiple format support
        LocalDateTime publishedDate = parsePublishedDate(message.publishedAt(), message.url());

        // Validate content
        boolean hasContent = message.content() != null && !message.content().isBlank() 
                && message.content().length() >= 50;

        CollectedData data = CollectedData.builder()
                .sourceId(message.sourceId())
                .title(message.title())
                .content(message.content())
                .url(message.url())
                .publishedDate(publishedDate)
                .metadataJson(message.metadataJson())
                .contentHash(contentHash)
                .processed(false)
                .hasContent(hasContent)
                .duplicate(false)
                .normalized(false) // Will be set true after normalization pipeline
                .build();

        CollectedData saved = collectedDataService.save(data);
        
        log.info("Saved crawl result: id={}, jobId={}, sourceId={}, url={}, hasContent={}, duplicate={}",
                saved.getId(), message.jobId(), message.sourceId(), message.url(), 
                hasContent, saved.getDuplicate());

        // Integrate with AutoCrawl: discover new URLs from article and notify completion
        if (autoCrawlEnabled) {
            // 1. Discover new URLs from the collected article's content
            autoCrawlIntegrationService.onArticleCollected(saved);
            
            // 2. Notify AutoCrawl of completion (update CrawlTarget status)
            // Note: For AutoCrawl-originated tasks, the callback is sent separately by autonomous-crawler
            // This is for crawl results that may be from other sources
            if (saved.getUrl() != null) {
                autoCrawlIntegrationService.onCrawlCompleted(saved.getUrl(), saved.getId());
            }
        }
    }

    /**
     * Parse publishedAt string with multiple format support.
     * Returns null if parsing fails for all formats.
     */
    private LocalDateTime parsePublishedDate(String publishedAt, String url) {
        if (publishedAt == null || publishedAt.isBlank()) {
            return null;
        }

        String trimmed = publishedAt.trim();

        for (DateTimeFormatter formatter : DATE_FORMATTERS) {
            try {
                // Try parsing as OffsetDateTime first (has timezone)
                if (formatter == DateTimeFormatter.ISO_OFFSET_DATE_TIME ||
                    formatter == DateTimeFormatter.RFC_1123_DATE_TIME) {
                    OffsetDateTime odt = OffsetDateTime.parse(trimmed, formatter);
                    return odt.toLocalDateTime();
                }
                
                // Try parsing as ZonedDateTime
                if (formatter == DateTimeFormatter.ISO_ZONED_DATE_TIME) {
                    ZonedDateTime zdt = ZonedDateTime.parse(trimmed, formatter);
                    return zdt.toLocalDateTime();
                }

                // Try parsing as LocalDateTime
                return LocalDateTime.parse(trimmed, formatter);
            } catch (DateTimeParseException e) {
                // Try next formatter
            }
        }

        log.warn("Failed to parse publishedAt with any known format: value='{}', url={}",
                publishedAt, url);
        return null;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/CrawlSearchService.java

```java
package com.newsinsight.collector.service;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.newsinsight.collector.client.AIDoveClient;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.http.MediaType;
import org.springframework.stereotype.Service;
import org.springframework.web.reactive.function.client.WebClient;
import reactor.core.publisher.Flux;
import reactor.core.publisher.Mono;

import java.net.URLEncoder;
import java.nio.charset.StandardCharsets;
import java.time.Duration;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;

/**
 * Service for crawling web content based on keyword search and analyzing with AI Dove.
 * This serves as a fallback when Perplexity API is not available.
 * 
 * Flow:
 * 1. Generate search URLs based on keywords (Google News, Naver News)
 * 2. Crawl URLs using Crawl4AI service
 * 3. Aggregate crawled content
 * 4. Analyze aggregated content with AI Dove
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class CrawlSearchService {

    private final WebClient webClient;
    private final ObjectMapper objectMapper;
    private final AIDoveClient aiDoveClient;

    @Value("${collector.crawler.base-url:http://web-crawler:11235}")
    private String crawlerBaseUrl;

    @Value("${collector.crawler.timeout-seconds:60}")
    private int crawlerTimeoutSeconds;

    @Value("${collector.crawler.max-urls:20}")
    private int maxUrls;

    /**
     * Result of a crawl operation
     */
    public record CrawlResult(
            String url,
            String title,
            String content,
            boolean success,
            String error
    ) {
        public static CrawlResult success(String url, String title, String content) {
            return new CrawlResult(url, title, content, true, null);
        }

        public static CrawlResult failure(String url, String error) {
            return new CrawlResult(url, null, null, false, error);
        }
    }

    /**
     * Search and analyze news for a given keyword.
     * Returns a streaming response of the analysis.
     *
     * @param keyword The search keyword
     * @param window Time window (1d, 7d, 30d)
     * @return Flux of analysis text chunks
     */
    public Flux<String> searchAndAnalyze(String keyword, String window) {
        if (!aiDoveClient.isEnabled()) {
            return Flux.just("AI Dove 서비스가 비활성화되어 있습니다. 관리자에게 문의하세요.");
        }

        return Flux.concat(
                Flux.just("🔍 '" + keyword + "' 관련 뉴스를 검색하고 있습니다...\n\n"),
                performSearchAndAnalysis(keyword, window)
        );
    }

    private Flux<String> performSearchAndAnalysis(String keyword, String window) {
        List<String> searchUrls = generateSearchUrls(keyword, window);

        return Flux.fromIterable(searchUrls)
                .flatMap(this::crawlUrl, 3) // Parallel crawling with concurrency 3
                .collectList()
                .flatMapMany(results -> {
                    List<CrawlResult> successfulResults = results.stream()
                            .filter(CrawlResult::success)
                            .toList();

                    if (successfulResults.isEmpty()) {
                        return Flux.just(
                                "⚠️ 뉴스 크롤링에 실패했습니다.\n\n" +
                                "검색된 URL에서 콘텐츠를 가져올 수 없습니다.\n" +
                                "잠시 후 다시 시도하거나, Browser AI Agent를 사용해 보세요."
                        );
                    }

                    String aggregatedContent = aggregateContent(successfulResults, keyword, window);

                    return Flux.concat(
                            Flux.just("📰 " + successfulResults.size() + "개의 뉴스 소스를 분석 중...\n\n"),
                            analyzeWithAIDove(aggregatedContent, keyword)
                    );
                })
                .onErrorResume(e -> {
                    log.error("Search and analyze failed for keyword '{}': {}", keyword, e.getMessage());
                    return Flux.just(
                            "❌ 분석 중 오류가 발생했습니다: " + e.getMessage() + "\n\n" +
                            "Browser AI Agent 또는 Deep AI Search를 사용해 보세요."
                    );
                });
    }

    /**
     * Generate search URLs for the given keyword.
     */
    private List<String> generateSearchUrls(String keyword, String window) {
        List<String> urls = new ArrayList<>();
        String encodedKeyword = URLEncoder.encode(keyword, StandardCharsets.UTF_8);

        // Google News search
        String googleNewsUrl = "https://news.google.com/search?q=" + encodedKeyword + "&hl=ko&gl=KR&ceid=KR:ko";
        urls.add(googleNewsUrl);

        // Naver News search
        String naverNewsUrl = "https://search.naver.com/search.naver?where=news&query=" + encodedKeyword;
        urls.add(naverNewsUrl);

        // Daum News search
        String daumNewsUrl = "https://search.daum.net/search?w=news&q=" + encodedKeyword;
        urls.add(daumNewsUrl);

        // Add time-specific search if needed
        if ("1d".equals(window)) {
            // Google News sorted by date (last 24 hours)
            String recentGoogleUrl = "https://www.google.com/search?q=" + encodedKeyword + 
                    "+site:news.google.com&tbs=qdr:d&tbm=nws";
            urls.add(recentGoogleUrl);
        } else if ("30d".equals(window)) {
            // Google News last month
            String monthlyGoogleUrl = "https://www.google.com/search?q=" + encodedKeyword + 
                    "+site:news.google.com&tbs=qdr:m&tbm=nws";
            urls.add(monthlyGoogleUrl);
        }

        return urls.stream().limit(maxUrls).toList();
    }

    /**
     * Crawl a single URL using Crawl4AI.
     */
    private Mono<CrawlResult> crawlUrl(String url) {
        log.debug("Crawling URL: {}", url);

        String crawlEndpoint = crawlerBaseUrl.endsWith("/") 
                ? crawlerBaseUrl + "md" 
                : crawlerBaseUrl + "/md";

        Map<String, Object> payload = Map.of(
                "url", url,
                "bypass_cache", true,
                "word_count_threshold", 50
        );

        return webClient.post()
                .uri(crawlEndpoint)
                .contentType(MediaType.APPLICATION_JSON)
                .bodyValue(payload)
                .retrieve()
                .bodyToMono(String.class)
                .timeout(Duration.ofSeconds(crawlerTimeoutSeconds))
                .map(response -> parseCrawlResponse(url, response))
                .onErrorResume(e -> {
                    log.warn("Failed to crawl {}: {}", url, e.getMessage());
                    return Mono.just(CrawlResult.failure(url, e.getMessage()));
                });
    }

    private CrawlResult parseCrawlResponse(String url, String response) {
        try {
            JsonNode node = objectMapper.readTree(response);

            // Try to extract markdown or content
            String content = null;
            String title = null;

            if (node.has("result")) {
                JsonNode result = node.get("result");
                if (result.has("markdown")) {
                    content = result.get("markdown").asText();
                }
                if (result.has("metadata") && result.get("metadata").has("title")) {
                    title = result.get("metadata").get("title").asText();
                }
            } else if (node.has("markdown")) {
                content = node.get("markdown").asText();
            } else if (node.has("content")) {
                content = node.get("content").asText();
            } else {
                // Fallback: use raw response if it looks like text
                content = response;
            }

            if (content == null || content.isBlank()) {
                return CrawlResult.failure(url, "No content extracted");
            }

            // Truncate very long content
            if (content.length() > 10000) {
                content = content.substring(0, 10000) + "...[truncated]";
            }

            return CrawlResult.success(url, title, content);
        } catch (Exception e) {
            log.warn("Failed to parse crawl response for {}: {}", url, e.getMessage());
            return CrawlResult.failure(url, "Failed to parse response: " + e.getMessage());
        }
    }

    /**
     * Aggregate crawled content into a single prompt for AI analysis.
     */
    private String aggregateContent(List<CrawlResult> results, String keyword, String window) {
        StringBuilder sb = new StringBuilder();
        sb.append("다음은 '").append(keyword).append("' 키워드로 검색한 뉴스 콘텐츠입니다:\n\n");

        int index = 1;
        for (CrawlResult result : results) {
            sb.append("--- 뉴스 소스 ").append(index++).append(" ---\n");
            if (result.title() != null) {
                sb.append("제목: ").append(result.title()).append("\n");
            }
            sb.append("URL: ").append(result.url()).append("\n");
            sb.append("내용:\n").append(result.content()).append("\n\n");
        }

        return sb.toString();
    }

    /**
     * Analyze aggregated content with AI Dove.
     */
    private Flux<String> analyzeWithAIDove(String aggregatedContent, String keyword) {
        String analysisPrompt = buildAnalysisPrompt(aggregatedContent, keyword);

        return aiDoveClient.chatStream(analysisPrompt, null)
                .onErrorResume(e -> {
                    log.error("AI Dove analysis failed: {}", e.getMessage());
                    return Flux.just("AI 분석 중 오류가 발생했습니다: " + e.getMessage());
                });
    }

    private String buildAnalysisPrompt(String aggregatedContent, String keyword) {
        return """
                당신은 뉴스 분석 전문가입니다. 아래 크롤링된 뉴스 콘텐츠를 분석하고 다음을 제공해 주세요:
                
                1. **핵심 요약**: '%s' 관련 주요 뉴스 흐름을 2-3문장으로 요약
                2. **주요 이슈**: bullet point로 3-5개의 핵심 이슈 정리
                3. **시장/산업 영향**: 관련 분야에 미치는 영향 분석
                4. **향후 전망**: 향후 예상되는 발전 방향
                5. **종합 의견**: 전체적인 분석 의견을 한 문단으로 정리
                
                반드시 한국어로 답변해 주세요.
                
                ---
                
                %s
                """.formatted(keyword, aggregatedContent);
    }

    /**
     * Check if the service is available.
     */
    public boolean isAvailable() {
        return aiDoveClient.isEnabled();
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/DashboardEventService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.dto.DashboardEventDto;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;
import reactor.core.publisher.Flux;
import reactor.core.publisher.Mono;
import reactor.core.publisher.Sinks;

import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.atomic.AtomicLong;

/**
 * 대시보드 실시간 이벤트 서비스.
 * SSE를 통해 클라이언트에 이벤트를 푸시하는 기능을 제공합니다.
 */
@Service
@Slf4j
public class DashboardEventService {

    private final Sinks.Many<DashboardEventDto> eventSink;
    
    // 간단한 통계 카운터 (실제 환경에서는 DB나 Redis에서 조회)
    private final AtomicLong totalCollected = new AtomicLong(0);
    private final AtomicLong activeSourceCount = new AtomicLong(0);
    private final AtomicLong todayCollected = new AtomicLong(0);

    public DashboardEventService() {
        this.eventSink = Sinks.many().multicast().onBackpressureBuffer();
    }

    /**
     * 이벤트 스트림을 구독합니다.
     * 
     * @return 이벤트 Flux
     */
    public Flux<DashboardEventDto> getEventStream() {
        return eventSink.asFlux()
                .doOnSubscribe(sub -> log.debug("New subscriber connected to event stream"))
                .doOnCancel(() -> log.debug("Subscriber disconnected from event stream"));
    }

    /**
     * 이벤트를 발행합니다.
     * 
     * @param event 발행할 이벤트
     */
    public void publishEvent(DashboardEventDto event) {
        log.debug("Publishing event: {}", event.getEventType());
        eventSink.tryEmitNext(event);
    }

    /**
     * 새 데이터 수집 이벤트를 발행합니다.
     * 
     * @param sourceId 소스 ID
     * @param count 수집된 항목 수
     */
    public void notifyNewData(String sourceId, int count) {
        totalCollected.addAndGet(count);
        todayCollected.addAndGet(count);
        
        Map<String, Object> data = new HashMap<>();
        data.put("sourceId", sourceId);
        data.put("count", count);
        data.put("totalCollected", totalCollected.get());
        
        publishEvent(DashboardEventDto.newData(
                "Collected " + count + " items from " + sourceId, 
                data
        ));
    }

    /**
     * 소스 상태 변경 이벤트를 발행합니다.
     * 
     * @param sourceId 소스 ID
     * @param status 새 상태
     */
    public void notifySourceUpdated(String sourceId, String status) {
        publishEvent(DashboardEventDto.sourceUpdated(sourceId, status));
    }

    /**
     * 현재 통계를 조회합니다.
     * 
     * @return 통계 이벤트 Mono
     */
    public Mono<DashboardEventDto> getCurrentStats() {
        Map<String, Object> stats = new HashMap<>();
        stats.put("totalCollected", totalCollected.get());
        stats.put("todayCollected", todayCollected.get());
        stats.put("activeSourceCount", activeSourceCount.get());
        stats.put("timestamp", System.currentTimeMillis());
        
        return Mono.just(DashboardEventDto.statsUpdated(stats));
    }

    /**
     * 활성 소스 수를 업데이트합니다.
     * 
     * @param count 활성 소스 수
     */
    public void updateActiveSourceCount(long count) {
        activeSourceCount.set(count);
    }

    /**
     * 일일 통계를 리셋합니다. (스케줄러에서 호출)
     */
    public void resetDailyStats() {
        todayCollected.set(0);
        log.info("Daily stats reset");
    }

    /**
     * 에러 이벤트를 발행합니다.
     * 
     * @param message 에러 메시지
     */
    public void notifyError(String message) {
        publishEvent(DashboardEventDto.error(message));
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/DataSourceService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.dto.*;
import com.newsinsight.collector.entity.DataSource;
import com.newsinsight.collector.entity.SourceType;
import com.newsinsight.collector.mapper.EntityMapper;
import com.newsinsight.collector.repository.DataSourceRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Optional;
import java.util.stream.Collectors;

@Slf4j
@Service
@RequiredArgsConstructor
public class DataSourceService {

    private final DataSourceRepository dataSourceRepository;
    private final EntityMapper entityMapper;

    /**
     * 모든 데이터 소스 목록 조회
     */
    @Transactional(readOnly = true)
    public List<DataSourceDTO> getAllSources() {
        return dataSourceRepository.findAll().stream()
                .map(entityMapper::toDTO)
                .collect(Collectors.toList());
    }

    /**
     * 활성화된 데이터 소스 목록 조회
     */
    @Transactional(readOnly = true)
    public List<DataSourceDTO> getActiveSources() {
        return dataSourceRepository.findByIsActiveTrue().stream()
                .map(entityMapper::toDTO)
                .collect(Collectors.toList());
    }

    /**
     * 소스 타입별 데이터 소스 조회
     */
    @Transactional(readOnly = true)
    public List<DataSourceDTO> getSourcesByType(SourceType sourceType) {
        return dataSourceRepository.findBySourceType(sourceType).stream()
                .map(entityMapper::toDTO)
                .collect(Collectors.toList());
    }

    /**
     * 데이터 소스 단건 조회 (ID)
     */
    @Transactional(readOnly = true)
    public DataSourceDTO getSource(Long id) {
        return dataSourceRepository.findById(id)
                .map(entityMapper::toDTO)
                .orElse(null);
    }

    // findById의 Optional<DataSource> 반환 버전
    @Transactional(readOnly = true)
    public Optional<DataSource> findById(Long id) {
        return dataSourceRepository.findById(id);
    }

    /**
     * 데이터 소스 생성 (DTO 요청 기반)
     */
    @Transactional
    public DataSourceDTO createSource(DataSourceCreateRequest request) {
        DataSource source = entityMapper.toEntity(request);
        DataSource saved = dataSourceRepository.save(source);
        log.info("Created data source: id={}, name={}, type={}", 
                 saved.getId(), saved.getName(), saved.getSourceType());
        return entityMapper.toDTO(saved);
    }

    // 엔티티 직접 저장/반환 버전
    @Transactional
    public DataSource create(DataSource source) {
        DataSource saved = dataSourceRepository.save(source);
        log.info("Created data source: id={}, name={}, type={}", 
                 saved.getId(), saved.getName(), saved.getSourceType());
        return saved;
    }

    /**
     * 데이터 소스 수정 (DTO 요청 기반)
     */
    @Transactional
    public DataSourceDTO updateSource(Long id, DataSourceUpdateRequest request) {
        DataSource source = dataSourceRepository.findById(id)
                .orElseThrow(() -> new IllegalArgumentException("Data source not found: " + id));
        
        entityMapper.updateEntity(source, request);
        DataSource saved = dataSourceRepository.save(source);
        log.info("Updated data source: id={}, name={}", saved.getId(), saved.getName());
        return entityMapper.toDTO(saved);
    }

    // 엔티티 직접 수정/반환 버전
    @Transactional
    public DataSource update(Long id, DataSourceUpdateRequest request) {
        DataSource source = dataSourceRepository.findById(id)
                .orElseThrow(() -> new IllegalArgumentException("Data source not found: " + id));
        
        entityMapper.updateEntity(source, request);
        DataSource saved = dataSourceRepository.save(source);
        log.info("Updated data source: id={}, name={}", saved.getId(), saved.getName());
        return saved;
    }

    /**
     * 데이터 소스 삭제 (예외 발생)
     */
    @Transactional
    public void deleteSource(Long id) {
        if (!dataSourceRepository.existsById(id)) {
            throw new IllegalArgumentException("Data source not found: " + id);
        }
        dataSourceRepository.deleteById(id);
        log.info("Deleted data source: id={}", id);
    }

    // 삭제 결과를 boolean으로 반환하는 버전
    @Transactional
    public boolean delete(Long id) {
        if (!dataSourceRepository.existsById(id)) {
            return false;
        }
        dataSourceRepository.deleteById(id);
        log.info("Deleted data source: id={}", id);
        return true;
    }

    /**
     * 마지막 수집 시각 업데이트
     */
    @Transactional
    public void updateLastCollected(Long id, LocalDateTime timestamp) {
        DataSource source = dataSourceRepository.findById(id)
                .orElseThrow(() -> new IllegalArgumentException("Data source not found: " + id));
        source.setLastCollected(timestamp);
        dataSourceRepository.save(source);
    }

    /**
     * 수집 대상(기한 도래) 소스 조회
     */
    @Transactional(readOnly = true)
    public List<DataSource> findDueForCollection() {
        LocalDateTime threshold = LocalDateTime.now().minusSeconds(3600); // Default 1 hour
        return dataSourceRepository.findDueForCollection(threshold);
    }

    /**
     * 활성화된 소스 목록 조회
     */
    @Transactional(readOnly = true)
    public List<DataSource> findActiveSources() {
        return dataSourceRepository.findByIsActiveTrue();
    }

    // 페이징 지원 메서드
    /**
     * 모든 소스 페이징 조회
     */
    @Transactional(readOnly = true)
    public Page<DataSource> findAll(Pageable pageable) {
        return dataSourceRepository.findAll(pageable);
    }

    /**
     * 활성 소스 페이징 조회 (주의: null 포함 가능)
     */
    @Transactional(readOnly = true)
    public Page<DataSource> findAllActive(Pageable pageable) {
        return dataSourceRepository.findAll(pageable)
                .map(source -> source.getIsActive() ? source : null);
    }

    /**
     * 전체 소스 개수 조회
     */
    @Transactional(readOnly = true)
    public long countAll() {
        return dataSourceRepository.count();
    }

    /**
     * 활성 소스 개수 조회
     */
    @Transactional(readOnly = true)
    public long countActive() {
        return dataSourceRepository.findByIsActiveTrue().size();
    }

    // 엔티티 직접 저장/업데이트
    /**
     * 데이터 소스 저장/업데이트 (엔티티 직접 전달)
     */
    @Transactional
    public DataSource save(DataSource source) {
        return dataSourceRepository.save(source);
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/DeepAnalysisService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.dto.DeepSearchJobDto;
import com.newsinsight.collector.dto.DeepSearchResultDto;
import com.newsinsight.collector.dto.EvidenceDto;
import com.newsinsight.collector.dto.StanceDistributionDto;
import com.newsinsight.collector.entity.CrawlEvidence;
import com.newsinsight.collector.entity.CrawlFailureReason;
import com.newsinsight.collector.entity.CrawlJob;
import com.newsinsight.collector.entity.CrawlJobStatus;
import com.newsinsight.collector.entity.EvidenceStance;
import com.newsinsight.collector.repository.CrawlEvidenceRepository;
import com.newsinsight.collector.repository.CrawlJobRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.ApplicationContext;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.PageRequest;
import org.springframework.data.domain.Pageable;
import org.springframework.data.domain.Sort;
import org.springframework.scheduling.annotation.Async;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Map;
import java.util.UUID;
import java.util.stream.Collectors;

/**
 * Service for managing deep AI search operations.
 * Handles job creation, progress tracking, and result retrieval.
 * Publishes SSE events via DeepSearchEventService for real-time updates.
 * 
 * Uses IntegratedCrawlerService with multiple strategies:
 * - Crawl4AI for JS-rendered pages
 * - Browser-Use API for complex interactions
 * - Direct HTTP for simple pages
 * - Search Engines (Google, Naver, Daum) for topic-based searches
 * 
 * Results are analyzed using AIDove for evidence extraction and stance analysis.
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class DeepAnalysisService {

    private final CrawlJobRepository crawlJobRepository;
    private final CrawlEvidenceRepository crawlEvidenceRepository;
    private final DeepSearchEventService deepSearchEventService;
    private final IntegratedCrawlerService integratedCrawlerService;
    private final ApplicationContext applicationContext;

    @Value("${collector.deep-search.timeout-minutes:30}")
    private int timeoutMinutes;

    @Value("${collector.deep-search.cleanup-days:7}")
    private int cleanupDays;

    @Value("${collector.deep-search.callback-token:}")
    private String expectedCallbackToken;

    /**
     * Start a new deep search job
     */
    @Transactional
    public DeepSearchJobDto startDeepSearch(String topic, String baseUrl) {
        // Check if integrated crawler is available
        if (!integratedCrawlerService.isAvailable()) {
            throw new IllegalStateException(
                "Deep search is not available. IntegratedCrawlerService is not ready. " +
                "Please ensure at least one of the following is configured: " +
                "Crawl4AI, Browser-Use API, or AIDove."
            );
        }

        String jobId = generateJobId();

        // Create job record
        CrawlJob job = CrawlJob.builder()
                .id(jobId)
                .topic(topic)
                .baseUrl(baseUrl)
                .status(CrawlJobStatus.PENDING)
                .build();

        crawlJobRepository.save(job);
        log.info("Created deep search job: id={}, topic={}", jobId, topic);

        // Publish initial status via SSE
        deepSearchEventService.publishStatusUpdate(jobId, "PENDING", "Job created, starting search...");

        // Start integrated crawler
        applicationContext.getBean(DeepAnalysisService.class)
                .triggerIntegratedSearchAsync(jobId, topic, baseUrl);

        return toJobDto(job);
    }

    /**
     * Async method to trigger search using IntegratedCrawlerService.
     * 
     * IMPORTANT: This method uses reactive subscribe() instead of block() to ensure
     * truly non-blocking execution. The @Async annotation ensures this runs in a
     * separate thread pool, and subscribe() ensures we don't block that thread.
     */
    @Async
    public void triggerIntegratedSearchAsync(String jobId, String topic, String baseUrl) {
        log.info("Starting integrated crawl: jobId={}, topic={}", jobId, topic);
        
        // Publish progress update immediately
        deepSearchEventService.publishProgressUpdate(jobId, 10, "Starting integrated crawler...");
        updateJobStatus(jobId, CrawlJobStatus.IN_PROGRESS);
        deepSearchEventService.publishStatusUpdate(jobId, "IN_PROGRESS", "Integrated crawl in progress...");

        // Build crawl request
        IntegratedCrawlerService.CrawlRequest request;
        if (baseUrl != null && !baseUrl.isBlank()) {
            request = IntegratedCrawlerService.CrawlRequest.forUrl(topic, baseUrl);
        } else {
            request = IntegratedCrawlerService.CrawlRequest.forTopic(topic);
        }

        // Create progress callback
        IntegratedCrawlerService.CrawlProgressCallback callback = new IntegratedCrawlerService.CrawlProgressCallback() {
            @Override
            public void onProgress(int current, int total, String message) {
                // Scale progress from 10-90%
                int scaledProgress = 10 + (int)((current / (double) Math.max(total, 1)) * 80);
                deepSearchEventService.publishProgressUpdate(jobId, scaledProgress, message);
            }

            @Override
            public void onPageCrawled(com.newsinsight.collector.dto.CrawledPage page) {
                log.debug("Page crawled for job {}: {}", jobId, page.url());
            }

            @Override
            public void onEvidenceFound(EvidenceDto evidence) {
                deepSearchEventService.publishEvidence(jobId, evidence);
            }

            @Override
            public void onError(String url, String error) {
                log.warn("Crawl error for job {} at {}: {}", jobId, url, error);
            }
        };

        // Execute crawl reactively - DO NOT use .block() as it defeats async execution!
        // Use subscribe() to process results when they arrive without blocking.
        integratedCrawlerService
                .crawl(request, callback)
                .subscribe(
                        result -> handleCrawlSuccess(jobId, result),
                        error -> handleCrawlError(jobId, error)
                );
    }

    /**
     * Handle successful crawl completion
     */
    private void handleCrawlSuccess(String jobId, IntegratedCrawlerService.CrawlResult result) {
        try {
            if (result != null && !result.evidence().isEmpty()) {
                // Save evidence to database
                List<CrawlEvidence> evidenceEntities = result.evidence().stream()
                        .map(e -> CrawlEvidence.builder()
                                .jobId(jobId)
                                .url(e.getUrl())
                                .title(e.getTitle())
                                .stance(parseStance(e.getStance()))
                                .snippet(e.getSnippet())
                                .source(e.getSource())
                                .build())
                        .toList();
                crawlEvidenceRepository.saveAll(evidenceEntities);

                // Update job as completed
                CrawlJob job = crawlJobRepository.findById(jobId).orElse(null);
                if (job != null) {
                    job.markCompleted(evidenceEntities.size());
                    crawlJobRepository.save(job);
                }

                // Publish completion
                deepSearchEventService.publishProgressUpdate(jobId, 100, "Completed");
                deepSearchEventService.publishComplete(jobId, toJobDto(job));
                
                log.info("Integrated crawl completed: jobId={}, evidence={}", jobId, evidenceEntities.size());
            } else {
                // Mark as completed with no evidence
                CrawlJob job = crawlJobRepository.findById(jobId).orElse(null);
                if (job != null) {
                    job.markCompleted(0);
                    crawlJobRepository.save(job);
                }
                deepSearchEventService.publishProgressUpdate(jobId, 100, "Completed (no evidence found)");
                deepSearchEventService.publishComplete(jobId, toJobDto(job));
                log.info("Integrated crawl completed with no evidence: jobId={}", jobId);
            }
        } catch (Exception e) {
            log.error("Error handling crawl success for jobId={}: {}", jobId, e.getMessage(), e);
            handleCrawlError(jobId, e);
        }
    }

    /**
     * Handle crawl error
     */
    private void handleCrawlError(String jobId, Throwable e) {
        log.error("Integrated crawl failed: jobId={}, error={}", jobId, e.getMessage(), e);
        CrawlFailureReason failureReason = CrawlFailureReason.fromException(e);
        String errorMsg = "Crawl failed: " + e.getMessage() + " [" + failureReason.getCode() + "]";
        updateJobStatusWithReason(jobId, CrawlJobStatus.FAILED, errorMsg, failureReason);
        deepSearchEventService.publishError(jobId, errorMsg, failureReason);
    }

    /**
     * Parse stance string to EvidenceStance enum
     */
    private EvidenceStance parseStance(String stance) {
        if (stance == null) return EvidenceStance.NEUTRAL;
        return switch (stance.toLowerCase()) {
            case "pro" -> EvidenceStance.PRO;
            case "con" -> EvidenceStance.CON;
            default -> EvidenceStance.NEUTRAL;
        };
    }

    /**
     * Process callback from internal workers (for extensibility)
     * This endpoint can be used by future internal async workers if needed.
     */
    @Transactional
    public DeepSearchResultDto processInternalCallback(
            String callbackToken,
            String jobId,
            String status,
            List<EvidenceDto> evidenceList
    ) {
        // Validate callback token if configured
        if (expectedCallbackToken != null && !expectedCallbackToken.isBlank()) {
            if (!expectedCallbackToken.equals(callbackToken)) {
                log.warn("Invalid callback token received for job: {}", jobId);
                throw new SecurityException("Invalid callback token");
            }
        }

        CrawlJob job = crawlJobRepository.findById(jobId)
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));

        // Check if already processed
        if (job.getCallbackReceived()) {
            log.warn("Duplicate callback received for job: {}", jobId);
            return getSearchResult(jobId);
        }

        // Publish progress update
        deepSearchEventService.publishProgressUpdate(jobId, 70, "Processing callback, saving evidence...");

        // Process evidence
        List<CrawlEvidence> savedEvidence = List.of();
        if (evidenceList != null && !evidenceList.isEmpty()) {
            savedEvidence = evidenceList.stream()
                    .map(e -> CrawlEvidence.builder()
                            .jobId(jobId)
                            .url(e.getUrl())
                            .title(e.getTitle())
                            .stance(parseStance(e.getStance()))
                            .snippet(e.getSnippet())
                            .source(e.getSource())
                            .build())
                    .toList();
            crawlEvidenceRepository.saveAll(savedEvidence);
            
            // Publish each evidence via SSE
            int evidenceCount = 0;
            for (EvidenceDto evidence : evidenceList) {
                evidenceCount++;
                deepSearchEventService.publishEvidence(jobId, evidence);
                
                // Update progress as evidence is processed
                int progress = 70 + (int) ((evidenceCount / (double) evidenceList.size()) * 25);
                deepSearchEventService.publishProgressUpdate(jobId, progress, 
                        String.format("Processing evidence %d/%d", evidenceCount, evidenceList.size()));
            }
        }

        // Update job status
        if ("completed".equalsIgnoreCase(status)) {
            job.markCompleted(savedEvidence.size());
            // Publish completion event
            deepSearchEventService.publishProgressUpdate(jobId, 100, "Completed");
            deepSearchEventService.publishComplete(jobId, toJobDto(job));
        } else {
            job.markFailed("Worker returned status: " + status);
            // Publish error event
            deepSearchEventService.publishError(jobId, "Worker returned status: " + status);
        }
        crawlJobRepository.save(job);

        log.info("Processed internal callback for job: id={}, evidenceCount={}, status={}", 
                jobId, savedEvidence.size(), job.getStatus());

        return getSearchResult(jobId);
    }

    /**
     * Get job status
     */
    @Transactional(readOnly = true)
    public DeepSearchJobDto getJobStatus(String jobId) {
        CrawlJob job = crawlJobRepository.findById(jobId)
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));
        return toJobDto(job);
    }

    /**
     * Get full search result including evidence
     */
    @Transactional(readOnly = true)
    public DeepSearchResultDto getSearchResult(String jobId) {
        CrawlJob job = crawlJobRepository.findById(jobId)
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));

        List<CrawlEvidence> evidenceList = crawlEvidenceRepository.findByJobId(jobId);
        List<EvidenceDto> evidenceDtos = evidenceList.stream()
                .map(this::toEvidenceDto)
                .collect(Collectors.toList());

        // Calculate stance distribution
        StanceDistributionDto stanceDistribution = calculateStanceDistribution(jobId);

        return DeepSearchResultDto.builder()
                .jobId(job.getId())
                .topic(job.getTopic())
                .baseUrl(job.getBaseUrl())
                .status(job.getStatus().name())
                .evidenceCount(evidenceList.size())
                .evidence(evidenceDtos)
                .stanceDistribution(stanceDistribution)
                .createdAt(job.getCreatedAt())
                .completedAt(job.getCompletedAt())
                .errorMessage(job.getErrorMessage())
                .failureReason(job.getFailureReason() != null ? job.getFailureReason().getCode() : null)
                .failureCategory(categorizeFailureReason(job.getFailureReason()))
                .build();
    }

    /**
     * List recent jobs
     */
    @Transactional(readOnly = true)
    public Page<DeepSearchJobDto> listJobs(int page, int size, CrawlJobStatus status) {
        Pageable pageable = PageRequest.of(page, size, Sort.by(Sort.Direction.DESC, "createdAt"));

        Page<CrawlJob> jobs;
        if (status != null) {
            jobs = crawlJobRepository.findByStatus(status, pageable);
        } else {
            jobs = crawlJobRepository.findAll(pageable);
        }

        return jobs.map(this::toJobDto);
    }

    /**
     * Cancel a pending or in-progress job
     */
    @Transactional
    public DeepSearchJobDto cancelJob(String jobId) {
        CrawlJob job = crawlJobRepository.findById(jobId)
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));

        if (job.getStatus() == CrawlJobStatus.PENDING || job.getStatus() == CrawlJobStatus.IN_PROGRESS) {
            job.setStatus(CrawlJobStatus.CANCELLED);
            job.setCompletedAt(LocalDateTime.now());
            job.setFailureReason(CrawlFailureReason.JOB_CANCELLED);
            job.setErrorMessage("Job was cancelled by user");
            crawlJobRepository.save(job);
            log.info("Cancelled job: {}", jobId);
            
            // Publish cancellation via SSE
            deepSearchEventService.publishStatusUpdate(jobId, "CANCELLED", "Job was cancelled by user");
            deepSearchEventService.publishComplete(jobId, toJobDto(job));
        }

        return toJobDto(job);
    }

    /**
     * Scheduled task to timeout old pending jobs
     */
    @Scheduled(fixedDelayString = "${collector.deep-search.timeout-check-interval:300000}")
    @Transactional
    public void timeoutOldJobs() {
        LocalDateTime cutoff = LocalDateTime.now().minusMinutes(timeoutMinutes);
        
        // Find jobs that will be timed out before marking them
        List<CrawlJob> jobsToTimeout = crawlJobRepository.findByStatusInAndCreatedAtBefore(
                List.of(CrawlJobStatus.PENDING, CrawlJobStatus.IN_PROGRESS),
                cutoff
        );
        
        if (!jobsToTimeout.isEmpty()) {
            // Update each job with proper failure reason
            for (CrawlJob job : jobsToTimeout) {
                job.markTimedOut(CrawlFailureReason.TIMEOUT_JOB_OVERALL);
                crawlJobRepository.save(job);
                
                String errorMsg = "Job timed out after " + timeoutMinutes + " minutes [" + 
                        CrawlFailureReason.TIMEOUT_JOB_OVERALL.getCode() + "]";
                deepSearchEventService.publishError(job.getId(), errorMsg, CrawlFailureReason.TIMEOUT_JOB_OVERALL);
            }
            log.info("Marked {} jobs as timed out with reason: {}", jobsToTimeout.size(), 
                    CrawlFailureReason.TIMEOUT_JOB_OVERALL.getCode());
        }
    }

    /**
     * Scheduled task to cleanup old jobs
     */
    @Scheduled(cron = "${collector.deep-search.cleanup-cron:0 0 3 * * ?}")
    @Transactional
    public void cleanupOldJobs() {
        LocalDateTime cutoff = LocalDateTime.now().minusDays(cleanupDays);
        
        // Get job IDs to delete
        List<CrawlJob> oldJobs = crawlJobRepository.findByStatusInAndCreatedAtBefore(
                List.of(CrawlJobStatus.COMPLETED, CrawlJobStatus.FAILED, 
                        CrawlJobStatus.TIMEOUT, CrawlJobStatus.CANCELLED),
                cutoff
        );

        if (!oldJobs.isEmpty()) {
            List<String> jobIds = oldJobs.stream().map(CrawlJob::getId).collect(Collectors.toList());
            
            // Delete evidence first
            int evidenceDeleted = crawlEvidenceRepository.deleteByJobIdIn(jobIds);
            
            // Delete jobs
            int jobsDeleted = crawlJobRepository.deleteOldJobs(cutoff);
            
            log.info("Cleanup completed: {} jobs deleted, {} evidence records deleted", 
                    jobsDeleted, evidenceDeleted);
        }
    }

    // Helper methods

    private String generateJobId() {
        return "crawl_" + UUID.randomUUID().toString().replace("-", "").substring(0, 16);
    }

    private void updateJobStatus(String jobId, CrawlJobStatus status) {
        updateJobStatus(jobId, status, null);
    }

    private void updateJobStatus(String jobId, CrawlJobStatus status, String errorMessage) {
        updateJobStatusWithReason(jobId, status, errorMessage, null);
    }

    private void updateJobStatusWithReason(String jobId, CrawlJobStatus status, String errorMessage, CrawlFailureReason failureReason) {
        crawlJobRepository.findById(jobId).ifPresent(job -> {
            job.setStatus(status);
            if (errorMessage != null) {
                job.setErrorMessage(errorMessage);
            }
            if (failureReason != null) {
                job.setFailureReason(failureReason);
            } else if (errorMessage != null && status == CrawlJobStatus.FAILED) {
                // Auto-detect failure reason from error message
                job.setFailureReason(CrawlFailureReason.fromErrorMessage(errorMessage));
            }
            if (status == CrawlJobStatus.FAILED || status == CrawlJobStatus.TIMEOUT) {
                job.setCompletedAt(LocalDateTime.now());
            }
            crawlJobRepository.save(job);
        });
    }

    private StanceDistributionDto calculateStanceDistribution(String jobId) {
        List<Object[]> distribution = crawlEvidenceRepository.getStanceDistribution(jobId);
        
        Map<EvidenceStance, Long> counts = distribution.stream()
                .collect(Collectors.toMap(
                        arr -> (EvidenceStance) arr[0],
                        arr -> (Long) arr[1]
                ));

        long total = counts.values().stream().mapToLong(Long::longValue).sum();
        if (total == 0) total = 1; // Avoid division by zero

        long finalTotal = total;
        return StanceDistributionDto.builder()
                .pro(counts.getOrDefault(EvidenceStance.PRO, 0L))
                .con(counts.getOrDefault(EvidenceStance.CON, 0L))
                .neutral(counts.getOrDefault(EvidenceStance.NEUTRAL, 0L))
                .proRatio(counts.getOrDefault(EvidenceStance.PRO, 0L) / (double) finalTotal)
                .conRatio(counts.getOrDefault(EvidenceStance.CON, 0L) / (double) finalTotal)
                .neutralRatio(counts.getOrDefault(EvidenceStance.NEUTRAL, 0L) / (double) finalTotal)
                .build();
    }

    private DeepSearchJobDto toJobDto(CrawlJob job) {
        return DeepSearchJobDto.builder()
                .jobId(job.getId())
                .topic(job.getTopic())
                .baseUrl(job.getBaseUrl())
                .status(job.getStatus().name())
                .evidenceCount(job.getEvidenceCount())
                .errorMessage(job.getErrorMessage())
                .failureReason(job.getFailureReason() != null ? job.getFailureReason().getCode() : null)
                .failureCategory(categorizeFailureReason(job.getFailureReason()))
                .createdAt(job.getCreatedAt())
                .completedAt(job.getCompletedAt())
                .build();
    }

    /**
     * Categorize failure reason into high-level categories for frontend display
     */
    private String categorizeFailureReason(CrawlFailureReason reason) {
        if (reason == null) return null;
        
        String code = reason.getCode();
        if (code.startsWith("timeout")) return "timeout";
        if (code.contains("connection") || code.contains("dns") || code.contains("network") || code.contains("ssl")) return "network";
        if (code.contains("service") || code.contains("unavailable") || code.contains("overloaded")) return "service";
        if (code.contains("content") || code.contains("parse") || code.contains("blocked")) return "content";
        if (code.contains("ai") || code.contains("evidence") || code.contains("stance")) return "processing";
        if (code.contains("cancelled") || code.contains("callback") || code.contains("token")) return "job";
        return "unknown";
    }

    private EvidenceDto toEvidenceDto(CrawlEvidence evidence) {
        return EvidenceDto.builder()
                .id(evidence.getId())
                .url(evidence.getUrl())
                .title(evidence.getTitle())
                .stance(evidence.getStance() != null ? evidence.getStance().name().toLowerCase() : "neutral")
                .snippet(evidence.getSnippet())
                .source(evidence.getSource())
                .build();
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/DeepOrchestrationService.java

```java
package com.newsinsight.collector.service;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.newsinsight.collector.dto.*;
import com.newsinsight.collector.entity.ai.*;
import com.newsinsight.collector.repository.AiJobRepository;
import com.newsinsight.collector.repository.AiSubTaskRepository;
import com.newsinsight.collector.service.autocrawl.AutoCrawlIntegrationService;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.PageRequest;
import org.springframework.data.domain.Pageable;
import org.springframework.data.domain.Sort;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.time.LocalDateTime;
import java.util.*;
import java.util.regex.Matcher;
import java.util.regex.Pattern;
import java.util.stream.Collectors;

/**
 * Orchestration service for multi-provider AI analysis.
 * Manages job lifecycle, sub-task distribution, and result aggregation.
 * 
 * AutoCrawl Integration: Notifies AutoCrawl of discovered URLs when deep analysis completes.
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class DeepOrchestrationService {

    private final AiJobRepository aiJobRepository;
    private final AiSubTaskRepository aiSubTaskRepository;
    private final KafkaTemplate<String, AiTaskRequestMessage> aiTaskRequestKafkaTemplate;
    private final ObjectMapper objectMapper;
    private final AutoCrawlIntegrationService autoCrawlIntegrationService;

    @Value("${collector.ai.orchestration.topic:ai.tasks.requests}")
    private String aiTaskRequestTopic;

    @Value("${collector.ai.orchestration.callback-base-url:${collector.deep-search.callback-base-url:http://localhost:8081}}")
    private String callbackBaseUrl;

    @Value("${collector.ai.orchestration.callback-token:${collector.deep-search.callback-token:}}")
    private String callbackToken;

    @Value("${collector.ai.orchestration.timeout-minutes:30}")
    private int timeoutMinutes;

    @Value("${collector.ai.orchestration.cleanup-days:7}")
    private int cleanupDays;

    @Value("${autocrawl.enabled:true}")
    private boolean autoCrawlEnabled;

    // URL extraction pattern for discovering URLs in AI results
    private static final Pattern URL_PATTERN = Pattern.compile(
            "https?://[\\w\\-._~:/?#\\[\\]@!$&'()*+,;=%]+",
            Pattern.CASE_INSENSITIVE
    );

    /**
     * Start a new deep analysis job with multiple AI providers.
     * 
     * @param topic The search topic
     * @param baseUrl Optional base URL for crawling
     * @param providers List of providers to use (null = default set)
     * @return Created job DTO
     */
    @Transactional
    public AiJobDto startDeepAnalysis(String topic, String baseUrl, List<AiProvider> providers) {
        // Generate job ID
        String jobId = AiJob.generateJobId();
        
        // Create job entity
        AiJob job = AiJob.builder()
                .id(jobId)
                .topic(topic)
                .baseUrl(baseUrl)
                .overallStatus(AiJobStatus.PENDING)
                .build();

        // Determine which providers to use
        List<AiProvider> targetProviders = providers != null && !providers.isEmpty()
                ? providers
                : getDefaultProviders();

        // Create sub-tasks for each provider
        for (AiProvider provider : targetProviders) {
            AiSubTask subTask = AiSubTask.create(job, provider, getTaskTypeForProvider(provider));
            log.debug("Created sub-task: {} for provider: {}", subTask.getId(), provider);
        }

        // Save job with sub-tasks
        aiJobRepository.save(job);
        log.info("Created AI job: id={}, topic={}, providers={}", jobId, topic, targetProviders);

        // Publish tasks to Kafka
        publishTasksToKafka(job);

        // Update job status to IN_PROGRESS
        job.markInProgress();
        aiJobRepository.save(job);

        return toJobDto(job);
    }

    /**
     * Start analysis with default providers
     */
    @Transactional
    public AiJobDto startDeepAnalysis(String topic, String baseUrl) {
        return startDeepAnalysis(topic, baseUrl, null);
    }

    /**
     * Handle callback from AI worker/n8n
     */
    @Transactional
    public void handleCallback(AiTaskCallbackRequest request) {
        log.info("Processing callback: jobId={}, subTaskId={}, status={}", 
                request.jobId(), request.subTaskId(), request.status());

        // Find sub-task
        AiSubTask subTask = findSubTask(request);
        if (subTask == null) {
            log.warn("Sub-task not found for callback: jobId={}, subTaskId={}, providerId={}", 
                    request.jobId(), request.subTaskId(), request.providerId());
            return;
        }

        // Check if already processed
        if (subTask.isTerminal()) {
            log.warn("Sub-task already in terminal state: {}", subTask.getId());
            return;
        }

        // Update sub-task status
        if (request.isSuccess()) {
            String resultJson = buildResultJson(request);
            subTask.markCompleted(resultJson);
            log.info("Sub-task completed: {}", subTask.getId());
        } else {
            subTask.markFailed(request.errorMessage());
            log.warn("Sub-task failed: {} - {}", subTask.getId(), request.errorMessage());
        }
        aiSubTaskRepository.save(subTask);

        // Update job overall status
        AiJob job = subTask.getAiJob();
        updateJobOverallStatus(job);
    }

    /**
     * Get job status
     */
    @Transactional(readOnly = true)
    public AiJobDto getJobStatus(String jobId) {
        AiJob job = aiJobRepository.findByIdWithSubTasks(jobId)
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));
        return toJobDto(job);
    }

    /**
     * List jobs with pagination
     */
    @Transactional(readOnly = true)
    public Page<AiJobDto> listJobs(int page, int size, AiJobStatus status) {
        Pageable pageable = PageRequest.of(page, size, Sort.by(Sort.Direction.DESC, "createdAt"));
        
        Page<AiJob> jobs = status != null
                ? aiJobRepository.findByOverallStatus(status, pageable)
                : aiJobRepository.findAll(pageable);

        return jobs.map(this::toJobDtoWithoutSubTasks);
    }

    /**
     * Cancel a job
     */
    @Transactional
    public AiJobDto cancelJob(String jobId) {
        AiJob job = aiJobRepository.findByIdWithSubTasks(jobId)
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));

        if (!job.isTerminal()) {
            job.markCancelled();
            
            // Cancel all pending sub-tasks
            for (AiSubTask subTask : job.getSubTasks()) {
                if (!subTask.isTerminal()) {
                    subTask.markCancelled();
                }
            }
            
            aiJobRepository.save(job);
            log.info("Cancelled job: {}", jobId);
        }

        return toJobDto(job);
    }

    /**
     * Retry failed sub-tasks for a job
     */
    @Transactional
    public AiJobDto retryFailedTasks(String jobId) {
        AiJob job = aiJobRepository.findByIdWithSubTasks(jobId)
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));

        List<AiSubTask> failedTasks = job.getSubTasks().stream()
                .filter(t -> t.getStatus() == AiTaskStatus.FAILED || t.getStatus() == AiTaskStatus.TIMEOUT)
                .collect(Collectors.toList());

        if (failedTasks.isEmpty()) {
            log.info("No failed tasks to retry for job: {}", jobId);
            return toJobDto(job);
        }

        // Reset failed tasks and re-publish
        for (AiSubTask task : failedTasks) {
            task.setStatus(AiTaskStatus.PENDING);
            task.setErrorMessage(null);
            task.setResultJson(null);
            task.setCompletedAt(null);
            task.incrementRetry();
            
            publishTaskToKafka(job, task);
        }

        job.setOverallStatus(AiJobStatus.IN_PROGRESS);
        job.setCompletedAt(null);
        aiJobRepository.save(job);

        log.info("Retrying {} failed tasks for job: {}", failedTasks.size(), jobId);
        return toJobDto(job);
    }

    /**
     * Scheduled task to timeout old pending jobs
     */
    @Scheduled(fixedDelayString = "${collector.ai.orchestration.timeout-check-interval:300000}")
    @Transactional
    public void timeoutOldJobs() {
        LocalDateTime cutoff = LocalDateTime.now().minusMinutes(timeoutMinutes);
        
        // Mark timed out sub-tasks
        int tasksTimedOut = aiSubTaskRepository.markTimedOutTasks(cutoff);
        
        // Mark timed out jobs
        int jobsTimedOut = aiJobRepository.markTimedOutJobs(cutoff);
        
        if (tasksTimedOut > 0 || jobsTimedOut > 0) {
            log.info("Timeout check: {} tasks, {} jobs marked as timed out", tasksTimedOut, jobsTimedOut);
        }
    }

    /**
     * Scheduled cleanup of old jobs
     */
    @Scheduled(cron = "${collector.ai.orchestration.cleanup-cron:0 0 3 * * ?}")
    @Transactional
    public void cleanupOldJobs() {
        LocalDateTime cutoff = LocalDateTime.now().minusDays(cleanupDays);
        
        // Get job IDs to delete
        List<AiJob> oldJobs = aiJobRepository.findByStatusInAndCreatedAtBefore(
                List.of(AiJobStatus.COMPLETED, AiJobStatus.FAILED, 
                        AiJobStatus.PARTIAL_SUCCESS, AiJobStatus.TIMEOUT, AiJobStatus.CANCELLED),
                cutoff
        );

        if (!oldJobs.isEmpty()) {
            List<String> jobIds = oldJobs.stream().map(AiJob::getId).collect(Collectors.toList());
            
            // Delete sub-tasks first
            int tasksDeleted = aiSubTaskRepository.deleteByJobIds(jobIds);
            
            // Delete jobs
            int jobsDeleted = aiJobRepository.deleteOldJobs(cutoff);
            
            log.info("Cleanup: {} jobs deleted, {} sub-tasks deleted", jobsDeleted, tasksDeleted);
        }
    }

    // ========== Helper Methods ==========

    private List<AiProvider> getDefaultProviders() {
        // Default set of providers for deep analysis
        return List.of(
                AiProvider.SCOUT,           // Quick reconnaissance
                AiProvider.DEEP_READER,     // In-depth analysis
                AiProvider.UNIVERSAL_AGENT  // General AI processing
        );
    }

    private String getTaskTypeForProvider(AiProvider provider) {
        return switch (provider) {
            case SCOUT -> "reconnaissance";
            case DEEP_READER -> "deep_analysis";
            case UNIVERSAL_AGENT -> "general_analysis";
            case LOCAL_QUICK -> "quick_process";
        };
    }

    private void publishTasksToKafka(AiJob job) {
        for (AiSubTask subTask : job.getSubTasks()) {
            publishTaskToKafka(job, subTask);
        }
    }

    private void publishTaskToKafka(AiJob job, AiSubTask subTask) {
        if (!subTask.getProviderId().isExternal()) {
            // LOCAL_QUICK doesn't need Kafka
            log.debug("Skipping Kafka publish for local provider: {}", subTask.getProviderId());
            return;
        }

        String callbackUrl = buildCallbackUrl();
        
        AiTaskRequestMessage message = AiTaskRequestMessage.builder()
                .jobId(job.getId())
                .subTaskId(subTask.getId())
                .providerId(subTask.getProviderId().name())
                .taskType(subTask.getTaskType())
                .topic(job.getTopic())
                .baseUrl(job.getBaseUrl())
                .payload(buildPayload(job, subTask))
                .callbackUrl(callbackUrl)
                .callbackToken(callbackToken)
                .createdAt(LocalDateTime.now())
                .build();

        try {
            aiTaskRequestKafkaTemplate.send(aiTaskRequestTopic, job.getId(), message);
            log.debug("Published task to Kafka: topic={}, jobId={}, subTaskId={}", 
                    aiTaskRequestTopic, job.getId(), subTask.getId());
        } catch (Exception e) {
            log.error("Failed to publish task to Kafka: {}", e.getMessage(), e);
            subTask.markFailed("Failed to publish to Kafka: " + e.getMessage());
            aiSubTaskRepository.save(subTask);
        }
    }

    private Map<String, Object> buildPayload(AiJob job, AiSubTask subTask) {
        Map<String, Object> payload = new HashMap<>();
        payload.put("topic", job.getTopic());
        payload.put("baseUrl", job.getBaseUrl());
        payload.put("taskType", subTask.getTaskType());
        payload.put("retryCount", subTask.getRetryCount());
        return payload;
    }

    private String buildCallbackUrl() {
        String base = callbackBaseUrl.endsWith("/") 
                ? callbackBaseUrl.substring(0, callbackBaseUrl.length() - 1) 
                : callbackBaseUrl;
        return base + "/api/v1/ai/callback";
    }

    private AiSubTask findSubTask(AiTaskCallbackRequest request) {
        // Try to find by subTaskId first
        if (request.subTaskId() != null && !request.subTaskId().isBlank()) {
            return aiSubTaskRepository.findById(request.subTaskId()).orElse(null);
        }
        
        // Fallback: find by jobId + providerId
        if (request.jobId() != null && request.providerId() != null) {
            try {
                AiProvider provider = AiProvider.valueOf(request.providerId());
                return aiSubTaskRepository.findByAiJobIdAndProviderId(request.jobId(), provider).orElse(null);
            } catch (IllegalArgumentException e) {
                log.warn("Invalid provider ID: {}", request.providerId());
            }
        }
        
        return null;
    }

    private String buildResultJson(AiTaskCallbackRequest request) {
        // If evidence is provided, include it in result
        if (request.evidence() != null && !request.evidence().isEmpty()) {
            try {
                Map<String, Object> result = new HashMap<>();
                result.put("evidence", request.evidence());
                result.put("resultJson", request.resultJson());
                return objectMapper.writeValueAsString(result);
            } catch (JsonProcessingException e) {
                log.warn("Failed to serialize evidence: {}", e.getMessage());
            }
        }
        return request.resultJson();
    }

    private void updateJobOverallStatus(AiJob job) {
        List<AiSubTask> subTasks = aiSubTaskRepository.findByAiJobId(job.getId());
        
        long total = subTasks.size();
        long completed = subTasks.stream().filter(t -> t.getStatus() == AiTaskStatus.COMPLETED).count();
        // long failed = subTasks.stream().filter(t -> t.getStatus() == AiTaskStatus.FAILED).count();
        long timeout = subTasks.stream().filter(t -> t.getStatus() == AiTaskStatus.TIMEOUT).count();
        long pending = subTasks.stream().filter(t -> 
                t.getStatus() == AiTaskStatus.PENDING || t.getStatus() == AiTaskStatus.IN_PROGRESS).count();

        AiJobStatus previousStatus = job.getOverallStatus();
        
        if (pending > 0) {
            // Still processing
            job.setOverallStatus(AiJobStatus.IN_PROGRESS);
        } else if (completed == total) {
            // All completed
            job.markCompleted();
        } else if (completed > 0) {
            // Some completed, some failed
            job.markPartialSuccess();
        } else if (timeout == total) {
            // All timed out
            job.markTimeout();
        } else {
            // All failed
            job.markFailed("All sub-tasks failed");
        }

        aiJobRepository.save(job);
        log.info("Updated job status: id={}, status={}, completed={}/{}", 
                job.getId(), job.getOverallStatus(), completed, total);

        // Notify AutoCrawl of discovered URLs when job completes (fully or partially)
        if (autoCrawlEnabled && previousStatus == AiJobStatus.IN_PROGRESS 
                && (job.getOverallStatus() == AiJobStatus.COMPLETED 
                    || job.getOverallStatus() == AiJobStatus.PARTIAL_SUCCESS)) {
            notifyAutoCrawlOfDiscoveredUrls(job, subTasks);
        }
    }

    /**
     * Extract URLs from completed sub-task results and notify AutoCrawl.
     */
    private void notifyAutoCrawlOfDiscoveredUrls(AiJob job, List<AiSubTask> subTasks) {
        try {
            Set<String> discoveredUrls = new HashSet<>();
            
            for (AiSubTask subTask : subTasks) {
                if (subTask.getStatus() == AiTaskStatus.COMPLETED && subTask.getResultJson() != null) {
                    // Extract URLs from result JSON
                    List<String> urls = extractUrlsFromText(subTask.getResultJson());
                    discoveredUrls.addAll(urls);
                }
            }

            if (!discoveredUrls.isEmpty()) {
                log.info("Deep search job {} discovered {} unique URLs, notifying AutoCrawl", 
                        job.getId(), discoveredUrls.size());
                autoCrawlIntegrationService.onDeepSearchCompleted(
                        job.getId(), 
                        job.getTopic(), 
                        new ArrayList<>(discoveredUrls)
                );
            }
        } catch (Exception e) {
            log.warn("Failed to notify AutoCrawl of discovered URLs: jobId={}, error={}", 
                    job.getId(), e.getMessage());
        }
    }

    /**
     * Extract URLs from text content.
     */
    private List<String> extractUrlsFromText(String text) {
        if (text == null || text.isBlank()) {
            return List.of();
        }
        
        Matcher matcher = URL_PATTERN.matcher(text);
        List<String> urls = new ArrayList<>();
        while (matcher.find()) {
            urls.add(matcher.group());
        }
        return urls;
    }

    private AiJobDto toJobDto(AiJob job) {
        List<AiSubTaskDto> subTaskDtos = job.getSubTasks().stream()
                .map(this::toSubTaskDto)
                .collect(Collectors.toList());

        long completed = subTaskDtos.stream()
                .filter(t -> "COMPLETED".equals(t.getStatus())).count();
        long failed = subTaskDtos.stream()
                .filter(t -> "FAILED".equals(t.getStatus()) || "TIMEOUT".equals(t.getStatus())).count();

        return AiJobDto.builder()
                .jobId(job.getId())
                .topic(job.getTopic())
                .baseUrl(job.getBaseUrl())
                .overallStatus(job.getOverallStatus().name())
                .subTasks(subTaskDtos)
                .totalTasks(subTaskDtos.size())
                .completedTasks((int) completed)
                .failedTasks((int) failed)
                .errorMessage(job.getErrorMessage())
                .createdAt(job.getCreatedAt())
                .updatedAt(job.getUpdatedAt())
                .completedAt(job.getCompletedAt())
                .build();
    }

    private AiJobDto toJobDtoWithoutSubTasks(AiJob job) {
        return AiJobDto.builder()
                .jobId(job.getId())
                .topic(job.getTopic())
                .baseUrl(job.getBaseUrl())
                .overallStatus(job.getOverallStatus().name())
                .subTasks(List.of())
                .errorMessage(job.getErrorMessage())
                .createdAt(job.getCreatedAt())
                .updatedAt(job.getUpdatedAt())
                .completedAt(job.getCompletedAt())
                .build();
    }

    private AiSubTaskDto toSubTaskDto(AiSubTask subTask) {
        return AiSubTaskDto.builder()
                .subTaskId(subTask.getId())
                .jobId(subTask.getAiJob() != null ? subTask.getAiJob().getId() : null)
                .providerId(subTask.getProviderId().name())
                .taskType(subTask.getTaskType())
                .status(subTask.getStatus().name())
                .resultJson(subTask.getResultJson())
                .errorMessage(subTask.getErrorMessage())
                .retryCount(subTask.getRetryCount())
                .createdAt(subTask.getCreatedAt())
                .updatedAt(subTask.getUpdatedAt())
                .completedAt(subTask.getCompletedAt())
                .build();
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/DeepSearchEventService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.dto.DeepSearchJobDto;
import com.newsinsight.collector.dto.EvidenceDto;
import com.newsinsight.collector.entity.CrawlFailureReason;
import lombok.extern.slf4j.Slf4j;
import org.springframework.http.codec.ServerSentEvent;
import org.springframework.stereotype.Service;
import reactor.core.publisher.Flux;
import reactor.core.publisher.Sinks;

import java.time.Duration;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;

/**
 * Service for managing SSE streams for deep search jobs.
 * Each job has its own event sink that clients can subscribe to.
 */
@Service
@Slf4j
public class DeepSearchEventService {

    // Map of jobId -> Sinks for that job
    private final Map<String, Sinks.Many<ServerSentEvent<Object>>> jobSinks = new ConcurrentHashMap<>();
    
    // Timeout for inactive sinks (30 minutes)
    // @CHECK 싱크 타임아웃 설정이 필요할 것 같음
    private static final Duration SINK_TIMEOUT = Duration.ofMinutes(30);

    /**
     * Get or create a sink for a job.
     * 
     * @param jobId The job ID
     * @return The event sink for this job
     */
    private Sinks.Many<ServerSentEvent<Object>> getOrCreateSink(String jobId) {
        return jobSinks.computeIfAbsent(jobId, id -> {
            log.info("Creating new SSE sink for job: {}", id);
            return Sinks.many().multicast().onBackpressureBuffer(100);
        });
    }

    /**
     * Get the event stream for a specific job.
     * Includes heartbeats every 15 seconds to keep connection alive.
     * 
     * @param jobId The job ID to subscribe to
     * @return SSE event stream
     */
    public Flux<ServerSentEvent<Object>> getJobEventStream(String jobId) {
        Sinks.Many<ServerSentEvent<Object>> sink = getOrCreateSink(jobId);
        
        // Heartbeat stream
        Flux<ServerSentEvent<Object>> heartbeat = Flux.interval(Duration.ofSeconds(15))
                .map(tick -> ServerSentEvent.builder()
                        .event("heartbeat")
                        .data(Map.of(
                                "eventType", "heartbeat",
                                "jobId", jobId,
                                "timestamp", System.currentTimeMillis()
                        ))
                        .build());

        // Main event stream from sink
        Flux<ServerSentEvent<Object>> events = sink.asFlux();

        return Flux.merge(heartbeat, events)
                .doOnSubscribe(sub -> log.info("New SSE subscriber for job: {}", jobId))
                .doOnCancel(() -> log.info("SSE subscriber disconnected for job: {}", jobId))
                .doOnError(e -> log.error("SSE stream error for job: {}", jobId, e));
    }

    /**
     * Publish a status update event.
     * 
     * @param jobId The job ID
     * @param status Current status
     * @param message Optional message
     */
    public void publishStatusUpdate(String jobId, String status, String message) {
        Sinks.Many<ServerSentEvent<Object>> sink = jobSinks.get(jobId);
        if (sink == null) {
            log.debug("No sink found for job: {}, creating new one", jobId);
            sink = getOrCreateSink(jobId);
        }

        ServerSentEvent<Object> event = ServerSentEvent.builder()
                .event("status")
                .data(Map.of(
                        "eventType", "status",
                        "jobId", jobId,
                        "status", status,
                        "message", message != null ? message : "",
                        "timestamp", System.currentTimeMillis()
                ))
                .build();

        sink.tryEmitNext(event);
        log.debug("Published status event for job: {}, status: {}", jobId, status);
    }

    /**
     * Publish a progress update event.
     * 
     * @param jobId The job ID
     * @param progress Progress percentage (0-100)
     * @param currentStep Current step description
     */
    public void publishProgressUpdate(String jobId, int progress, String currentStep) {
        Sinks.Many<ServerSentEvent<Object>> sink = jobSinks.get(jobId);
        if (sink == null) {
            log.debug("No sink found for job: {}, creating new one for progress update", jobId);
            sink = getOrCreateSink(jobId);
        }

        ServerSentEvent<Object> event = ServerSentEvent.builder()
                .event("progress")
                .data(Map.of(
                        "eventType", "progress",
                        "jobId", jobId,
                        "progress", progress,
                        "progressMessage", currentStep,
                        "timestamp", System.currentTimeMillis()
                ))
                .build();

        sink.tryEmitNext(event);
        log.debug("Published progress event for job: {}, progress: {}%", jobId, progress);
    }

    /**
     * Publish an evidence discovered event.
     * 
     * @param jobId The job ID
     * @param evidence The evidence DTO
     */
    public void publishEvidence(String jobId, EvidenceDto evidence) {
        Sinks.Many<ServerSentEvent<Object>> sink = jobSinks.get(jobId);
        if (sink == null) {
            log.debug("No sink found for job: {}, creating new one for evidence", jobId);
            sink = getOrCreateSink(jobId);
        }

        // Get current evidence count from the sink's context or use a simple counter
        int evidenceCount = evidence.getId() != null ? evidence.getId().intValue() : 1;

        ServerSentEvent<Object> event = ServerSentEvent.builder()
                .event("evidence")
                .data(Map.of(
                        "eventType", "evidence",
                        "jobId", jobId,
                        "evidence", evidence,
                        "evidenceCount", evidenceCount,
                        "timestamp", System.currentTimeMillis()
                ))
                .build();

        sink.tryEmitNext(event);
        log.debug("Published evidence event for job: {}, url: {}", jobId, evidence.getUrl());
    }

    /**
     * Publish a job completion event.
     * 
     * @param jobId The job ID
     * @param jobDto The final job DTO
     */
    public void publishComplete(String jobId, DeepSearchJobDto jobDto) {
        Sinks.Many<ServerSentEvent<Object>> sink = jobSinks.get(jobId);
        if (sink == null) {
            log.debug("No sink found for job: {}, creating new one for completion", jobId);
            sink = getOrCreateSink(jobId);
        }

        ServerSentEvent<Object> event = ServerSentEvent.builder()
                .event("complete")
                .data(Map.of(
                        "eventType", "complete",
                        "jobId", jobId,
                        "result", jobDto,
                        "timestamp", System.currentTimeMillis()
                ))
                .build();

        sink.tryEmitNext(event);
        log.info("Published complete event for job: {}", jobId);

        // Complete the sink and schedule cleanup
        sink.tryEmitComplete();
        scheduleCleanup(jobId);
    }

    /**
     * Publish an error event.
     * 
     * @param jobId The job ID
     * @param errorMessage Error message
     */
    public void publishError(String jobId, String errorMessage) {
        publishError(jobId, errorMessage, null);
    }

    /**
     * Publish an error event with a failure reason.
     * 
     * @param jobId The job ID
     * @param errorMessage Error message
     * @param failureReason The categorized failure reason for diagnostics
     */
    public void publishError(String jobId, String errorMessage, CrawlFailureReason failureReason) {
        Sinks.Many<ServerSentEvent<Object>> sink = jobSinks.get(jobId);
        if (sink == null) {
            log.debug("No sink found for job: {}, creating new one for error", jobId);
            sink = getOrCreateSink(jobId);
        }

        // Build error data map with optional failure reason
        java.util.Map<String, Object> errorData = new java.util.HashMap<>();
        errorData.put("eventType", "error");
        errorData.put("jobId", jobId);
        errorData.put("error", errorMessage);
        errorData.put("timestamp", System.currentTimeMillis());
        
        if (failureReason != null) {
            errorData.put("failureReason", failureReason.getCode());
            errorData.put("failureCategory", categorizeFailureReason(failureReason));
            errorData.put("failureDescription", failureReason.getDescription());
        }

        ServerSentEvent<Object> event = ServerSentEvent.builder()
                .event("error")
                .data(errorData)
                .build();

        sink.tryEmitNext(event);
        log.info("Published error event for job: {}, error: {}, reason: {}", 
                jobId, errorMessage, failureReason != null ? failureReason.getCode() : "unknown");

        // Complete the sink and schedule cleanup
        sink.tryEmitComplete();
        scheduleCleanup(jobId);
    }

    /**
     * Categorize failure reason into high-level categories for frontend display
     */
    private String categorizeFailureReason(CrawlFailureReason reason) {
        if (reason == null) return "unknown";
        
        String code = reason.getCode();
        if (code.startsWith("timeout")) return "timeout";
        if (code.contains("connection") || code.contains("dns") || code.contains("network") || code.contains("ssl")) return "network";
        if (code.contains("service") || code.contains("unavailable") || code.contains("overloaded")) return "service";
        if (code.contains("content") || code.contains("parse") || code.contains("blocked")) return "content";
        if (code.contains("ai") || code.contains("evidence") || code.contains("stance")) return "processing";
        if (code.contains("cancelled") || code.contains("callback") || code.contains("token")) return "job";
        return "unknown";
    }

    /**
     * Schedule cleanup of a job's sink after a delay.
     * 
     * @param jobId The job ID to clean up
     */
    private void scheduleCleanup(String jobId) {
        // Use virtual thread or executor for delayed cleanup
        Thread.startVirtualThread(() -> {
            try {
                Thread.sleep(Duration.ofMinutes(5));
                jobSinks.remove(jobId);
                log.debug("Cleaned up sink for job: {}", jobId);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
        });
    }

    /**
     * Remove a job's sink immediately.
     * 
     * @param jobId The job ID
     */
    public void removeSink(String jobId) {
        Sinks.Many<ServerSentEvent<Object>> sink = jobSinks.remove(jobId);
        if (sink != null) {
            sink.tryEmitComplete();
            log.debug("Removed sink for job: {}", jobId);
        }
    }

    /**
     * Check if a job has an active sink.
     * 
     * @param jobId The job ID
     * @return true if there's an active sink
     */
    public boolean hasSink(String jobId) {
        return jobSinks.containsKey(jobId);
    }

    /**
     * Get the number of active sinks.
     * 
     * @return Count of active sinks
     */
    public int getActiveSinkCount() {
        return jobSinks.size();
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/FactCheckChatService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.controller.FactCheckChatController.ChatMessage;
import com.newsinsight.collector.entity.chat.FactCheckChatSession;
import com.newsinsight.collector.repository.FactCheckChatSessionRepository;
import com.newsinsight.collector.service.FactVerificationService.DeepAnalysisEvent;
import io.micrometer.core.annotation.Timed;
import io.micrometer.core.instrument.Counter;
import io.micrometer.core.instrument.MeterRegistry;
import io.micrometer.core.instrument.Timer;
import jakarta.annotation.PostConstruct;
import lombok.Builder;
import lombok.Data;
import lombok.extern.slf4j.Slf4j;
import org.springframework.cache.CacheManager;
import org.springframework.stereotype.Service;
import reactor.core.publisher.Flux;

import java.time.LocalDateTime;
import java.util.ArrayList;
import java.util.List;
import java.util.UUID;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.atomic.AtomicLong;
import java.util.stream.Collectors;

/**
 * 팩트체크 챗봇 서비스
 * 
 * MongoDB에 채팅 이력을 저장하고 Redis로 캐싱합니다.
 * 백그라운드에서 FactVerificationService를 호출하고
 * 결과를 SSE로 스트리밍합니다.
 * 
 * 주요 기능:
 * - 세션 관리 (생성, 조회, 종료)
 * - 메시지 처리 및 팩트체크 실행
 * - Redis 캐싱 (수동 관리)
 * - 백그라운드 동기화 트리거
 * - 메트릭 수집
 */
@Service
@Slf4j
public class FactCheckChatService {

    private static final String CACHE_NAME_SESSIONS = "chatSessions";
    private static final String CACHE_NAME_MESSAGES = "chatMessages";

    private final FactVerificationService factVerificationService;
    private final FactCheckChatSessionRepository sessionRepository;
    private final ChatSyncService chatSyncService;
    private final CacheManager cacheManager;
    private final MeterRegistry meterRegistry;

    // 메트릭
    private Counter sessionCreatedCounter;
    private Counter sessionClosedCounter;
    private Counter messageProcessedCounter;
    private Counter factCheckSuccessCounter;
    private Counter factCheckErrorCounter;
    private Timer factCheckTimer;
    private final AtomicLong activeSessionsGauge = new AtomicLong(0);

    // 진행 중인 세션 트래킹 (동시성 제어)
    private final ConcurrentHashMap<String, Boolean> processingSessions = new ConcurrentHashMap<>();

    public FactCheckChatService(
            FactVerificationService factVerificationService,
            FactCheckChatSessionRepository sessionRepository,
            ChatSyncService chatSyncService,
            CacheManager cacheManager,
            MeterRegistry meterRegistry
    ) {
        this.factVerificationService = factVerificationService;
        this.sessionRepository = sessionRepository;
        this.chatSyncService = chatSyncService;
        this.cacheManager = cacheManager;
        this.meterRegistry = meterRegistry;
    }

    @PostConstruct
    public void initMetrics() {
        sessionCreatedCounter = Counter.builder("factcheck.chat.sessions.created")
                .description("Number of chat sessions created")
                .register(meterRegistry);
        
        sessionClosedCounter = Counter.builder("factcheck.chat.sessions.closed")
                .description("Number of chat sessions closed")
                .register(meterRegistry);
        
        messageProcessedCounter = Counter.builder("factcheck.chat.messages.processed")
                .description("Number of messages processed")
                .register(meterRegistry);
        
        factCheckSuccessCounter = Counter.builder("factcheck.chat.factcheck.success")
                .description("Number of successful fact checks")
                .register(meterRegistry);
        
        factCheckErrorCounter = Counter.builder("factcheck.chat.factcheck.error")
                .description("Number of failed fact checks")
                .register(meterRegistry);
        
        factCheckTimer = Timer.builder("factcheck.chat.factcheck.duration")
                .description("Time taken for fact check operations")
                .register(meterRegistry);

        meterRegistry.gauge("factcheck.chat.sessions.active", activeSessionsGauge);
    }

    /**
     * 세션 생성 또는 조회
     * 캐시를 수동으로 관리하여 proxy 문제 회피
     */
    @Timed(value = "factcheck.chat.session.get", description = "Time to get or create session")
    public FactCheckChatSession getOrCreateSession(String sessionId) {
        // 1. 캐시에서 먼저 조회
        FactCheckChatSession cached = getCachedSession(sessionId);
        if (cached != null) {
            log.debug("Session {} found in cache", sessionId);
            return cached;
        }

        // 2. MongoDB에서 조회
        return sessionRepository.findBySessionId(sessionId)
                .map(session -> {
                    putSessionToCache(session);
                    return session;
                })
                .orElseGet(() -> {
                    // 3. 새 세션 생성
                    FactCheckChatSession session = FactCheckChatSession.builder()
                            .sessionId(sessionId)
                            .startedAt(LocalDateTime.now())
                            .lastActivityAt(LocalDateTime.now())
                            .status(FactCheckChatSession.SessionStatus.ACTIVE)
                            .messages(new ArrayList<>())
                            .build();
                    FactCheckChatSession saved = sessionRepository.save(session);
                    
                    // 메트릭 업데이트
                    sessionCreatedCounter.increment();
                    activeSessionsGauge.incrementAndGet();
                    
                    putSessionToCache(saved);
                    log.info("Created new chat session: {}", sessionId);
                    return saved;
                });
    }

    /**
     * 세션 생성 (사용자 정보 포함)
     */
    public FactCheckChatSession createSession(String sessionId, String userId, String userAgent, String ipAddress) {
        FactCheckChatSession session = FactCheckChatSession.builder()
                .sessionId(sessionId)
                .userId(userId)
                .startedAt(LocalDateTime.now())
                .lastActivityAt(LocalDateTime.now())
                .status(FactCheckChatSession.SessionStatus.ACTIVE)
                .messages(new ArrayList<>())
                .metadata(FactCheckChatSession.SessionMetadata.builder()
                        .userAgent(userAgent)
                        .ipAddress(ipAddress)
                        .messageCount(0)
                        .factCheckCount(0)
                        .build())
                .build();
        
        FactCheckChatSession saved = sessionRepository.save(session);
        
        sessionCreatedCounter.increment();
        activeSessionsGauge.incrementAndGet();
        putSessionToCache(saved);
        
        log.info("Created new chat session: {} for user: {}", sessionId, userId);
        return saved;
    }

    /**
     * 사용자 메시지 처리 및 팩트체크 수행
     * 
     * @param sessionId 세션 ID
     * @param userMessage 사용자 메시지
     * @param claims 검증할 주장 목록 (선택)
     * @return 챗봇 응답 이벤트 스트림
     */
    @Timed(value = "factcheck.chat.message.process", description = "Time to process message")
    public Flux<ChatEvent> processMessage(String sessionId, String userMessage, List<String> claims) {
        log.info("Processing message for session {}: {}", sessionId, userMessage);
        
        // 중복 처리 방지
        if (processingSessions.putIfAbsent(sessionId, true) != null) {
            log.warn("Session {} is already processing a message", sessionId);
            return Flux.just(ChatEvent.builder()
                    .type("error")
                    .role("system")
                    .content("이전 요청을 처리 중입니다. 잠시 후 다시 시도해주세요.")
                    .timestamp(System.currentTimeMillis())
                    .build());
        }
        
        messageProcessedCounter.increment();
        
        // 세션 조회 또는 생성
        FactCheckChatSession session = getOrCreateSession(sessionId);
        
        // 사용자 메시지 저장
        FactCheckChatSession.ChatMessage userMsg = FactCheckChatSession.ChatMessage.builder()
                .messageId(UUID.randomUUID().toString())
                .role("user")
                .content(userMessage)
                .timestamp(System.currentTimeMillis())
                .type(FactCheckChatSession.MessageType.MESSAGE)
                .build();
        
        session.getMessages().add(userMsg);
        session.setLastActivityAt(LocalDateTime.now());
        
        // 메타데이터 업데이트
        updateSessionMetadata(session);
        
        saveSession(session);

        return Flux.create(sink -> {
            Timer.Sample sample = Timer.start(meterRegistry);
            
            // 1. 인사 메시지
            sink.next(ChatEvent.builder()
                    .type("message")
                    .role("assistant")
                    .content("안녕하세요! 팩트체크 챗봇입니다. 입력하신 내용을 분석하겠습니다.")
                    .timestamp(System.currentTimeMillis())
                    .build());

            // 2. 분석 시작 알림
            sink.next(ChatEvent.builder()
                    .type("status")
                    .role("system")
                    .content("🔍 팩트체크를 시작합니다...")
                    .phase("init")
                    .timestamp(System.currentTimeMillis())
                    .build());

            // 3. 백그라운드에서 팩트체크 실행
            executeFactCheckAsync(sessionId, userMessage, claims, sink, sample);
        });
    }

    /**
     * 백그라운드에서 팩트체크 실행
     */
    private void executeFactCheckAsync(
            String sessionId, 
            String topic, 
            List<String> claims,
            reactor.core.publisher.FluxSink<ChatEvent> sink,
            Timer.Sample timerSample
    ) {
        try {
            StringBuilder assistantResponse = new StringBuilder();
            
            // FactVerificationService 호출
            factVerificationService.analyzeAndVerify(topic, claims)
                    .doOnNext(event -> {
                        // DeepAnalysisEvent를 ChatEvent로 변환
                        ChatEvent chatEvent = convertToChatEvent(event);
                        
                        // 어시스턴트 응답 누적
                        if ("ai_synthesis".equals(event.getEventType())) {
                            assistantResponse.append(event.getMessage());
                        }
                        
                        sink.next(chatEvent);
                    })
                    .doOnComplete(() -> {
                        // 최종 응답 저장
                        if (assistantResponse.length() > 0) {
                            addToHistory(sessionId, assistantResponse.toString(), 
                                    FactCheckChatSession.MessageType.AI_SYNTHESIS);
                        }
                        
                        // 완료 메시지
                        sink.next(ChatEvent.builder()
                                .type("complete")
                                .role("system")
                                .content("✅ 팩트체크가 완료되었습니다. 추가로 궁금한 점이 있으시면 질문해주세요!")
                                .timestamp(System.currentTimeMillis())
                                .build());
                        
                        // 메트릭 기록
                        timerSample.stop(factCheckTimer);
                        factCheckSuccessCounter.increment();
                        
                        // 세션 메타데이터 업데이트
                        FactCheckChatSession session = getOrCreateSession(sessionId);
                        if (session.getMetadata() != null) {
                            Integer count = session.getMetadata().getFactCheckCount();
                            session.getMetadata().setFactCheckCount(count != null ? count + 1 : 1);
                            saveSession(session);
                        }
                        
                        // 처리 상태 해제
                        processingSessions.remove(sessionId);
                        
                        sink.complete();
                    })
                    .doOnError(error -> {
                        log.error("Fact check failed for session {}: {}", sessionId, error.getMessage());
                        
                        // 에러 메시지 저장
                        addToHistory(sessionId, "팩트체크 중 오류 발생: " + error.getMessage(), 
                                FactCheckChatSession.MessageType.ERROR);
                        
                        sink.next(ChatEvent.builder()
                                .type("error")
                                .role("system")
                                .content("❌ 팩트체크 중 오류가 발생했습니다: " + error.getMessage())
                                .timestamp(System.currentTimeMillis())
                                .build());
                        
                        // 메트릭 기록
                        timerSample.stop(factCheckTimer);
                        factCheckErrorCounter.increment();
                        
                        // 처리 상태 해제
                        processingSessions.remove(sessionId);
                        
                        sink.error(error);
                    })
                    .subscribe();
                    
        } catch (Exception e) {
            log.error("Failed to execute fact check for session {}: {}", sessionId, e.getMessage());
            factCheckErrorCounter.increment();
            processingSessions.remove(sessionId);
            sink.error(e);
        }
    }

    /**
     * DeepAnalysisEvent를 ChatEvent로 변환
     */
    private ChatEvent convertToChatEvent(DeepAnalysisEvent event) {
        ChatEvent.ChatEventBuilder builder = ChatEvent.builder()
                .type(event.getEventType())
                .role("assistant")
                .content(event.getMessage())
                .phase(event.getPhase())
                .timestamp(System.currentTimeMillis());

        // 증거 정보 추가
        if (event.getEvidence() != null && !event.getEvidence().isEmpty()) {
            builder.evidence(event.getEvidence());
        }

        // 검증 결과 추가
        if (event.getVerificationResult() != null) {
            builder.verificationResult(event.getVerificationResult());
        }

        // 신뢰도 평가 추가
        if (event.getCredibility() != null) {
            builder.credibility(event.getCredibility());
        }

        return builder.build();
    }

    /**
     * 세션 저장 (MongoDB + Redis 캐시 갱신)
     */
    private FactCheckChatSession saveSession(FactCheckChatSession session) {
        session.setLastActivityAt(LocalDateTime.now());
        FactCheckChatSession saved = sessionRepository.save(session);
        
        // 캐시 업데이트
        putSessionToCache(saved);
        evictMessagesCache(session.getSessionId());
        
        // 백그라운드 동기화 트리거
        chatSyncService.scheduleSyncIfNeeded(saved);
        
        return saved;
    }

    /**
     * 이력에 메시지 추가
     */
    private void addToHistory(String sessionId, String content, FactCheckChatSession.MessageType type) {
        try {
            FactCheckChatSession session = getOrCreateSession(sessionId);
            
            FactCheckChatSession.ChatMessage message = FactCheckChatSession.ChatMessage.builder()
                    .messageId(UUID.randomUUID().toString())
                    .role("assistant")
                    .content(content)
                    .timestamp(System.currentTimeMillis())
                    .type(type)
                    .build();
            
            session.getMessages().add(message);
            saveSession(session);
            
            log.debug("Added message to history for session {}: type={}", sessionId, type);
        } catch (Exception e) {
            log.error("Failed to add message to history for session {}: {}", sessionId, e.getMessage());
        }
    }

    /**
     * 메시지 추가 및 저장 (공개 메서드)
     */
    public void addMessageToSession(String sessionId, FactCheckChatSession.ChatMessage message) {
        FactCheckChatSession session = getOrCreateSession(sessionId);
        session.getMessages().add(message);
        updateSessionMetadata(session);
        saveSession(session);
    }

    /**
     * 세션 메타데이터 업데이트
     */
    private void updateSessionMetadata(FactCheckChatSession session) {
        if (session.getMetadata() == null) {
            session.setMetadata(FactCheckChatSession.SessionMetadata.builder()
                    .messageCount(0)
                    .factCheckCount(0)
                    .build());
        }
        session.getMetadata().setMessageCount(session.getMessages().size());
    }

    /**
     * 세션 이력 조회
     */
    @Timed(value = "factcheck.chat.history.get", description = "Time to get chat history")
    public List<ChatMessage> getHistory(String sessionId) {
        // 1. 캐시에서 먼저 조회
        List<ChatMessage> cached = getCachedMessages(sessionId);
        if (cached != null) {
            log.debug("History for session {} found in cache", sessionId);
            return cached;
        }

        // 2. MongoDB에서 조회
        List<ChatMessage> history = sessionRepository.findBySessionId(sessionId)
                .map(session -> session.getMessages().stream()
                        .map(msg -> ChatMessage.builder()
                                .role(msg.getRole())
                                .content(msg.getContent())
                                .timestamp(msg.getTimestamp())
                                .build())
                        .collect(Collectors.toList()))
                .orElse(new ArrayList<>());
        
        // 캐시에 저장
        putMessagesToCache(sessionId, history);
        
        return history;
    }

    /**
     * 세션 종료
     */
    public void closeSession(String sessionId) {
        sessionRepository.findBySessionId(sessionId).ifPresent(session -> {
            session.setStatus(FactCheckChatSession.SessionStatus.COMPLETED);
            session.setEndedAt(LocalDateTime.now());
            sessionRepository.save(session);
            
            // 캐시 삭제
            evictSessionCache(sessionId);
            evictMessagesCache(sessionId);
            
            // 최종 동기화 트리거
            chatSyncService.syncSessionToRdb(session);
            
            // 메트릭 업데이트
            sessionClosedCounter.increment();
            activeSessionsGauge.decrementAndGet();
            
            // 처리 상태 정리
            processingSessions.remove(sessionId);
            
            log.info("Closed fact-check chat session: {}", sessionId);
        });
    }

    /**
     * 사용자별 세션 목록 조회
     */
    public List<FactCheckChatSession> getUserSessions(String userId) {
        return sessionRepository.findByUserIdOrderByStartedAtDesc(userId);
    }

    /**
     * 세션 상태 조회
     */
    public FactCheckChatSession.SessionStatus getSessionStatus(String sessionId) {
        return sessionRepository.findBySessionId(sessionId)
                .map(FactCheckChatSession::getStatus)
                .orElse(null);
    }

    // =====================
    // 캐시 관리 메서드
    // =====================

    private FactCheckChatSession getCachedSession(String sessionId) {
        try {
            var cache = cacheManager.getCache(CACHE_NAME_SESSIONS);
            if (cache != null) {
                var wrapper = cache.get(sessionId, FactCheckChatSession.class);
                return wrapper;
            }
        } catch (Exception e) {
            log.warn("Failed to get session from cache: {}", e.getMessage());
        }
        return null;
    }

    private void putSessionToCache(FactCheckChatSession session) {
        try {
            var cache = cacheManager.getCache(CACHE_NAME_SESSIONS);
            if (cache != null) {
                cache.put(session.getSessionId(), session);
            }
        } catch (Exception e) {
            log.warn("Failed to put session to cache: {}", e.getMessage());
        }
    }

    private void evictSessionCache(String sessionId) {
        try {
            var cache = cacheManager.getCache(CACHE_NAME_SESSIONS);
            if (cache != null) {
                cache.evict(sessionId);
            }
        } catch (Exception e) {
            log.warn("Failed to evict session from cache: {}", e.getMessage());
        }
    }

    @SuppressWarnings("unchecked")
    private List<ChatMessage> getCachedMessages(String sessionId) {
        try {
            var cache = cacheManager.getCache(CACHE_NAME_MESSAGES);
            if (cache != null) {
                return cache.get(sessionId, List.class);
            }
        } catch (Exception e) {
            log.warn("Failed to get messages from cache: {}", e.getMessage());
        }
        return null;
    }

    private void putMessagesToCache(String sessionId, List<ChatMessage> messages) {
        try {
            var cache = cacheManager.getCache(CACHE_NAME_MESSAGES);
            if (cache != null) {
                cache.put(sessionId, messages);
            }
        } catch (Exception e) {
            log.warn("Failed to put messages to cache: {}", e.getMessage());
        }
    }

    private void evictMessagesCache(String sessionId) {
        try {
            var cache = cacheManager.getCache(CACHE_NAME_MESSAGES);
            if (cache != null) {
                cache.evict(sessionId);
            }
        } catch (Exception e) {
            log.warn("Failed to evict messages from cache: {}", e.getMessage());
        }
    }

    /**
     * 챗봇 이벤트 DTO
     */
    @Data
    @Builder
    public static class ChatEvent {
        private String type;        // message, status, evidence, verification, assessment, ai_synthesis, complete, error
        private String role;        // user, assistant, system
        private String content;     // 메시지 내용
        private String phase;       // init, concepts, verification, assessment, synthesis, complete
        private Long timestamp;
        
        // 추가 데이터
        private Object evidence;
        private Object verificationResult;
        private Object credibility;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/FactVerificationService.java

```java
package com.newsinsight.collector.service;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.newsinsight.collector.client.PerplexityClient;
import com.newsinsight.collector.client.OpenAICompatibleClient;
import com.newsinsight.collector.client.AIDoveClient;
import com.newsinsight.collector.config.TrustScoreConfig;
import com.newsinsight.collector.service.factcheck.FactCheckSource;
import com.newsinsight.collector.service.search.AdvancedIntentAnalyzer;
import com.newsinsight.collector.service.search.AdvancedIntentAnalyzer.AnalyzedQuery;
import com.newsinsight.collector.service.search.AdvancedIntentAnalyzer.FallbackStrategy;
import lombok.Builder;
import lombok.Data;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.http.MediaType;
import org.springframework.stereotype.Service;
import org.springframework.web.reactive.function.client.WebClient;
import reactor.core.publisher.Flux;
import reactor.core.publisher.Mono;
import reactor.core.scheduler.Schedulers;

import java.net.URLEncoder;
import java.nio.charset.StandardCharsets;
import java.time.Duration;
import java.util.ArrayList;
import java.util.List;
import java.util.UUID;
import java.util.concurrent.CopyOnWriteArrayList;
import java.util.regex.Matcher;
import java.util.regex.Pattern;
import java.util.stream.Collectors;

/**
 * 심층 분석 신뢰성 검증 서비스
 * 
 * Wikipedia, 학술DB 등 신뢰할 수 있는 출처와 대조하여
 * 주장의 타당성을 검증합니다.
 */
@Service
@Slf4j
public class FactVerificationService {

    private final WebClient webClient;
    private final ObjectMapper objectMapper;
    private final PerplexityClient perplexityClient;
    private final OpenAICompatibleClient openAICompatibleClient;
    private final AIDoveClient aiDoveClient;
    private final List<FactCheckSource> factCheckSources;
    private final TrustScoreConfig trustScoreConfig;
    private final List<TrustedSource> trustedSources;
    private final AdvancedIntentAnalyzer advancedIntentAnalyzer;

    public FactVerificationService(
            WebClient webClient,
            ObjectMapper objectMapper,
            PerplexityClient perplexityClient,
            OpenAICompatibleClient openAICompatibleClient,
            AIDoveClient aiDoveClient,
            List<FactCheckSource> factCheckSources,
            TrustScoreConfig trustScoreConfig,
            AdvancedIntentAnalyzer advancedIntentAnalyzer) {
        this.webClient = webClient;
        this.objectMapper = objectMapper;
        this.perplexityClient = perplexityClient;
        this.openAICompatibleClient = openAICompatibleClient;
        this.aiDoveClient = aiDoveClient;
        this.factCheckSources = factCheckSources;
        this.trustScoreConfig = trustScoreConfig;
        this.advancedIntentAnalyzer = advancedIntentAnalyzer;
        
        // Initialize trusted sources with externalized scores
        this.trustedSources = initializeTrustedSources();
        
        log.info("FactVerificationService initialized with {} sources: {}", 
                factCheckSources.size(),
                factCheckSources.stream()
                        .map(s -> s.getSourceId() + (s.isAvailable() ? " (active)" : " (disabled)"))
                        .collect(Collectors.joining(", ")));
    }

    private List<TrustedSource> initializeTrustedSources() {
        TrustScoreConfig.TrustedSources ts = trustScoreConfig.getTrusted();
        return List.of(
                new TrustedSource("wikipedia", "위키백과", "https://ko.wikipedia.org/wiki/", ts.getWikipediaKo()),
                new TrustedSource("wikipedia_en", "Wikipedia", "https://en.wikipedia.org/wiki/", ts.getWikipediaEn()),
                new TrustedSource("britannica", "브리태니커", "https://www.britannica.com/search?query=", ts.getBritannica()),
                new TrustedSource("namu", "나무위키", "https://namu.wiki/w/", ts.getNamuWiki()),
                new TrustedSource("kosis", "통계청", "https://kosis.kr/search/search.do?query=", ts.getKosis()),
                new TrustedSource("scholar", "학술 자료", "https://scholar.google.com/scholar?q=", ts.getGoogleScholar())
        );
    }

    @Value("${collector.crawler.base-url:http://web-crawler:11235}")
    private String crawlerBaseUrl;

    @Value("${collector.fact-check.timeout-seconds:30}")
    private int timeoutSeconds;

    // ============================================
    // DTO Classes
    // ============================================

    @Data
    @Builder
    public static class VerificationResult {
        private String claimId;
        private String originalClaim;       // 원본 주장
        private VerificationStatus status;  // 검증 상태
        private Double confidenceScore;     // 신뢰도 점수 (0-1)
        private List<SourceEvidence> supportingEvidence;    // 지지 근거
        private List<SourceEvidence> contradictingEvidence; // 반박 근거
        private String verificationSummary; // 검증 요약
        private List<String> relatedConcepts; // 관련 개념
    }

    public enum VerificationStatus {
        VERIFIED,           // 검증됨 (신뢰할 수 있는 출처에서 확인)
        PARTIALLY_VERIFIED, // 부분 검증됨
        UNVERIFIED,         // 검증 불가 (정보 부족)
        DISPUTED,           // 논쟁 중 (상반된 정보 존재)
        FALSE               // 거짓으로 판명
    }

    @Data
    @Builder
    public static class SourceEvidence {
        private String sourceType;      // wikipedia, scholar, news 등
        private String sourceName;      // 출처 이름
        private String url;             // URL
        private String excerpt;         // 관련 발췌문
        private Double relevanceScore;  // 관련성 점수
        private String stance;          // support, contradict, neutral
    }

    @Data
    @Builder
    public static class DeepAnalysisResult {
        private String topic;
        private List<VerificationResult> verifiedClaims;
        private ConceptMap conceptMap;          // 개념 관계도
        private List<String> keyInsights;       // 핵심 인사이트
        private CredibilityAssessment credibility; // 전체 신뢰도 평가
        private String finalConclusion;         // 최종 결론
    }

    @Data
    @Builder
    public static class ConceptMap {
        private String mainTopic;
        private List<RelatedConcept> relatedConcepts;
        private List<ConceptLink> links;
    }

    @Data
    @Builder
    public static class RelatedConcept {
        private String name;
        private String description;
        private String wikiUrl;
        private Double relevance;
    }

    @Data
    @Builder
    public static class ConceptLink {
        private String from;
        private String to;
        private String relationship;
    }

    @Data
    @Builder
    public static class CredibilityAssessment {
        private Double overallScore;        // 전체 신뢰도 (0-1)
        private Integer verifiedCount;      // 검증된 주장 수
        private Integer totalClaims;        // 전체 주장 수
        private String riskLevel;           // low, medium, high
        private List<String> warnings;      // 주의사항
    }

    private record TrustedSource(String id, String name, String searchUrl, double trustScore) {}

    // ============================================
    // Main Verification Methods
    // ============================================

    /**
     * 매우 단순한 언어 감지: 영문 알파벳이 포함되어 있으면 영어(en),
     * 그렇지 않으면 기본적으로 한국어(ko)로 간주.
     */
    private String detectLanguage(String text) {
        if (text == null || text.isBlank()) {
            return "ko";
        }
        for (int i = 0; i < text.length(); i++) {
            char c = text.charAt(i);
            if ((c >= 'A' && c <= 'Z') || (c >= 'a' && c <= 'z')) {
                return "en";
            }
        }
        return "ko";
    }

    /**
     * Claim 목록을 하나로 합쳐서 기준 텍스트를 만들고,
     * evidence.excerpt 와의 자카드 유사도를 이용해 의미 있는 근거만 남긴다.
     */
    private List<SourceEvidence> filterEvidenceForClaims(List<SourceEvidence> allEvidence, List<String> claims) {
        if (allEvidence == null || allEvidence.isEmpty()) {
            return List.of();
        }
        if (claims == null || claims.isEmpty()) {
            // Claim 정보가 없으면 필터링 없이 그대로 사용
            return new ArrayList<>(allEvidence);
        }

        String combinedClaims = claims.stream()
                .filter(c -> c != null && !c.isBlank())
                .collect(Collectors.joining(" "));
        if (combinedClaims.isBlank()) {
            return new ArrayList<>(allEvidence);
        }

        List<SourceEvidence> filtered = new ArrayList<>();
        for (SourceEvidence evidence : allEvidence) {
            if (evidence == null || evidence.getExcerpt() == null || evidence.getExcerpt().isBlank()) {
                continue;
            }
            double sim = calculateSimilarity(combinedClaims, evidence.getExcerpt());
            // 너무 낮은 유사도는 제거 (기본 0.1 기준)
            if (sim >= 0.1) {
                filtered.add(evidence);
            }
        }

        // 너무 많을 경우 상위 N개만 사용 (기본 50개)
        if (filtered.size() > 50) {
            return filtered.subList(0, 50);
        }
        return filtered;
    }

    /**
     * 주어진 주제에 대해 심층 분석 및 검증 수행
     */
    public Flux<DeepAnalysisEvent> analyzeAndVerify(String topic, List<String> claims) {
        log.info("Starting deep analysis and verification for topic: {}", topic);

        // Advanced Intent Analysis for better search strategies
        AnalyzedQuery analyzedTopic = advancedIntentAnalyzer.analyzeQuery(topic);
        log.info("Topic analyzed: keywords={}, primary='{}', intent={}, strategies={}",
                analyzedTopic.getKeywords().size(),
                analyzedTopic.getPrimaryKeyword(),
                analyzedTopic.getIntentType(),
                analyzedTopic.getFallbackStrategies().size());

        // 간단한 언어 감지 (영문 알파벳 포함 여부 기준)
        String language = analyzedTopic.getLanguage();

        return Flux.create(sink -> {
            // 1. 시작 이벤트
            sink.next(DeepAnalysisEvent.builder()
                    .eventType("status")
                    .phase("init")
                    .message("심층 분석을 시작합니다: " + topic)
                    .build());

            // 2. 관련 개념 수집
            sink.next(DeepAnalysisEvent.builder()
                    .eventType("status")
                    .phase("concepts")
                    .message("관련 개념을 수집하고 있습니다...")
                    .build());

            // 병렬로 모든 신뢰할 수 있는 소스에서 정보 수집 (폴백 전략 포함)
            List<SourceEvidence> allEvidence = fetchAllSourceEvidenceWithFallback(analyzedTopic, language);

            // Claim 정보가 있다면, claim과의 유사도 기반으로 근거를 1차 필터링
            List<SourceEvidence> filteredEvidence = filterEvidenceForClaims(allEvidence, claims);

            if (!filteredEvidence.isEmpty()) {
                // 소스별 통계 생성
                var sourceStats = filteredEvidence.stream()
                        .collect(Collectors.groupingBy(
                                SourceEvidence::getSourceType,
                                Collectors.counting()));
                String statsMessage = sourceStats.entrySet().stream()
                        .map(e -> e.getKey() + ": " + e.getValue() + "개")
                        .collect(Collectors.joining(", "));
                
                sink.next(DeepAnalysisEvent.builder()
                        .eventType("evidence")
                        .phase("concepts")
                        .message("신뢰할 수 있는 출처에서 " + filteredEvidence.size() + "개의 유의미한 근거를 수집했습니다. (" + statsMessage + ")")
                        .evidence(filteredEvidence)
                        .build());
            } else {
                // 결과가 없을 때 도움말 메시지
                String noResultMessage = advancedIntentAnalyzer.buildNoResultMessage(analyzedTopic);
                sink.next(DeepAnalysisEvent.builder()
                        .eventType("status")
                        .phase("concepts")
                        .message("관련 근거를 찾기 어려웠습니다.\n" + noResultMessage)
                        .build());
            }

            // 3. 각 주장에 대한 검증 (향상된 키워드 매칭)
            final List<VerificationResult> verificationResults = new ArrayList<>();
            final CredibilityAssessment[] credibilityHolder = new CredibilityAssessment[1];
            
            if (claims != null && !claims.isEmpty()) {
                sink.next(DeepAnalysisEvent.builder()
                        .eventType("status")
                        .phase("verification")
                        .message(claims.size() + "개의 주장을 검증하고 있습니다...")
                        .build());
                
                for (int i = 0; i < claims.size(); i++) {
                    String claim = claims.get(i);
                    // 향상된 claim 검증
                    VerificationResult result = verifyClaimWithIntentAnalysis(claim, filteredEvidence);
                    verificationResults.add(result);

                    sink.next(DeepAnalysisEvent.builder()
                            .eventType("verification")
                            .phase("verification")
                            .message("주장 " + (i + 1) + "/" + claims.size() + " 검증 완료")
                            .verificationResult(result)
                            .build());
                }

                // 4. 신뢰도 평가
                credibilityHolder[0] = assessCredibility(verificationResults);
                
                sink.next(DeepAnalysisEvent.builder()
                        .eventType("assessment")
                        .phase("assessment")
                        .message("신뢰도 평가 완료")
                        .credibility(credibilityHolder[0])
                        .build());
            }

            // 5. AI 기반 종합 분석 (Fallback Chain)
            sink.next(DeepAnalysisEvent.builder()
                    .eventType("status")
                    .phase("synthesis")
                    .message("AI가 수집된 정보를 종합 분석하고 있습니다...")
                    .build());

            // Build provider chain and try each in sequence
            String synthesisPrompt = buildSynthesisPrompt(topic, filteredEvidence, claims);
            StringBuilder aiResponse = new StringBuilder();

            // Try AI providers in order of preference
            Flux<String> aiStream = getAiStreamWithFallback(synthesisPrompt);
            
            aiStream
                    .doOnNext(chunk -> {
                        aiResponse.append(chunk);
                        sink.next(DeepAnalysisEvent.builder()
                                .eventType("ai_synthesis")
                                .phase("synthesis")
                                .message(chunk)
                                .build());
                    })
                    .doOnComplete(() -> {
                        String conclusion = aiResponse.toString();
                        if (conclusion.isBlank()) {
                            conclusion = buildFallbackConclusion(topic, verificationResults, credibilityHolder[0]);
                        }
                        sink.next(DeepAnalysisEvent.builder()
                                .eventType("complete")
                                .phase("complete")
                                .message("심층 분석이 완료되었습니다.")
                                .finalConclusion(conclusion)
                                .build());
                        sink.complete();
                    })
                    .doOnError(e -> {
                        log.error("All AI providers failed: {}", e.getMessage());
                        // Generate fallback conclusion without AI
                        String fallbackConclusion = buildFallbackConclusion(topic, verificationResults, credibilityHolder[0]);
                        sink.next(DeepAnalysisEvent.builder()
                                .eventType("complete")
                                .phase("complete")
                                .message("분석이 완료되었습니다.")
                                .finalConclusion(fallbackConclusion)
                                .build());
                        sink.complete();
                    })
                    .subscribe();
        });
    }

    /**
     * Get AI stream with fallback chain.
     * Tries providers in order: Perplexity -> OpenAI -> OpenRouter -> Azure -> AI Dove -> Ollama
     */
    private Flux<String> getAiStreamWithFallback(String prompt) {
        List<AiProviderAttempt> providers = buildAiProviderChain(prompt);
        
        if (providers.isEmpty()) {
            log.warn("No AI providers available, returning empty stream");
            return Flux.empty();
        }

        log.info("AI synthesis using fallback chain: {}", 
                providers.stream().map(AiProviderAttempt::name).toList());

        return tryAiProvidersInSequence(providers, 0);
    }

    /**
     * Build the AI provider chain based on availability
     */
    private List<AiProviderAttempt> buildAiProviderChain(String prompt) {
        List<AiProviderAttempt> chain = new ArrayList<>();

        // 1. Perplexity - Best for fact-checking with online search
        if (perplexityClient.isEnabled()) {
            chain.add(new AiProviderAttempt("Perplexity", () -> perplexityClient.streamCompletion(prompt)));
        }

        // 2. OpenAI
        if (openAICompatibleClient.isOpenAIEnabled()) {
            chain.add(new AiProviderAttempt("OpenAI", () -> openAICompatibleClient.streamFromOpenAI(prompt)));
        }

        // 3. OpenRouter - Access to multiple models
        if (openAICompatibleClient.isOpenRouterEnabled()) {
            chain.add(new AiProviderAttempt("OpenRouter", () -> openAICompatibleClient.streamFromOpenRouter(prompt)));
        }

        // 4. Azure OpenAI
        if (openAICompatibleClient.isAzureEnabled()) {
            chain.add(new AiProviderAttempt("Azure", () -> openAICompatibleClient.streamFromAzure(prompt)));
        }

        // 5. AI Dove (n8n webhook) - Simulated streaming
        if (aiDoveClient.isEnabled()) {
            chain.add(new AiProviderAttempt("AI Dove", () -> aiDoveClient.chatStream(prompt, null)));
        }

        // 6. Ollama - Local LLM (always in chain, may fail if not running)
        chain.add(new AiProviderAttempt("Ollama", () -> openAICompatibleClient.streamFromOllama(prompt)));

        // 7. Custom endpoint
        if (openAICompatibleClient.isCustomEnabled()) {
            chain.add(new AiProviderAttempt("Custom", () -> openAICompatibleClient.streamFromCustom(prompt)));
        }

        return chain;
    }

    /**
     * Try AI providers in sequence until one succeeds
     */
    private Flux<String> tryAiProvidersInSequence(List<AiProviderAttempt> providers, int index) {
        if (index >= providers.size()) {
            log.warn("All AI providers exhausted");
            return Flux.empty();
        }

        AiProviderAttempt current = providers.get(index);
        log.info("Trying AI provider: {} ({}/{})", current.name(), index + 1, providers.size());

        return current.streamSupplier().get()
                .timeout(Duration.ofSeconds(90))
                .onErrorResume(e -> {
                    log.warn("AI provider {} failed: {}. Trying next...", current.name(), e.getMessage());
                    return tryAiProvidersInSequence(providers, index + 1);
                })
                .switchIfEmpty(Flux.defer(() -> {
                    log.warn("AI provider {} returned empty. Trying next...", current.name());
                    return tryAiProvidersInSequence(providers, index + 1);
                }));
    }

    /**
     * Build a fallback conclusion when AI is not available
     */
    private String buildFallbackConclusion(String topic, List<VerificationResult> results, CredibilityAssessment credibility) {
        StringBuilder sb = new StringBuilder();
        sb.append("## ").append(topic).append(" 분석 결과\n\n");
        
        if (results == null || results.isEmpty()) {
            sb.append("검증된 주장이 없습니다.\n");
        } else {
            sb.append("### 검증 결과 요약\n\n");
            int verified = 0, unverified = 0, contradicted = 0;
            for (VerificationResult r : results) {
                if (r.getStatus() == null) continue;
                switch (r.getStatus()) {
                    case VERIFIED, PARTIALLY_VERIFIED -> verified++;
                    case UNVERIFIED -> unverified++;
                    case DISPUTED, FALSE -> contradicted++;
                }
            }
            sb.append(String.format("- 검증됨: %d건\n", verified));
            sb.append(String.format("- 미확인: %d건\n", unverified));
            sb.append(String.format("- 반박됨: %d건\n\n", contradicted));
        }

        if (credibility != null) {
            sb.append("### 신뢰도 평가\n");
            sb.append(String.format("- 전체 신뢰도: %.0f%%\n", credibility.getOverallScore() * 100));
            sb.append(String.format("- 위험 수준: %s\n", credibility.getRiskLevel()));
        }

        sb.append("\n*AI 종합 분석은 현재 사용 불가합니다. 위 결과를 참고하여 판단해 주세요.*");
        return sb.toString();
    }

    /**
     * AI provider attempt wrapper
     */
    private record AiProviderAttempt(
            String name,
            java.util.function.Supplier<Flux<String>> streamSupplier
    ) {}

    // ============================================
    // Enhanced Evidence Collection with Fallback
    // ============================================

    /**
     * 폴백 전략을 사용하여 모든 소스에서 근거 수집
     */
    private List<SourceEvidence> fetchAllSourceEvidenceWithFallback(AnalyzedQuery analyzedQuery, String language) {
        List<SourceEvidence> allEvidence = new CopyOnWriteArrayList<>();
        
        // 원본 쿼리로 먼저 시도
        String currentQuery = analyzedQuery.getOriginalQuery();
        allEvidence.addAll(fetchAllSourceEvidence(currentQuery, language));
        
        // 결과가 부족하면 폴백 전략 사용
        if (allEvidence.size() < 3 && analyzedQuery.getFallbackStrategies() != null) {
            int maxAttempts = Math.min(3, analyzedQuery.getFallbackStrategies().size());
            
            for (int i = 0; i < maxAttempts && allEvidence.size() < 5; i++) {
                FallbackStrategy strategy = analyzedQuery.getFallbackStrategies().get(i);
                log.info("Fact verification fallback attempt {}: strategy='{}', query='{}'", 
                        i + 1, strategy.getStrategyType(), strategy.getQuery());
                
                List<SourceEvidence> fallbackEvidence = fetchAllSourceEvidence(strategy.getQuery(), language);
                
                // 중복 제거하며 추가
                for (SourceEvidence evidence : fallbackEvidence) {
                    boolean isDuplicate = allEvidence.stream()
                            .anyMatch(e -> e.getUrl() != null && e.getUrl().equals(evidence.getUrl()));
                    if (!isDuplicate) {
                        allEvidence.add(evidence);
                    }
                }
            }
        }
        
        log.info("Total evidence collected with fallback: {} items", allEvidence.size());
        return new ArrayList<>(allEvidence);
    }

    /**
     * 향상된 Claim 검증 - Intent Analysis 사용
     */
    private VerificationResult verifyClaimWithIntentAnalysis(String claim, List<SourceEvidence> backgroundEvidence) {
        // Claim에 대한 의도 분석
        AnalyzedQuery analyzedClaim = advancedIntentAnalyzer.analyzeQuery(claim);
        List<String> keywords = analyzedClaim.getKeywords();
        String primaryKeyword = analyzedClaim.getPrimaryKeyword();

        // 배경 증거와 대조
        List<SourceEvidence> supporting = new ArrayList<>();
        List<SourceEvidence> contradicting = new ArrayList<>();

        for (SourceEvidence evidence : backgroundEvidence) {
            // 향상된 유사도 계산 - 키워드 매칭 포함
            double similarity = calculateEnhancedSimilarity(claim, evidence.getExcerpt(), keywords, primaryKeyword);
            
            if (similarity > 0.25) {  // 낮은 임계값으로 더 많은 매칭
                evidence.setRelevanceScore(similarity);
                
                // 감성 분석으로 지지/반박 구분
                if (containsContradiction(claim, evidence.getExcerpt())) {
                    evidence.setStance("contradict");
                    contradicting.add(evidence);
                } else {
                    evidence.setStance("support");
                    supporting.add(evidence);
                }
            }
        }

        // 검증 상태 결정
        VerificationStatus status;
        double confidence;

        if (!supporting.isEmpty() && contradicting.isEmpty()) {
            status = VerificationStatus.VERIFIED;
            confidence = Math.min(0.6 + supporting.size() * 0.1, 0.95);
        } else if (!supporting.isEmpty() && !contradicting.isEmpty()) {
            status = VerificationStatus.DISPUTED;
            confidence = 0.5;
        } else if (supporting.isEmpty() && !contradicting.isEmpty()) {
            status = VerificationStatus.FALSE;
            confidence = 0.3;
        } else {
            status = VerificationStatus.UNVERIFIED;
            confidence = 0.4;
        }

        String summary = generateVerificationSummary(status, supporting.size(), contradicting.size());

        return VerificationResult.builder()
                .claimId(UUID.randomUUID().toString())
                .originalClaim(claim)
                .status(status)
                .confidenceScore(confidence)
                .supportingEvidence(supporting)
                .contradictingEvidence(contradicting)
                .verificationSummary(summary)
                .relatedConcepts(keywords)
                .build();
    }

    /**
     * 향상된 유사도 계산 - 키워드 매칭 + 자카드 유사도 결합
     */
    private double calculateEnhancedSimilarity(
            String claim, 
            String evidence, 
            List<String> keywords, 
            String primaryKeyword) {
        
        if (claim == null || evidence == null) return 0;
        
        String lowerClaim = claim.toLowerCase();
        String lowerEvidence = evidence.toLowerCase();
        
        double score = 0;
        
        // 1. 기본 자카드 유사도
        double jaccardScore = calculateSimilarity(claim, evidence);
        score += jaccardScore * 0.4;
        
        // 2. 주요 키워드 매칭 (높은 가중치)
        if (primaryKeyword != null && !primaryKeyword.isBlank() && 
                lowerEvidence.contains(primaryKeyword.toLowerCase())) {
            score += 0.3;
        }
        
        // 3. 기타 키워드 매칭
        if (keywords != null && !keywords.isEmpty()) {
            int matchCount = 0;
            for (String keyword : keywords) {
                if (lowerEvidence.contains(keyword.toLowerCase())) {
                    matchCount++;
                }
            }
            score += (double) matchCount / keywords.size() * 0.3;
        }
        
        return Math.min(score, 1.0);
    }

    // ============================================
    // Wikipedia & Trusted Source Fetching
    // ============================================

    /**
     * 모든 등록된 팩트체크 소스에서 병렬로 근거를 수집합니다.
     */
    private List<SourceEvidence> fetchAllSourceEvidence(String topic, String language) {
        List<SourceEvidence> allEvidence = new CopyOnWriteArrayList<>();
        
        // 1. 기본 Wikipedia 정보 수집 (기존 로직 유지)
        List<SourceEvidence> wikiEvidence = fetchWikipediaInfo(topic);
        allEvidence.addAll(wikiEvidence);
        
        // 2. 추가 팩트체크 소스에서 병렬 수집
        if (factCheckSources != null && !factCheckSources.isEmpty()) {
            List<Mono<List<SourceEvidence>>> sourceFetches = factCheckSources.stream()
                    .filter(FactCheckSource::isAvailable)
                    .map(source -> {
                        log.debug("Fetching evidence from source: {}", source.getSourceId());
                        return source.fetchEvidence(topic, language)
                                .collectList()
                                .timeout(Duration.ofSeconds(timeoutSeconds))
                                .doOnNext(evidences -> 
                                    log.debug("Source {} returned {} evidences", 
                                            source.getSourceId(), evidences.size()))
                                .onErrorResume(e -> {
                                    log.warn("Failed to fetch from {}: {}", 
                                            source.getSourceId(), e.getMessage());
                                    return Mono.just(List.of());
                                });
                    })
                    .toList();
            
            if (!sourceFetches.isEmpty()) {
                try {
                    List<List<SourceEvidence>> results = Flux.merge(sourceFetches)
                            .collectList()
                            .block(Duration.ofSeconds(timeoutSeconds * 2));
                    
                    if (results != null) {
                        for (List<SourceEvidence> evidences : results) {
                            allEvidence.addAll(evidences);
                        }
                    }
                } catch (Exception e) {
                    log.warn("Error during parallel evidence fetch: {}", e.getMessage());
                }
            }
        }
        
        log.info("Collected total {} evidence items for topic: {}", allEvidence.size(), topic);
        return new ArrayList<>(allEvidence);
    }

    private List<SourceEvidence> fetchWikipediaInfo(String topic) {
        List<SourceEvidence> evidenceList = new ArrayList<>();

        // 한국어 위키백과
        try {
            String koWikiContent = fetchWikipediaContent(topic, "ko");
            if (koWikiContent != null && !koWikiContent.isBlank()) {
                evidenceList.add(SourceEvidence.builder()
                        .sourceType("wikipedia")
                        .sourceName("위키백과")
                        .url("https://ko.wikipedia.org/wiki/" + URLEncoder.encode(topic, StandardCharsets.UTF_8))
                        .excerpt(truncateContent(koWikiContent, 500))
                        .relevanceScore(0.9)
                        .stance("neutral")
                        .build());
            }
        } catch (Exception e) {
            log.debug("Failed to fetch Korean Wikipedia: {}", e.getMessage());
        }

        // 영어 위키백과
        try {
            String enWikiContent = fetchWikipediaContent(topic, "en");
            if (enWikiContent != null && !enWikiContent.isBlank()) {
                evidenceList.add(SourceEvidence.builder()
                        .sourceType("wikipedia")
                        .sourceName("Wikipedia (EN)")
                        .url("https://en.wikipedia.org/wiki/" + URLEncoder.encode(topic, StandardCharsets.UTF_8))
                        .excerpt(truncateContent(enWikiContent, 500))
                        .relevanceScore(0.9)
                        .stance("neutral")
                        .build());
            }
        } catch (Exception e) {
            log.debug("Failed to fetch English Wikipedia: {}", e.getMessage());
        }

        return evidenceList;
    }

    private String fetchWikipediaContent(String topic, String lang) {
        try {
            String apiUrl = String.format(
                    "https://%s.wikipedia.org/api/rest_v1/page/summary/%s",
                    lang,
                    URLEncoder.encode(topic.replace(" ", "_"), StandardCharsets.UTF_8)
            );

            String response = webClient.get()
                    .uri(apiUrl)
                    .accept(MediaType.APPLICATION_JSON)
                    .retrieve()
                    .bodyToMono(String.class)
                    .timeout(Duration.ofSeconds(timeoutSeconds))
                    .block();

            if (response != null) {
                JsonNode node = objectMapper.readTree(response);
                if (node.has("extract")) {
                    return node.get("extract").asText();
                }
            }
        } catch (Exception e) {
            log.debug("Wikipedia API call failed for topic '{}' ({}): {}", topic, lang, e.getMessage());
        }
        return null;
    }

    // ============================================
    // Claim Verification
    // ============================================

    private VerificationResult verifyClaim(String claim, List<SourceEvidence> backgroundEvidence) {
        // 주장에서 핵심 키워드 추출
        List<String> keywords = extractKeywords(claim);

        // 배경 증거와 대조
        List<SourceEvidence> supporting = new ArrayList<>();
        List<SourceEvidence> contradicting = new ArrayList<>();

        for (SourceEvidence evidence : backgroundEvidence) {
            double similarity = calculateSimilarity(claim, evidence.getExcerpt());
            if (similarity > 0.3) {
                evidence.setRelevanceScore(similarity);
                // 간단한 감성 분석으로 지지/반박 구분 (실제로는 더 정교한 분석 필요)
                if (containsContradiction(claim, evidence.getExcerpt())) {
                    evidence.setStance("contradict");
                    contradicting.add(evidence);
                } else {
                    evidence.setStance("support");
                    supporting.add(evidence);
                }
            }
        }

        // 검증 상태 결정
        VerificationStatus status;
        double confidence;

        if (!supporting.isEmpty() && contradicting.isEmpty()) {
            status = VerificationStatus.VERIFIED;
            confidence = 0.8;
        } else if (!supporting.isEmpty() && !contradicting.isEmpty()) {
            status = VerificationStatus.DISPUTED;
            confidence = 0.5;
        } else if (supporting.isEmpty() && !contradicting.isEmpty()) {
            status = VerificationStatus.FALSE;
            confidence = 0.3;
        } else {
            status = VerificationStatus.UNVERIFIED;
            confidence = 0.4;
        }

        String summary = generateVerificationSummary(status, supporting.size(), contradicting.size());

        return VerificationResult.builder()
                .claimId(UUID.randomUUID().toString())
                .originalClaim(claim)
                .status(status)
                .confidenceScore(confidence)
                .supportingEvidence(supporting)
                .contradictingEvidence(contradicting)
                .verificationSummary(summary)
                .relatedConcepts(keywords)
                .build();
    }

    private List<String> extractKeywords(String text) {
        // 간단한 키워드 추출 (명사 추출)
        List<String> keywords = new ArrayList<>();
        String[] words = text.split("[\\s,\\.\\?!]+");
        for (String word : words) {
            if (word.length() > 2 && !isStopWord(word)) {
                keywords.add(word.toLowerCase());
            }
        }
        return keywords.stream().distinct().limit(5).toList();
    }

    private boolean isStopWord(String word) {
        return List.of("the", "a", "an", "is", "are", "was", "were", "이", "그", "저", 
                "는", "은", "가", "이", "를", "을", "에", "의").contains(word.toLowerCase());
    }

    private double calculateSimilarity(String text1, String text2) {
        if (text1 == null || text2 == null) return 0;
        
        // 간단한 자카드 유사도
        String[] words1 = text1.toLowerCase().split("\\s+");
        String[] words2 = text2.toLowerCase().split("\\s+");
        
        java.util.Set<String> set1 = new java.util.HashSet<>(List.of(words1));
        java.util.Set<String> set2 = new java.util.HashSet<>(List.of(words2));
        
        java.util.Set<String> intersection = new java.util.HashSet<>(set1);
        intersection.retainAll(set2);
        
        java.util.Set<String> union = new java.util.HashSet<>(set1);
        union.addAll(set2);
        
        return union.isEmpty() ? 0 : (double) intersection.size() / union.size();
    }

    private boolean containsContradiction(String claim, String evidence) {
        // 간단한 부정 표현 감지
        String lowerEvidence = evidence.toLowerCase();
        String lowerClaim = claim.toLowerCase();
        
        List<String> negativePatterns = List.of(
                "not true", "false", "incorrect", "wrong", "disputed", "controversy",
                "사실이 아", "거짓", "논쟁", "오류", "틀린", "잘못"
        );
        
        for (String pattern : negativePatterns) {
            if (lowerEvidence.contains(pattern)) {
                return true;
            }
        }
        return false;
    }

    private String generateVerificationSummary(VerificationStatus status, int supportCount, int contradictCount) {
        return switch (status) {
            case VERIFIED -> String.format("✅ 신뢰할 수 있는 %d개의 출처에서 확인되었습니다.", supportCount);
            case PARTIALLY_VERIFIED -> String.format("⚠️ 부분적으로 확인되었습니다. (지지: %d, 반박: %d)", supportCount, contradictCount);
            case UNVERIFIED -> "❓ 신뢰할 수 있는 출처에서 관련 정보를 찾을 수 없습니다.";
            case DISPUTED -> String.format("⚖️ 논쟁 중인 주장입니다. (지지: %d, 반박: %d)", supportCount, contradictCount);
            case FALSE -> String.format("❌ 신뢰할 수 있는 출처에서 반박되었습니다. (반박: %d)", contradictCount);
        };
    }

    // ============================================
    // Credibility Assessment
    // ============================================

    private CredibilityAssessment assessCredibility(List<VerificationResult> results) {
        int verified = 0;
        int disputed = 0;
        int falseClaims = 0;
        List<String> warnings = new ArrayList<>();

        for (VerificationResult result : results) {
            switch (result.getStatus()) {
                case VERIFIED, PARTIALLY_VERIFIED -> verified++;
                case DISPUTED -> {
                    disputed++;
                    warnings.add("논쟁 중: " + truncateContent(result.getOriginalClaim(), 50));
                }
                case FALSE -> {
                    falseClaims++;
                    warnings.add("주의 필요: " + truncateContent(result.getOriginalClaim(), 50));
                }
                default -> {}
            }
        }

        double score = results.isEmpty() ? 0.5 : 
                (double) verified / results.size() * 0.7 + 
                (1 - (double) falseClaims / Math.max(1, results.size())) * 0.3;

        String riskLevel;
        if (falseClaims > 0 || disputed > verified) {
            riskLevel = "high";
        } else if (disputed > 0) {
            riskLevel = "medium";
        } else {
            riskLevel = "low";
        }

        return CredibilityAssessment.builder()
                .overallScore(score)
                .verifiedCount(verified)
                .totalClaims(results.size())
                .riskLevel(riskLevel)
                .warnings(warnings)
                .build();
    }

    // ============================================
    // AI Synthesis
    // ============================================

    private String buildSynthesisPrompt(String topic, List<SourceEvidence> evidence, List<String> claims) {
        StringBuilder prompt = new StringBuilder();
        prompt.append("당신은 팩트체커이자 심층 분석 전문가입니다.\n\n");
        prompt.append("주제: ").append(topic).append("\n\n");
        
        // 통화/단위 맥락 분석
        String currencyHint = buildCurrencyHint(topic);
        if (!currencyHint.isEmpty()) {
            prompt.append(currencyHint).append("\n");
        }

        if (!evidence.isEmpty()) {
            prompt.append("## 신뢰할 수 있는 출처에서 수집된 정보:\n");
            for (SourceEvidence e : evidence) {
                prompt.append("- [").append(e.getSourceName()).append("] ").append(e.getExcerpt()).append("\n");
            }
            prompt.append("\n");
        }

        if (claims != null && !claims.isEmpty()) {
            prompt.append("## 검증이 필요한 주장들:\n");
            for (String claim : claims) {
                prompt.append("- ").append(claim).append("\n");
            }
            prompt.append("\n");
        }

        prompt.append("""
                위 정보를 바탕으로 다음을 제공해주세요:
                
                ## 사실 확인 결과
                각 주장에 대한 팩트체크 결과를 제시
                
                ## 배경 지식
                이 주제를 이해하는 데 필요한 핵심 개념 설명
                
                ## 다양한 관점
                서로 다른 시각이나 해석이 있다면 균형있게 제시
                
                ## 결론
                객관적인 종합 판단
                
                한국어로 답변해주세요. 불확실한 정보는 명확히 표시해주세요.
                """);

        return prompt.toString();
    }
    
    /**
     * 토픽에서 통화/단위 맥락을 분석하여 힌트 생성
     */
    private String buildCurrencyHint(String topic) {
        if (topic == null) return "";
        
        // 한국어 숫자 단위 + 가격 관련 키워드 감지
        boolean hasKoreanNumber = topic.matches(".*\\d+\\s*(억|만|조|천).*");
        boolean hasPriceKeyword = topic.matches(".*(가격|price|도달|목표|전망|예측).*");
        boolean hasExplicitCurrency = topic.matches(".*\\$|USD|달러|₩|KRW|원화.*");
        
        if (hasKoreanNumber && hasPriceKeyword && !hasExplicitCurrency) {
            return """
                ## 통화 단위 주의
                - 이 주제에 한국어 숫자 단위가 포함되어 있습니다
                - 단위가 명시되지 않은 금액은 **한국 원화(KRW)**일 가능성을 고려하세요
                - 예: "10억" = 10억 원 ≈ $670,000 USD
                - 가능하면 원화와 달러 양쪽 기준을 모두 분석해주세요
                """;
        }
        return "";
    }

    // ============================================
    // Utility Methods
    // ============================================

    private String truncateContent(String content, int maxLength) {
        if (content == null) return "";
        if (content.length() <= maxLength) return content;
        return content.substring(0, maxLength) + "...";
    }

    // ============================================
    // Event DTO
    // ============================================

    @Data
    @Builder
    public static class DeepAnalysisEvent {
        private String eventType;       // status, evidence, verification, assessment, ai_synthesis, complete
        private String phase;           // init, concepts, verification, assessment, synthesis, complete
        private String message;
        private List<SourceEvidence> evidence;
        private VerificationResult verificationResult;
        private CredibilityAssessment credibility;
        private String finalConclusion;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/IntegratedCrawlerService.java

```java
package com.newsinsight.collector.service;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.newsinsight.collector.client.AIDoveClient;
import com.newsinsight.collector.client.Crawl4aiClient;
import com.newsinsight.collector.dto.CrawledPage;
import com.newsinsight.collector.dto.EvidenceDto;
import com.newsinsight.collector.entity.EvidenceStance;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.nodes.Element;
import org.jsoup.select.Elements;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.http.MediaType;
import org.springframework.stereotype.Service;
import org.springframework.web.reactive.function.client.WebClient;
import reactor.core.publisher.Flux;
import reactor.core.publisher.Mono;
import reactor.core.scheduler.Schedulers;

import java.net.URI;
import java.net.URLEncoder;
import java.nio.charset.StandardCharsets;
import java.time.Duration;
import java.util.*;
import java.util.concurrent.ConcurrentHashMap;
import java.util.regex.Matcher;
import java.util.regex.Pattern;
import java.util.stream.Collectors;

/**
 * Integrated Crawler Service
 * 
 * Combines multiple crawling strategies for deep, comprehensive web crawling:
 * 1. Crawl4AI - Fast, efficient web scraping
 * 2. Browser-Use API - JavaScript-rendered content with AI agent
 * 3. Direct HTTP - Lightweight fallback
 * 4. Search Engines - Google, Naver, Daum news aggregation
 * 
 * Features:
 * - Multi-depth recursive crawling
 * - Link extraction and following
 * - AI-powered stance analysis
 * - Evidence collection and classification
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class IntegratedCrawlerService {

    private final WebClient webClient;
    private final ObjectMapper objectMapper;
    private final Crawl4aiClient crawl4aiClient;
    private final AIDoveClient aiDoveClient;

    @Value("${collector.crawler.base-url:http://web-crawler:11235}")
    private String crawl4aiBaseUrl;

    @Value("${collector.browser-use.base-url:http://browser-use-api:8500}")
    private String browserUseBaseUrl;

    @Value("${collector.integrated-crawler.max-depth:2}")
    private int maxDepth;

    @Value("${collector.integrated-crawler.max-pages:20}")
    private int maxPages;

    @Value("${collector.integrated-crawler.timeout-seconds:30}")
    private int timeoutSeconds;

    @Value("${collector.integrated-crawler.concurrent-crawls:5}")
    private int concurrentCrawls;

    /**
     * Crawling strategy enum
     */
    public enum CrawlStrategy {
        CRAWL4AI,       // Use Crawl4AI service
        BROWSER_USE,    // Use Browser-Use API for JS rendering
        DIRECT_HTTP,    // Direct HTTP fetch with Jsoup
        SEARCH_ENGINE   // Search engine aggregation
    }

    /**
     * Crawl request with options
     */
    public record CrawlRequest(
            String topic,
            String baseUrl,
            int maxDepth,
            int maxPages,
            Set<CrawlStrategy> strategies,
            boolean extractEvidence
    ) {
        public static CrawlRequest forTopic(String topic) {
            return new CrawlRequest(topic, null, 2, 20, 
                    EnumSet.of(CrawlStrategy.CRAWL4AI, CrawlStrategy.SEARCH_ENGINE), true);
        }

        public static CrawlRequest forUrl(String topic, String baseUrl) {
            return new CrawlRequest(topic, baseUrl, 2, 15, 
                    EnumSet.of(CrawlStrategy.CRAWL4AI, CrawlStrategy.DIRECT_HTTP), true);
        }
    }

    /**
     * Crawl result containing all collected pages and evidence
     */
    public record CrawlResult(
            String topic,
            List<CrawledPage> pages,
            List<EvidenceDto> evidence,
            Map<String, Object> metadata
    ) {}

    /**
     * Progress callback interface
     */
    public interface CrawlProgressCallback {
        void onProgress(int current, int total, String message);
        void onPageCrawled(CrawledPage page);
        void onEvidenceFound(EvidenceDto evidence);
        void onError(String url, String error);
    }

    /**
     * Perform integrated deep crawling for a topic
     */
    public Mono<CrawlResult> crawl(CrawlRequest request, CrawlProgressCallback callback) {
        log.info("Starting integrated crawl: topic={}, strategies={}", request.topic(), request.strategies());

        Set<String> visitedUrls = ConcurrentHashMap.newKeySet();
        List<CrawledPage> allPages = Collections.synchronizedList(new ArrayList<>());
        List<EvidenceDto> allEvidence = Collections.synchronizedList(new ArrayList<>());

        // Generate initial URLs based on strategies
        List<String> seedUrls = generateSeedUrls(request);
        
        if (callback != null) {
            callback.onProgress(0, seedUrls.size(), "Starting crawl with " + seedUrls.size() + " seed URLs");
        }

        return Flux.fromIterable(seedUrls)
                .flatMap(url -> crawlWithStrategies(url, request.topic(), request.strategies(), visitedUrls, 0, request.maxDepth()),
                        concurrentCrawls)
                .doOnNext(page -> {
                    allPages.add(page);
                    if (callback != null) {
                        callback.onPageCrawled(page);
                        callback.onProgress(allPages.size(), request.maxPages(), "Crawled: " + page.url());
                    }
                })
                .takeUntil(page -> allPages.size() >= request.maxPages())
                .collectList()
                .flatMap(pages -> {
                    if (request.extractEvidence() && !pages.isEmpty()) {
                        return extractEvidence(pages, request.topic(), callback)
                                .collectList()
                                .map(evidence -> {
                                    allEvidence.addAll(evidence);
                                    return createResult(request.topic(), allPages, allEvidence);
                                });
                    }
                    return Mono.just(createResult(request.topic(), allPages, allEvidence));
                })
                .doOnSuccess(result -> log.info("Crawl completed: topic={}, pages={}, evidence={}", 
                        request.topic(), result.pages().size(), result.evidence().size()));
    }

    /**
     * Generate seed URLs for crawling based on topic and strategies
     */
    private List<String> generateSeedUrls(CrawlRequest request) {
        List<String> urls = new ArrayList<>();
        String encodedTopic = URLEncoder.encode(request.topic(), StandardCharsets.UTF_8);

        // If base URL provided, use it
        if (request.baseUrl() != null && !request.baseUrl().isBlank()) {
            urls.add(request.baseUrl());
        }

        // Add search engine URLs
        if (request.strategies().contains(CrawlStrategy.SEARCH_ENGINE)) {
            // Google News Korea
            urls.add("https://news.google.com/search?q=" + encodedTopic + "&hl=ko&gl=KR&ceid=KR:ko");
            
            // Naver News
            urls.add("https://search.naver.com/search.naver?where=news&query=" + encodedTopic);
            
            // Daum News
            urls.add("https://search.daum.net/search?w=news&q=" + encodedTopic);
            
            // Google News English (for broader coverage)
            urls.add("https://news.google.com/search?q=" + encodedTopic + "&hl=en&gl=US&ceid=US:en");
        }

        return urls;
    }

    /**
     * Crawl URL using multiple strategies with fallback
     */
    private Flux<CrawledPage> crawlWithStrategies(String url, String topic, Set<CrawlStrategy> strategies,
                                                   Set<String> visitedUrls, int currentDepth, int maxDepth) {
        if (visitedUrls.contains(url) || currentDepth > maxDepth) {
            return Flux.empty();
        }
        visitedUrls.add(url);

        // Try strategies in order of preference
        Mono<CrawledPage> crawlMono = Mono.empty();

        if (strategies.contains(CrawlStrategy.CRAWL4AI)) {
            crawlMono = crawlMono.switchIfEmpty(crawlWithCrawl4AI(url));
        }
        if (strategies.contains(CrawlStrategy.BROWSER_USE)) {
            crawlMono = crawlMono.switchIfEmpty(crawlWithBrowserUse(url, topic));
        }
        if (strategies.contains(CrawlStrategy.DIRECT_HTTP)) {
            crawlMono = crawlMono.switchIfEmpty(crawlDirect(url));
        }

        return crawlMono
                .flux()
                .flatMap(page -> {
                    // Extract links for recursive crawling
                    if (currentDepth < maxDepth && page.content() != null) {
                        List<String> links = extractLinks(page.content(), url, topic);
                        return Flux.concat(
                                Flux.just(page),
                                Flux.fromIterable(links)
                                        .filter(link -> !visitedUrls.contains(link))
                                        .take(15) // Limit links per page (increased from 5)
                                        .flatMap(link -> crawlWithStrategies(link, topic, strategies, visitedUrls, currentDepth + 1, maxDepth))
                        );
                    }
                    return Flux.just(page);
                })
                .onErrorResume(e -> {
                    log.warn("Failed to crawl {}: {}", url, e.getMessage());
                    return Flux.empty();
                });
    }

    /**
     * Crawl using Crawl4AI service
     */
    private Mono<CrawledPage> crawlWithCrawl4AI(String url) {
        String endpoint = crawl4aiBaseUrl + "/md";

        Map<String, Object> payload = Map.of(
                "url", url,
                "bypass_cache", true,
                "word_count_threshold", 50,
                "remove_overlay_elements", true,
                "process_iframes", true
        );

        return webClient.post()
                .uri(endpoint)
                .contentType(MediaType.APPLICATION_JSON)
                .bodyValue(payload)
                .retrieve()
                .bodyToMono(String.class)
                .timeout(Duration.ofSeconds(timeoutSeconds))
                .map(response -> parseCrawl4AIResponse(url, response))
                .filter(page -> page.content() != null && !page.content().isBlank())
                .doOnSuccess(page -> log.debug("Crawl4AI success: {}", url))
                .onErrorResume(e -> {
                    log.debug("Crawl4AI failed for {}: {}", url, e.getMessage());
                    return Mono.empty();
                });
    }

    /**
     * Crawl using Browser-Use API for JavaScript-rendered content
     */
    private Mono<CrawledPage> crawlWithBrowserUse(String url, String topic) {
        String endpoint = browserUseBaseUrl + "/browse";

        Map<String, Object> payload = Map.of(
                "task", "Navigate to the URL and extract all news content related to: " + topic,
                "url", url,
                "max_steps", 5,
                "timeout_seconds", timeoutSeconds,
                "headless", true
        );

        return webClient.post()
                .uri(endpoint)
                .contentType(MediaType.APPLICATION_JSON)
                .bodyValue(payload)
                .retrieve()
                .bodyToMono(String.class)
                .timeout(Duration.ofSeconds(timeoutSeconds + 10))
                .flatMap(response -> pollBrowserUseResult(response, url))
                .doOnSuccess(page -> log.debug("Browser-Use success: {}", url))
                .onErrorResume(e -> {
                    log.debug("Browser-Use failed for {}: {}", url, e.getMessage());
                    return Mono.empty();
                });
    }

    /**
     * Poll Browser-Use job for result
     */
    private Mono<CrawledPage> pollBrowserUseResult(String initialResponse, String url) {
        try {
            JsonNode node = objectMapper.readTree(initialResponse);
            String jobId = node.has("job_id") ? node.get("job_id").asText() : null;
            
            if (jobId == null) {
                // Immediate result
                String result = node.has("result") ? node.get("result").asText() : null;
                return Mono.justOrEmpty(result)
                        .map(r -> new CrawledPage(url, "Browser-Use Result", r, "browser-use", new ArrayList<>()));
            }

            // Poll for result
            return Flux.interval(Duration.ofSeconds(2))
                    .take(15) // Max 30 seconds of polling
                    .flatMap(i -> checkBrowserUseJob(jobId))
                    .filter(status -> "completed".equals(status.status()) || "failed".equals(status.status()))
                    .next()
                    .filter(status -> "completed".equals(status.status()))
                    .map(status -> new CrawledPage(url, "Browser-Use Result", status.result(), "browser-use", new ArrayList<>()));
        } catch (Exception e) {
            return Mono.empty();
        }
    }

    private record BrowserUseJobStatus(String status, String result) {}

    private Mono<BrowserUseJobStatus> checkBrowserUseJob(String jobId) {
        return webClient.get()
                .uri(browserUseBaseUrl + "/jobs/" + jobId)
                .retrieve()
                .bodyToMono(String.class)
                .map(response -> {
                    try {
                        JsonNode node = objectMapper.readTree(response);
                        return new BrowserUseJobStatus(
                                node.has("status") ? node.get("status").asText() : "unknown",
                                node.has("result") ? node.get("result").asText() : null
                        );
                    } catch (Exception e) {
                        return new BrowserUseJobStatus("error", null);
                    }
                })
                .onErrorReturn(new BrowserUseJobStatus("error", null));
    }

    /**
     * Direct HTTP crawl using Jsoup
     */
    private Mono<CrawledPage> crawlDirect(String url) {
        return Mono.fromCallable(() -> {
                    Document doc = Jsoup.connect(url)
                            .userAgent("Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
                            .timeout(timeoutSeconds * 1000)
                            .followRedirects(true)
                            .get();

                    String title = doc.title();
                    String content = extractMainContent(doc);
                    List<String> links = extractDocumentLinks(doc, url);

                    return new CrawledPage(url, title, content, "direct", links);
                })
                .subscribeOn(Schedulers.boundedElastic())
                .filter(page -> page.content() != null && page.content().length() > 100)
                .doOnSuccess(page -> log.debug("Direct crawl success: {}", url))
                .onErrorResume(e -> {
                    log.debug("Direct crawl failed for {}: {}", url, e.getMessage());
                    return Mono.empty();
                });
    }

    /**
     * Parse Crawl4AI response
     */
    private CrawledPage parseCrawl4AIResponse(String url, String response) {
        try {
            JsonNode node = objectMapper.readTree(response);
            String content = null;
            String title = null;
            List<String> links = new ArrayList<>();

            if (node.has("result")) {
                JsonNode result = node.get("result");
                if (result.has("markdown")) {
                    content = result.get("markdown").asText();
                }
                if (result.has("metadata") && result.get("metadata").has("title")) {
                    title = result.get("metadata").get("title").asText();
                }
                if (result.has("links")) {
                    result.get("links").forEach(link -> {
                        if (link.has("href")) {
                            links.add(link.get("href").asText());
                        }
                    });
                }
            } else if (node.has("markdown")) {
                content = node.get("markdown").asText();
            }

            // Truncate very long content
            if (content != null && content.length() > 15000) {
                content = content.substring(0, 15000) + "\n...[truncated]";
            }

            return new CrawledPage(url, title, content, "crawl4ai", links);
        } catch (Exception e) {
            log.warn("Failed to parse Crawl4AI response for {}: {}", url, e.getMessage());
            return new CrawledPage(url, null, null, "crawl4ai", new ArrayList<>());
        }
    }

    /**
     * Extract main content from HTML document
     */
    private String extractMainContent(Document doc) {
        // Remove unwanted elements
        doc.select("script, style, nav, header, footer, aside, .advertisement, .ads, .sidebar").remove();

        // Try to find article content
        Element article = doc.selectFirst("article, .article, .content, .post-content, main, .main-content");
        if (article != null) {
            return article.text();
        }

        // Fallback to body
        Element body = doc.body();
        return body != null ? body.text() : doc.text();
    }

    /**
     * Extract links from document
     */
    private List<String> extractDocumentLinks(Document doc, String baseUrl) {
        List<String> links = new ArrayList<>();
        Elements anchors = doc.select("a[href]");

        for (Element anchor : anchors) {
            String href = anchor.absUrl("href");
            if (isValidNewsLink(href, baseUrl)) {
                links.add(href);
            }
        }

        return links.stream().distinct().limit(30).collect(Collectors.toList());
    }

    /**
     * Extract links from markdown/text content
     */
    private List<String> extractLinks(String content, String baseUrl, String topic) {
        List<String> links = new ArrayList<>();
        
        // URL pattern
        Pattern urlPattern = Pattern.compile("https?://[\\w\\-._~:/?#\\[\\]@!$&'()*+,;=%]+", Pattern.CASE_INSENSITIVE);
        Matcher matcher = urlPattern.matcher(content);

        while (matcher.find()) {
            String url = matcher.group();
            if (isValidNewsLink(url, baseUrl)) {
                links.add(url);
            }
        }

        return links.stream().distinct().limit(30).collect(Collectors.toList());
    }

    /**
     * Check if link is a valid news article link
     */
    private boolean isValidNewsLink(String url, String baseUrl) {
        if (url == null || url.isBlank()) return false;
        
        try {
            URI uri = URI.create(url);
            String host = uri.getHost();
            if (host == null) return false;

            // Skip common non-news domains
            if (host.contains("facebook.com") || host.contains("twitter.com") ||
                host.contains("instagram.com") || host.contains("youtube.com") ||
                host.contains("linkedin.com") || host.contains("tiktok.com")) {
                return false;
            }

            // Skip non-http URLs
            String scheme = uri.getScheme();
            if (!"http".equals(scheme) && !"https".equals(scheme)) {
                return false;
            }

            // Skip media files
            String path = uri.getPath();
            if (path != null && (path.endsWith(".jpg") || path.endsWith(".png") ||
                path.endsWith(".gif") || path.endsWith(".pdf") || path.endsWith(".mp4"))) {
                return false;
            }

            return true;
        } catch (Exception e) {
            return false;
        }
    }

    /**
     * Extract evidence from crawled pages using AI
     */
    private Flux<EvidenceDto> extractEvidence(List<CrawledPage> pages, String topic, CrawlProgressCallback callback) {
        if (!aiDoveClient.isEnabled()) {
            log.warn("AI Dove is disabled, using simple extraction");
            return Flux.fromIterable(pages)
                    .map(page -> createSimpleEvidence(page, topic));
        }

        String aggregatedContent = aggregateContent(pages, topic);
        String prompt = buildEvidenceExtractionPrompt(aggregatedContent, topic);

        return aiDoveClient.chat(prompt, null)
                .flatMapMany(response -> parseEvidenceFromAI(response.reply(), pages, topic))
                .doOnNext(evidence -> {
                    if (callback != null) {
                        callback.onEvidenceFound(evidence);
                    }
                })
                .onErrorResume(e -> {
                    log.error("AI evidence extraction failed: {}", e.getMessage());
                    // Fallback to simple extraction
                    return Flux.fromIterable(pages)
                            .map(page -> createSimpleEvidence(page, topic));
                });
    }

    /**
     * Aggregate content from multiple pages for AI analysis
     */
    private String aggregateContent(List<CrawledPage> pages, String topic) {
        StringBuilder sb = new StringBuilder();
        sb.append("Topic: ").append(topic).append("\n\n");

        int index = 1;
        for (CrawledPage page : pages) {
            if (page.content() == null || page.content().isBlank()) continue;

            sb.append("=== Source ").append(index++).append(" ===\n");
            sb.append("URL: ").append(page.url()).append("\n");
            if (page.title() != null) {
                sb.append("Title: ").append(page.title()).append("\n");
            }
            
            // Limit content per page
            String content = page.content();
            if (content.length() > 3000) {
                content = content.substring(0, 3000) + "...[truncated]";
            }
            sb.append("Content:\n").append(content).append("\n\n");

            if (sb.length() > 20000) {
                sb.append("\n...[additional sources truncated]\n");
                break;
            }
        }

        return sb.toString();
    }

    /**
     * Build prompt for evidence extraction
     */
    private String buildEvidenceExtractionPrompt(String content, String topic) {
        return """
                You are an expert fact-checker and evidence analyst. Analyze the following news content about "%s" and extract evidence.

                For each piece of evidence, determine:
                1. The stance (pro/con/neutral) - whether it supports, opposes, or is neutral to the topic
                2. A brief snippet summarizing the key point
                3. The source URL and title

                Return your analysis as a JSON array with the following structure:
                [
                  {
                    "url": "source URL",
                    "title": "article title",
                    "stance": "pro" | "con" | "neutral",
                    "snippet": "key evidence snippet (1-2 sentences)",
                    "source": "publication name"
                  }
                ]

                Only include factual evidence, not opinions. Maximum 10 pieces of evidence.
                Respond ONLY with the JSON array, no other text.

                --- CONTENT ---
                %s
                """.formatted(topic, content);
    }

    /**
     * Parse evidence from AI response
     */
    private Flux<EvidenceDto> parseEvidenceFromAI(String aiResponse, List<CrawledPage> pages, String topic) {
        try {
            // Extract JSON array from response
            String json = extractJsonArray(aiResponse);
            if (json == null) {
                return Flux.fromIterable(pages).map(page -> createSimpleEvidence(page, topic));
            }

            JsonNode evidenceArray = objectMapper.readTree(json);
            List<EvidenceDto> evidenceList = new ArrayList<>();

            for (JsonNode node : evidenceArray) {
                EvidenceDto evidence = EvidenceDto.builder()
                        .url(node.has("url") ? node.get("url").asText() : "")
                        .title(node.has("title") ? node.get("title").asText() : "")
                        .stance(node.has("stance") ? node.get("stance").asText().toLowerCase() : "neutral")
                        .snippet(node.has("snippet") ? node.get("snippet").asText() : "")
                        .source(node.has("source") ? node.get("source").asText() : "")
                        .build();
                evidenceList.add(evidence);
            }

            return Flux.fromIterable(evidenceList);
        } catch (Exception e) {
            log.warn("Failed to parse AI evidence response: {}", e.getMessage());
            return Flux.fromIterable(pages).map(page -> createSimpleEvidence(page, topic));
        }
    }

    /**
     * Extract JSON array from text that may contain other content
     */
    private String extractJsonArray(String text) {
        if (text == null) return null;
        
        int start = text.indexOf('[');
        int end = text.lastIndexOf(']');
        
        if (start >= 0 && end > start) {
            return text.substring(start, end + 1);
        }
        return null;
    }

    /**
     * Create simple evidence from page without AI
     */
    private EvidenceDto createSimpleEvidence(CrawledPage page, String topic) {
        String snippet = page.content();
        if (snippet != null && snippet.length() > 300) {
            snippet = snippet.substring(0, 300) + "...";
        }

        return EvidenceDto.builder()
                .url(page.url())
                .title(page.title() != null ? page.title() : "Untitled")
                .stance("neutral")
                .snippet(snippet != null ? snippet : "")
                .source(extractDomain(page.url()))
                .build();
    }

    /**
     * Extract domain from URL
     */
    private String extractDomain(String url) {
        try {
            URI uri = URI.create(url);
            return uri.getHost();
        } catch (Exception e) {
            return url;
        }
    }

    /**
     * Create final result
     */
    private CrawlResult createResult(String topic, List<CrawledPage> pages, List<EvidenceDto> evidence) {
        Map<String, Object> metadata = new HashMap<>();
        metadata.put("totalPages", pages.size());
        metadata.put("totalEvidence", evidence.size());
        metadata.put("sources", pages.stream().map(CrawledPage::source).distinct().collect(Collectors.toList()));

        // Calculate stance distribution
        Map<String, Long> stanceCount = evidence.stream()
                .collect(Collectors.groupingBy(EvidenceDto::getStance, Collectors.counting()));
        metadata.put("stanceDistribution", stanceCount);

        return new CrawlResult(topic, pages, evidence, metadata);
    }

    /**
     * Check if service is available
     */
    public boolean isAvailable() {
        return true; // At least direct HTTP is always available
    }

    /**
     * Get available strategies
     */
    public Set<CrawlStrategy> getAvailableStrategies() {
        Set<CrawlStrategy> strategies = EnumSet.of(CrawlStrategy.DIRECT_HTTP, CrawlStrategy.SEARCH_ENGINE);
        
        // Check Crawl4AI
        try {
            webClient.get()
                    .uri(crawl4aiBaseUrl + "/health")
                    .retrieve()
                    .bodyToMono(String.class)
                    .timeout(Duration.ofSeconds(5))
                    .block();
            strategies.add(CrawlStrategy.CRAWL4AI);
        } catch (Exception e) {
            log.debug("Crawl4AI not available: {}", e.getMessage());
        }

        // Check Browser-Use
        try {
            webClient.get()
                    .uri(browserUseBaseUrl + "/health")
                    .retrieve()
                    .bodyToMono(String.class)
                    .timeout(Duration.ofSeconds(5))
                    .block();
            strategies.add(CrawlStrategy.BROWSER_USE);
        } catch (Exception e) {
            log.debug("Browser-Use not available: {}", e.getMessage());
        }

        return strategies;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/LlmProviderSettingsService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.dto.llm.LlmProviderSettingsDto;
import com.newsinsight.collector.dto.llm.LlmProviderSettingsRequest;
import com.newsinsight.collector.dto.llm.LlmTestResult;
import com.newsinsight.collector.entity.settings.LlmProviderSettings;
import com.newsinsight.collector.entity.settings.LlmProviderType;
import com.newsinsight.collector.repository.LlmProviderSettingsRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.http.*;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;
import org.springframework.web.client.RestTemplate;

import java.time.LocalDateTime;
import java.util.*;
import java.util.stream.Collectors;

/**
 * LLM Provider 설정 관리 서비스.
 * 
 * 관리자 전역 설정과 사용자별 설정을 관리하며,
 * 사용자 요청 시 유효한 설정(사용자 > 전역 우선순위)을 반환.
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class LlmProviderSettingsService {

    private final LlmProviderSettingsRepository repository;
    private final RestTemplate restTemplate;

    // ========== 전역(관리자) 설정 관리 ==========

    /**
     * 모든 전역 설정 조회
     */
    @Transactional(readOnly = true)
    public List<LlmProviderSettingsDto> getAllGlobalSettings() {
        return repository.findAllGlobalSettings().stream()
                .map(this::toDto)
                .collect(Collectors.toList());
    }

    /**
     * 특정 Provider의 전역 설정 조회
     */
    @Transactional(readOnly = true)
    public Optional<LlmProviderSettingsDto> getGlobalSetting(LlmProviderType providerType) {
        return repository.findGlobalByProviderType(providerType)
                .map(this::toDto);
    }

    /**
     * 전역 설정 생성/업데이트
     */
    @Transactional
    public LlmProviderSettingsDto saveGlobalSetting(LlmProviderSettingsRequest request) {
        LlmProviderSettings settings = repository.findGlobalByProviderType(request.getProviderType())
                .orElse(LlmProviderSettings.builder()
                        .providerType(request.getProviderType())
                        .userId(null) // 전역 설정
                        .build());

        updateSettingsFromRequest(settings, request);
        LlmProviderSettings saved = repository.save(settings);
        log.info("Saved global LLM setting for provider: {}", request.getProviderType());
        return toDto(saved);
    }

    /**
     * 전역 설정 삭제
     */
    @Transactional
    public void deleteGlobalSetting(LlmProviderType providerType) {
        repository.deleteGlobalByProviderType(providerType);
        log.info("Deleted global LLM setting for provider: {}", providerType);
    }

    // ========== 사용자별 설정 관리 ==========

    /**
     * 사용자의 모든 개인 설정 조회
     */
    @Transactional(readOnly = true)
    public List<LlmProviderSettingsDto> getUserSettings(String userId) {
        return repository.findByUserIdOrderByPriorityAsc(userId).stream()
                .map(this::toDto)
                .collect(Collectors.toList());
    }

    /**
     * 사용자의 특정 Provider 설정 조회
     */
    @Transactional(readOnly = true)
    public Optional<LlmProviderSettingsDto> getUserSetting(String userId, LlmProviderType providerType) {
        return repository.findByProviderTypeAndUserId(providerType, userId)
                .map(this::toDto);
    }

    /**
     * 사용자 설정 생성/업데이트
     */
    @Transactional
    public LlmProviderSettingsDto saveUserSetting(String userId, LlmProviderSettingsRequest request) {
        LlmProviderSettings settings = repository.findByProviderTypeAndUserId(request.getProviderType(), userId)
                .orElse(LlmProviderSettings.builder()
                        .providerType(request.getProviderType())
                        .userId(userId)
                        .build());

        updateSettingsFromRequest(settings, request);
        LlmProviderSettings saved = repository.save(settings);
        log.info("Saved user LLM setting for user: {}, provider: {}", userId, request.getProviderType());
        return toDto(saved);
    }

    /**
     * 사용자 설정 삭제 (전역 설정으로 폴백)
     */
    @Transactional
    public void deleteUserSetting(String userId, LlmProviderType providerType) {
        repository.deleteByProviderTypeAndUserId(providerType, userId);
        log.info("Deleted user LLM setting for user: {}, provider: {}", userId, providerType);
    }

    /**
     * 사용자의 모든 설정 삭제
     */
    @Transactional
    public void deleteAllUserSettings(String userId) {
        repository.deleteByUserId(userId);
        log.info("Deleted all LLM settings for user: {}", userId);
    }

    // ========== 유효(Effective) 설정 조회 ==========

    /**
     * 사용자에게 유효한 모든 설정 조회
     * - 사용자 설정이 있으면 사용자 설정 반환
     * - 없으면 전역 설정 반환
     */
    @Transactional(readOnly = true)
    public List<LlmProviderSettingsDto> getEffectiveSettings(String userId) {
        // 전역 설정 가져오기
        Map<LlmProviderType, LlmProviderSettings> effectiveMap = new LinkedHashMap<>();
        for (LlmProviderSettings global : repository.findAllGlobalSettings()) {
            effectiveMap.put(global.getProviderType(), global);
        }

        // 사용자 설정으로 오버라이드
        if (userId != null && !userId.isBlank()) {
            for (LlmProviderSettings userSetting : repository.findByUserIdOrderByPriorityAsc(userId)) {
                effectiveMap.put(userSetting.getProviderType(), userSetting);
            }
        }

        return effectiveMap.values().stream()
                .sorted(Comparator.comparing(LlmProviderSettings::getPriority))
                .map(this::toDto)
                .collect(Collectors.toList());
    }

    /**
     * 특정 Provider의 유효 설정 조회
     */
    @Transactional(readOnly = true)
    public Optional<LlmProviderSettingsDto> getEffectiveSetting(String userId, LlmProviderType providerType) {
        // 사용자 설정 먼저 확인
        if (userId != null && !userId.isBlank()) {
            Optional<LlmProviderSettings> userSetting = repository.findByProviderTypeAndUserId(providerType, userId);
            if (userSetting.isPresent()) {
                return userSetting.map(this::toDto);
            }
        }
        // 없으면 전역 설정 반환
        return repository.findGlobalByProviderType(providerType).map(this::toDto);
    }

    /**
     * 활성화된 Provider 목록 (Fallback 체인용)
     */
    @Transactional(readOnly = true)
    public List<LlmProviderSettingsDto> getEnabledProviders(String userId) {
        return getEffectiveSettings(userId).stream()
                .filter(LlmProviderSettingsDto::getEnabled)
                .sorted(Comparator.comparing(LlmProviderSettingsDto::getPriority))
                .collect(Collectors.toList());
    }

    // ========== 연결 테스트 ==========

    /**
     * Provider 연결 테스트
     */
    @Transactional
    public LlmTestResult testConnection(Long settingsId) {
        LlmProviderSettings settings = repository.findById(settingsId)
                .orElseThrow(() -> new IllegalArgumentException("Settings not found: " + settingsId));

        LlmTestResult result = performConnectionTest(settings);

        // 테스트 결과 업데이트
        repository.updateTestResult(settingsId, LocalDateTime.now(), result.isSuccess());

        return result;
    }

    /**
     * Provider 연결 테스트 (설정 객체로 직접)
     */
    public LlmTestResult testConnection(LlmProviderSettingsRequest request) {
        LlmProviderSettings settings = LlmProviderSettings.builder()
                .providerType(request.getProviderType())
                .apiKey(request.getApiKey())
                .baseUrl(request.getBaseUrl())
                .defaultModel(request.getDefaultModel())
                .azureDeploymentName(request.getAzureDeploymentName())
                .azureApiVersion(request.getAzureApiVersion())
                .build();

        return performConnectionTest(settings);
    }

    private LlmTestResult performConnectionTest(LlmProviderSettings settings) {
        try {
            String testUrl = buildTestUrl(settings);
            HttpHeaders headers = buildHeaders(settings);

            HttpEntity<String> entity = new HttpEntity<>(headers);
            ResponseEntity<String> response = restTemplate.exchange(
                    testUrl, HttpMethod.GET, entity, String.class
            );

            boolean success = response.getStatusCode().is2xxSuccessful();
            return LlmTestResult.builder()
                    .success(success)
                    .providerType(settings.getProviderType())
                    .message(success ? "Connection successful" : "Connection failed")
                    .responseTime(System.currentTimeMillis())
                    .build();

        } catch (Exception e) {
            log.warn("LLM connection test failed for {}: {}", settings.getProviderType(), e.getMessage());
            return LlmTestResult.builder()
                    .success(false)
                    .providerType(settings.getProviderType())
                    .message("Connection failed: " + e.getMessage())
                    .error(e.getMessage())
                    .build();
        }
    }

    private String buildTestUrl(LlmProviderSettings settings) {
        String baseUrl = settings.getBaseUrl() != null ? settings.getBaseUrl() 
                : settings.getProviderType().getDefaultBaseUrl();

        return switch (settings.getProviderType()) {
            case OPENAI, OPENROUTER -> baseUrl + "/models";
            case ANTHROPIC -> baseUrl + "/v1/messages"; // Will return 405 but proves connectivity
            case GOOGLE -> baseUrl + "/v1/models";
            case OLLAMA -> baseUrl + "/api/tags";
            case AZURE_OPENAI -> baseUrl + "/openai/deployments?api-version=" + 
                    (settings.getAzureApiVersion() != null ? settings.getAzureApiVersion() : "2024-02-01");
            case CUSTOM -> baseUrl + "/health";
        };
    }

    private HttpHeaders buildHeaders(LlmProviderSettings settings) {
        HttpHeaders headers = new HttpHeaders();
        headers.setContentType(MediaType.APPLICATION_JSON);

        if (settings.getApiKey() != null && !settings.getApiKey().isBlank()) {
            switch (settings.getProviderType()) {
                case OPENAI, OPENROUTER -> headers.setBearerAuth(settings.getApiKey());
                case ANTHROPIC -> {
                    headers.set("x-api-key", settings.getApiKey());
                    headers.set("anthropic-version", "2023-06-01");
                }
                case GOOGLE -> headers.set("x-goog-api-key", settings.getApiKey());
                case AZURE_OPENAI -> headers.set("api-key", settings.getApiKey());
                default -> headers.setBearerAuth(settings.getApiKey());
            }
        }

        return headers;
    }

    // ========== 활성화/비활성화 ==========

    @Transactional
    public void setEnabled(Long settingsId, boolean enabled) {
        repository.updateEnabled(settingsId, enabled);
        log.info("Updated LLM settings {} enabled status to: {}", settingsId, enabled);
    }

    // ========== DTO 변환 ==========

    private LlmProviderSettingsDto toDto(LlmProviderSettings entity) {
        return LlmProviderSettingsDto.builder()
                .id(entity.getId())
                .providerType(entity.getProviderType())
                .providerDisplayName(entity.getProviderType().getDisplayName())
                .userId(entity.getUserId())
                .isGlobal(entity.isGlobal())
                .apiKeyMasked(entity.getMaskedApiKey())
                .hasApiKey(entity.getApiKey() != null && !entity.getApiKey().isBlank())
                .defaultModel(entity.getDefaultModel())
                .baseUrl(entity.getBaseUrl())
                .enabled(entity.getEnabled())
                .priority(entity.getPriority())
                .maxTokens(entity.getMaxTokens())
                .temperature(entity.getTemperature())
                .timeoutMs(entity.getTimeoutMs())
                .maxRequestsPerMinute(entity.getMaxRequestsPerMinute())
                .azureDeploymentName(entity.getAzureDeploymentName())
                .azureApiVersion(entity.getAzureApiVersion())
                .lastTestedAt(entity.getLastTestedAt())
                .lastTestSuccess(entity.getLastTestSuccess())
                .createdAt(entity.getCreatedAt())
                .updatedAt(entity.getUpdatedAt())
                .build();
    }

    private void updateSettingsFromRequest(LlmProviderSettings settings, LlmProviderSettingsRequest request) {
        if (request.getApiKey() != null) {
            settings.setApiKey(request.getApiKey());
        }
        if (request.getDefaultModel() != null) {
            settings.setDefaultModel(request.getDefaultModel());
        }
        if (request.getBaseUrl() != null) {
            settings.setBaseUrl(request.getBaseUrl());
        }
        if (request.getEnabled() != null) {
            settings.setEnabled(request.getEnabled());
        }
        if (request.getPriority() != null) {
            settings.setPriority(request.getPriority());
        }
        if (request.getMaxTokens() != null) {
            settings.setMaxTokens(request.getMaxTokens());
        }
        if (request.getTemperature() != null) {
            settings.setTemperature(request.getTemperature());
        }
        if (request.getTimeoutMs() != null) {
            settings.setTimeoutMs(request.getTimeoutMs());
        }
        if (request.getMaxRequestsPerMinute() != null) {
            settings.setMaxRequestsPerMinute(request.getMaxRequestsPerMinute());
        }
        if (request.getAzureDeploymentName() != null) {
            settings.setAzureDeploymentName(request.getAzureDeploymentName());
        }
        if (request.getAzureApiVersion() != null) {
            settings.setAzureApiVersion(request.getAzureApiVersion());
        }
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/ProjectAutoCollectService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.entity.project.Project;
import com.newsinsight.collector.entity.project.ProjectActivityLog;
import com.newsinsight.collector.entity.project.ProjectItem;
import com.newsinsight.collector.entity.project.ProjectNotification;
import com.newsinsight.collector.entity.search.SearchType;
import com.newsinsight.collector.repository.ProjectRepository;
import com.newsinsight.collector.service.SearchJobQueueService.SearchJobRequest;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Map;

/**
 * Service for automatic news collection for projects.
 * Runs on a schedule to collect news for projects with auto-collect enabled.
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class ProjectAutoCollectService {

    private final ProjectRepository projectRepository;
    private final ProjectService projectService;
    private final SearchJobQueueService searchJobQueueService;
    private final UnifiedSearchService unifiedSearchService;

    /**
     * Scheduled task to process auto-collection for projects.
     * Runs every 30 minutes.
     */
    @Scheduled(fixedRate = 1800000) // 30 minutes
    @Transactional
    public void processAutoCollection() {
        log.info("Starting scheduled auto-collection processing");

        LocalDateTime now = LocalDateTime.now();
        LocalDateTime hourAgo = now.minusHours(1);
        LocalDateTime dayAgo = now.minusDays(1);
        LocalDateTime weekAgo = now.minusWeeks(1);

        List<Project> projectsToCollect = projectRepository.findProjectsNeedingCollection(
                hourAgo, dayAgo, weekAgo
        );

        log.info("Found {} projects needing collection", projectsToCollect.size());

        for (Project project : projectsToCollect) {
            try {
                collectForProject(project);
            } catch (Exception e) {
                log.error("Failed to collect for project {}: {}", project.getId(), e.getMessage(), e);
            }
        }

        log.info("Completed auto-collection processing");
    }

    /**
     * Collect news for a specific project.
     */
    @Transactional
    public void collectForProject(Project project) {
        log.info("Starting collection for project: id={}, name='{}'", project.getId(), project.getName());

        List<String> keywords = project.getKeywords();
        if (keywords == null || keywords.isEmpty()) {
            log.warn("Project {} has no keywords configured for collection", project.getId());
            return;
        }

        Project.ProjectSettings settings = project.getSettings();
        String timeWindow = settings != null && settings.getTimeWindow() != null 
                ? settings.getTimeWindow() 
                : "7d";

        // Build search query from keywords
        String query = buildSearchQuery(keywords);

        // Start search job
        SearchJobRequest jobRequest = SearchJobRequest.builder()
                .type(SearchType.UNIFIED)
                .query(query)
                .timeWindow(timeWindow)
                .userId(project.getOwnerId())
                .projectId(project.getId())
                .options(Map.of(
                        "autoCollect", true,
                        "projectName", project.getName()
                ))
                .build();

        String jobId = searchJobQueueService.startJob(jobRequest);
        log.info("Started auto-collection job: jobId={}, projectId={}", jobId, project.getId());

        // Update project last collected timestamp
        projectRepository.updateLastCollected(project.getId(), LocalDateTime.now());

        // Log activity
        projectService.logActivity(
                project.getId(),
                "system",
                ProjectActivityLog.ActivityType.AUTO_COLLECTION,
                "자동 수집 실행: " + query,
                "job",
                jobId,
                Map.of("keywords", keywords, "timeWindow", timeWindow)
        );
    }

    /**
     * Manually trigger collection for a project.
     */
    @Transactional
    public String triggerCollection(Long projectId, String userId) {
        Project project = projectRepository.findById(projectId)
                .orElseThrow(() -> new IllegalArgumentException("Project not found: " + projectId));

        log.info("Manual collection triggered: projectId={}, triggeredBy={}", projectId, userId);

        List<String> keywords = project.getKeywords();
        if (keywords == null || keywords.isEmpty()) {
            throw new IllegalStateException("Project has no keywords configured for collection");
        }

        Project.ProjectSettings settings = project.getSettings();
        String timeWindow = settings != null && settings.getTimeWindow() != null 
                ? settings.getTimeWindow() 
                : "7d";

        String query = buildSearchQuery(keywords);

        SearchJobRequest jobRequest = SearchJobRequest.builder()
                .type(SearchType.UNIFIED)
                .query(query)
                .timeWindow(timeWindow)
                .userId(userId)
                .projectId(projectId)
                .options(Map.of(
                        "manualTrigger", true,
                        "triggeredBy", userId
                ))
                .build();

        String jobId = searchJobQueueService.startJob(jobRequest);

        // Update project
        projectRepository.updateLastCollected(projectId, LocalDateTime.now());
        projectRepository.updateLastActivity(projectId, LocalDateTime.now());

        // Log activity
        projectService.logActivity(
                projectId,
                userId,
                ProjectActivityLog.ActivityType.MANUAL_COLLECTION,
                "수동 수집 실행: " + query,
                "job",
                jobId,
                Map.of("keywords", keywords, "timeWindow", timeWindow)
        );

        return jobId;
    }

    /**
     * Process search results and add to project.
     * Called by SearchJobQueueService when a project-related search completes.
     */
    @Transactional
    public void processSearchResults(Long projectId, String jobId, List<Map<String, Object>> results, String userId) {
        log.info("Processing search results for project: projectId={}, resultCount={}", projectId, results.size());

        int addedCount = 0;
        int duplicateCount = 0;

        for (Map<String, Object> result : results) {
            try {
                String url = (String) result.get("url");
                
                // Check for duplicates by URL
                List<ProjectItem> existing = projectService.getProject(projectId)
                        .map(p -> List.<ProjectItem>of()) // Simplified - would need actual check
                        .orElse(List.of());
                
                // For now, assume no duplicates check needed (would need proper implementation)
                
                ProjectService.AddItemRequest itemRequest = ProjectService.AddItemRequest.builder()
                        .itemType(ProjectItem.ItemType.ARTICLE)
                        .title((String) result.get("title"))
                        .summary((String) result.get("snippet"))
                        .url(url)
                        .thumbnailUrl((String) result.get("imageUrl"))
                        .sourceName((String) result.get("source"))
                        .sourceId(jobId)
                        .sourceType("auto_collect")
                        .publishedAt(parsePublishedAt(result.get("publishedAt")))
                        .sentiment((String) result.get("sentiment"))
                        .importance(calculateImportance(result))
                        .metadata(Map.of(
                                "jobId", jobId,
                                "autoCollected", true
                        ))
                        .build();

                projectService.addItem(projectId, itemRequest, userId != null ? userId : "system");
                addedCount++;
                
            } catch (Exception e) {
                log.warn("Failed to add result to project: {}", e.getMessage());
            }
        }

        log.info("Added {} items to project {} (duplicates: {})", addedCount, projectId, duplicateCount);

        // Notify project owner if significant results found
        if (addedCount > 0) {
            Project project = projectRepository.findById(projectId).orElse(null);
            if (project != null) {
                projectService.createNotification(
                        projectId,
                        project.getOwnerId(),
                        ProjectNotification.NotificationType.NEW_ARTICLES,
                        "새로운 기사 수집 완료",
                        String.format("%d개의 새로운 기사가 수집되었습니다.", addedCount),
                        "/projects/" + projectId + "/items"
                );
            }
        }
    }

    /**
     * Build search query from keywords.
     */
    private String buildSearchQuery(List<String> keywords) {
        if (keywords.size() == 1) {
            return keywords.get(0);
        }
        
        // Join keywords with OR for broader search
        // Could be made more sophisticated with AND/OR options
        return String.join(" OR ", keywords);
    }

    /**
     * Parse published date from result.
     */
    private LocalDateTime parsePublishedAt(Object publishedAt) {
        if (publishedAt == null) {
            return null;
        }
        
        if (publishedAt instanceof LocalDateTime) {
            return (LocalDateTime) publishedAt;
        }
        
        if (publishedAt instanceof String dateStr) {
            try {
                return LocalDateTime.parse(dateStr);
            } catch (Exception e) {
                // Try other formats
                try {
                    return LocalDateTime.parse(dateStr.replace("Z", ""));
                } catch (Exception e2) {
                    return null;
                }
            }
        }
        
        return null;
    }

    /**
     * Calculate importance score for an article.
     */
    private int calculateImportance(Map<String, Object> result) {
        int importance = 50; // Default

        // Boost for credibility score
        Object credibility = result.get("credibilityScore");
        if (credibility instanceof Number) {
            importance += ((Number) credibility).intValue() / 2;
        }

        // Boost for recent articles
        LocalDateTime publishedAt = parsePublishedAt(result.get("publishedAt"));
        if (publishedAt != null && publishedAt.isAfter(LocalDateTime.now().minusDays(1))) {
            importance += 10;
        }

        // Cap at 100
        return Math.min(importance, 100);
    }

    /**
     * Get collection status for a project.
     */
    public Map<String, Object> getCollectionStatus(Long projectId) {
        Project project = projectRepository.findById(projectId)
                .orElseThrow(() -> new IllegalArgumentException("Project not found: " + projectId));

        boolean autoCollectEnabled = project.isAutoCollectEnabled();
        LocalDateTime lastCollected = project.getLastCollectedAt();
        String interval = project.getSettings() != null ? project.getSettings().getCollectInterval() : "daily";

        LocalDateTime nextCollection = null;
        if (lastCollected != null && autoCollectEnabled) {
            nextCollection = switch (interval) {
                case "hourly" -> lastCollected.plusHours(1);
                case "weekly" -> lastCollected.plusWeeks(1);
                default -> lastCollected.plusDays(1); // daily
            };
        }

        return Map.of(
                "projectId", projectId,
                "autoCollectEnabled", autoCollectEnabled,
                "interval", interval,
                "lastCollectedAt", lastCollected != null ? lastCollected.toString() : null,
                "nextCollectionAt", nextCollection != null ? nextCollection.toString() : null,
                "keywords", project.getKeywords() != null ? project.getKeywords() : List.of()
        );
    }

    /**
     * Update auto-collect settings for a project.
     */
    @Transactional
    public void updateAutoCollectSettings(Long projectId, boolean enabled, String interval, String userId) {
        Project project = projectRepository.findById(projectId)
                .orElseThrow(() -> new IllegalArgumentException("Project not found: " + projectId));

        Project.ProjectSettings settings = project.getSettings();
        if (settings == null) {
            settings = Project.ProjectSettings.builder().build();
        }

        settings.setAutoCollect(enabled);
        if (interval != null) {
            settings.setCollectInterval(interval);
        }

        project.setSettings(settings);
        projectRepository.save(project);

        // Log activity
        projectService.logActivity(
                projectId,
                userId,
                ProjectActivityLog.ActivityType.SETTINGS_CHANGED,
                "자동 수집 설정 변경: " + (enabled ? "활성화" : "비활성화"),
                "project",
                projectId.toString(),
                Map.of("autoCollect", enabled, "interval", interval != null ? interval : settings.getCollectInterval())
        );

        log.info("Updated auto-collect settings: projectId={}, enabled={}, interval={}", 
                projectId, enabled, interval);
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/ProjectService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.entity.project.*;
import com.newsinsight.collector.repository.*;
import lombok.Builder;
import lombok.Data;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.PageRequest;
import org.springframework.data.domain.Pageable;
import org.springframework.data.domain.Sort;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.time.LocalDateTime;
import java.util.*;

/**
 * Service for managing Projects.
 * Provides CRUD operations for projects, members, items, and activity logging.
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class ProjectService {

    private final ProjectRepository projectRepository;
    private final ProjectMemberRepository projectMemberRepository;
    private final ProjectItemRepository projectItemRepository;
    private final ProjectActivityLogRepository activityLogRepository;
    private final ProjectNotificationRepository notificationRepository;

    // ============================================
    // Project CRUD
    // ============================================

    /**
     * Create a new project.
     */
    @Transactional
    public Project createProject(CreateProjectRequest request) {
        Project project = Project.builder()
                .name(request.getName())
                .description(request.getDescription())
                .keywords(request.getKeywords())
                .category(request.getCategory() != null ? request.getCategory() : Project.ProjectCategory.CUSTOM)
                .status(Project.ProjectStatus.ACTIVE)
                .visibility(request.getVisibility() != null ? request.getVisibility() : Project.ProjectVisibility.PRIVATE)
                .ownerId(request.getOwnerId())
                .color(request.getColor())
                .icon(request.getIcon())
                .isDefault(request.getIsDefault() != null && request.getIsDefault())
                .settings(request.getSettings())
                .tags(request.getTags())
                .lastActivityAt(LocalDateTime.now())
                .build();

        Project saved = projectRepository.save(project);
        log.info("Created project: id={}, name='{}', owner={}", saved.getId(), saved.getName(), saved.getOwnerId());

        // Add owner as admin member
        addMember(saved.getId(), request.getOwnerId(), ProjectMember.MemberRole.ADMIN, null);

        // Log activity
        logActivity(saved.getId(), request.getOwnerId(), ProjectActivityLog.ActivityType.PROJECT_CREATED,
                "프로젝트 생성: " + saved.getName(), "project", saved.getId().toString(), null);

        return saved;
    }

    /**
     * Get project by ID.
     */
    public Optional<Project> getProject(Long id) {
        return projectRepository.findById(id);
    }

    /**
     * Get project with access check.
     */
    public Optional<Project> getProjectWithAccess(Long id, String userId) {
        Optional<Project> project = projectRepository.findById(id);
        if (project.isEmpty()) {
            return Optional.empty();
        }

        Project p = project.get();
        
        // Owner always has access
        if (p.getOwnerId().equals(userId)) {
            return project;
        }

        // Public projects are accessible to all
        if (p.getVisibility() == Project.ProjectVisibility.PUBLIC) {
            return project;
        }

        // Check membership for team projects
        if (p.getVisibility() == Project.ProjectVisibility.TEAM) {
            boolean isMember = projectMemberRepository.existsByProjectIdAndUserIdAndStatus(
                    id, userId, ProjectMember.MemberStatus.ACTIVE
            );
            if (isMember) {
                return project;
            }
        }

        return Optional.empty();
    }

    /**
     * Update project.
     */
    @Transactional
    public Project updateProject(Long id, UpdateProjectRequest request, String userId) {
        Project project = projectRepository.findById(id)
                .orElseThrow(() -> new IllegalArgumentException("Project not found: " + id));

        // Check permission
        if (!hasEditPermission(id, userId)) {
            throw new IllegalStateException("User does not have edit permission for this project");
        }

        if (request.getName() != null) {
            project.setName(request.getName());
        }
        if (request.getDescription() != null) {
            project.setDescription(request.getDescription());
        }
        if (request.getKeywords() != null) {
            project.setKeywords(request.getKeywords());
        }
        if (request.getCategory() != null) {
            project.setCategory(request.getCategory());
        }
        if (request.getVisibility() != null) {
            project.setVisibility(request.getVisibility());
        }
        if (request.getColor() != null) {
            project.setColor(request.getColor());
        }
        if (request.getIcon() != null) {
            project.setIcon(request.getIcon());
        }
        if (request.getSettings() != null) {
            project.setSettings(request.getSettings());
        }
        if (request.getTags() != null) {
            project.setTags(request.getTags());
        }

        project.touchActivity();
        Project saved = projectRepository.save(project);

        // Log activity
        logActivity(id, userId, ProjectActivityLog.ActivityType.PROJECT_UPDATED,
                "프로젝트 수정", "project", id.toString(), null);

        log.info("Updated project: id={}, name='{}'", saved.getId(), saved.getName());
        return saved;
    }

    /**
     * Update project status.
     */
    @Transactional
    public Project updateProjectStatus(Long id, Project.ProjectStatus status, String userId) {
        Project project = projectRepository.findById(id)
                .orElseThrow(() -> new IllegalArgumentException("Project not found: " + id));

        if (!project.getOwnerId().equals(userId)) {
            throw new IllegalStateException("Only owner can change project status");
        }

        project.setStatus(status);
        project.touchActivity();
        
        Project saved = projectRepository.save(project);

        // Log activity
        logActivity(id, userId, ProjectActivityLog.ActivityType.PROJECT_STATUS_CHANGED,
                "프로젝트 상태 변경: " + status, "project", id.toString(), null);

        return saved;
    }

    /**
     * Delete project.
     */
    @Transactional
    public void deleteProject(Long id, String userId) {
        Project project = projectRepository.findById(id)
                .orElseThrow(() -> new IllegalArgumentException("Project not found: " + id));

        if (!project.getOwnerId().equals(userId)) {
            throw new IllegalStateException("Only owner can delete the project");
        }

        // Delete all related data
        notificationRepository.deleteByProjectId(id);
        activityLogRepository.deleteByProjectId(id);
        projectItemRepository.deleteByProjectId(id);
        projectMemberRepository.deleteByProjectId(id);
        projectRepository.delete(project);

        log.info("Deleted project: id={}, name='{}'", id, project.getName());
    }

    /**
     * Get projects by owner.
     */
    public Page<Project> getProjectsByOwner(String ownerId, int page, int size) {
        Pageable pageable = PageRequest.of(page, size);
        return projectRepository.findByOwnerIdOrderByLastActivityAtDesc(ownerId, pageable);
    }

    /**
     * Get projects by owner and status.
     */
    public Page<Project> getProjectsByOwnerAndStatus(String ownerId, Project.ProjectStatus status, int page, int size) {
        Pageable pageable = PageRequest.of(page, size);
        return projectRepository.findByOwnerIdAndStatus(ownerId, status, pageable);
    }

    /**
     * Search projects by name.
     */
    public Page<Project> searchProjects(String name, int page, int size) {
        Pageable pageable = PageRequest.of(page, size);
        return projectRepository.searchByName(name, pageable);
    }

    /**
     * Get user's default project (create if not exists).
     */
    @Transactional
    public Project getOrCreateDefaultProject(String userId) {
        return projectRepository.findByOwnerIdAndIsDefaultTrue(userId)
                .orElseGet(() -> {
                    CreateProjectRequest request = CreateProjectRequest.builder()
                            .name("My Project")
                            .description("기본 프로젝트")
                            .ownerId(userId)
                            .isDefault(true)
                            .build();
                    return createProject(request);
                });
    }

    // ============================================
    // Member Management
    // ============================================

    /**
     * Add member to project.
     */
    @Transactional
    public ProjectMember addMember(Long projectId, String userId, ProjectMember.MemberRole role, String invitedBy) {
        // Check if already a member
        Optional<ProjectMember> existing = projectMemberRepository.findByProjectIdAndUserId(projectId, userId);
        if (existing.isPresent()) {
            ProjectMember member = existing.get();
            if (member.getStatus() == ProjectMember.MemberStatus.ACTIVE) {
                return member;
            }
            // Reactivate if previously left
            member.setStatus(ProjectMember.MemberStatus.ACTIVE);
            member.setRole(role);
            return projectMemberRepository.save(member);
        }

        ProjectMember member = ProjectMember.builder()
                .projectId(projectId)
                .userId(userId)
                .role(role)
                .status(ProjectMember.MemberStatus.ACTIVE)
                .invitedBy(invitedBy)
                .joinedAt(LocalDateTime.now())
                .lastActiveAt(LocalDateTime.now())
                .build();

        ProjectMember saved = projectMemberRepository.save(member);

        // Log activity
        if (invitedBy != null) {
            logActivity(projectId, invitedBy, ProjectActivityLog.ActivityType.MEMBER_ADDED,
                    "멤버 추가: " + userId, "member", saved.getId().toString(), null);
        }

        // Update project activity
        projectRepository.updateLastActivity(projectId, LocalDateTime.now());

        return saved;
    }

    /**
     * Invite member (creates pending invitation).
     */
    @Transactional
    public ProjectMember inviteMember(Long projectId, String userId, ProjectMember.MemberRole role, String invitedBy) {
        // Check inviter has permission
        if (!hasInvitePermission(projectId, invitedBy)) {
            throw new IllegalStateException("User does not have permission to invite members");
        }

        // Check if already invited or member
        Optional<ProjectMember> existing = projectMemberRepository.findByProjectIdAndUserId(projectId, userId);
        if (existing.isPresent()) {
            throw new IllegalStateException("User is already invited or a member");
        }

        String inviteToken = UUID.randomUUID().toString();

        ProjectMember member = ProjectMember.builder()
                .projectId(projectId)
                .userId(userId)
                .role(role)
                .status(ProjectMember.MemberStatus.PENDING)
                .invitedBy(invitedBy)
                .inviteToken(inviteToken)
                .inviteExpiresAt(LocalDateTime.now().plusDays(7))
                .build();

        ProjectMember saved = projectMemberRepository.save(member);

        // Create notification
        createNotification(projectId, userId, ProjectNotification.NotificationType.MEMBER_INVITED,
                "프로젝트 초대", "프로젝트에 초대되었습니다", null);

        log.info("Invited member: projectId={}, userId={}, invitedBy={}", projectId, userId, invitedBy);
        return saved;
    }

    /**
     * Accept invitation.
     */
    @Transactional
    public ProjectMember acceptInvitation(String inviteToken, String userId) {
        ProjectMember member = projectMemberRepository.findByInviteToken(inviteToken)
                .orElseThrow(() -> new IllegalArgumentException("Invalid or expired invitation"));

        if (!member.getUserId().equals(userId)) {
            throw new IllegalStateException("Invitation is for a different user");
        }

        if (member.getInviteExpiresAt() != null && member.getInviteExpiresAt().isBefore(LocalDateTime.now())) {
            throw new IllegalStateException("Invitation has expired");
        }

        member.setStatus(ProjectMember.MemberStatus.ACTIVE);
        member.setJoinedAt(LocalDateTime.now());
        member.setInviteToken(null);
        member.setInviteExpiresAt(null);

        ProjectMember saved = projectMemberRepository.save(member);

        // Log activity
        logActivity(member.getProjectId(), userId, ProjectActivityLog.ActivityType.MEMBER_JOINED,
                "멤버 참여", "member", saved.getId().toString(), null);

        return saved;
    }

    /**
     * Remove member from project.
     */
    @Transactional
    public void removeMember(Long projectId, String userId, String removedBy) {
        ProjectMember member = projectMemberRepository.findByProjectIdAndUserId(projectId, userId)
                .orElseThrow(() -> new IllegalArgumentException("Member not found"));

        // Check permission
        if (!canRemoveMember(projectId, removedBy, member)) {
            throw new IllegalStateException("User does not have permission to remove this member");
        }

        member.setStatus(ProjectMember.MemberStatus.LEFT);
        projectMemberRepository.save(member);

        // Log activity
        logActivity(projectId, removedBy, ProjectActivityLog.ActivityType.MEMBER_REMOVED,
                "멤버 제거: " + userId, "member", member.getId().toString(), null);

        log.info("Removed member: projectId={}, userId={}, removedBy={}", projectId, userId, removedBy);
    }

    /**
     * Update member role.
     */
    @Transactional
    public ProjectMember updateMemberRole(Long projectId, String userId, ProjectMember.MemberRole newRole, String updatedBy) {
        ProjectMember member = projectMemberRepository.findByProjectIdAndUserId(projectId, userId)
                .orElseThrow(() -> new IllegalArgumentException("Member not found"));

        // Only admin or owner can change roles
        if (!hasAdminPermission(projectId, updatedBy)) {
            throw new IllegalStateException("User does not have permission to change roles");
        }

        member.setRole(newRole);
        ProjectMember saved = projectMemberRepository.save(member);

        // Log activity
        logActivity(projectId, updatedBy, ProjectActivityLog.ActivityType.MEMBER_ROLE_CHANGED,
                "멤버 역할 변경: " + userId + " -> " + newRole, "member", member.getId().toString(), null);

        return saved;
    }

    /**
     * Get project members.
     */
    public List<ProjectMember> getMembers(Long projectId) {
        return projectMemberRepository.findByProjectIdOrderByJoinedAtDesc(projectId);
    }

    /**
     * Get active members.
     */
    public List<ProjectMember> getActiveMembers(Long projectId) {
        return projectMemberRepository.findByProjectIdAndStatus(projectId, ProjectMember.MemberStatus.ACTIVE);
    }

    // ============================================
    // Item Management
    // ============================================

    /**
     * Add item to project.
     */
    @Transactional
    public ProjectItem addItem(Long projectId, AddItemRequest request, String userId) {
        // Check permission
        if (!hasEditPermission(projectId, userId)) {
            throw new IllegalStateException("User does not have permission to add items");
        }

        ProjectItem item = ProjectItem.builder()
                .projectId(projectId)
                .itemType(request.getItemType())
                .title(request.getTitle())
                .summary(request.getSummary())
                .url(request.getUrl())
                .thumbnailUrl(request.getThumbnailUrl())
                .sourceName(request.getSourceName())
                .sourceId(request.getSourceId())
                .sourceType(request.getSourceType())
                .publishedAt(request.getPublishedAt())
                .category(request.getCategory())
                .tags(request.getTags())
                .sentimentLabel(request.getSentiment())
                .importance(request.getImportance() != null ? request.getImportance() : 50)
                .addedBy(userId)
                .addedAt(LocalDateTime.now())
                .isRead(false)
                .bookmarked(false)
                .metadata(request.getMetadata())
                .build();

        ProjectItem saved = projectItemRepository.save(item);

        // Log activity
        logActivity(projectId, userId, ProjectActivityLog.ActivityType.ITEM_ADDED,
                "아이템 추가: " + item.getTitle(), "item", saved.getId().toString(), null);

        // Update project activity
        projectRepository.updateLastActivity(projectId, LocalDateTime.now());

        return saved;
    }

    /**
     * Get project items.
     */
    public Page<ProjectItem> getItems(Long projectId, int page, int size) {
        Pageable pageable = PageRequest.of(page, size);
        return projectItemRepository.findByProjectIdOrderByAddedAtDesc(projectId, pageable);
    }

    /**
     * Get project items by type.
     */
    public Page<ProjectItem> getItemsByType(Long projectId, ProjectItem.ItemType type, int page, int size) {
        Pageable pageable = PageRequest.of(page, size);
        return projectItemRepository.findByProjectIdAndItemType(projectId, type, pageable);
    }

    /**
     * Search items.
     */
    public Page<ProjectItem> searchItems(Long projectId, String query, int page, int size) {
        Pageable pageable = PageRequest.of(page, size);
        return projectItemRepository.searchByContent(projectId, query, pageable);
    }

    /**
     * Mark item as read.
     */
    @Transactional
    public void markItemAsRead(Long itemId, String userId) {
        projectItemRepository.markAsRead(itemId);
    }

    /**
     * Toggle item bookmark.
     */
    @Transactional
    public void toggleItemBookmark(Long itemId, String userId) {
        projectItemRepository.toggleBookmark(itemId);
    }

    /**
     * Delete item.
     */
    @Transactional
    public void deleteItem(Long projectId, Long itemId, String userId) {
        if (!hasEditPermission(projectId, userId)) {
            throw new IllegalStateException("User does not have permission to delete items");
        }

        projectItemRepository.deleteById(itemId);

        logActivity(projectId, userId, ProjectActivityLog.ActivityType.ITEM_DELETED,
                "아이템 삭제", "item", itemId.toString(), null);
    }

    // ============================================
    // Activity Log
    // ============================================

    /**
     * Log activity.
     */
    @Transactional
    public ProjectActivityLog logActivity(Long projectId, String userId, ProjectActivityLog.ActivityType type,
                                          String description, String entityType, String entityId, Map<String, Object> metadata) {
        ProjectActivityLog activityLog = ProjectActivityLog.builder()
                .projectId(projectId)
                .userId(userId)
                .activityType(type)
                .description(description)
                .entityType(entityType)
                .entityId(entityId)
                .metadata(metadata)
                .build();

        return activityLogRepository.save(activityLog);
    }

    /**
     * Get project activity log.
     */
    public Page<ProjectActivityLog> getActivityLog(Long projectId, int page, int size) {
        Pageable pageable = PageRequest.of(page, size);
        return activityLogRepository.findByProjectIdOrderByCreatedAtDesc(projectId, pageable);
    }

    /**
     * Get recent activity.
     */
    public List<ProjectActivityLog> getRecentActivity(Long projectId) {
        return activityLogRepository.findTop20ByProjectIdOrderByCreatedAtDesc(projectId);
    }

    // ============================================
    // Notifications
    // ============================================

    /**
     * Create notification.
     */
    @Transactional
    public ProjectNotification createNotification(Long projectId, String userId, 
                                                   ProjectNotification.NotificationType type,
                                                   String title, String message, String actionUrl) {
        ProjectNotification notification = ProjectNotification.builder()
                .projectId(projectId)
                .userId(userId)
                .notificationType(type)
                .title(title)
                .message(message)
                .actionUrl(actionUrl)
                .isRead(false)
                .build();

        return notificationRepository.save(notification);
    }

    /**
     * Get user notifications.
     */
    public Page<ProjectNotification> getUserNotifications(String userId, int page, int size) {
        Pageable pageable = PageRequest.of(page, size);
        return notificationRepository.findByUserIdOrderByCreatedAtDesc(userId, pageable);
    }

    /**
     * Get unread notifications.
     */
    public List<ProjectNotification> getUnreadNotifications(String userId) {
        return notificationRepository.findByUserIdAndIsReadFalseOrderByCreatedAtDesc(userId);
    }

    /**
     * Mark notification as read.
     */
    @Transactional
    public void markNotificationAsRead(Long notificationId) {
        notificationRepository.markAsRead(notificationId);
    }

    /**
     * Mark all notifications as read.
     */
    @Transactional
    public void markAllNotificationsAsRead(String userId) {
        notificationRepository.markAllAsRead(userId);
    }

    // ============================================
    // Statistics
    // ============================================

    /**
     * Get project statistics.
     */
    public Map<String, Object> getProjectStats(Long projectId) {
        long itemCount = projectItemRepository.countByProjectId(projectId);
        long unreadCount = projectItemRepository.countByProjectIdAndIsReadFalse(projectId);
        long memberCount = projectMemberRepository.countByProjectIdAndStatus(projectId, ProjectMember.MemberStatus.ACTIVE);
        List<String> categories = projectItemRepository.findDistinctCategories(projectId);

        return Map.of(
                "itemCount", itemCount,
                "unreadCount", unreadCount,
                "memberCount", memberCount,
                "categories", categories
        );
    }

    // ============================================
    // Permission Helpers
    // ============================================

    private boolean hasEditPermission(Long projectId, String userId) {
        Project project = projectRepository.findById(projectId).orElse(null);
        if (project == null) return false;
        
        if (project.getOwnerId().equals(userId)) return true;

        Optional<ProjectMember> member = projectMemberRepository.findByProjectIdAndUserId(projectId, userId);
        if (member.isEmpty() || member.get().getStatus() != ProjectMember.MemberStatus.ACTIVE) {
            return false;
        }

        ProjectMember.MemberRole role = member.get().getRole();
        return role == ProjectMember.MemberRole.ADMIN || role == ProjectMember.MemberRole.EDITOR;
    }

    private boolean hasAdminPermission(Long projectId, String userId) {
        Project project = projectRepository.findById(projectId).orElse(null);
        if (project == null) return false;
        
        if (project.getOwnerId().equals(userId)) return true;

        Optional<ProjectMember> member = projectMemberRepository.findByProjectIdAndUserId(projectId, userId);
        return member.isPresent() 
                && member.get().getStatus() == ProjectMember.MemberStatus.ACTIVE
                && member.get().getRole() == ProjectMember.MemberRole.ADMIN;
    }

    private boolean hasInvitePermission(Long projectId, String userId) {
        return hasAdminPermission(projectId, userId);
    }

    private boolean canRemoveMember(Long projectId, String removedBy, ProjectMember member) {
        Project project = projectRepository.findById(projectId).orElse(null);
        if (project == null) return false;

        // Owner can remove anyone
        if (project.getOwnerId().equals(removedBy)) return true;

        // Member can remove themselves
        if (member.getUserId().equals(removedBy)) return true;

        // Admin can remove non-admin members
        if (hasAdminPermission(projectId, removedBy) && member.getRole() != ProjectMember.MemberRole.ADMIN) {
            return true;
        }

        return false;
    }

    // ============================================
    // DTOs
    // ============================================

    @Data
    @Builder
    public static class CreateProjectRequest {
        private String name;
        private String description;
        private List<String> keywords;
        private Project.ProjectCategory category;
        private Project.ProjectVisibility visibility;
        private String ownerId;
        private String color;
        private String icon;
        private Boolean isDefault;
        private Project.ProjectSettings settings;
        private List<String> tags;
    }

    @Data
    @Builder
    public static class UpdateProjectRequest {
        private String name;
        private String description;
        private List<String> keywords;
        private Project.ProjectCategory category;
        private Project.ProjectVisibility visibility;
        private String color;
        private String icon;
        private Project.ProjectSettings settings;
        private List<String> tags;
    }

    @Data
    @Builder
    public static class AddItemRequest {
        private ProjectItem.ItemType itemType;
        private String title;
        private String summary;
        private String url;
        private String thumbnailUrl;
        private String sourceName;
        private String sourceId;
        private String sourceType;
        private LocalDateTime publishedAt;
        private String category;
        private List<String> tags;
        private String sentiment;
        private Integer importance;
        private Map<String, Object> metadata;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/RssFeedService.java

```java
package com.newsinsight.collector.service;

import com.fasterxml.jackson.databind.ObjectMapper;
import com.newsinsight.collector.entity.CollectedData;
import com.newsinsight.collector.entity.DataSource;
import com.rometools.rome.feed.synd.SyndEntry;
import com.rometools.rome.feed.synd.SyndFeed;
import com.rometools.rome.io.SyndFeedInput;
import com.rometools.rome.io.XmlReader;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;

import java.net.HttpURLConnection;
import java.net.URL;
import java.time.LocalDateTime;
import java.time.ZoneId;
import java.util.ArrayList;
import java.util.Date;
import java.util.List;
import java.util.Map;
import java.util.stream.Collectors;

@Service
@RequiredArgsConstructor
@Slf4j
public class RssFeedService {

    private final CollectedDataService collectedDataService;
    private final ObjectMapper objectMapper;

    /**
     * 공백을 정리하여 텍스트를 정규화
     */
    private String normalizeText(String text) {
        if (text == null || text.isBlank()) {
            return "";
        }
        return text.replaceAll("\\s+", " ").trim();
    }

    /**
     * RSS 피드를 조회하고 파싱
     */
    public List<CollectedData> fetchRssFeed(DataSource source) {
        List<CollectedData> results = new ArrayList<>();
        
        try {
            log.info("Fetching RSS feed from: {}", source.getUrl());
            
            URL feedUrl = new URL(source.getUrl());
            
            // User-Agent를 설정하여 봇 차단 우회
            HttpURLConnection connection = (HttpURLConnection) feedUrl.openConnection();
            connection.setRequestProperty("User-Agent", 
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36");
            connection.setRequestProperty("Accept", "application/rss+xml, application/xml, text/xml, */*");
            connection.setConnectTimeout(10000);
            connection.setReadTimeout(30000);
            connection.setInstanceFollowRedirects(true);
            
            SyndFeedInput input = new SyndFeedInput();
            SyndFeed feed = input.build(new XmlReader(connection.getInputStream()));
            
            log.info("Found {} entries in feed: {}", feed.getEntries().size(), source.getName());
            
            for (SyndEntry entry : feed.getEntries()) {
                try {
                    CollectedData data = parseEntry(entry, source);
                    if (data != null) {
                        results.add(data);
                    }
                } catch (Exception e) {
                    log.error("Error parsing RSS entry: {}", e.getMessage(), e);
                }
            }
            
        } catch (Exception e) {
            log.error("Error fetching RSS feed from {}: {}", source.getUrl(), e.getMessage(), e);
        }
        
        return results;
    }

    /**
     * RSS 엔트리 1건을 CollectedData로 변환
     */
    private CollectedData parseEntry(SyndEntry entry, DataSource source) {
        String title = entry.getTitle();
        String description = entry.getDescription() != null ? entry.getDescription().getValue() : "";
        String link = entry.getLink();
        
        // 콘텐츠 정규화
        String content = normalizeText(description);
        
        // 콘텐츠가 너무 짧으면 스킵
        if (content.length() < 10) {
            log.debug("Skipping entry with too short content: {}", title);
            return null;
        }
        
        // 게시일 파싱
        LocalDateTime publishedDate = null;
        Date pubDate = entry.getPublishedDate() != null ? entry.getPublishedDate() : entry.getUpdatedDate();
        if (pubDate != null) {
            publishedDate = LocalDateTime.ofInstant(pubDate.toInstant(), ZoneId.systemDefault());
        }
        
        // 콘텐츠 해시 계산
        String contentHash = collectedDataService.computeContentHash(link, title, content);
        
        // 중복 여부 확인
        if (collectedDataService.isDuplicate(contentHash)) {
            log.debug("Duplicate entry detected: {}", title);
            return null;
        }
        
        // 태그/카테고리 추출
        List<String> tags = entry.getCategories() != null 
            ? entry.getCategories().stream()
                .map(cat -> cat.getName())
                .collect(Collectors.toList())
            : List.of();
        
        // 메타데이터 구성
        Map<String, Object> metadata = Map.of(
            "adapter", "rss",
            "tags", tags,
            "author", entry.getAuthor() != null ? entry.getAuthor() : "",
            "source_name", source.getName()
        );
        
        // 메타데이터를 JSON 문자열로 변환
        String metadataJson;
        try {
            metadataJson = objectMapper.writeValueAsString(metadata);
        } catch (Exception e) {
            log.warn("Failed to serialize metadata to JSON: {}", e.getMessage());
            metadataJson = "{}";
        }
        
        // CollectedData 엔티티 생성
        CollectedData data = CollectedData.builder()
                .sourceId(source.getId())
                .title(title)
                .content(content)
                .url(link)
                .publishedDate(publishedDate)
                .contentHash(contentHash)
                .metadataJson(metadataJson)
                .processed(false)
                .hasContent(true)
                .duplicate(false)
                .normalized(true)
                .build();
        
        return data;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/SearchCacheService.java

```java
package com.newsinsight.collector.service;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.ObjectMapper;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.stereotype.Service;

import java.nio.charset.StandardCharsets;
import java.security.MessageDigest;
import java.security.NoSuchAlgorithmException;
import java.time.Duration;
import java.util.List;
import java.util.Optional;

/**
 * Search Result Cache Service
 * 
 * Redis를 사용하여 검색 결과를 캐싱합니다.
 * - DB 검색 결과: 10분 TTL
 * - 통합 검색 결과: 5분 TTL
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class SearchCacheService {

    private final RedisTemplate<String, Object> redisTemplate;
    private final ObjectMapper objectMapper;

    private static final String DB_SEARCH_CACHE_PREFIX = "newsinsight:search:db:";
    private static final String UNIFIED_SEARCH_CACHE_PREFIX = "newsinsight:search:unified:";
    private static final Duration DB_SEARCH_TTL = Duration.ofMinutes(10);
    private static final Duration UNIFIED_SEARCH_TTL = Duration.ofMinutes(5);

    /**
     * 캐시 키 생성 (쿼리 + 윈도우 해시)
     */
    public String generateCacheKey(String query, String window) {
        String input = query.toLowerCase().trim() + ":" + (window != null ? window : "all");
        try {
            MessageDigest md = MessageDigest.getInstance("SHA-256");
            byte[] hash = md.digest(input.getBytes(StandardCharsets.UTF_8));
            StringBuilder hexString = new StringBuilder();
            for (int i = 0; i < Math.min(hash.length, 16); i++) {
                String hex = Integer.toHexString(0xff & hash[i]);
                if (hex.length() == 1) hexString.append('0');
                hexString.append(hex);
            }
            return hexString.toString();
        } catch (NoSuchAlgorithmException e) {
            // Fallback to simple hash
            return String.valueOf(input.hashCode());
        }
    }

    /**
     * DB 검색 결과 캐시 조회
     */
    @SuppressWarnings("unchecked")
    public <T> Optional<List<T>> getDbSearchResults(String query, String window, Class<T> elementType) {
        String cacheKey = DB_SEARCH_CACHE_PREFIX + generateCacheKey(query, window);
        try {
            Object cached = redisTemplate.opsForValue().get(cacheKey);
            if (cached != null) {
                log.debug("Cache HIT for DB search: query='{}', window='{}'", query, window);
                if (cached instanceof List) {
                    return Optional.of((List<T>) cached);
                }
            }
            log.debug("Cache MISS for DB search: query='{}', window='{}'", query, window);
        } catch (Exception e) {
            log.warn("Error reading from cache: {}", e.getMessage());
        }
        return Optional.empty();
    }

    /**
     * DB 검색 결과 캐시 저장
     */
    public <T> void cacheDbSearchResults(String query, String window, List<T> results) {
        if (results == null || results.isEmpty()) {
            return; // 빈 결과는 캐싱하지 않음
        }
        
        String cacheKey = DB_SEARCH_CACHE_PREFIX + generateCacheKey(query, window);
        try {
            redisTemplate.opsForValue().set(cacheKey, results, DB_SEARCH_TTL);
            log.debug("Cached DB search results: query='{}', window='{}', count={}", 
                    query, window, results.size());
        } catch (Exception e) {
            log.warn("Error caching DB search results: {}", e.getMessage());
        }
    }

    /**
     * 통합 검색 결과 캐시 조회
     */
    @SuppressWarnings("unchecked")
    public <T> Optional<T> getUnifiedSearchResults(String query, String window, Class<T> resultType) {
        String cacheKey = UNIFIED_SEARCH_CACHE_PREFIX + generateCacheKey(query, window);
        try {
            Object cached = redisTemplate.opsForValue().get(cacheKey);
            if (cached != null) {
                log.debug("Cache HIT for unified search: query='{}', window='{}'", query, window);
                return Optional.of((T) cached);
            }
            log.debug("Cache MISS for unified search: query='{}', window='{}'", query, window);
        } catch (Exception e) {
            log.warn("Error reading from cache: {}", e.getMessage());
        }
        return Optional.empty();
    }

    /**
     * 통합 검색 결과 캐시 저장
     */
    public <T> void cacheUnifiedSearchResults(String query, String window, T results) {
        if (results == null) {
            return;
        }
        
        String cacheKey = UNIFIED_SEARCH_CACHE_PREFIX + generateCacheKey(query, window);
        try {
            redisTemplate.opsForValue().set(cacheKey, results, UNIFIED_SEARCH_TTL);
            log.debug("Cached unified search results: query='{}', window='{}'", query, window);
        } catch (Exception e) {
            log.warn("Error caching unified search results: {}", e.getMessage());
        }
    }

    /**
     * 검색 캐시 무효화
     */
    public void invalidateSearchCache(String query, String window) {
        String dbKey = DB_SEARCH_CACHE_PREFIX + generateCacheKey(query, window);
        String unifiedKey = UNIFIED_SEARCH_CACHE_PREFIX + generateCacheKey(query, window);
        
        try {
            redisTemplate.delete(dbKey);
            redisTemplate.delete(unifiedKey);
            log.debug("Invalidated search cache for query='{}', window='{}'", query, window);
        } catch (Exception e) {
            log.warn("Error invalidating cache: {}", e.getMessage());
        }
    }

    /**
     * 모든 검색 캐시 클리어
     */
    public void clearAllSearchCaches() {
        try {
            redisTemplate.delete(redisTemplate.keys(DB_SEARCH_CACHE_PREFIX + "*"));
            redisTemplate.delete(redisTemplate.keys(UNIFIED_SEARCH_CACHE_PREFIX + "*"));
            log.info("Cleared all search caches");
        } catch (Exception e) {
            log.warn("Error clearing all search caches: {}", e.getMessage());
        }
    }

    /**
     * 캐시 통계 조회
     */
    public CacheStats getStats() {
        try {
            Long dbKeyCount = Optional.ofNullable(
                    redisTemplate.keys(DB_SEARCH_CACHE_PREFIX + "*")
            ).map(keys -> (long) keys.size()).orElse(0L);
            
            Long unifiedKeyCount = Optional.ofNullable(
                    redisTemplate.keys(UNIFIED_SEARCH_CACHE_PREFIX + "*")
            ).map(keys -> (long) keys.size()).orElse(0L);
            
            return new CacheStats(dbKeyCount, unifiedKeyCount);
        } catch (Exception e) {
            log.warn("Error getting cache stats: {}", e.getMessage());
            return new CacheStats(0L, 0L);
        }
    }

    public record CacheStats(Long dbSearchKeys, Long unifiedSearchKeys) {
        public Long totalKeys() {
            return dbSearchKeys + unifiedSearchKeys;
        }
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/SearchHistoryConsumerService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.dto.SearchHistoryMessage;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.support.Acknowledgment;
import org.springframework.kafka.support.KafkaHeaders;
import org.springframework.messaging.handler.annotation.Header;
import org.springframework.messaging.handler.annotation.Payload;
import org.springframework.stereotype.Service;

/**
 * Kafka consumer service for search history persistence.
 * Listens to search history topic and persists records to database.
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class SearchHistoryConsumerService {

    private final SearchHistoryService searchHistoryService;

    /**
     * Consume search history messages and persist to database.
     */
    @KafkaListener(
            topics = "newsinsight.search.history",
            containerFactory = "searchHistoryKafkaListenerContainerFactory",
            groupId = "${spring.application.name:collector-service}-search-history"
    )
    public void consumeSearchHistory(
            @Payload SearchHistoryMessage message,
            @Header(KafkaHeaders.RECEIVED_KEY) String key,
            @Header(KafkaHeaders.RECEIVED_TOPIC) String topic,
            @Header(KafkaHeaders.RECEIVED_PARTITION) int partition,
            @Header(KafkaHeaders.OFFSET) long offset,
            Acknowledgment acknowledgment
    ) {
        log.debug("Received search history message: key={}, topic={}, partition={}, offset={}",
                key, topic, partition, offset);

        try {
            // Persist to database
            searchHistoryService.saveFromMessage(message);
            
            // Acknowledge successful processing
            acknowledgment.acknowledge();
            
            log.debug("Successfully processed search history: externalId={}, type={}, query='{}'",
                    message.getExternalId(), message.getSearchType(), message.getQuery());
                    
        } catch (Exception e) {
            log.error("Failed to process search history message: key={}, error={}", 
                    key, e.getMessage(), e);
            // Don't acknowledge - message will be retried or sent to DLQ
            throw e;
        }
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/SearchHistoryEventService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.dto.SearchHistoryDto;
import com.newsinsight.collector.entity.search.SearchHistory;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;
import reactor.core.publisher.Flux;
import reactor.core.publisher.Sinks;

import java.time.Duration;
import java.util.Map;
import java.util.concurrent.atomic.AtomicLong;

/**
 * SSE event service for real-time search history updates.
 * Broadcasts new search history entries to connected clients.
 */
@Service
@Slf4j
public class SearchHistoryEventService {

    private final Sinks.Many<SearchHistoryEventDto> eventSink;
    private final AtomicLong subscriberCount = new AtomicLong(0);

    public SearchHistoryEventService() {
        this.eventSink = Sinks.many().multicast().onBackpressureBuffer(256);
    }

    /**
     * Subscribe to the search history event stream.
     * Returns a Flux that emits events when new search history entries are saved.
     * 
     * Events include:
     * - new_search: A new search was saved
     * - updated_search: An existing search was updated
     * - deleted_search: A search was deleted
     * - heartbeat: Keep-alive signal (every 30 seconds)
     */
    public Flux<SearchHistoryEventDto> getEventStream() {
        return Flux.merge(
            eventSink.asFlux(),
            createHeartbeat()
        )
        .doOnSubscribe(sub -> {
            long count = subscriberCount.incrementAndGet();
            log.debug("New subscriber connected to search history stream. Total: {}", count);
        })
        .doOnCancel(() -> {
            long count = subscriberCount.decrementAndGet();
            log.debug("Subscriber disconnected from search history stream. Total: {}", count);
        })
        .doOnError(err -> log.error("Error in search history stream: {}", err.getMessage()));
    }

    /**
     * Get current subscriber count
     */
    public long getSubscriberCount() {
        return subscriberCount.get();
    }

    /**
     * Notify subscribers of a new search history entry.
     */
    public void notifyNewSearch(SearchHistory searchHistory) {
        if (subscriberCount.get() == 0) {
            log.debug("No subscribers, skipping event broadcast");
            return;
        }

        SearchHistoryDto dto = SearchHistoryDto.fromEntity(searchHistory);
        SearchHistoryEventDto event = new SearchHistoryEventDto(
            "new_search",
            dto,
            System.currentTimeMillis()
        );
        
        log.debug("Broadcasting new search event: type={}, query='{}'", 
                searchHistory.getSearchType(), searchHistory.getQuery());
        
        Sinks.EmitResult result = eventSink.tryEmitNext(event);
        if (result.isFailure()) {
            log.warn("Failed to emit search history event: {}", result);
        }
    }

    /**
     * Notify subscribers of an updated search history entry.
     */
    public void notifyUpdatedSearch(SearchHistory searchHistory) {
        if (subscriberCount.get() == 0) {
            return;
        }

        SearchHistoryDto dto = SearchHistoryDto.fromEntity(searchHistory);
        SearchHistoryEventDto event = new SearchHistoryEventDto(
            "updated_search",
            dto,
            System.currentTimeMillis()
        );
        
        log.debug("Broadcasting updated search event: id={}", searchHistory.getId());
        eventSink.tryEmitNext(event);
    }

    /**
     * Notify subscribers of a deleted search history entry.
     */
    public void notifyDeletedSearch(Long id) {
        if (subscriberCount.get() == 0) {
            return;
        }

        SearchHistoryEventDto event = new SearchHistoryEventDto(
            "deleted_search",
            Map.of("id", id),
            System.currentTimeMillis()
        );
        
        log.debug("Broadcasting deleted search event: id={}", id);
        eventSink.tryEmitNext(event);
    }

    /**
     * Create heartbeat events to keep connection alive.
     */
    private Flux<SearchHistoryEventDto> createHeartbeat() {
        return Flux.interval(Duration.ofSeconds(30))
            .map(tick -> new SearchHistoryEventDto(
                "heartbeat",
                Map.of("tick", tick, "subscribers", subscriberCount.get()),
                System.currentTimeMillis()
            ));
    }

    /**
     * DTO for SSE events
     */
    public record SearchHistoryEventDto(
        String eventType,
        Object data,
        long timestamp
    ) {}
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/SearchHistoryService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.dto.SearchHistoryMessage;
import com.newsinsight.collector.entity.search.SearchHistory;
import com.newsinsight.collector.entity.search.SearchType;
import com.newsinsight.collector.repository.SearchHistoryRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.PageRequest;
import org.springframework.data.domain.Pageable;
import org.springframework.data.domain.Sort;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import java.util.concurrent.TimeUnit;

/**
 * Service for managing search history.
 * Provides CRUD operations and Kafka integration for async persistence.
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class SearchHistoryService {

    private final SearchHistoryRepository searchHistoryRepository;
    private final KafkaTemplate<String, SearchHistoryMessage> searchHistoryKafkaTemplate;
    private final SearchHistoryEventService searchHistoryEventService;

    // Kafka topic for search history
    public static final String SEARCH_HISTORY_TOPIC = "newsinsight.search.history";

    /**
     * Send search result to Kafka for async persistence.
     * This is the primary method to save search results asynchronously.
     * Throws IllegalStateException if Kafka send fails.
     */
    public void sendToKafka(SearchHistoryMessage message) {
        if (message.getTimestamp() == null) {
            message.setTimestamp(System.currentTimeMillis());
        }
        
        String key = message.getExternalId() != null ? message.getExternalId() : String.valueOf(message.getTimestamp());
        
        try {
            searchHistoryKafkaTemplate.send(SEARCH_HISTORY_TOPIC, key, message)
                    .get(5, TimeUnit.SECONDS);  // 동기 대기 + 5초 타임아웃
            
            log.debug("Search history sent to Kafka: key={}, topic={}", key, SEARCH_HISTORY_TOPIC);
        } catch (Exception ex) {
            log.error("Failed to send search history to Kafka: key={}, error={}", key, ex.getMessage(), ex);
            throw new IllegalStateException("Failed to queue search history for saving", ex);
        }
    }

    /**
     * Save search history directly (synchronous).
     * Use sendToKafka() for async persistence in production.
     */
    @Transactional
    public SearchHistory save(SearchHistory searchHistory) {
        return searchHistoryRepository.save(searchHistory);
    }

    /**
     * Save from Kafka message (used by consumer).
     */
    @Transactional
    public SearchHistory saveFromMessage(SearchHistoryMessage message) {
        // Check for duplicate by externalId
        if (message.getExternalId() != null) {
            Optional<SearchHistory> existing = searchHistoryRepository.findByExternalId(message.getExternalId());
            if (existing.isPresent()) {
                log.debug("Search history already exists for externalId: {}", message.getExternalId());
                return updateFromMessage(existing.get(), message);
            }
        }

        SearchHistory history = SearchHistory.builder()
                .externalId(message.getExternalId())
                .searchType(message.getSearchType())
                .query(message.getQuery())
                .timeWindow(message.getTimeWindow())
                .userId(message.getUserId())
                .sessionId(message.getSessionId())
                .parentSearchId(message.getParentSearchId())
                .depthLevel(message.getDepthLevel())
                .resultCount(message.getResultCount())
                .results(message.getResults())
                .aiSummary(message.getAiSummary())
                .discoveredUrls(message.getDiscoveredUrls())
                .factCheckResults(message.getFactCheckResults())
                .credibilityScore(message.getCredibilityScore())
                .stanceDistribution(message.getStanceDistribution())
                .metadata(message.getMetadata())
                .durationMs(message.getDurationMs())
                .errorMessage(message.getErrorMessage())
                .success(message.getSuccess())
                .build();

        SearchHistory saved = searchHistoryRepository.save(history);
        log.info("Saved search history: id={}, type={}, query='{}'", 
                saved.getId(), saved.getSearchType(), saved.getQuery());
        
        // Notify SSE subscribers
        searchHistoryEventService.notifyNewSearch(saved);
        
        return saved;
    }

    /**
     * Update existing search history from message.
     */
    private SearchHistory updateFromMessage(SearchHistory existing, SearchHistoryMessage message) {
        if (message.getResults() != null) {
            existing.setResults(message.getResults());
        }
        if (message.getResultCount() != null) {
            existing.setResultCount(message.getResultCount());
        }
        if (message.getAiSummary() != null) {
            existing.setAiSummary(message.getAiSummary());
        }
        if (message.getDiscoveredUrls() != null) {
            existing.setDiscoveredUrls(message.getDiscoveredUrls());
        }
        if (message.getFactCheckResults() != null) {
            existing.setFactCheckResults(message.getFactCheckResults());
        }
        if (message.getCredibilityScore() != null) {
            existing.setCredibilityScore(message.getCredibilityScore());
        }
        if (message.getStanceDistribution() != null) {
            existing.setStanceDistribution(message.getStanceDistribution());
        }
        if (message.getDurationMs() != null) {
            existing.setDurationMs(message.getDurationMs());
        }
        if (message.getErrorMessage() != null) {
            existing.setErrorMessage(message.getErrorMessage());
        }
        if (message.getSuccess() != null) {
            existing.setSuccess(message.getSuccess());
        }
        
        SearchHistory updated = searchHistoryRepository.save(existing);
        
        // Notify SSE subscribers of update
        searchHistoryEventService.notifyUpdatedSearch(updated);
        
        return updated;
    }

    /**
     * Find by ID.
     */
    public Optional<SearchHistory> findById(Long id) {
        return searchHistoryRepository.findById(id);
    }

    /**
     * Find by external ID (e.g., jobId).
     */
    public Optional<SearchHistory> findByExternalId(String externalId) {
        return searchHistoryRepository.findByExternalId(externalId);
    }

    /**
     * Get paginated search history.
     */
    public Page<SearchHistory> findAll(int page, int size, String sortBy, String direction) {
        Sort sort = direction.equalsIgnoreCase("ASC") 
                ? Sort.by(sortBy).ascending() 
                : Sort.by(sortBy).descending();
        Pageable pageable = PageRequest.of(page, size, sort);
        return searchHistoryRepository.findAll(pageable);
    }

    /**
     * Get search history by type.
     */
    public Page<SearchHistory> findByType(SearchType searchType, int page, int size) {
        Pageable pageable = PageRequest.of(page, size, Sort.by("createdAt").descending());
        return searchHistoryRepository.findBySearchType(searchType, pageable);
    }

    /**
     * Get search history by user.
     */
    public Page<SearchHistory> findByUser(String userId, int page, int size) {
        Pageable pageable = PageRequest.of(page, size, Sort.by("createdAt").descending());
        return searchHistoryRepository.findByUserId(userId, pageable);
    }

    /**
     * Get search history by user and type.
     */
    public Page<SearchHistory> findByUserAndType(String userId, SearchType searchType, int page, int size) {
        Pageable pageable = PageRequest.of(page, size, Sort.by("createdAt").descending());
        return searchHistoryRepository.findByUserIdAndSearchType(userId, searchType, pageable);
    }

    /**
     * Search history by query text.
     */
    public Page<SearchHistory> searchByQuery(String query, int page, int size) {
        Pageable pageable = PageRequest.of(page, size, Sort.by("createdAt").descending());
        return searchHistoryRepository.searchByQuery(query, pageable);
    }

    /**
     * Get bookmarked searches.
     */
    public Page<SearchHistory> findBookmarked(int page, int size) {
        Pageable pageable = PageRequest.of(page, size, Sort.by("createdAt").descending());
        return searchHistoryRepository.findByBookmarkedTrue(pageable);
    }

    /**
     * Get derived searches from a parent.
     */
    public List<SearchHistory> findDerivedSearches(Long parentSearchId) {
        return searchHistoryRepository.findByParentSearchIdOrderByCreatedAtDesc(parentSearchId);
    }

    /**
     * Get searches from a session.
     */
    public List<SearchHistory> findBySession(String sessionId) {
        return searchHistoryRepository.findBySessionIdOrderByCreatedAtDesc(sessionId);
    }

    /**
     * Toggle bookmark status.
     */
    @Transactional
    public SearchHistory toggleBookmark(Long id) {
        SearchHistory history = searchHistoryRepository.findById(id)
                .orElseThrow(() -> new IllegalArgumentException("Search history not found: " + id));
        history.setBookmarked(!history.getBookmarked());
        return searchHistoryRepository.save(history);
    }

    /**
     * Update tags.
     */
    @Transactional
    public SearchHistory updateTags(Long id, List<String> tags) {
        SearchHistory history = searchHistoryRepository.findById(id)
                .orElseThrow(() -> new IllegalArgumentException("Search history not found: " + id));
        history.setTags(tags);
        return searchHistoryRepository.save(history);
    }

    /**
     * Update notes.
     */
    @Transactional
    public SearchHistory updateNotes(Long id, String notes) {
        SearchHistory history = searchHistoryRepository.findById(id)
                .orElseThrow(() -> new IllegalArgumentException("Search history not found: " + id));
        history.setNotes(notes);
        return searchHistoryRepository.save(history);
    }

    /**
     * Delete search history.
     */
    @Transactional
    public void delete(Long id) {
        searchHistoryRepository.deleteById(id);
        log.info("Deleted search history: id={}", id);
        
        // Notify SSE subscribers
        searchHistoryEventService.notifyDeletedSearch(id);
    }

    /**
     * Delete old non-bookmarked searches (for cleanup).
     */
    @Transactional
    public void cleanupOldSearches(int daysOld) {
        LocalDateTime before = LocalDateTime.now().minusDays(daysOld);
        searchHistoryRepository.deleteOldSearches(before);
        log.info("Cleaned up search history older than {} days", daysOld);
    }

    /**
     * Get search statistics.
     */
    public Map<String, Object> getStatistics(int days) {
        LocalDateTime after = LocalDateTime.now().minusDays(days);
        List<SearchHistoryRepository.SearchStatsSummary> stats = 
                searchHistoryRepository.getSearchStatsSummary(after);
        
        long totalCount = stats.stream().mapToLong(SearchHistoryRepository.SearchStatsSummary::getCount).sum();
        
        return Map.of(
                "totalSearches", totalCount,
                "byType", stats,
                "period", Map.of("days", days, "since", after.toString())
        );
    }

    /**
     * Get recently discovered URLs.
     */
    public List<String> getRecentDiscoveredUrls(int days, int limit) {
        LocalDateTime after = LocalDateTime.now().minusDays(days);
        return searchHistoryRepository.findRecentDiscoveredUrls(after, limit);
    }

    /**
     * Create a derived search (for drill-down functionality).
     */
    @Transactional
    public SearchHistory createDerivedSearch(Long parentId, SearchHistoryMessage message) {
        SearchHistory parent = searchHistoryRepository.findById(parentId)
                .orElseThrow(() -> new IllegalArgumentException("Parent search not found: " + parentId));
        
        message.setParentSearchId(parentId);
        message.setDepthLevel(parent.getDepthLevel() + 1);
        message.setSessionId(parent.getSessionId());
        message.setUserId(parent.getUserId());
        
        return saveFromMessage(message);
    }

    // ============================================
    // Continue Work Feature
    // ============================================

    /**
     * Find actionable items for "Continue Work" feature.
     * Returns searches that need user attention:
     * - IN_PROGRESS: Still running
     * - FAILED: Need retry
     * - PARTIAL: Incomplete results
     * - DRAFT: Not executed yet
     * - COMPLETED but not viewed: Need review
     */
    public List<SearchHistory> findContinueWorkItems(String userId, String sessionId, int limit) {
        Pageable pageable = PageRequest.of(0, limit);
        return searchHistoryRepository.findContinueWorkItems(userId, sessionId, pageable);
    }

    /**
     * Mark search as viewed.
     */
    @Transactional
    public SearchHistory markAsViewed(Long id) {
        SearchHistory history = searchHistoryRepository.findById(id)
                .orElseThrow(() -> new IllegalArgumentException("Search history not found: " + id));
        
        history.markViewed();
        return searchHistoryRepository.save(history);
    }

    /**
     * Mark search as viewed by external ID.
     */
    @Transactional
    public SearchHistory markAsViewedByExternalId(String externalId) {
        SearchHistory history = searchHistoryRepository.findByExternalId(externalId)
                .orElseThrow(() -> new IllegalArgumentException("Search history not found for externalId: " + externalId));
        
        history.markViewed();
        return searchHistoryRepository.save(history);
    }

    /**
     * Update completion status.
     */
    @Transactional
    public SearchHistory updateCompletionStatus(Long id, SearchHistory.CompletionStatus status) {
        SearchHistory history = searchHistoryRepository.findById(id)
                .orElseThrow(() -> new IllegalArgumentException("Search history not found: " + id));
        
        history.setCompletionStatus(status);
        return searchHistoryRepository.save(history);
    }

    /**
     * Find by completion status.
     */
    public Page<SearchHistory> findByCompletionStatus(SearchHistory.CompletionStatus status, int page, int size) {
        Pageable pageable = PageRequest.of(page, size, Sort.by("updatedAt").descending());
        return searchHistoryRepository.findByCompletionStatus(status, pageable);
    }

    /**
     * Find by project ID.
     */
    public Page<SearchHistory> findByProjectId(Long projectId, int page, int size) {
        Pageable pageable = PageRequest.of(page, size, Sort.by("createdAt").descending());
        return searchHistoryRepository.findByProjectId(projectId, pageable);
    }

    /**
     * Find failed searches for potential retry.
     */
    public List<SearchHistory> findFailedSearches(int daysBack, int limit) {
        LocalDateTime after = LocalDateTime.now().minusDays(daysBack);
        Pageable pageable = PageRequest.of(0, limit);
        return searchHistoryRepository.findFailedSearches(after, pageable);
    }

    /**
     * Count in-progress searches for a user.
     */
    public long countInProgressByUser(String userId) {
        return searchHistoryRepository.countInProgressByUser(userId);
    }

    /**
     * Get continue work statistics.
     */
    public Map<String, Object> getContinueWorkStats(String userId, String sessionId) {
        List<SearchHistory> items = findContinueWorkItems(userId, sessionId, 100);
        
        long inProgress = items.stream()
                .filter(h -> h.getCompletionStatus() == SearchHistory.CompletionStatus.IN_PROGRESS)
                .count();
        long failed = items.stream()
                .filter(h -> h.getCompletionStatus() == SearchHistory.CompletionStatus.FAILED)
                .count();
        long draft = items.stream()
                .filter(h -> h.getCompletionStatus() == SearchHistory.CompletionStatus.DRAFT)
                .count();
        long partial = items.stream()
                .filter(h -> h.getCompletionStatus() == SearchHistory.CompletionStatus.PARTIAL)
                .count();
        long unviewed = items.stream()
                .filter(h -> h.getCompletionStatus() == SearchHistory.CompletionStatus.COMPLETED && !h.getViewed())
                .count();

        return Map.of(
                "total", items.size(),
                "inProgress", inProgress,
                "failed", failed,
                "draft", draft,
                "partial", partial,
                "unviewedCompleted", unviewed
        );
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/SearchJobQueueService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.dto.SearchHistoryMessage;
import com.newsinsight.collector.entity.search.SearchHistory;
import com.newsinsight.collector.entity.search.SearchType;
import com.newsinsight.collector.repository.SearchHistoryRepository;
import lombok.Builder;
import lombok.Data;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.scheduling.annotation.Async;
import org.springframework.stereotype.Service;

import java.time.LocalDateTime;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import java.util.UUID;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.function.Consumer;

/**
 * Service for managing concurrent search jobs.
 * Enables users to run multiple searches simultaneously
 * (Unified Search, Deep Search, Fact Check, etc.)
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class SearchJobQueueService {

    private final SearchHistoryRepository searchHistoryRepository;
    private final SearchHistoryService searchHistoryService;
    private final UnifiedSearchService unifiedSearchService;
    private final DeepAnalysisService deepAnalysisService;

    // Active jobs tracked in memory
    private final Map<String, SearchJob> activeJobs = new ConcurrentHashMap<>();
    
    // Job listeners for SSE notifications
    private final Map<String, Consumer<SearchJobEvent>> jobListeners = new ConcurrentHashMap<>();

    // Executor for async job execution
    private final ExecutorService executorService = Executors.newFixedThreadPool(10);

    /**
     * Start a new search job
     */
    public String startJob(SearchJobRequest request) {
        String jobId = UUID.randomUUID().toString();
        
        SearchJob job = SearchJob.builder()
                .jobId(jobId)
                .type(request.getType())
                .query(request.getQuery())
                .timeWindow(request.getTimeWindow())
                .userId(request.getUserId())
                .sessionId(request.getSessionId())
                .projectId(request.getProjectId())
                .status(JobStatus.PENDING)
                .progress(0)
                .startedAt(LocalDateTime.now())
                .build();
        
        activeJobs.put(jobId, job);
        
        // Create initial SearchHistory entry
        SearchHistory history = SearchHistory.builder()
                .externalId(jobId)
                .searchType(request.getType())
                .query(request.getQuery())
                .timeWindow(request.getTimeWindow())
                .userId(request.getUserId())
                .sessionId(request.getSessionId())
                .projectId(request.getProjectId())
                .completionStatus(SearchHistory.CompletionStatus.IN_PROGRESS)
                .progress(0)
                .currentPhase("초기화 중...")
                .build();
        
        searchHistoryRepository.save(history);
        
        // Execute job asynchronously
        executeJobAsync(job);
        
        log.info("Started search job: id={}, type={}, query='{}'", jobId, request.getType(), request.getQuery());
        
        return jobId;
    }

    /**
     * Execute job asynchronously
     */
    @Async
    protected void executeJobAsync(SearchJob job) {
        try {
            job.setStatus(JobStatus.RUNNING);
            notifyJobUpdate(job, "started", "검색을 시작합니다");
            
            switch (job.getType()) {
                case UNIFIED -> executeUnifiedSearch(job);
                case DEEP_SEARCH -> executeDeepSearch(job);
                case FACT_CHECK -> executeFactCheck(job);
                case BROWSER_AGENT -> executeBrowserAgent(job);
                default -> throw new IllegalArgumentException("Unknown job type: " + job.getType());
            }
            
        } catch (Exception e) {
            log.error("Job execution failed: jobId={}, error={}", job.getJobId(), e.getMessage(), e);
            markJobFailed(job, e.getMessage());
        }
    }

    /**
     * Execute unified search
     */
    private void executeUnifiedSearch(SearchJob job) {
        updateJobProgress(job, 10, "데이터베이스 검색 중...");
        
        // Delegate to UnifiedSearchService
        // The service will handle SSE streaming and updates
        unifiedSearchService.executeSearchAsync(
                job.getJobId(),
                job.getQuery(),
                job.getTimeWindow(),
                null // priority URLs
        );
        
        // Note: Job completion is handled by the callback from UnifiedSearchService
    }

    /**
     * Execute deep search
     */
    private void executeDeepSearch(SearchJob job) {
        updateJobProgress(job, 10, "Deep Search 시작...");
        
        // Delegate to DeepAnalysisService
        deepAnalysisService.startDeepSearch(job.getQuery(), null);
        
        // Note: Job completion is handled by the callback from DeepAnalysisService
    }

    /**
     * Execute fact check (placeholder)
     */
    private void executeFactCheck(SearchJob job) {
        updateJobProgress(job, 10, "팩트체크 시작...");
        // TODO: Implement fact check execution
        markJobCompleted(job, Map.of("status", "not_implemented"));
    }

    /**
     * Execute browser agent (placeholder)
     */
    private void executeBrowserAgent(SearchJob job) {
        updateJobProgress(job, 10, "브라우저 에이전트 시작...");
        // TODO: Implement browser agent execution
        markJobCompleted(job, Map.of("status", "not_implemented"));
    }

    /**
     * Update job progress
     */
    public void updateJobProgress(String jobId, int progress, String phase) {
        SearchJob job = activeJobs.get(jobId);
        if (job != null) {
            updateJobProgress(job, progress, phase);
        }
    }

    private void updateJobProgress(SearchJob job, int progress, String phase) {
        job.setProgress(progress);
        job.setCurrentPhase(phase);
        
        // Update SearchHistory
        searchHistoryRepository.findByExternalId(job.getJobId()).ifPresent(history -> {
            history.updateProgress(progress, phase);
            searchHistoryRepository.save(history);
        });
        
        notifyJobUpdate(job, "progress", phase);
    }

    /**
     * Mark job as completed
     */
    public void markJobCompleted(String jobId, Map<String, Object> result) {
        SearchJob job = activeJobs.get(jobId);
        if (job != null) {
            markJobCompleted(job, result);
        }
    }

    private void markJobCompleted(SearchJob job, Map<String, Object> result) {
        job.setStatus(JobStatus.COMPLETED);
        job.setProgress(100);
        job.setCompletedAt(LocalDateTime.now());
        job.setResult(result);
        
        // Update SearchHistory
        searchHistoryRepository.findByExternalId(job.getJobId()).ifPresent(history -> {
            history.markCompleted();
            searchHistoryRepository.save(history);
        });
        
        notifyJobUpdate(job, "completed", "검색이 완료되었습니다");
        
        // Keep in active jobs for a while for status queries
        // Will be cleaned up by scheduled task
        
        log.info("Job completed: jobId={}, duration={}ms", 
                job.getJobId(), 
                java.time.Duration.between(job.getStartedAt(), job.getCompletedAt()).toMillis());
    }

    /**
     * Mark job as failed
     */
    public void markJobFailed(String jobId, String errorMessage) {
        SearchJob job = activeJobs.get(jobId);
        if (job != null) {
            markJobFailed(job, errorMessage);
        }
    }

    private void markJobFailed(SearchJob job, String errorMessage) {
        job.setStatus(JobStatus.FAILED);
        job.setErrorMessage(errorMessage);
        job.setCompletedAt(LocalDateTime.now());
        
        // Update SearchHistory
        searchHistoryRepository.findByExternalId(job.getJobId()).ifPresent(history -> {
            history.markFailed(job.getCurrentPhase(), errorMessage, null);
            searchHistoryRepository.save(history);
        });
        
        notifyJobUpdate(job, "failed", errorMessage);
        
        log.error("Job failed: jobId={}, error={}", job.getJobId(), errorMessage);
    }

    /**
     * Cancel a job
     */
    public boolean cancelJob(String jobId) {
        SearchJob job = activeJobs.get(jobId);
        if (job == null || job.getStatus() != JobStatus.RUNNING) {
            return false;
        }
        
        job.setStatus(JobStatus.CANCELLED);
        job.setCompletedAt(LocalDateTime.now());
        
        // Update SearchHistory
        searchHistoryRepository.findByExternalId(jobId).ifPresent(history -> {
            history.setCompletionStatus(SearchHistory.CompletionStatus.CANCELLED);
            searchHistoryRepository.save(history);
        });
        
        notifyJobUpdate(job, "cancelled", "작업이 취소되었습니다");
        
        log.info("Job cancelled: jobId={}", jobId);
        return true;
    }

    /**
     * Get job status
     */
    public Optional<SearchJob> getJobStatus(String jobId) {
        return Optional.ofNullable(activeJobs.get(jobId));
    }

    /**
     * Get active jobs for user
     */
    public List<SearchJob> getActiveJobs(String userId) {
        return activeJobs.values().stream()
                .filter(job -> userId.equals(job.getUserId()))
                .filter(job -> job.getStatus() == JobStatus.PENDING || job.getStatus() == JobStatus.RUNNING)
                .toList();
    }

    /**
     * Get all jobs for user (including completed)
     */
    public List<SearchJob> getAllJobs(String userId, int limit) {
        return activeJobs.values().stream()
                .filter(job -> userId.equals(job.getUserId()))
                .sorted((a, b) -> b.getStartedAt().compareTo(a.getStartedAt()))
                .limit(limit)
                .toList();
    }

    /**
     * Register job listener for SSE
     */
    public void registerListener(String jobId, Consumer<SearchJobEvent> listener) {
        jobListeners.put(jobId, listener);
    }

    /**
     * Unregister job listener
     */
    public void unregisterListener(String jobId) {
        jobListeners.remove(jobId);
    }

    /**
     * Notify job update to listeners
     */
    private void notifyJobUpdate(SearchJob job, String eventType, String message) {
        Consumer<SearchJobEvent> listener = jobListeners.get(job.getJobId());
        if (listener != null) {
            SearchJobEvent event = SearchJobEvent.builder()
                    .jobId(job.getJobId())
                    .eventType(eventType)
                    .status(job.getStatus())
                    .progress(job.getProgress())
                    .currentPhase(job.getCurrentPhase())
                    .message(message)
                    .timestamp(System.currentTimeMillis())
                    .build();
            
            try {
                listener.accept(event);
            } catch (Exception e) {
                log.warn("Failed to notify job listener: jobId={}, error={}", job.getJobId(), e.getMessage());
            }
        }
    }

    /**
     * Cleanup completed jobs (called by scheduler)
     */
    public void cleanupCompletedJobs() {
        LocalDateTime cutoff = LocalDateTime.now().minusHours(1);
        
        activeJobs.entrySet().removeIf(entry -> {
            SearchJob job = entry.getValue();
            return (job.getStatus() == JobStatus.COMPLETED 
                    || job.getStatus() == JobStatus.FAILED 
                    || job.getStatus() == JobStatus.CANCELLED)
                    && job.getCompletedAt() != null 
                    && job.getCompletedAt().isBefore(cutoff);
        });
    }

    // ============ DTOs ============

    @Data
    @Builder
    public static class SearchJobRequest {
        private SearchType type;
        private String query;
        private String timeWindow;
        private String userId;
        private String sessionId;
        private Long projectId;
        private Map<String, Object> options;
    }

    @Data
    @Builder
    public static class SearchJob {
        private String jobId;
        private SearchType type;
        private String query;
        private String timeWindow;
        private String userId;
        private String sessionId;
        private Long projectId;
        private JobStatus status;
        private int progress;
        private String currentPhase;
        private String errorMessage;
        private LocalDateTime startedAt;
        private LocalDateTime completedAt;
        private Map<String, Object> result;
    }

    @Data
    @Builder
    public static class SearchJobEvent {
        private String jobId;
        private String eventType;
        private JobStatus status;
        private int progress;
        private String currentPhase;
        private String message;
        private long timestamp;
    }

    public enum JobStatus {
        PENDING,
        RUNNING,
        COMPLETED,
        FAILED,
        CANCELLED
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/SearchTemplateService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.dto.SearchTemplateDto;
import com.newsinsight.collector.entity.search.SearchTemplate;
import com.newsinsight.collector.repository.SearchTemplateRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.PageRequest;
import org.springframework.data.domain.Pageable;
import org.springframework.data.domain.Sort;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.util.List;
import java.util.Map;
import java.util.Optional;

/**
 * Service for managing search templates.
 * Provides CRUD operations and query functionality for templates.
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class SearchTemplateService {

    private final SearchTemplateRepository searchTemplateRepository;

    /**
     * Create a new template
     */
    @Transactional
    public SearchTemplate create(SearchTemplateDto dto) {
        if (dto.getName() == null || dto.getName().isBlank()) {
            throw new IllegalArgumentException("Template name is required");
        }
        if (dto.getQuery() == null || dto.getQuery().isBlank()) {
            throw new IllegalArgumentException("Template query is required");
        }
        if (dto.getMode() == null || dto.getMode().isBlank()) {
            throw new IllegalArgumentException("Template mode is required");
        }

        // Check for duplicate name for same user
        if (dto.getUserId() != null && 
            searchTemplateRepository.existsByUserIdAndName(dto.getUserId(), dto.getName())) {
            throw new IllegalArgumentException("Template with this name already exists");
        }

        SearchTemplate template = dto.toEntity();
        SearchTemplate saved = searchTemplateRepository.save(template);
        log.info("Created template: id={}, name='{}', mode={}, userId={}", 
                saved.getId(), saved.getName(), saved.getMode(), saved.getUserId());
        return saved;
    }

    /**
     * Update an existing template
     */
    @Transactional
    public SearchTemplate update(Long id, SearchTemplateDto dto) {
        SearchTemplate template = searchTemplateRepository.findById(id)
                .orElseThrow(() -> new IllegalArgumentException("Template not found: " + id));

        if (dto.getName() != null && !dto.getName().isBlank()) {
            // Check for duplicate name if changing
            if (!dto.getName().equals(template.getName()) && 
                template.getUserId() != null &&
                searchTemplateRepository.existsByUserIdAndName(template.getUserId(), dto.getName())) {
                throw new IllegalArgumentException("Template with this name already exists");
            }
            template.setName(dto.getName());
        }
        if (dto.getQuery() != null) {
            template.setQuery(dto.getQuery());
        }
        if (dto.getMode() != null) {
            template.setMode(dto.getMode());
        }
        if (dto.getItems() != null) {
            template.setItems(dto.getItems());
        }
        if (dto.getDescription() != null) {
            template.setDescription(dto.getDescription());
        }
        if (dto.getTags() != null) {
            template.setTags(dto.getTags());
        }
        if (dto.getMetadata() != null) {
            template.setMetadata(dto.getMetadata());
        }

        SearchTemplate updated = searchTemplateRepository.save(template);
        log.info("Updated template: id={}, name='{}'", updated.getId(), updated.getName());
        return updated;
    }

    /**
     * Find by ID
     */
    public Optional<SearchTemplate> findById(Long id) {
        return searchTemplateRepository.findById(id);
    }

    /**
     * Get paginated templates
     */
    public Page<SearchTemplate> findAll(int page, int size, String sortBy, String direction) {
        Sort sort = direction.equalsIgnoreCase("ASC")
                ? Sort.by(sortBy).ascending()
                : Sort.by(sortBy).descending();
        Pageable pageable = PageRequest.of(page, size, sort);
        return searchTemplateRepository.findAll(pageable);
    }

    /**
     * Get templates by user
     */
    public Page<SearchTemplate> findByUser(String userId, int page, int size) {
        Pageable pageable = PageRequest.of(page, size, Sort.by("createdAt").descending());
        return searchTemplateRepository.findByUserId(userId, pageable);
    }

    /**
     * Get all templates for a user (list)
     */
    public List<SearchTemplate> findAllByUser(String userId) {
        return searchTemplateRepository.findByUserIdOrderByCreatedAtDesc(userId);
    }

    /**
     * Get templates by user and mode
     */
    public Page<SearchTemplate> findByUserAndMode(String userId, String mode, int page, int size) {
        Pageable pageable = PageRequest.of(page, size, Sort.by("createdAt").descending());
        return searchTemplateRepository.findByUserIdAndMode(userId, mode, pageable);
    }

    /**
     * Get favorite templates for a user
     */
    public List<SearchTemplate> findFavoritesByUser(String userId) {
        return searchTemplateRepository.findByUserIdAndFavoriteTrueOrderByLastUsedAtDesc(userId);
    }

    /**
     * Search templates by name
     */
    public Page<SearchTemplate> searchByName(String name, String userId, int page, int size) {
        Pageable pageable = PageRequest.of(page, size, Sort.by("createdAt").descending());
        if (userId != null) {
            return searchTemplateRepository.searchByNameAndUserId(name, userId, pageable);
        }
        return searchTemplateRepository.searchByName(name, pageable);
    }

    /**
     * Get most used templates for a user
     */
    public List<SearchTemplate> findMostUsed(String userId, int limit) {
        Pageable pageable = PageRequest.of(0, limit);
        return searchTemplateRepository.findMostUsedByUser(userId, pageable);
    }

    /**
     * Get recently used templates for a user
     */
    public List<SearchTemplate> findRecentlyUsed(String userId, int limit) {
        Pageable pageable = PageRequest.of(0, limit);
        return searchTemplateRepository.findRecentlyUsedByUser(userId, pageable);
    }

    /**
     * Toggle favorite status
     */
    @Transactional
    public SearchTemplate toggleFavorite(Long id) {
        SearchTemplate template = searchTemplateRepository.findById(id)
                .orElseThrow(() -> new IllegalArgumentException("Template not found: " + id));
        template.setFavorite(!template.getFavorite());
        return searchTemplateRepository.save(template);
    }

    /**
     * Record template usage
     */
    @Transactional
    public void recordUsage(Long id) {
        searchTemplateRepository.incrementUseCount(id);
        log.debug("Recorded usage for template: id={}", id);
    }

    /**
     * Delete template
     */
    @Transactional
    public void delete(Long id) {
        if (!searchTemplateRepository.existsById(id)) {
            throw new IllegalArgumentException("Template not found: " + id);
        }
        searchTemplateRepository.deleteById(id);
        log.info("Deleted template: id={}", id);
    }

    /**
     * Get template statistics
     */
    public Map<String, Object> getStatistics(String userId) {
        long totalCount = userId != null 
                ? searchTemplateRepository.countByUserId(userId)
                : searchTemplateRepository.count();
        
        long unifiedCount = searchTemplateRepository.countByMode("unified");
        long deepCount = searchTemplateRepository.countByMode("deep");
        long factcheckCount = searchTemplateRepository.countByMode("factcheck");

        return Map.of(
                "totalTemplates", totalCount,
                "byMode", Map.of(
                        "unified", unifiedCount,
                        "deep", deepCount,
                        "factcheck", factcheckCount
                ),
                "userId", userId != null ? userId : "all"
        );
    }

    /**
     * Duplicate a template
     */
    @Transactional
    public SearchTemplate duplicate(Long id, String newName, String userId) {
        SearchTemplate original = searchTemplateRepository.findById(id)
                .orElseThrow(() -> new IllegalArgumentException("Template not found: " + id));

        String name = newName != null ? newName : original.getName() + " (copy)";
        
        // Ensure unique name
        String finalName = name;
        int counter = 1;
        while (userId != null && searchTemplateRepository.existsByUserIdAndName(userId, finalName)) {
            finalName = name + " " + counter++;
        }

        SearchTemplate copy = SearchTemplate.builder()
                .name(finalName)
                .query(original.getQuery())
                .mode(original.getMode())
                .userId(userId != null ? userId : original.getUserId())
                .items(original.getItems())
                .description(original.getDescription())
                .tags(original.getTags())
                .metadata(original.getMetadata())
                .sourceSearchId(original.getSourceSearchId())
                .build();

        SearchTemplate saved = searchTemplateRepository.save(copy);
        log.info("Duplicated template: originalId={}, newId={}, newName='{}'", 
                id, saved.getId(), saved.getName());
        return saved;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/UnifiedSearchEventService.java

```java
package com.newsinsight.collector.service;

import lombok.extern.slf4j.Slf4j;
import org.springframework.http.codec.ServerSentEvent;
import org.springframework.stereotype.Service;
import reactor.core.publisher.Flux;
import reactor.core.publisher.Sinks;

import java.time.Duration;
import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;

/**
 * Service for managing SSE streams for unified search jobs.
 * Each job has its own event sink that clients can subscribe to.
 * 
 * This follows the same pattern as DeepSearchEventService to enable:
 * - Job-based async search execution
 * - SSE stream reconnection with same jobId
 * - Page navigation without losing search results
 * - Collecting all search results for persistence
 */
@Service
@Slf4j
public class UnifiedSearchEventService {

    // Map of jobId -> Sinks for that job
    private final Map<String, Sinks.Many<ServerSentEvent<Object>>> jobSinks = new ConcurrentHashMap<>();
    
    // Map of jobId -> Job metadata (status, query, etc.)
    private final Map<String, JobMetadata> jobMetadataMap = new ConcurrentHashMap<>();

    // Map of jobId -> Collected results for persistence
    private final Map<String, List<Map<String, Object>>> jobResults = new ConcurrentHashMap<>();

    /**
     * Metadata for a search job.
     */
    public record JobMetadata(
            String jobId,
            String query,
            String window,
            String status, // PENDING, IN_PROGRESS, COMPLETED, FAILED
            long createdAt,
            Long completedAt
    ) {
        public JobMetadata withStatus(String newStatus) {
            return new JobMetadata(jobId, query, window, newStatus, createdAt, 
                    "COMPLETED".equals(newStatus) || "FAILED".equals(newStatus) 
                            ? Long.valueOf(System.currentTimeMillis()) : completedAt);
        }
    }

    /**
     * Create a new job and return its metadata.
     */
    public JobMetadata createJob(String jobId, String query, String window) {
        JobMetadata metadata = new JobMetadata(jobId, query, window, "PENDING", System.currentTimeMillis(), null);
        jobMetadataMap.put(jobId, metadata);
        jobResults.put(jobId, Collections.synchronizedList(new ArrayList<>()));
        getOrCreateSink(jobId); // Ensure sink is created
        log.info("Created unified search job: {} for query: '{}'", jobId, query);
        return metadata;
    }

    /**
     * Get job metadata.
     */
    public JobMetadata getJobMetadata(String jobId) {
        return jobMetadataMap.get(jobId);
    }

    /**
     * Update job status.
     */
    public void updateJobStatus(String jobId, String status) {
        JobMetadata existing = jobMetadataMap.get(jobId);
        if (existing != null) {
            jobMetadataMap.put(jobId, existing.withStatus(status));
        }
    }

    /**
     * Get or create a sink for a job.
     */
    private Sinks.Many<ServerSentEvent<Object>> getOrCreateSink(String jobId) {
        return jobSinks.computeIfAbsent(jobId, id -> {
            log.info("Creating new SSE sink for unified search job: {}", id);
            return Sinks.many().multicast().onBackpressureBuffer(200);
        });
    }

    /**
     * Get the event stream for a specific job.
     * Includes heartbeats every 15 seconds to keep connection alive.
     */
    public Flux<ServerSentEvent<Object>> getJobEventStream(String jobId) {
        Sinks.Many<ServerSentEvent<Object>> sink = getOrCreateSink(jobId);
        
        // Heartbeat stream
        Flux<ServerSentEvent<Object>> heartbeat = Flux.interval(Duration.ofSeconds(15))
                .map(tick -> ServerSentEvent.builder()
                        .event("heartbeat")
                        .data(Map.of("timestamp", System.currentTimeMillis(), "jobId", jobId))
                        .build());

        // Main event stream from sink
        Flux<ServerSentEvent<Object>> events = sink.asFlux();

        // Check if job is already completed - send initial status
        JobMetadata metadata = jobMetadataMap.get(jobId);
        Flux<ServerSentEvent<Object>> initialStatus = Flux.empty();
        if (metadata != null) {
            initialStatus = Flux.just(ServerSentEvent.builder()
                    .event("job_status")
                    .data(Map.of(
                            "jobId", jobId,
                            "query", metadata.query(),
                            "window", metadata.window(),
                            "status", metadata.status(),
                            "createdAt", metadata.createdAt()
                    ))
                    .build());
        }

        return Flux.concat(initialStatus, Flux.merge(heartbeat, events))
                .doOnSubscribe(sub -> log.info("New SSE subscriber for unified search job: {}", jobId))
                .doOnCancel(() -> log.info("SSE subscriber disconnected for unified search job: {}", jobId))
                .doOnError(e -> log.error("SSE stream error for unified search job: {}", jobId, e));
    }

    /**
     * Publish a status update event.
     */
    public void publishStatusUpdate(String jobId, String source, String message) {
        Sinks.Many<ServerSentEvent<Object>> sink = jobSinks.get(jobId);
        if (sink == null) {
            log.debug("No sink found for job: {}, creating new one", jobId);
            sink = getOrCreateSink(jobId);
        }

        ServerSentEvent<Object> event = ServerSentEvent.builder()
                .event("status")
                .data(Map.of(
                        "jobId", jobId,
                        "eventType", "status",
                        "source", source,
                        "message", message != null ? message : "",
                        "timestamp", System.currentTimeMillis()
                ))
                .build();

        sink.tryEmitNext(event);
        log.debug("Published status event for job: {}, source: {}", jobId, source);
    }

    /**
     * Publish a search result event and collect it for persistence.
     */
    public void publishResult(String jobId, String source, Object result) {
        Sinks.Many<ServerSentEvent<Object>> sink = jobSinks.get(jobId);
        if (sink == null) return;

        // Collect result for persistence (skip AI results as they're saved separately)
        if (!"ai".equals(source) && result != null) {
            collectResult(jobId, source, result);
        }

        ServerSentEvent<Object> event = ServerSentEvent.builder()
                .event("result")
                .data(Map.of(
                        "jobId", jobId,
                        "eventType", "result",
                        "source", source,
                        "result", result,
                        "timestamp", System.currentTimeMillis()
                ))
                .build();

        sink.tryEmitNext(event);
        log.debug("Published result event for job: {}, source: {}", jobId, source);
    }

    /**
     * Collect a search result for later persistence.
     */
    @SuppressWarnings("unchecked")
    private void collectResult(String jobId, String source, Object result) {
        List<Map<String, Object>> results = jobResults.get(jobId);
        if (results == null) {
            results = Collections.synchronizedList(new ArrayList<>());
            jobResults.put(jobId, results);
        }

        try {
            Map<String, Object> resultMap;
            if (result instanceof Map) {
                resultMap = new ConcurrentHashMap<>((Map<String, Object>) result);
            } else {
                // Convert SearchResult object to Map
                resultMap = convertToMap(result);
            }
            resultMap.put("_source", source);
            resultMap.put("_collectedAt", System.currentTimeMillis());
            results.add(resultMap);
            log.debug("Collected result for job: {}, source: {}, total collected: {}", jobId, source, results.size());
        } catch (Exception e) {
            log.warn("Failed to collect result for job: {}, source: {}, error: {}", jobId, source, e.getMessage());
        }
    }

    /**
     * Convert a SearchResult object to a Map for persistence.
     */
    private Map<String, Object> convertToMap(Object result) {
        Map<String, Object> map = new ConcurrentHashMap<>();
        try {
            // Use reflection to convert SearchResult to Map
            for (var field : result.getClass().getDeclaredFields()) {
                field.setAccessible(true);
                Object value = field.get(result);
                if (value != null) {
                    map.put(field.getName(), value);
                }
            }
        } catch (Exception e) {
            log.warn("Failed to convert result to map: {}", e.getMessage());
        }
        return map;
    }

    /**
     * Get all collected results for a job.
     */
    public List<Map<String, Object>> getCollectedResults(String jobId) {
        List<Map<String, Object>> results = jobResults.get(jobId);
        return results != null ? new ArrayList<>(results) : new ArrayList<>();
    }

    /**
     * Get the count of collected results for a job.
     */
    public int getCollectedResultCount(String jobId) {
        List<Map<String, Object>> results = jobResults.get(jobId);
        return results != null ? results.size() : 0;
    }

    /**
     * Publish an AI chunk event.
     */
    public void publishAiChunk(String jobId, String chunk) {
        Sinks.Many<ServerSentEvent<Object>> sink = jobSinks.get(jobId);
        if (sink == null) return;

        ServerSentEvent<Object> event = ServerSentEvent.builder()
                .event("ai_chunk")
                .data(Map.of(
                        "jobId", jobId,
                        "eventType", "ai_chunk",
                        "source", "ai",
                        "message", chunk,
                        "timestamp", System.currentTimeMillis()
                ))
                .build();

        sink.tryEmitNext(event);
    }

    /**
     * Publish a source complete event.
     */
    public void publishSourceComplete(String jobId, String source, String message, int totalCount) {
        Sinks.Many<ServerSentEvent<Object>> sink = jobSinks.get(jobId);
        if (sink == null) return;

        ServerSentEvent<Object> event = ServerSentEvent.builder()
                .event("source_complete")
                .data(Map.of(
                        "jobId", jobId,
                        "eventType", "complete",
                        "source", source,
                        "message", message != null ? message : "",
                        "totalCount", totalCount,
                        "timestamp", System.currentTimeMillis()
                ))
                .build();

        sink.tryEmitNext(event);
        log.debug("Published source complete event for job: {}, source: {}, count: {}", jobId, source, totalCount);
    }

    /**
     * Publish an error event for a source.
     */
    public void publishSourceError(String jobId, String source, String errorMessage) {
        Sinks.Many<ServerSentEvent<Object>> sink = jobSinks.get(jobId);
        if (sink == null) return;

        ServerSentEvent<Object> event = ServerSentEvent.builder()
                .event("source_error")
                .data(Map.of(
                        "jobId", jobId,
                        "eventType", "error",
                        "source", source,
                        "message", errorMessage,
                        "timestamp", System.currentTimeMillis()
                ))
                .build();

        sink.tryEmitNext(event);
        log.warn("Published source error event for job: {}, source: {}, error: {}", jobId, source, errorMessage);
    }

    /**
     * Publish a job completion event (all sources done).
     */
    public void publishJobComplete(String jobId, int totalResults) {
        updateJobStatus(jobId, "COMPLETED");
        
        Sinks.Many<ServerSentEvent<Object>> sink = jobSinks.get(jobId);
        if (sink == null) return;

        ServerSentEvent<Object> event = ServerSentEvent.builder()
                .event("done")
                .data(Map.of(
                        "jobId", jobId,
                        "totalResults", totalResults,
                        "message", "Search completed",
                        "timestamp", System.currentTimeMillis()
                ))
                .build();

        sink.tryEmitNext(event);
        log.info("Published job complete event for job: {}, total results: {}", jobId, totalResults);

        // Complete the sink and schedule cleanup
        sink.tryEmitComplete();
        scheduleCleanup(jobId);
    }

    /**
     * Publish a job error event.
     */
    public void publishJobError(String jobId, String errorMessage) {
        updateJobStatus(jobId, "FAILED");
        
        Sinks.Many<ServerSentEvent<Object>> sink = jobSinks.get(jobId);
        if (sink == null) return;

        ServerSentEvent<Object> event = ServerSentEvent.builder()
                .event("job_error")
                .data(Map.of(
                        "jobId", jobId,
                        "error", errorMessage,
                        "timestamp", System.currentTimeMillis()
                ))
                .build();

        sink.tryEmitNext(event);
        log.error("Published job error event for job: {}, error: {}", jobId, errorMessage);

        sink.tryEmitComplete();
        scheduleCleanup(jobId);
    }

    /**
     * Schedule cleanup of a job's sink after a delay.
     */
    private void scheduleCleanup(String jobId) {
        Thread.startVirtualThread(() -> {
            try {
                Thread.sleep(Duration.ofMinutes(10)); // Keep completed jobs for 10 minutes
                jobSinks.remove(jobId);
                jobMetadataMap.remove(jobId);
                jobResults.remove(jobId); // Also clean up collected results
                log.debug("Cleaned up sink, metadata, and results for job: {}", jobId);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
        });
    }

    /**
     * Remove a job's sink immediately.
     */
    public void removeSink(String jobId) {
        Sinks.Many<ServerSentEvent<Object>> sink = jobSinks.remove(jobId);
        if (sink != null) {
            sink.tryEmitComplete();
            log.debug("Removed sink for job: {}", jobId);
        }
        jobMetadataMap.remove(jobId);
        jobResults.remove(jobId);
    }

    /**
     * Check if a job exists.
     */
    public boolean hasJob(String jobId) {
        return jobMetadataMap.containsKey(jobId);
    }

    /**
     * Get the number of active jobs.
     */
    public int getActiveJobCount() {
        return jobSinks.size();
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/UnifiedSearchService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.dto.SearchHistoryMessage;
import com.newsinsight.collector.client.Crawl4aiClient;
import com.newsinsight.collector.client.PerplexityClient;
import com.newsinsight.collector.client.OpenAICompatibleClient;
import com.newsinsight.collector.client.AIDoveClient;
import com.newsinsight.collector.dto.ArticleDto;
import com.newsinsight.collector.dto.ArticleWithAnalysisDto;
import com.newsinsight.collector.entity.CollectedData;
import com.newsinsight.collector.entity.DataSource;
import com.newsinsight.collector.entity.analysis.ArticleAnalysis;
import com.newsinsight.collector.entity.analysis.ArticleDiscussion;
import com.newsinsight.collector.entity.search.SearchType;
import com.newsinsight.collector.repository.ArticleAnalysisRepository;
import com.newsinsight.collector.repository.ArticleDiscussionRepository;
import com.newsinsight.collector.repository.CollectedDataRepository;
import com.newsinsight.collector.repository.DataSourceRepository;
import com.newsinsight.collector.service.autocrawl.AutoCrawlIntegrationService;
import com.newsinsight.collector.service.search.AdvancedIntentAnalyzer;
import com.newsinsight.collector.service.search.AdvancedIntentAnalyzer.AnalyzedQuery;
import com.newsinsight.collector.service.search.AdvancedIntentAnalyzer.FallbackStrategy;
import com.newsinsight.collector.service.search.HybridSearchService;
import com.newsinsight.collector.service.search.HybridRankingService.RankedResult;
import lombok.Builder;
import lombok.Data;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.jsoup.Jsoup;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.PageRequest;
import org.springframework.data.domain.Sort;
import org.springframework.scheduling.annotation.Async;
import org.springframework.stereotype.Service;
import reactor.core.publisher.Flux;
import reactor.core.publisher.Mono;
import reactor.core.scheduler.Schedulers;

import java.net.URLEncoder;
import java.nio.charset.StandardCharsets;
import java.time.Duration;
import java.time.LocalDateTime;
import java.time.format.DateTimeFormatter;
import java.time.format.DateTimeParseException;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.UUID;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.function.Function;
import java.util.stream.Collectors;

/**
 * Unified Search Service - 병렬 검색 통합 서비스
 * 
 * DB, 웹 크롤링, AI 검색을 병렬로 실행하고 결과가 나오는 대로 스트리밍합니다.
 * 특정 기술/API 이름을 노출하지 않고 통합된 검색 경험을 제공합니다.
 * 
 * AutoCrawl Integration: 검색 결과에서 발견된 URL을 자동 크롤링 큐에 추가합니다.
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class UnifiedSearchService {

    private final CollectedDataRepository collectedDataRepository;
    private final DataSourceRepository dataSourceRepository;
    private final ArticleAnalysisRepository articleAnalysisRepository;
    private final ArticleDiscussionRepository articleDiscussionRepository;
    private final PerplexityClient perplexityClient;
    private final OpenAICompatibleClient openAICompatibleClient;
    private final AIDoveClient aiDoveClient;
    private final Crawl4aiClient crawl4aiClient;
    private final CrawlSearchService crawlSearchService;
    private final UnifiedSearchEventService unifiedSearchEventService;
    private final HybridSearchService hybridSearchService;
    private final AutoCrawlIntegrationService autoCrawlIntegrationService;
    private final SearchHistoryService searchHistoryService;
    private final AdvancedIntentAnalyzer advancedIntentAnalyzer;
    private final SearchCacheService searchCacheService;

    @Value("${autocrawl.enabled:true}")
    private boolean autoCrawlEnabled;

    @Value("${search.fallback.max-attempts:3}")
    private int maxFallbackAttempts;

    private static final int SNIPPET_MAX_LENGTH = 200;
    private static final int MAX_DB_RESULTS = 20;
    
    // Deduplication settings
    private static final double TITLE_SIMILARITY_THRESHOLD = 0.85;
    private static final double CONTENT_SIMILARITY_THRESHOLD = 0.90;

    private static final String AI_SUMMARY_KEY_CONTENT = "content";
    private static final String AI_SUMMARY_KEY_SUMMARY = "summary";
    private static final String AI_SUMMARY_KEY_GENERATED_AT = "generatedAt";
    
    // Thread-safe deduplication tracker for streaming results
    private final java.util.concurrent.ConcurrentHashMap<String, SearchResult> seenResults = 
            new java.util.concurrent.ConcurrentHashMap<>();

    // ============================================
    // DTO Classes
    // ============================================

    @Data
    @Builder
    public static class SearchResult {
        private String id;
        private String source;          // "database", "web", "ai"
        private String sourceLabel;     // 사용자에게 보여줄 출처명
        private String title;
        private String snippet;         // UI 표시용 요약 (200자)
        private String content;         // 전체 본문 (export/저장용)
        private String url;
        private String publishedAt;
        private Double relevanceScore;
        private String category;        // 주제 분류
        
        // ========== 분석 결과 (optional) ==========
        private Boolean analyzed;           // 분석 완료 여부
        private String analysisStatus;      // pending, partial, complete
        
        // 신뢰도
        private Double reliabilityScore;    // 0-100
        private String reliabilityGrade;    // high, medium, low
        private String reliabilityColor;    // green, yellow, red
        
        // 감정 분석
        private String sentimentLabel;      // positive, negative, neutral
        private Double sentimentScore;      // -1 ~ 1
        
        // 편향도
        private String biasLabel;           // left, right, center
        private Double biasScore;           // -1 ~ 1
        
        // 팩트체크
        private String factcheckStatus;     // verified, suspicious, unverified
        private String misinfoRisk;         // low, mid, high
        
        // 위험 태그
        private List<String> riskTags;
        
        // 토픽
        private List<String> topics;
        
        // 여론 정보
        private Boolean hasDiscussion;
        private Integer totalCommentCount;
        private String discussionSentiment;
    }

    @Data
    @Builder
    public static class SearchEvent {
        private String eventType;       // "status", "result", "complete", "error"
        private String source;          // 어느 소스에서 온 이벤트인지
        private String message;         // 상태 메시지
        private SearchResult result;    // 검색 결과 (result 타입일 때)
        private Integer totalCount;     // 총 결과 수 (complete 타입일 때)
    }

    @Data
    @Builder
    public static class AISummary {
        private String summary;
        private List<String> keyPoints;
        private String sentiment;
    }

    // ============================================
    // Deduplication Methods
    // ============================================
    
    /**
     * URL 정규화 - 쿼리 파라미터 제거, 프로토콜 통일
     */
    private String normalizeUrl(String url) {
        if (url == null || url.isBlank()) {
            return "";
        }
        try {
            // Remove protocol, www, trailing slash, query params, and fragments
            String normalized = url.toLowerCase()
                    .replaceFirst("^https?://", "")
                    .replaceFirst("^www\\.", "")
                    .replaceAll("\\?.*$", "")
                    .replaceAll("#.*$", "")
                    .replaceAll("/$", "");
            return normalized;
        } catch (Exception e) {
            return url.toLowerCase();
        }
    }
    
    /**
     * 제목 유사도 계산 (Jaccard similarity)
     */
    private double calculateTitleSimilarity(String title1, String title2) {
        if (title1 == null || title2 == null) {
            return 0.0;
        }
        
        // 간단한 토큰화 및 정규화
        java.util.Set<String> tokens1 = java.util.Arrays.stream(
                title1.toLowerCase().replaceAll("[^가-힣a-z0-9\\s]", " ").split("\\s+"))
                .filter(s -> s.length() >= 2)
                .collect(Collectors.toSet());
        
        java.util.Set<String> tokens2 = java.util.Arrays.stream(
                title2.toLowerCase().replaceAll("[^가-힣a-z0-9\\s]", " ").split("\\s+"))
                .filter(s -> s.length() >= 2)
                .collect(Collectors.toSet());
        
        if (tokens1.isEmpty() || tokens2.isEmpty()) {
            return 0.0;
        }
        
        // Jaccard similarity
        java.util.Set<String> intersection = new java.util.HashSet<>(tokens1);
        intersection.retainAll(tokens2);
        
        java.util.Set<String> union = new java.util.HashSet<>(tokens1);
        union.addAll(tokens2);
        
        return (double) intersection.size() / union.size();
    }
    
    /**
     * 중복 검사 - URL 기반 + 제목 유사도 기반
     */
    private boolean isDuplicate(SearchResult newResult, Map<String, SearchResult> existingResults) {
        // 1. URL 기반 중복 체크 (정확한 매칭)
        String normalizedUrl = normalizeUrl(newResult.getUrl());
        if (!normalizedUrl.isEmpty()) {
            for (SearchResult existing : existingResults.values()) {
                if (normalizedUrl.equals(normalizeUrl(existing.getUrl()))) {
                    log.debug("Duplicate detected by URL: {}", normalizedUrl);
                    return true;
                }
            }
        }
        
        // 2. 제목 유사도 기반 중복 체크 (유사한 기사 필터링)
        String newTitle = newResult.getTitle();
        if (newTitle != null && !newTitle.isBlank()) {
            for (SearchResult existing : existingResults.values()) {
                double similarity = calculateTitleSimilarity(newTitle, existing.getTitle());
                if (similarity >= TITLE_SIMILARITY_THRESHOLD) {
                    log.debug("Duplicate detected by title similarity ({:.2f}): '{}' ~ '{}'", 
                            similarity, newTitle, existing.getTitle());
                    return true;
                }
            }
        }
        
        return false;
    }
    
    /**
     * 검색 세션용 중복 제거 트래커 초기화
     */
    private Map<String, SearchResult> createDeduplicationTracker() {
        return new java.util.concurrent.ConcurrentHashMap<>();
    }
    
    /**
     * 중복이 아닌 경우에만 결과 추가하고 true 반환
     */
    private boolean addIfNotDuplicate(SearchResult result, Map<String, SearchResult> tracker) {
        if (isDuplicate(result, tracker)) {
            return false;
        }
        
        // 결과 ID 또는 URL을 키로 사용
        String key = result.getId() != null ? result.getId() : 
                    (result.getUrl() != null ? normalizeUrl(result.getUrl()) : 
                    String.valueOf(System.nanoTime()));
        tracker.put(key, result);
        return true;
    }

    // ============================================
    // Main Search Method - Parallel Execution
    // ============================================

    /**
     * 병렬 통합 검색 - 모든 소스에서 동시에 검색하고 결과를 스트리밍
     *
     * @param query 검색 쿼리
     * @param window 시간 범위 (1d, 7d, 30d)
     * @return 검색 이벤트 스트림
     */
    public Flux<SearchEvent> searchParallel(String query, String window) {
        if (query == null || query.isBlank()) {
            return Flux.just(SearchEvent.builder()
                    .eventType("error")
                    .message("검색어를 입력해주세요.")
                    .build());
        }

        log.info("Starting parallel search for query: '{}', window: {}", query, window);

        // Advanced Intent Analysis
        AnalyzedQuery analyzedQuery = advancedIntentAnalyzer.analyzeQuery(query);
        log.info("Query analyzed: keywords={}, primary='{}', intent={}, confidence={}, strategies={}",
                analyzedQuery.getKeywords().size(),
                analyzedQuery.getPrimaryKeyword(),
                analyzedQuery.getIntentType(),
                analyzedQuery.getConfidence(),
                analyzedQuery.getFallbackStrategies().size());

        // Collect discovered URLs for AutoCrawl integration
        List<String> discoveredUrls = new ArrayList<>();
        
        // Deduplication tracker for this search session
        Map<String, SearchResult> deduplicationTracker = createDeduplicationTracker();
        java.util.concurrent.atomic.AtomicInteger duplicateCount = new java.util.concurrent.atomic.AtomicInteger(0);

        return Flux.merge(
                // 1. 데이터베이스 검색 (가장 빠름)
                searchDatabase(query, window)
                        .subscribeOn(Schedulers.boundedElastic()),

                // 2. 웹 크롤링 검색
                searchWeb(query, window)
                        .subscribeOn(Schedulers.boundedElastic()),

                // 3. AI 기반 실시간 분석
                searchAI(query, window)
                        .subscribeOn(Schedulers.boundedElastic())
        )
        // Filter duplicates before emitting results
        .filter(event -> {
            if (!"result".equals(event.getEventType()) || event.getResult() == null) {
                return true; // Pass through non-result events
            }
            
            SearchResult result = event.getResult();
            if (addIfNotDuplicate(result, deduplicationTracker)) {
                return true; // Unique result, pass through
            } else {
                duplicateCount.incrementAndGet();
                log.debug("Filtered duplicate result: '{}' from {}", 
                        result.getTitle(), result.getSource());
                return false; // Duplicate, filter out
            }
        })
        .doOnNext(event -> {
            // Collect URLs from search results for AutoCrawl
            if ("result".equals(event.getEventType()) && event.getResult() != null 
                    && event.getResult().getUrl() != null) {
                synchronized (discoveredUrls) {
                    discoveredUrls.add(event.getResult().getUrl());
                }
            }
        })
        .doOnComplete(() -> {
            log.info("Parallel search completed for query: '{}', discovered {} URLs, filtered {} duplicates", 
                    query, discoveredUrls.size(), duplicateCount.get());
            
            // Notify AutoCrawl of discovered URLs
            if (autoCrawlEnabled && !discoveredUrls.isEmpty()) {
                autoCrawlIntegrationService.onSearchCompleted(query, discoveredUrls);
            }
        })
        .doOnError(e -> log.error("Parallel search error for query '{}': {}", query, e.getMessage()));
    }

    /**
     * 결과 보장 검색 - 폴백 전략을 사용하여 최소 결과 보장
     * Intent analysis를 사용하여 더 높은 확률로 의도에 맞는 결과 반환
     *
     * @param query 검색 쿼리
     * @param window 시간 범위
     * @return 검색 이벤트 스트림 (결과 보장)
     */
    public Flux<SearchEvent> searchWithGuaranteedResults(String query, String window) {
        if (query == null || query.isBlank()) {
            return Flux.just(SearchEvent.builder()
                    .eventType("error")
                    .message("검색어를 입력해주세요.")
                    .build());
        }

        // Advanced Intent Analysis
        AnalyzedQuery analyzedQuery = advancedIntentAnalyzer.analyzeQuery(query);
        
        return searchWithFallback(analyzedQuery, window, 0, new ArrayList<>());
    }

    /**
     * 폴백 전략을 사용한 검색 (재귀적)
     */
    private Flux<SearchEvent> searchWithFallback(
            AnalyzedQuery analyzedQuery, 
            String window, 
            int attemptIndex,
            List<SearchResult> accumulatedResults) {

        String currentQuery = attemptIndex == 0 
                ? analyzedQuery.getOriginalQuery()
                : analyzedQuery.getFallbackStrategies().size() > attemptIndex - 1
                        ? analyzedQuery.getFallbackStrategies().get(attemptIndex - 1).getQuery()
                        : analyzedQuery.getPrimaryKeyword();

        String strategyDescription = attemptIndex == 0 
                ? "원본 쿼리"
                : attemptIndex <= analyzedQuery.getFallbackStrategies().size()
                        ? analyzedQuery.getFallbackStrategies().get(attemptIndex - 1).getDescription()
                        : "주요 키워드";

        log.info("Search attempt {}/{}: query='{}', strategy='{}'", 
                attemptIndex + 1, maxFallbackAttempts, currentQuery, strategyDescription);

        return Flux.create(sink -> {
            // 현재 시도에 대한 상태 이벤트
            sink.next(SearchEvent.builder()
                    .eventType("status")
                    .source("system")
                    .message("검색 전략 " + (attemptIndex + 1) + ": " + strategyDescription)
                    .build());

            // DB 검색 실행
            List<SearchResult> currentResults = new ArrayList<>();
            
            searchDatabaseSync(currentQuery, window).forEach(result -> {
                currentResults.add(result);
                sink.next(SearchEvent.builder()
                        .eventType("result")
                        .source("database")
                        .result(result)
                        .build());
            });

            // 결과 누적
            accumulatedResults.addAll(currentResults);

            // 충분한 결과가 있거나 최대 시도 횟수에 도달한 경우
            if (accumulatedResults.size() >= 5 || attemptIndex >= maxFallbackAttempts - 1) {
                // 검색 완료
                if (accumulatedResults.isEmpty()) {
                    // 결과가 없을 때 도움말 메시지 생성
                    String noResultMessage = advancedIntentAnalyzer.buildNoResultMessage(analyzedQuery);
                    sink.next(SearchEvent.builder()
                            .eventType("no_result_help")
                            .source("system")
                            .message(noResultMessage)
                            .build());
                }

                sink.next(SearchEvent.builder()
                        .eventType("complete")
                        .source("system")
                        .message("검색 완료 (시도: " + (attemptIndex + 1) + ", 결과: " + accumulatedResults.size() + ")")
                        .totalCount(accumulatedResults.size())
                        .build());

                sink.complete();
            } else if (currentResults.isEmpty() || currentResults.size() < 3) {
                // 결과가 부족하면 다음 폴백 전략 시도
                sink.next(SearchEvent.builder()
                        .eventType("status")
                        .source("system")
                        .message("결과가 부족합니다. 다음 전략을 시도합니다...")
                        .build());

                // 재귀적으로 다음 폴백 시도
                searchWithFallback(analyzedQuery, window, attemptIndex + 1, accumulatedResults)
                        .subscribe(
                                sink::next,
                                sink::error,
                                sink::complete
                        );
            } else {
                sink.next(SearchEvent.builder()
                        .eventType("complete")
                        .source("system")
                        .message("검색 완료")
                        .totalCount(accumulatedResults.size())
                        .build());
                sink.complete();
            }
        });
    }

    /**
     * 동기식 데이터베이스 검색 (폴백용) - with caching
     */
    private List<SearchResult> searchDatabaseSync(String query, String window) {
        // Check cache first
        var cachedResults = searchCacheService.getDbSearchResults(query, window, SearchResult.class);
        if (cachedResults.isPresent()) {
            log.debug("Returning cached DB search results for query: '{}'", query);
            return cachedResults.get();
        }
        
        List<SearchResult> results = new ArrayList<>();
        
        try {
            LocalDateTime since = calculateSinceDate(window);
            PageRequest pageRequest = PageRequest.of(0, MAX_DB_RESULTS,
                    Sort.by(Sort.Direction.DESC, "publishedDate")
                            .and(Sort.by(Sort.Direction.DESC, "collectedAt")));

            Page<CollectedData> page = collectedDataRepository.searchByQueryAndSince(query, since, pageRequest);

            List<Long> articleIds = page.getContent().stream()
                    .map(CollectedData::getId)
                    .filter(id -> id != null)
                    .toList();

            Map<Long, ArticleAnalysis> analysisMap = articleIds.isEmpty()
                    ? Map.of()
                    : articleAnalysisRepository.findByArticleIdIn(articleIds).stream()
                            .collect(Collectors.toMap(ArticleAnalysis::getArticleId, Function.identity()));

            Map<Long, ArticleDiscussion> discussionMap = articleIds.isEmpty()
                    ? Map.of()
                    : articleDiscussionRepository.findByArticleIdIn(articleIds).stream()
                            .collect(Collectors.toMap(ArticleDiscussion::getArticleId, Function.identity()));

            for (CollectedData data : page.getContent()) {
                ArticleAnalysis analysis = data.getId() != null ? analysisMap.get(data.getId()) : null;
                ArticleDiscussion discussion = data.getId() != null ? discussionMap.get(data.getId()) : null;
                results.add(convertToSearchResult(data, analysis, discussion));
            }
            
            // Cache the results
            if (!results.isEmpty()) {
                searchCacheService.cacheDbSearchResults(query, window, results);
            }
        } catch (Exception e) {
            log.error("Database sync search failed: {}", e.getMessage());
        }

        return results;
    }

    // ============================================
    // Database Search (with Hybrid Search integration)
    // ============================================

    private Flux<SearchEvent> searchDatabase(String query, String window) {
        // Use hybrid search if available, otherwise fall back to keyword-only search
        if (hybridSearchService.isEnabled() && hybridSearchService.isSemanticSearchAvailable()) {
            return searchDatabaseHybrid(query, window);
        }
        return searchDatabaseKeywordOnly(query, window);
    }

    /**
     * Hybrid search: combines keyword + semantic search with RRF ranking
     */
    private Flux<SearchEvent> searchDatabaseHybrid(String query, String window) {
        return Flux.create(sink -> {
            try {
                sink.next(SearchEvent.builder()
                        .eventType("status")
                        .source("database")
                        .message("하이브리드 검색 중 (키워드 + 시맨틱)...")
                        .build());

                hybridSearchService.search(query, window)
                        .subscribe(
                                hybridResult -> {
                                    log.info("Hybrid search completed: keyword={}, semantic={}, total={}",
                                            hybridResult.getKeywordResultCount(),
                                            hybridResult.getSemanticResultCount(),
                                            hybridResult.getTotalResultCount());

                                    // Batch load analysis data for hybrid results
                                    List<Long> articleIds = hybridResult.getResults().stream()
                                            .map(r -> {
                                                try {
                                                    return Long.parseLong(r.getId());
                                                } catch (NumberFormatException e) {
                                                    return null;
                                                }
                                            })
                                            .filter(id -> id != null)
                                            .toList();

                                    Map<Long, ArticleAnalysis> analysisMap = articleIds.isEmpty()
                                            ? Map.of()
                                            : articleAnalysisRepository.findByArticleIdIn(articleIds).stream()
                                                    .collect(Collectors.toMap(ArticleAnalysis::getArticleId, Function.identity()));

                                    Map<Long, ArticleDiscussion> discussionMap = articleIds.isEmpty()
                                            ? Map.of()
                                            : articleDiscussionRepository.findByArticleIdIn(articleIds).stream()
                                                    .collect(Collectors.toMap(ArticleDiscussion::getArticleId, Function.identity()));

                                    int count = 0;
                                    for (RankedResult rankedResult : hybridResult.getResults()) {
                                        Long articleId = null;
                                        try {
                                            articleId = Long.parseLong(rankedResult.getId());
                                        } catch (NumberFormatException ignored) {}

                                        ArticleAnalysis analysis = articleId != null ? analysisMap.get(articleId) : null;
                                        ArticleDiscussion discussion = articleId != null ? discussionMap.get(articleId) : null;

                                        SearchResult result = convertRankedResultToSearchResult(rankedResult, analysis, discussion);
                                        sink.next(SearchEvent.builder()
                                                .eventType("result")
                                                .source("database")
                                                .result(result)
                                                .build());
                                        count++;
                                    }

                                    // Include search metadata in complete message
                                    String message = String.format("하이브리드 검색 완료 (키워드: %d, 시맨틱: %d, RRF 융합: %d, %dms)",
                                            hybridResult.getKeywordResultCount(),
                                            hybridResult.getSemanticResultCount(),
                                            hybridResult.getTotalResultCount(),
                                            hybridResult.getSearchTimeMs());

                                    sink.next(SearchEvent.builder()
                                            .eventType("complete")
                                            .source("database")
                                            .message(message)
                                            .totalCount(count)
                                            .build());

                                    sink.complete();
                                },
                                error -> {
                                    log.error("Hybrid search failed, falling back to keyword search: {}", error.getMessage());
                                    // Fall back to keyword-only search on error
                                    searchDatabaseKeywordOnly(query, window)
                                            .subscribe(sink::next, sink::error, sink::complete);
                                }
                        );
            } catch (Exception e) {
                log.error("Hybrid search initialization failed: {}", e.getMessage());
                // Fall back to keyword-only search
                searchDatabaseKeywordOnly(query, window)
                        .subscribe(sink::next, sink::error, sink::complete);
            }
        });
    }

    /**
     * Keyword-only search (original implementation)
     */
    private Flux<SearchEvent> searchDatabaseKeywordOnly(String query, String window) {
        return Flux.create(sink -> {
            try {
                sink.next(SearchEvent.builder()
                        .eventType("status")
                        .source("database")
                        .message("저장된 뉴스에서 검색 중...")
                        .build());

                LocalDateTime since = calculateSinceDate(window);
                PageRequest pageRequest = PageRequest.of(0, MAX_DB_RESULTS,
                        Sort.by(Sort.Direction.DESC, "publishedDate")
                                .and(Sort.by(Sort.Direction.DESC, "collectedAt")));

                Page<CollectedData> page = collectedDataRepository.searchByQueryAndSince(
                        query, since, pageRequest);

                // 분석 결과 일괄 조회 (N+1 방지)
                List<Long> articleIds = page.getContent().stream()
                        .map(CollectedData::getId)
                        .filter(id -> id != null)
                        .toList();
                
                Map<Long, ArticleAnalysis> analysisMap = articleIds.isEmpty() 
                        ? Map.of()
                        : articleAnalysisRepository.findByArticleIdIn(articleIds).stream()
                                .collect(Collectors.toMap(ArticleAnalysis::getArticleId, Function.identity()));
                
                Map<Long, ArticleDiscussion> discussionMap = articleIds.isEmpty()
                        ? Map.of()
                        : articleDiscussionRepository.findByArticleIdIn(articleIds).stream()
                                .collect(Collectors.toMap(ArticleDiscussion::getArticleId, Function.identity()));

                int count = 0;
                for (CollectedData data : page.getContent()) {
                    ArticleAnalysis analysis = data.getId() != null ? analysisMap.get(data.getId()) : null;
                    ArticleDiscussion discussion = data.getId() != null ? discussionMap.get(data.getId()) : null;
                    
                    SearchResult result = convertToSearchResult(data, analysis, discussion);
                    sink.next(SearchEvent.builder()
                            .eventType("result")
                            .source("database")
                            .result(result)
                            .build());
                    count++;
                }

                sink.next(SearchEvent.builder()
                        .eventType("complete")
                        .source("database")
                        .message("저장된 뉴스 검색 완료")
                        .totalCount(count)
                        .build());

                sink.complete();
            } catch (Exception e) {
                log.error("Database search failed: {}", e.getMessage());
                sink.next(SearchEvent.builder()
                        .eventType("error")
                        .source("database")
                        .message("데이터베이스 검색 오류: " + e.getMessage())
                        .build());
                sink.complete();
            }
        });
    }

    private SearchResult convertToSearchResult(CollectedData data, ArticleAnalysis analysis, ArticleDiscussion discussion) {
        DataSource source = data.getSourceId() != null
                ? dataSourceRepository.findById(data.getSourceId()).orElse(null)
                : null;
        String sourceName = source != null ? source.getName() : "뉴스";

        String publishedAt = data.getPublishedDate() != null
                ? data.getPublishedDate().toString()
                : (data.getCollectedAt() != null ? data.getCollectedAt().toString() : null);

        // 원본 콘텐츠를 보존하면서 정제된 텍스트 생성
        String rawContent = data.getContent();
        String cleanedContent = cleanContent(rawContent);
        
        // snippet은 정제된 콘텐츠에서 생성하되, content는 정제된 전체 텍스트 사용
        SearchResult.SearchResultBuilder builder = SearchResult.builder()
                .id(data.getId() != null ? data.getId().toString() : UUID.randomUUID().toString())
                .source("database")
                .sourceLabel(sourceName)
                .title(data.getTitle())
                .snippet(buildSnippetFromCleanText(cleanedContent))
                .content(cleanedContent)  // HTML 제거된 전체 본문 (원본 텍스트 보존)
                .url(data.getUrl())
                .publishedAt(publishedAt)
                .relevanceScore(data.getQualityScore());
        
        // 분석 결과 추가
        if (analysis != null) {
            builder.analyzed(true)
                    .analysisStatus(analysis.getFullyAnalyzed() != null && analysis.getFullyAnalyzed() 
                            ? "complete" : "partial")
                    .reliabilityScore(analysis.getReliabilityScore())
                    .reliabilityGrade(analysis.getReliabilityGrade())
                    .reliabilityColor(analysis.getReliabilityColor())
                    .sentimentLabel(analysis.getSentimentLabel())
                    .sentimentScore(analysis.getSentimentScore())
                    .biasLabel(analysis.getBiasLabel())
                    .biasScore(analysis.getBiasScore())
                    .factcheckStatus(analysis.getFactcheckStatus())
                    .misinfoRisk(analysis.getMisinfoRisk())
                    .riskTags(analysis.getRiskTags())
                    .topics(analysis.getTopics());
        } else {
            builder.analyzed(false)
                    .analysisStatus("pending");
        }
        
        // 여론 분석 결과 추가
        if (discussion != null) {
            builder.hasDiscussion(true)
                    .totalCommentCount(discussion.getTotalCommentCount())
                    .discussionSentiment(discussion.getOverallSentiment());
        } else {
            builder.hasDiscussion(false);
        }
        
        return builder.build();
    }

    /**
     * Convert RankedResult from hybrid search to SearchResult
     */
    private SearchResult convertRankedResultToSearchResult(RankedResult rankedResult, ArticleAnalysis analysis, ArticleDiscussion discussion) {
        // Determine source label based on the sources that found this result
        String sourceLabel = "뉴스";
        if (rankedResult.getSources() != null && !rankedResult.getSources().isEmpty()) {
            if (rankedResult.getSources().contains("semantic") && rankedResult.getSources().contains("keyword")) {
                sourceLabel = "하이브리드 검색";
            } else if (rankedResult.getSources().contains("semantic")) {
                sourceLabel = "시맨틱 검색";
            } else if (rankedResult.getSources().contains("keyword")) {
                sourceLabel = "키워드 검색";
            }
        }

        SearchResult.SearchResultBuilder builder = SearchResult.builder()
                .id(rankedResult.getId())
                .source("database")
                .sourceLabel(sourceLabel)
                .title(rankedResult.getTitle())
                .snippet(rankedResult.getSnippet())
                .content(rankedResult.getContent())
                .url(rankedResult.getUrl())
                .publishedAt(rankedResult.getPublishedAt())
                .relevanceScore(rankedResult.getRrfScore());  // Use RRF score as relevance

        // 분석 결과 추가
        if (analysis != null) {
            builder.analyzed(true)
                    .analysisStatus(analysis.getFullyAnalyzed() != null && analysis.getFullyAnalyzed()
                            ? "complete" : "partial")
                    .reliabilityScore(analysis.getReliabilityScore())
                    .reliabilityGrade(analysis.getReliabilityGrade())
                    .reliabilityColor(analysis.getReliabilityColor())
                    .sentimentLabel(analysis.getSentimentLabel())
                    .sentimentScore(analysis.getSentimentScore())
                    .biasLabel(analysis.getBiasLabel())
                    .biasScore(analysis.getBiasScore())
                    .factcheckStatus(analysis.getFactcheckStatus())
                    .misinfoRisk(analysis.getMisinfoRisk())
                    .riskTags(analysis.getRiskTags())
                    .topics(analysis.getTopics());
        } else {
            builder.analyzed(false)
                    .analysisStatus("pending");
        }

        // 여론 분석 결과 추가
        if (discussion != null) {
            builder.hasDiscussion(true)
                    .totalCommentCount(discussion.getTotalCommentCount())
                    .discussionSentiment(discussion.getOverallSentiment());
        } else {
            builder.hasDiscussion(false);
        }

        return builder.build();
    }

    // ============================================
    // Web Crawling Search
    // ============================================

    private Flux<SearchEvent> searchWeb(String query, String window) {
        return Flux.create(sink -> {
            try {
                sink.next(SearchEvent.builder()
                        .eventType("status")
                        .source("web")
                        .message("웹에서 최신 정보 수집 중...")
                        .build());

                List<String> searchUrls = generateSearchUrls(query, window);
                int successCount = 0;

                for (String url : searchUrls) {
                    try {
                        Crawl4aiClient.CrawlResult crawlResult = crawl4aiClient.crawl(url);
                        if (crawlResult != null && crawlResult.getContent() != null) {
                            String rawContent = crawlResult.getContent();
                            String fullContent = cleanContent(rawContent);  // 전체 본문 정제
                            
                            SearchResult result = SearchResult.builder()
                                    .id(UUID.randomUUID().toString())
                                    .source("web")
                                    .sourceLabel("웹 검색")
                                    .title(crawlResult.getTitle() != null ? crawlResult.getTitle() : extractTitleFromUrl(url))
                                    .snippet(buildSnippet(rawContent))
                                    .content(fullContent)  // 전체 본문 보존
                                    .url(url)
                                    .build();

                            sink.next(SearchEvent.builder()
                                    .eventType("result")
                                    .source("web")
                                    .result(result)
                                    .build());
                            successCount++;
                        }
                    } catch (Exception e) {
                        log.debug("Failed to crawl URL {}: {}", url, e.getMessage());
                    }
                }

                sink.next(SearchEvent.builder()
                        .eventType("complete")
                        .source("web")
                        .message("웹 검색 완료")
                        .totalCount(successCount)
                        .build());

                sink.complete();
            } catch (Exception e) {
                log.error("Web search failed: {}", e.getMessage());
                sink.next(SearchEvent.builder()
                        .eventType("error")
                        .source("web")
                        .message("웹 검색 오류")
                        .build());
                sink.complete();
            }
        });
    }

    private List<String> generateSearchUrls(String query, String window) {
        List<String> urls = new ArrayList<>();
        String encodedQuery = URLEncoder.encode(query, StandardCharsets.UTF_8);

        // 1. 먼저 DB에서 활성화된 웹 검색 소스를 조회
        List<DataSource> webSearchSources = dataSourceRepository.findActiveWebSearchSources();
        
        if (!webSearchSources.isEmpty()) {
            log.info("Found {} active web search sources from database", webSearchSources.size());
            for (DataSource source : webSearchSources) {
                String searchUrl = source.buildSearchUrl(encodedQuery);
                if (searchUrl != null) {
                    urls.add(searchUrl);
                    log.debug("Added search URL from source '{}': {}", source.getName(), searchUrl);
                }
            }
        }
        
        // 2. DB에 등록된 소스가 없으면 기본 포털 사용 (폴백)
        if (urls.isEmpty()) {
            log.info("No web search sources in database, using default portals");
            
            // 네이버 뉴스
            urls.add("https://search.naver.com/search.naver?where=news&query=" + encodedQuery);

            // 다음 뉴스
            urls.add("https://search.daum.net/search?w=news&q=" + encodedQuery);

            // 구글 뉴스 (한국)
            urls.add("https://news.google.com/search?q=" + encodedQuery + "&hl=ko&gl=KR");
        }

        log.info("Generated {} search URLs for query: '{}'", urls.size(), query);
        return urls;
    }

    private String extractTitleFromUrl(String url) {
        if (url.contains("naver")) return "네이버 뉴스";
        if (url.contains("daum")) return "다음 뉴스";
        if (url.contains("google")) return "구글 뉴스";
        return "웹 검색 결과";
    }

    // ============================================
    // AI-Powered Search with Fallback Chain
    // ============================================

    private Flux<SearchEvent> searchAI(String query, String window) {
        // Check if any AI provider is available
        boolean hasAnyProvider = perplexityClient.isEnabled() 
                || openAICompatibleClient.isEnabled() 
                || aiDoveClient.isEnabled()
                || crawlSearchService.isAvailable();

        if (!hasAnyProvider) {
            return Flux.just(SearchEvent.builder()
                    .eventType("status")
                    .source("ai")
                    .message("AI 분석 기능이 비활성화되어 있습니다.")
                    .build());
        }

        return Flux.create(sink -> {
            sink.next(SearchEvent.builder()
                    .eventType("status")
                    .source("ai")
                    .message("AI가 관련 정보를 분석하고 있습니다...")
                    .build());

            String prompt = buildAISearchPrompt(query, window);

            // Build AI stream with fallback chain
            Flux<String> aiStream = getAiStreamWithFallbackForSearch(prompt, query, window);

            StringBuilder fullResponse = new StringBuilder();

            aiStream
                    .doOnNext(chunk -> {
                        fullResponse.append(chunk);
                        // AI 응답을 실시간으로 전송
                        sink.next(SearchEvent.builder()
                                .eventType("ai_chunk")
                                .source("ai")
                                .message(chunk)
                                .build());
                    })
                    .doOnComplete(() -> {
                        // AI 분석 완료 - 전체 텍스트 보존
                        String fullContent = fullResponse.toString();
                        SearchResult aiResult = SearchResult.builder()
                                .id(UUID.randomUUID().toString())
                                .source("ai")
                                .sourceLabel("AI 분석")
                                .title("'" + query + "' AI 분석 결과")
                                .snippet(fullContent.length() > SNIPPET_MAX_LENGTH
                                        ? fullContent.substring(0, SNIPPET_MAX_LENGTH) + "..."
                                        : fullContent)
                                .content(fullContent)  // 전체 AI 분석 결과 보존
                                .build();

                        sink.next(SearchEvent.builder()
                                .eventType("result")
                                .source("ai")
                                .result(aiResult)
                                .build());

                        sink.next(SearchEvent.builder()
                                .eventType("complete")
                                .source("ai")
                                .message("AI 분석 완료")
                                .totalCount(1)
                                .build());

                        sink.complete();
                    })
                    .doOnError(e -> {
                        log.error("AI search failed: {}", e.getMessage());
                        sink.next(SearchEvent.builder()
                                .eventType("error")
                                .source("ai")
                                .message("AI 분석 오류")
                                .build());
                        sink.complete();
                    })
                    .subscribe();
        });
    }

    /**
     * Get AI stream with fallback chain for search.
     * Tries providers in order until one succeeds.
     */
    private Flux<String> getAiStreamWithFallbackForSearch(String prompt, String query, String window) {
        List<AiSearchProviderAttempt> providers = buildAiSearchProviderChain(prompt, query, window);
        
        if (providers.isEmpty()) {
            log.warn("No AI providers available for search");
            return Flux.just("AI 분석을 수행할 수 없습니다.");
        }

        log.info("AI search using fallback chain: {}", 
                providers.stream().map(AiSearchProviderAttempt::name).toList());

        return tryAiSearchProvidersInSequence(providers, 0);
    }

    /**
     * Build AI provider chain for search
     */
    private List<AiSearchProviderAttempt> buildAiSearchProviderChain(String prompt, String query, String window) {
        List<AiSearchProviderAttempt> chain = new ArrayList<>();

        // 1. Perplexity - Best for search with online capabilities
        if (perplexityClient.isEnabled()) {
            chain.add(new AiSearchProviderAttempt("Perplexity", () -> perplexityClient.streamCompletion(prompt)));
        }

        // 2. OpenAI
        if (openAICompatibleClient.isOpenAIEnabled()) {
            chain.add(new AiSearchProviderAttempt("OpenAI", () -> openAICompatibleClient.streamFromOpenAI(prompt)));
        }

        // 3. OpenRouter
        if (openAICompatibleClient.isOpenRouterEnabled()) {
            chain.add(new AiSearchProviderAttempt("OpenRouter", () -> openAICompatibleClient.streamFromOpenRouter(prompt)));
        }

        // 4. Azure OpenAI
        if (openAICompatibleClient.isAzureEnabled()) {
            chain.add(new AiSearchProviderAttempt("Azure", () -> openAICompatibleClient.streamFromAzure(prompt)));
        }

        // 5. AI Dove
        if (aiDoveClient.isEnabled()) {
            chain.add(new AiSearchProviderAttempt("AI Dove", () -> aiDoveClient.chatStream(prompt, null)));
        }

        // 6. CrawlSearchService as fallback
        if (crawlSearchService.isAvailable()) {
            chain.add(new AiSearchProviderAttempt("Crawl Search", () -> crawlSearchService.searchAndAnalyze(query, window)));
        }

        // 7. Ollama - Local LLM
        chain.add(new AiSearchProviderAttempt("Ollama", () -> openAICompatibleClient.streamFromOllama(prompt)));

        // 8. Custom endpoint
        if (openAICompatibleClient.isCustomEnabled()) {
            chain.add(new AiSearchProviderAttempt("Custom", () -> openAICompatibleClient.streamFromCustom(prompt)));
        }

        return chain;
    }

    /**
     * Try AI search providers in sequence
     */
    private Flux<String> tryAiSearchProvidersInSequence(List<AiSearchProviderAttempt> providers, int index) {
        if (index >= providers.size()) {
            log.warn("All AI search providers exhausted");
            return Flux.just("AI 분석 서비스에 연결할 수 없습니다.");
        }

        AiSearchProviderAttempt current = providers.get(index);
        log.info("Trying AI search provider: {} ({}/{})", current.name(), index + 1, providers.size());

        return current.streamSupplier().get()
                .timeout(Duration.ofSeconds(90))
                .onErrorResume(e -> {
                    log.warn("AI search provider {} failed: {}. Trying next...", current.name(), e.getMessage());
                    return tryAiSearchProvidersInSequence(providers, index + 1);
                })
                .switchIfEmpty(Flux.defer(() -> {
                    log.warn("AI search provider {} returned empty. Trying next...", current.name());
                    return tryAiSearchProvidersInSequence(providers, index + 1);
                }));
    }

    /**
     * AI search provider attempt wrapper
     */
    private record AiSearchProviderAttempt(
            String name,
            java.util.function.Supplier<Flux<String>> streamSupplier
    ) {}

    private String buildAISearchPrompt(String query, String window) {
        String timeFrame = switch (window) {
            case "1d" -> "최근 24시간";
            case "30d" -> "최근 한 달";
            default -> "최근 일주일";
        };
        
        // 통화/단위 맥락 분석 힌트 생성
        String currencyContext = buildCurrencyContext(query);

        return """
                [중요: "알겠습니다", "네", "검색하겠습니다" 등의 서두 없이 바로 아래 형식으로 보고서를 작성하세요]
                
                '%s'에 대해 %s 동안의 정보를 철저히 조사하고 분석한 보고서입니다.
                
                ## 분석 원칙
                - **확실한 정보만 보고**: 불확실하거나 추측성 내용은 포함하지 마세요
                - **출처 명시**: 모든 주요 주장에는 반드시 출처를 표기하세요
                - **교차 검증**: 가능한 경우 여러 출처에서 확인된 정보만 포함하세요
                - **객관적 분석**: 특정 입장에 치우치지 않고 균형 있게 분석하세요
                %s
                
                ## 보고서 형식 (이 형식을 정확히 따라주세요)
                
                ### [요약] 핵심 요약
                현재 상황을 4-5문장으로 명확하게 요약해주세요. 핵심 사실만 포함하세요.
                
                ### [검증] 검증된 사실
                여러 출처에서 확인된 사실들을 나열하세요. 각 사실에 출처를 명시하세요.
                
                | 사실 | 출처 | 검증 수준 |
                |------|------|----------|
                | [사실 내용] | [출처명/기관] | 높음/중간/낮음 |
                
                ### [데이터] 주요 수치 및 데이터
                관련된 구체적인 수치, 통계, 날짜 등을 정리하세요.
                - 수치1: [내용] (출처: [출처명])
                - 수치2: [내용] (출처: [출처명])
                
                ### [관점] 다양한 관점
                이 주제에 대한 서로 다른 입장이나 시각을 균형있게 제시하세요.
                
                **입장 A**: [내용] - 출처: [기관/매체명]
                **입장 B**: [내용] - 출처: [기관/매체명]
                
                ### [주의] 주의사항 및 한계
                - 정보의 한계나 불확실한 부분
                - 추가 확인이 필요한 사항
                - 잠재적인 편향이나 이해관계
                
                ### [결론] 결론
                수집된 정보를 바탕으로 한 객관적인 종합 분석을 제공하세요.
                확실하지 않은 내용은 "추가 확인 필요"로 명시하세요.
                
                ---
                * 이 분석은 수집된 자료를 기반으로 작성되었으며, 모든 주장은 출처와 함께 제공됩니다.
                * 최종 판단은 독자의 몫입니다.
                
                한국어로 답변해주세요. 마크다운 형식을 사용하고, "### [요약]"부터 바로 시작하세요.
                """.formatted(query, timeFrame, currencyContext);
    }
    
    /**
     * 쿼리에서 통화/단위 맥락을 분석하여 AI에게 힌트 제공
     * 
     * 예: "비트코인 10억" → 한국어 맥락에서 원화(KRW)일 가능성 높음
     * 예: "Bitcoin $1B" → 달러(USD)로 명시됨
     */
    private String buildCurrencyContext(String query) {
        StringBuilder context = new StringBuilder();
        
        // 숫자 + 억/만/조 패턴 감지 (한국어 숫자 단위)
        boolean hasKoreanNumber = query.matches(".*\\d+\\s*(억|만|조|천).*");
        
        // 명시적 통화 기호 감지
        boolean hasExplicitUsd = query.matches(".*\\$|USD|달러|dollar.*");
        boolean hasExplicitKrw = query.matches(".*₩|KRW|원화|won.*");
        boolean hasExplicitBtc = query.matches(".*BTC|비트코인|bitcoin.*");
        
        // 가격/금액 관련 키워드 감지
        boolean hasPriceKeyword = query.matches(".*(가격|price|도달|목표|전망|예측|forecast).*");
        
        if (hasKoreanNumber && !hasExplicitUsd && hasPriceKeyword) {
            context.append("""
                
                ## 통화/단위 주의사항
                - **중요**: 이 쿼리에 한국어 숫자 단위(억, 만 등)가 포함되어 있습니다
                - 한국어 맥락에서 단위 없는 숫자는 **한국 원화(KRW)**일 가능성이 높습니다
                - 예: "10억" = 10억 원(KRW) ≈ $670,000 USD (환율에 따라 변동)
                - 분석 시 **원화와 달러 양쪽 해석**을 모두 고려하여 작성해주세요
                - 현재 환율 정보도 함께 제공하면 좋습니다
                """);
        } else if (hasExplicitBtc && hasPriceKeyword && !hasExplicitUsd && !hasExplicitKrw) {
            context.append("""
                
                ## 통화/단위 주의사항
                - 암호화폐 가격 분석 시 **USD와 KRW 양쪽 기준**을 모두 언급해주세요
                - 현재 시세와 비교하여 현실적인 분석을 제공해주세요
                - 명시되지 않은 금액은 맥락에 따라 해석하되, 양쪽 가능성을 모두 제시하세요
                """);
        }
        
        return context.toString();
    }

    // ============================================
    // Utility Methods
    // ============================================

    private LocalDateTime calculateSinceDate(String window) {
        return calculateSinceDate(window, null, null);
    }

    /**
     * Calculate the start date for search based on window or custom date range.
     * 
     * @param window Time window (1d, 3d, 7d, 14d, 30d, 90d, 180d, 365d, all)
     * @param startDate Custom start date (ISO 8601 format)
     * @param endDate Custom end date (ISO 8601 format) - currently unused for "since" calculation
     * @return LocalDateTime representing the start date for search
     */
    private LocalDateTime calculateSinceDate(String window, String startDate, String endDate) {
        // If custom startDate is provided, use it
        if (startDate != null && !startDate.isBlank()) {
            try {
                return LocalDateTime.parse(startDate, DateTimeFormatter.ISO_DATE_TIME);
            } catch (DateTimeParseException e) {
                log.warn("Invalid startDate format: '{}', falling back to window: {}", startDate, window);
            }
        }

        LocalDateTime now = LocalDateTime.now();
        return switch (window) {
            case "1h" -> now.minusHours(1);
            case "1d" -> now.minusDays(1);
            case "3d" -> now.minusDays(3);
            case "14d" -> now.minusDays(14);
            case "30d" -> now.minusDays(30);
            case "90d" -> now.minusDays(90);
            case "180d" -> now.minusDays(180);
            case "365d" -> now.minusDays(365);
            case "all" -> LocalDateTime.of(2000, 1, 1, 0, 0);  // Effectively no time limit
            default -> now.minusDays(7);  // Default to 7 days
        };
    }

    /**
     * Calculate the end date for search (for custom date range support).
     * 
     * @param endDate Custom end date (ISO 8601 format)
     * @return LocalDateTime representing the end date for search, or null for "now"
     */
    private LocalDateTime calculateEndDate(String endDate) {
        if (endDate != null && !endDate.isBlank()) {
            try {
                return LocalDateTime.parse(endDate, DateTimeFormatter.ISO_DATE_TIME);
            } catch (DateTimeParseException e) {
                log.warn("Invalid endDate format: '{}', using current time", endDate);
            }
        }
        return null;  // null means "now" (no upper limit)
    }

    /**
     * 이미 정제된 텍스트에서 snippet 생성 (HTML 파싱 불필요)
     */
    private String buildSnippetFromCleanText(String cleanText) {
        if (cleanText == null || cleanText.isBlank()) {
            return null;
        }

        if (cleanText.length() <= SNIPPET_MAX_LENGTH) {
            return cleanText;
        }

        // 단어 경계에서 자르기
        int cut = SNIPPET_MAX_LENGTH;
        for (int i = Math.min(SNIPPET_MAX_LENGTH - 1, cleanText.length() - 1); 
             i > SNIPPET_MAX_LENGTH * 0.6 && i >= 0; i--) {
            if (Character.isWhitespace(cleanText.charAt(i))) {
                cut = i;
                break;
            }
        }

        return cleanText.substring(0, cut).trim() + "...";
    }

    /**
     * 레거시 호환성을 위한 buildSnippet (HTML 파싱 포함)
     * 웹 크롤링 결과 등에서 사용
     */
    private String buildSnippet(String content) {
        if (content == null || content.isBlank()) {
            return null;
        }

        String text;
        try {
            text = Jsoup.parse(content).text();
        } catch (Exception e) {
            text = content;
        }

        text = text.replaceAll("\\s+", " ").trim();
        if (text.isEmpty()) {
            return null;
        }

        if (text.length() <= SNIPPET_MAX_LENGTH) {
            return text;
        }

        int cut = SNIPPET_MAX_LENGTH;
        for (int i = Math.min(SNIPPET_MAX_LENGTH - 1, text.length() - 1); 
             i > SNIPPET_MAX_LENGTH * 0.6 && i >= 0; i--) {
            if (Character.isWhitespace(text.charAt(i))) {
                cut = i;
                break;
            }
        }

        return text.substring(0, cut).trim() + "...";
    }

    /**
     * HTML 태그를 제거하고 정리된 전체 텍스트를 반환합니다.
     * snippet과 달리 길이 제한 없이 전체 내용을 반환합니다.
     * 
     * 중요: 이 메서드는 원본 텍스트 내용을 최대한 보존하며,
     * HTML 태그만 제거하고 실제 텍스트 데이터는 변경하지 않습니다.
     *
     * @param content 원본 콘텐츠 (HTML 포함 가능)
     * @return 정리된 전체 텍스트 (원본 데이터 보존)
     */
    private String cleanContent(String content) {
        if (content == null || content.isBlank()) {
            return null;
        }

        String text;
        try {
            // Jsoup을 사용하여 HTML 태그만 제거, 텍스트 내용은 보존
            text = Jsoup.parse(content).text();
        } catch (Exception e) {
            // HTML 파싱 실패 시 원본 그대로 사용
            text = content;
        }

        // 연속 공백만 정리 (실제 텍스트 내용은 변경하지 않음)
        text = text.replaceAll("\\s+", " ").trim();
        
        return text.isEmpty() ? null : text;
    }

    // ============================================
    // Async Job-based Search (for SSE reconnection support)
    // ============================================

    /**
     * Execute search asynchronously for a job.
     * Results are published to UnifiedSearchEventService.
     * This allows SSE reconnection with the same jobId.
     * 
     * Uses AdvancedIntentAnalyzer for better query understanding and fallback strategies.
     *
     * @param jobId The job ID
     * @param query Search query
     * @param window Time window (1d, 7d, 30d)
     * @param priorityUrls Optional list of URLs to prioritize for web crawling
     * @param startDate Custom start date (ISO 8601 format) - overrides window if provided
     * @param endDate Custom end date (ISO 8601 format)
     */
    @Async
    public void executeSearchAsync(String jobId, String query, String window, List<String> priorityUrls, 
                                   String startDate, String endDate) {
        log.info("Starting async search for job: {}, query: '{}', window: {}, priorityUrls: {}, startDate: {}, endDate: {}", 
                jobId, query, window, priorityUrls != null ? priorityUrls.size() : 0, startDate, endDate);
        
        // Advanced Intent Analysis
        AnalyzedQuery analyzedQuery = advancedIntentAnalyzer.analyzeQuery(query);
        log.info("Async search - Query analyzed: keywords={}, primary='{}', intent={}, strategies={}",
                analyzedQuery.getKeywords().size(),
                analyzedQuery.getPrimaryKeyword(),
                analyzedQuery.getIntentType(),
                analyzedQuery.getFallbackStrategies().size());
        
        unifiedSearchEventService.updateJobStatus(jobId, "IN_PROGRESS");
        
        AtomicInteger totalResults = new AtomicInteger(0);
        AtomicInteger completedSources = new AtomicInteger(0);
        
        // Collect discovered URLs for AutoCrawl integration
        List<String> discoveredUrls = new ArrayList<>();
        
        // Calculate effective date range
        LocalDateTime effectiveStartDate = calculateSinceDate(window, startDate, endDate);
        LocalDateTime effectiveEndDate = calculateEndDate(endDate);
        
        log.info("Effective date range for job {}: {} to {}", jobId, effectiveStartDate, 
                effectiveEndDate != null ? effectiveEndDate : "now");
        
        try {
            // Execute all three searches in parallel
            CompletableFuture<Void> dbFuture = CompletableFuture.runAsync(() -> 
                    executeDbSearchWithFallback(jobId, analyzedQuery, window, startDate, endDate, totalResults, discoveredUrls));
            
            CompletableFuture<Void> webFuture = CompletableFuture.runAsync(() -> 
                    executeWebSearch(jobId, query, window, totalResults, priorityUrls, discoveredUrls));
            
            CompletableFuture<Void> aiFuture = CompletableFuture.runAsync(() -> 
                    executeAiSearch(jobId, query, window, totalResults));
            
            // Wait for all to complete
            CompletableFuture.allOf(dbFuture, webFuture, aiFuture)
                    .thenRun(() -> {
                        log.info("All sources completed for job: {}, total results: {}, discovered URLs: {}", 
                                jobId, totalResults.get(), discoveredUrls.size());
                        
                        // If no results, provide helpful message
                        if (totalResults.get() == 0) {
                            String noResultMessage = advancedIntentAnalyzer.buildNoResultMessage(analyzedQuery);
                            unifiedSearchEventService.publishStatusUpdate(jobId, "system", noResultMessage);
                        }
                        
                        // Save all collected results to search history
                        persistAllResultsToSearchHistory(jobId, query, window, discoveredUrls);
                        
                        unifiedSearchEventService.publishJobComplete(jobId, totalResults.get());
                        
                        // Notify AutoCrawl of discovered URLs
                        if (autoCrawlEnabled && !discoveredUrls.isEmpty()) {
                            autoCrawlIntegrationService.onSearchCompleted(query, discoveredUrls);
                        }
                    })
                    .exceptionally(ex -> {
                        log.error("Error in async search for job: {}", jobId, ex);
                        unifiedSearchEventService.publishJobError(jobId, ex.getMessage());
                        return null;
                    });
                    
        } catch (Exception e) {
            log.error("Failed to start async search for job: {}", jobId, e);
            unifiedSearchEventService.publishJobError(jobId, e.getMessage());
        }
    }

    /**
     * Execute search asynchronously (backward compatible - without custom date range).
     */
    @Async
    public void executeSearchAsync(String jobId, String query, String window, List<String> priorityUrls) {
        executeSearchAsync(jobId, query, window, priorityUrls, null, null);
    }

    /**
     * DB 검색 with 폴백 전략
     */
    private void executeDbSearchWithFallback(
            String jobId, 
            AnalyzedQuery analyzedQuery, 
            String window,
            String startDate,
            String endDate,
            AtomicInteger totalResults,
            List<String> discoveredUrls) {
        
        int attempt = 0;
        int resultsFound = 0;
        
        // 원본 쿼리로 먼저 시도
        String currentQuery = analyzedQuery.getOriginalQuery();
        
        while (attempt < maxFallbackAttempts && resultsFound < 3) {
            String strategyDesc = attempt == 0 
                    ? "원본 쿼리" 
                    : (attempt <= analyzedQuery.getFallbackStrategies().size() 
                            ? analyzedQuery.getFallbackStrategies().get(attempt - 1).getDescription()
                            : "주요 키워드");
            
            unifiedSearchEventService.publishStatusUpdate(jobId, "database", 
                    "검색 전략 " + (attempt + 1) + "/" + maxFallbackAttempts + ": " + strategyDesc);
            
            int found = executeDbSearchForQuery(jobId, currentQuery, window, startDate, endDate, totalResults, discoveredUrls);
            resultsFound += found;
            
            if (resultsFound >= 3) {
                break;  // 충분한 결과 찾음
            }
            
            // 다음 폴백 전략으로
            attempt++;
            if (attempt <= analyzedQuery.getFallbackStrategies().size()) {
                currentQuery = analyzedQuery.getFallbackStrategies().get(attempt - 1).getQuery();
            } else {
                currentQuery = analyzedQuery.getPrimaryKeyword();
            }
        }
        
        String finalMessage = resultsFound > 0 
                ? "데이터베이스 검색 완료 (시도: " + (attempt + 1) + ", 결과: " + resultsFound + ")"
                : "데이터베이스에서 관련 결과를 찾지 못했습니다. 다른 소스를 확인해주세요.";
        
        unifiedSearchEventService.publishSourceComplete(jobId, "database", finalMessage, resultsFound);
    }

    /**
     * 단일 쿼리로 DB 검색 실행
     */
    private int executeDbSearchForQuery(
            String jobId, 
            String query, 
            String window,
            String startDate,
            String endDate,
            AtomicInteger totalResults,
            List<String> discoveredUrls) {
        
        try {
            // Use hybrid search if available
            if (hybridSearchService.isEnabled() && hybridSearchService.isSemanticSearchAvailable()) {
                return executeDbSearchHybridForQuery(jobId, query, window, startDate, endDate, totalResults, discoveredUrls);
            } else {
                return executeDbSearchKeywordForQuery(jobId, query, window, startDate, endDate, totalResults, discoveredUrls);
            }
        } catch (Exception e) {
            log.error("DB search failed for query '{}': {}", query, e.getMessage());
            return 0;
        }
    }

    private int executeDbSearchHybridForQuery(
            String jobId, 
            String query, 
            String window,
            String startDate,
            String endDate,
            AtomicInteger totalResults,
            List<String> discoveredUrls) {
        
        try {
            // Use custom date range if provided, otherwise use window
            String effectiveWindow = (startDate != null && !startDate.isBlank()) ? "custom" : window;
            HybridSearchService.HybridSearchResult hybridResult = hybridSearchService
                    .search(query, effectiveWindow, startDate, endDate).block();
            
            if (hybridResult == null || hybridResult.getResults().isEmpty()) {
                return 0;
            }

            List<Long> articleIds = hybridResult.getResults().stream()
                    .map(r -> {
                        try { return Long.parseLong(r.getId()); } 
                        catch (NumberFormatException e) { return null; }
                    })
                    .filter(id -> id != null)
                    .toList();

            Map<Long, ArticleAnalysis> analysisMap = articleIds.isEmpty()
                    ? Map.of()
                    : articleAnalysisRepository.findByArticleIdIn(articleIds).stream()
                            .collect(Collectors.toMap(ArticleAnalysis::getArticleId, Function.identity()));

            Map<Long, ArticleDiscussion> discussionMap = articleIds.isEmpty()
                    ? Map.of()
                    : articleDiscussionRepository.findByArticleIdIn(articleIds).stream()
                            .collect(Collectors.toMap(ArticleDiscussion::getArticleId, Function.identity()));

            int count = 0;
            for (RankedResult rankedResult : hybridResult.getResults()) {
                Long articleId = null;
                try { articleId = Long.parseLong(rankedResult.getId()); } 
                catch (NumberFormatException ignored) {}

                ArticleAnalysis analysis = articleId != null ? analysisMap.get(articleId) : null;
                ArticleDiscussion discussion = articleId != null ? discussionMap.get(articleId) : null;

                SearchResult result = convertRankedResultToSearchResult(rankedResult, analysis, discussion);
                unifiedSearchEventService.publishResult(jobId, "database", result);
                
                if (result.getUrl() != null && discoveredUrls != null) {
                    synchronized (discoveredUrls) {
                        discoveredUrls.add(result.getUrl());
                    }
                }
                
                count++;
                totalResults.incrementAndGet();
            }
            
            return count;
        } catch (Exception e) {
            log.error("Hybrid search failed: {}", e.getMessage());
            return 0;
        }
    }

    private int executeDbSearchKeywordForQuery(
            String jobId, 
            String query, 
            String window,
            String startDate,
            String endDate,
            AtomicInteger totalResults,
            List<String> discoveredUrls) {
        
        try {
            LocalDateTime since = calculateSinceDate(window, startDate, endDate);
            LocalDateTime until = calculateEndDate(endDate);
            
            PageRequest pageRequest = PageRequest.of(0, MAX_DB_RESULTS,
                    Sort.by(Sort.Direction.DESC, "publishedDate")
                            .and(Sort.by(Sort.Direction.DESC, "collectedAt")));

            // Use date range query if endDate is specified
            Page<CollectedData> page;
            if (until != null) {
                page = collectedDataRepository.searchByQueryAndDateRange(query, since, until, pageRequest);
            } else {
                page = collectedDataRepository.searchByQueryAndSince(query, since, pageRequest);
            }

            List<Long> articleIds = page.getContent().stream()
                    .map(CollectedData::getId)
                    .filter(id -> id != null)
                    .toList();

            Map<Long, ArticleAnalysis> analysisMap = articleIds.isEmpty()
                    ? Map.of()
                    : articleAnalysisRepository.findByArticleIdIn(articleIds).stream()
                            .collect(Collectors.toMap(ArticleAnalysis::getArticleId, Function.identity()));

            Map<Long, ArticleDiscussion> discussionMap = articleIds.isEmpty()
                    ? Map.of()
                    : articleDiscussionRepository.findByArticleIdIn(articleIds).stream()
                            .collect(Collectors.toMap(ArticleDiscussion::getArticleId, Function.identity()));

            int count = 0;
            for (CollectedData data : page.getContent()) {
                ArticleAnalysis analysis = data.getId() != null ? analysisMap.get(data.getId()) : null;
                ArticleDiscussion discussion = data.getId() != null ? discussionMap.get(data.getId()) : null;

                SearchResult result = convertToSearchResult(data, analysis, discussion);
                unifiedSearchEventService.publishResult(jobId, "database", result);

                if (result.getUrl() != null && discoveredUrls != null) {
                    synchronized (discoveredUrls) {
                        discoveredUrls.add(result.getUrl());
                    }
                }

                count++;
                totalResults.incrementAndGet();
            }

            return count;
        } catch (Exception e) {
            log.error("Keyword search failed: {}", e.getMessage());
            return 0;
        }
    }

    private void executeDbSearch(String jobId, String query, String window, AtomicInteger totalResults, List<String> discoveredUrls) {
        // Use hybrid search if available
        if (hybridSearchService.isEnabled() && hybridSearchService.isSemanticSearchAvailable()) {
            executeDbSearchHybrid(jobId, query, window, totalResults, discoveredUrls);
        } else {
            executeDbSearchKeywordOnly(jobId, query, window, totalResults, discoveredUrls);
        }
    }

    private void executeDbSearchHybrid(String jobId, String query, String window, AtomicInteger totalResults, List<String> discoveredUrls) {
        try {
            unifiedSearchEventService.publishStatusUpdate(jobId, "database", "하이브리드 검색 중 (키워드 + 시맨틱)...");

            HybridSearchService.HybridSearchResult hybridResult = hybridSearchService.search(query, window).block();
            
            if (hybridResult == null || hybridResult.getResults().isEmpty()) {
                log.info("Hybrid search returned no results for job: {}, falling back to keyword search", jobId);
                executeDbSearchKeywordOnly(jobId, query, window, totalResults, discoveredUrls);
                return;
            }

            log.info("Hybrid search completed for job {}: keyword={}, semantic={}, fused={}",
                    jobId, hybridResult.getKeywordResultCount(),
                    hybridResult.getSemanticResultCount(),
                    hybridResult.getTotalResultCount());

            // Batch load analysis data for hybrid results
            List<Long> articleIds = hybridResult.getResults().stream()
                    .map(r -> {
                        try {
                            return Long.parseLong(r.getId());
                        } catch (NumberFormatException e) {
                            return null;
                        }
                    })
                    .filter(id -> id != null)
                    .toList();

            Map<Long, ArticleAnalysis> analysisMap = articleIds.isEmpty()
                    ? Map.of()
                    : articleAnalysisRepository.findByArticleIdIn(articleIds).stream()
                            .collect(Collectors.toMap(ArticleAnalysis::getArticleId, Function.identity()));

            Map<Long, ArticleDiscussion> discussionMap = articleIds.isEmpty()
                    ? Map.of()
                    : articleDiscussionRepository.findByArticleIdIn(articleIds).stream()
                            .collect(Collectors.toMap(ArticleDiscussion::getArticleId, Function.identity()));

            int count = 0;
            for (RankedResult rankedResult : hybridResult.getResults()) {
                Long articleId = null;
                try {
                    articleId = Long.parseLong(rankedResult.getId());
                } catch (NumberFormatException ignored) {}

                ArticleAnalysis analysis = articleId != null ? analysisMap.get(articleId) : null;
                ArticleDiscussion discussion = articleId != null ? discussionMap.get(articleId) : null;

                SearchResult result = convertRankedResultToSearchResult(rankedResult, analysis, discussion);
                unifiedSearchEventService.publishResult(jobId, "database", result);
                
                // Collect URL for AutoCrawl
                if (result.getUrl() != null && discoveredUrls != null) {
                    synchronized (discoveredUrls) {
                        discoveredUrls.add(result.getUrl());
                    }
                }
                
                count++;
                totalResults.incrementAndGet();
            }

            String message = String.format("하이브리드 검색 완료 (키워드: %d, 시맨틱: %d, RRF 융합: %d, %dms)",
                    hybridResult.getKeywordResultCount(),
                    hybridResult.getSemanticResultCount(),
                    hybridResult.getTotalResultCount(),
                    hybridResult.getSearchTimeMs());

            unifiedSearchEventService.publishSourceComplete(jobId, "database", message, count);

        } catch (Exception e) {
            log.error("Hybrid search failed for job: {}, falling back to keyword search: {}", jobId, e.getMessage());
            executeDbSearchKeywordOnly(jobId, query, window, totalResults, discoveredUrls);
        }
    }

    private void executeDbSearchKeywordOnly(String jobId, String query, String window, AtomicInteger totalResults, List<String> discoveredUrls) {
        try {
            unifiedSearchEventService.publishStatusUpdate(jobId, "database", "저장된 뉴스에서 검색 중...");
            
            LocalDateTime since = calculateSinceDate(window);
            PageRequest pageRequest = PageRequest.of(0, MAX_DB_RESULTS,
                    Sort.by(Sort.Direction.DESC, "publishedDate")
                            .and(Sort.by(Sort.Direction.DESC, "collectedAt")));

            Page<CollectedData> page = collectedDataRepository.searchByQueryAndSince(
                    query, since, pageRequest);

            // Batch load analysis data
            List<Long> articleIds = page.getContent().stream()
                    .map(CollectedData::getId)
                    .filter(id -> id != null)
                    .toList();
            
            Map<Long, ArticleAnalysis> analysisMap = articleIds.isEmpty() 
                    ? Map.of()
                    : articleAnalysisRepository.findByArticleIdIn(articleIds).stream()
                            .collect(Collectors.toMap(ArticleAnalysis::getArticleId, Function.identity()));
            
            Map<Long, ArticleDiscussion> discussionMap = articleIds.isEmpty()
                    ? Map.of()
                    : articleDiscussionRepository.findByArticleIdIn(articleIds).stream()
                            .collect(Collectors.toMap(ArticleDiscussion::getArticleId, Function.identity()));

            int count = 0;
            for (CollectedData data : page.getContent()) {
                ArticleAnalysis analysis = data.getId() != null ? analysisMap.get(data.getId()) : null;
                ArticleDiscussion discussion = data.getId() != null ? discussionMap.get(data.getId()) : null;
                
                SearchResult result = convertToSearchResult(data, analysis, discussion);
                unifiedSearchEventService.publishResult(jobId, "database", result);
                
                // Collect URL for AutoCrawl
                if (result.getUrl() != null && discoveredUrls != null) {
                    synchronized (discoveredUrls) {
                        discoveredUrls.add(result.getUrl());
                    }
                }
                
                count++;
                totalResults.incrementAndGet();
            }

            unifiedSearchEventService.publishSourceComplete(jobId, "database", "저장된 뉴스 검색 완료", count);
            
        } catch (Exception e) {
            log.error("Database search failed for job: {}", jobId, e);
            unifiedSearchEventService.publishSourceError(jobId, "database", "데이터베이스 검색 오류: " + e.getMessage());
        }
    }

    private void executeWebSearch(String jobId, String query, String window, AtomicInteger totalResults, List<String> priorityUrls, List<String> discoveredUrls) {
        try {
            unifiedSearchEventService.publishStatusUpdate(jobId, "web", "웹에서 최신 정보 수집 중...");
            
            // Use priorityUrls if provided, otherwise fall back to generated URLs
            List<String> searchUrls;
            if (priorityUrls != null && !priorityUrls.isEmpty()) {
                searchUrls = priorityUrls;
                log.info("Using {} priority URLs for web search in job: {}", priorityUrls.size(), jobId);
            } else {
                searchUrls = generateSearchUrls(query, window);
                log.info("Using {} generated search URLs for web search in job: {}", searchUrls.size(), jobId);
            }
            
            int successCount = 0;

            for (String url : searchUrls) {
                try {
                    Crawl4aiClient.CrawlResult crawlResult = crawl4aiClient.crawl(url);
                    if (crawlResult != null && crawlResult.getContent() != null) {
                        String fullContent = cleanContent(crawlResult.getContent());
                        SearchResult result = SearchResult.builder()
                                .id(UUID.randomUUID().toString())
                                .source("web")
                                .sourceLabel("웹 검색")
                                .title(crawlResult.getTitle() != null ? crawlResult.getTitle() : extractTitleFromUrl(url))
                                .snippet(buildSnippet(crawlResult.getContent()))
                                .content(fullContent)  // 전체 본문 추가
                                .url(url)
                                .build();

                        unifiedSearchEventService.publishResult(jobId, "web", result);
                        
                        // Collect URL for AutoCrawl
                        if (discoveredUrls != null) {
                            synchronized (discoveredUrls) {
                                discoveredUrls.add(url);
                            }
                        }
                        
                        successCount++;
                        totalResults.incrementAndGet();
                    }
                } catch (Exception e) {
                    log.debug("Failed to crawl URL {} for job {}: {}", url, jobId, e.getMessage());
                }
            }

            unifiedSearchEventService.publishSourceComplete(jobId, "web", "웹 검색 완료", successCount);
            
        } catch (Exception e) {
            log.error("Web search failed for job: {}", jobId, e);
            unifiedSearchEventService.publishSourceError(jobId, "web", "웹 검색 오류");
        }
    }

    private void executeAiSearch(String jobId, String query, String window, AtomicInteger totalResults) {
        // Check if any AI provider is available
        boolean hasAnyProvider = perplexityClient.isEnabled() 
                || openAICompatibleClient.isEnabled() 
                || aiDoveClient.isEnabled()
                || crawlSearchService.isAvailable();

        if (!hasAnyProvider) {
            unifiedSearchEventService.publishStatusUpdate(jobId, "ai", "AI 분석 기능이 비활성화되어 있습니다.");
            unifiedSearchEventService.publishSourceComplete(jobId, "ai", "AI 분석 비활성화", 0);
            return;
        }

        try {
            unifiedSearchEventService.publishStatusUpdate(jobId, "ai", "AI가 관련 정보를 분석하고 있습니다...");
            
            String prompt = buildAISearchPrompt(query, window);
            
            // Use fallback chain
            Flux<String> aiStream = getAiStreamWithFallbackForSearch(prompt, query, window);

            StringBuilder fullResponse = new StringBuilder();
            
            // Block and collect all AI response (since we're in async context)
            aiStream
                    .doOnNext(chunk -> {
                        fullResponse.append(chunk);
                        unifiedSearchEventService.publishAiChunk(jobId, chunk);
                    })
                    .blockLast(Duration.ofMinutes(2));

            // Publish final AI result - 전체 텍스트 보존
            String fullContent = fullResponse.toString();
            SearchResult aiResult = SearchResult.builder()
                    .id(UUID.randomUUID().toString())
                    .source("ai")
                    .sourceLabel("AI 분석")
                    .title("'" + query + "' AI 분석 결과")
                    .snippet(fullContent.length() > SNIPPET_MAX_LENGTH
                            ? fullContent.substring(0, SNIPPET_MAX_LENGTH) + "..."
                            : fullContent)
                    .content(fullContent)  // 전체 AI 분석 결과 보존
                    .build();

            unifiedSearchEventService.publishResult(jobId, "ai", aiResult);
            totalResults.incrementAndGet();
            unifiedSearchEventService.publishSourceComplete(jobId, "ai", "AI 분석 완료", 1);

            persistAiReportToSearchHistory(jobId, query, window, fullContent);
            
        } catch (Exception e) {
            log.error("AI search failed for job: {}", jobId, e);
            unifiedSearchEventService.publishSourceError(jobId, "ai", "AI 분석 오류");
        }
    }

    private void persistAiReportToSearchHistory(String jobId, String query, String window, String fullMarkdown) {
        try {
            Map<String, Object> aiSummary = new HashMap<>();
            aiSummary.put(AI_SUMMARY_KEY_CONTENT, fullMarkdown);
            aiSummary.put(AI_SUMMARY_KEY_SUMMARY, extractSummarySection(fullMarkdown));
            aiSummary.put(AI_SUMMARY_KEY_GENERATED_AT, System.currentTimeMillis());

            SearchHistoryMessage message = SearchHistoryMessage.builder()
                    .externalId(jobId)
                    .searchType(SearchType.UNIFIED)
                    .query(query)
                    .timeWindow(window)
                    .resultCount(0)
                    .results(List.of())
                    .aiSummary(aiSummary)
                    .success(true)
                    .timestamp(System.currentTimeMillis())
                    .build();

            searchHistoryService.saveFromMessage(message);
            log.info("Saved unified AI report to search history: jobId={}", jobId);
        } catch (Exception e) {
            log.warn("Failed to save unified AI report to search history: jobId={}, error={}", jobId, e.getMessage());
        }
    }

    /**
     * Save all collected search results to search history.
     * This includes DB results, web crawl results, and discovered URLs.
     */
    private void persistAllResultsToSearchHistory(String jobId, String query, String window, List<String> discoveredUrls) {
        try {
            // Get all collected results from the event service
            List<Map<String, Object>> collectedResults = unifiedSearchEventService.getCollectedResults(jobId);
            
            if (collectedResults.isEmpty()) {
                log.debug("No results to persist for job: {}", jobId);
                return;
            }

            SearchHistoryMessage message = SearchHistoryMessage.builder()
                    .externalId(jobId + "-results")
                    .searchType(SearchType.UNIFIED)
                    .query(query)
                    .timeWindow(window)
                    .resultCount(collectedResults.size())
                    .results(collectedResults)
                    .discoveredUrls(discoveredUrls)
                    .success(true)
                    .timestamp(System.currentTimeMillis())
                    .build();

            searchHistoryService.saveFromMessage(message);
            log.info("Saved {} unified search results to search history: jobId={}", collectedResults.size(), jobId);
        } catch (Exception e) {
            log.warn("Failed to save unified search results to search history: jobId={}, error={}", jobId, e.getMessage());
        }
    }

    private String extractSummarySection(String markdown) {
        if (markdown == null || markdown.isBlank()) {
            return null;
        }

        int start = markdown.indexOf("### [요약]");
        if (start < 0) {
            start = markdown.indexOf("## [요약]");
        }
        if (start < 0) {
            return null;
        }

        int next = markdown.indexOf("\n### ", start + 1);
        if (next < 0) {
            next = markdown.length();
        }

        String section = markdown.substring(start, next).trim();
        return section.isEmpty() ? null : section;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/VectorEmbeddingService.java

```java
package com.newsinsight.collector.service;

import io.micrometer.core.instrument.Counter;
import io.micrometer.core.instrument.MeterRegistry;
import io.micrometer.core.instrument.Timer;
import jakarta.annotation.PostConstruct;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.boot.context.event.ApplicationReadyEvent;
import org.springframework.context.event.EventListener;
import org.springframework.http.MediaType;
import org.springframework.retry.annotation.Backoff;
import org.springframework.retry.annotation.Retryable;
import org.springframework.stereotype.Service;
import org.springframework.web.reactive.function.client.WebClient;
import org.springframework.web.reactive.function.client.WebClientResponseException;
import reactor.core.publisher.Mono;
import reactor.util.retry.Retry;

import java.time.Duration;
import java.util.*;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicLong;

/**
 * 벡터 임베딩 서비스
 * 
 * 채팅 메시지를 벡터 DB에 임베딩하여 저장합니다.
 * 유사 질문 검색, 컨텍스트 검색 등에 활용됩니다.
 * 
 * 개선사항:
 * - 자동 초기화 (ApplicationReadyEvent)
 * - 재시도 로직 (Retry)
 * - 배치 임베딩 지원
 * - 연결 상태 확인
 * - 메트릭 수집
 * - 로컬 임베딩 대체 지원
 */
@Service
@Slf4j
public class VectorEmbeddingService {

    private final WebClient webClient;
    private final MeterRegistry meterRegistry;

    @Value("${vector.db.enabled:false}")
    private boolean vectorDbEnabled;

    @Value("${vector.db.url:http://localhost:6333}")
    private String vectorDbUrl;

    @Value("${vector.db.collection:factcheck_chat}")
    private String collectionName;

    @Value("${vector.embedding.model:text-embedding-ada-002}")
    private String embeddingModel;

    @Value("${vector.embedding.api-key:}")
    private String apiKey;

    @Value("${vector.embedding.dimension:1536}")
    private int embeddingDimension;

    @Value("${vector.embedding.timeout-seconds:30}")
    private int timeoutSeconds;

    @Value("${vector.embedding.max-retry:3}")
    private int maxRetry;

    @Value("${vector.embedding.batch-size:10}")
    private int batchSize;

    // 로컬 임베딩 서비스 설정 (HuggingFace TEI 등)
    @Value("${vector.embedding.local.enabled:false}")
    private boolean localEmbeddingEnabled;

    @Value("${vector.embedding.local.url:http://localhost:8011}")
    private String localEmbeddingUrl;

    // 상태 플래그
    private final AtomicBoolean vectorDbHealthy = new AtomicBoolean(false);
    private final AtomicBoolean embeddingServiceHealthy = new AtomicBoolean(false);

    // 메트릭
    private Counter embeddingSuccessCounter;
    private Counter embeddingErrorCounter;
    private Counter searchSuccessCounter;
    private Counter searchErrorCounter;
    private Timer embeddingDurationTimer;
    private Timer searchDurationTimer;
    private final AtomicLong embeddingQueueSize = new AtomicLong(0);

    public VectorEmbeddingService(WebClient.Builder webClientBuilder, MeterRegistry meterRegistry) {
        this.webClient = webClientBuilder
                .codecs(configurer -> configurer.defaultCodecs().maxInMemorySize(16 * 1024 * 1024))
                .build();
        this.meterRegistry = meterRegistry;
    }

    @PostConstruct
    public void initMetrics() {
        embeddingSuccessCounter = Counter.builder("vector.embedding.success")
                .description("Number of successful embeddings")
                .register(meterRegistry);

        embeddingErrorCounter = Counter.builder("vector.embedding.error")
                .description("Number of failed embeddings")
                .register(meterRegistry);

        searchSuccessCounter = Counter.builder("vector.search.success")
                .description("Number of successful searches")
                .register(meterRegistry);

        searchErrorCounter = Counter.builder("vector.search.error")
                .description("Number of failed searches")
                .register(meterRegistry);

        embeddingDurationTimer = Timer.builder("vector.embedding.duration")
                .description("Time taken for embedding generation")
                .register(meterRegistry);

        searchDurationTimer = Timer.builder("vector.search.duration")
                .description("Time taken for vector search")
                .register(meterRegistry);

        meterRegistry.gauge("vector.embedding.queue.size", embeddingQueueSize);
        meterRegistry.gauge("vector.db.healthy", vectorDbHealthy, b -> b.get() ? 1.0 : 0.0);
        meterRegistry.gauge("vector.embedding.service.healthy", embeddingServiceHealthy, b -> b.get() ? 1.0 : 0.0);
    }

    /**
     * 애플리케이션 시작 시 벡터 DB 초기화
     */
    @EventListener(ApplicationReadyEvent.class)
    public void onApplicationReady() {
        if (vectorDbEnabled) {
            log.info("Initializing Vector DB on application startup...");
            initializeVectorDb();
            checkVectorDbHealth();
            checkEmbeddingServiceHealth();
        } else {
            log.info("Vector DB is disabled");
        }
    }

    /**
     * 채팅 메시지를 벡터 DB에 임베딩
     * 
     * @param sessionId 세션 ID
     * @param messageId 메시지 ID
     * @param content 메시지 내용
     * @param metadata 메타데이터
     * @return 임베딩 ID
     */
    @Retryable(
            retryFor = {WebClientResponseException.class},
            maxAttempts = 3,
            backoff = @Backoff(delay = 1000, multiplier = 2)
    )
    public String embedChatMessage(String sessionId, String messageId, String content, Object metadata) {
        if (!vectorDbEnabled) {
            log.debug("Vector DB is disabled, skipping embedding");
            return null;
        }

        if (!vectorDbHealthy.get()) {
            log.warn("Vector DB is not healthy, skipping embedding");
            return null;
        }

        Timer.Sample sample = Timer.start(meterRegistry);
        embeddingQueueSize.incrementAndGet();

        try {
            // 1. 텍스트 임베딩 생성
            List<Double> embedding = generateEmbeddingWithFallback(content);

            if (embedding == null || embedding.isEmpty()) {
                log.error("Failed to generate embedding for message {}", messageId);
                embeddingErrorCounter.increment();
                return null;
            }

            // 2. 벡터 DB에 저장
            String embeddingId = UUID.randomUUID().toString();
            storeEmbedding(embeddingId, sessionId, messageId, content, embedding, metadata);

            sample.stop(embeddingDurationTimer);
            embeddingSuccessCounter.increment();
            
            log.info("Embedded message {} to vector DB with ID: {}", messageId, embeddingId);
            return embeddingId;

        } catch (Exception e) {
            log.error("Failed to embed message {}: {}", messageId, e.getMessage(), e);
            sample.stop(embeddingDurationTimer);
            embeddingErrorCounter.increment();
            return null;
        } finally {
            embeddingQueueSize.decrementAndGet();
        }
    }

    /**
     * 배치로 여러 메시지 임베딩
     */
    public List<String> embedChatMessagesBatch(List<EmbeddingRequest> requests) {
        if (!vectorDbEnabled || !vectorDbHealthy.get()) {
            return Collections.emptyList();
        }

        List<String> embeddingIds = new ArrayList<>();
        
        // 배치 크기로 나누어 처리
        for (int i = 0; i < requests.size(); i += batchSize) {
            List<EmbeddingRequest> batch = requests.subList(i, Math.min(i + batchSize, requests.size()));
            
            for (EmbeddingRequest request : batch) {
                String embeddingId = embedChatMessage(
                        request.getSessionId(),
                        request.getMessageId(),
                        request.getContent(),
                        request.getMetadata()
                );
                if (embeddingId != null) {
                    embeddingIds.add(embeddingId);
                }
            }
        }
        
        return embeddingIds;
    }

    /**
     * 텍스트 임베딩 생성 (폴백 포함)
     */
    private List<Double> generateEmbeddingWithFallback(String text) {
        // 1. 로컬 임베딩 서비스 시도
        if (localEmbeddingEnabled && embeddingServiceHealthy.get()) {
            try {
                List<Double> embedding = generateLocalEmbedding(text);
                if (embedding != null && !embedding.isEmpty()) {
                    return embedding;
                }
            } catch (Exception e) {
                log.warn("Local embedding failed, falling back to OpenAI: {}", e.getMessage());
            }
        }

        // 2. OpenAI API 시도
        if (apiKey != null && !apiKey.isBlank()) {
            try {
                return generateOpenAIEmbedding(text);
            } catch (Exception e) {
                log.error("OpenAI embedding failed: {}", e.getMessage());
            }
        }

        // 3. 더미 임베딩 (최후의 수단)
        log.warn("All embedding methods failed, using dummy embedding");
        return generateDummyEmbedding();
    }

    /**
     * 로컬 임베딩 서비스로 임베딩 생성 (HuggingFace TEI)
     */
    private List<Double> generateLocalEmbedding(String text) {
        Map<String, Object> request = new HashMap<>();
        request.put("inputs", text);

        return webClient.post()
                .uri(localEmbeddingUrl + "/embed")
                .contentType(MediaType.APPLICATION_JSON)
                .bodyValue(request)
                .retrieve()
                .bodyToMono(List.class)
                .timeout(Duration.ofSeconds(timeoutSeconds))
                .retryWhen(Retry.backoff(maxRetry, Duration.ofSeconds(1)))
                .block();
    }

    /**
     * OpenAI API로 임베딩 생성
     */
    @SuppressWarnings("unchecked")
    private List<Double> generateOpenAIEmbedding(String text) {
        Map<String, Object> request = new HashMap<>();
        request.put("input", text);
        request.put("model", embeddingModel);

        Map<String, Object> response = webClient.post()
                .uri("https://api.openai.com/v1/embeddings")
                .header("Authorization", "Bearer " + apiKey)
                .contentType(MediaType.APPLICATION_JSON)
                .bodyValue(request)
                .retrieve()
                .bodyToMono(Map.class)
                .timeout(Duration.ofSeconds(timeoutSeconds))
                .retryWhen(Retry.backoff(maxRetry, Duration.ofSeconds(1)))
                .block();

        if (response != null && response.containsKey("data")) {
            List<Map<String, Object>> data = (List<Map<String, Object>>) response.get("data");
            if (!data.isEmpty()) {
                return (List<Double>) data.get(0).get("embedding");
            }
        }

        return null;
    }

    /**
     * 벡터 DB에 임베딩 저장 (Qdrant)
     */
    private void storeEmbedding(
            String embeddingId,
            String sessionId,
            String messageId,
            String content,
            List<Double> embedding,
            Object metadata
    ) {
        Map<String, Object> point = new HashMap<>();
        point.put("id", embeddingId);
        point.put("vector", embedding);

        Map<String, Object> payload = new HashMap<>();
        payload.put("session_id", sessionId);
        payload.put("message_id", messageId);
        payload.put("content", content);
        payload.put("metadata", metadata);
        payload.put("timestamp", System.currentTimeMillis());
        payload.put("created_at", java.time.Instant.now().toString());
        point.put("payload", payload);

        Map<String, Object> request = new HashMap<>();
        request.put("points", List.of(point));

        webClient.put()
                .uri(vectorDbUrl + "/collections/" + collectionName + "/points")
                .contentType(MediaType.APPLICATION_JSON)
                .bodyValue(request)
                .retrieve()
                .bodyToMono(Void.class)
                .timeout(Duration.ofSeconds(timeoutSeconds))
                .retryWhen(Retry.backoff(maxRetry, Duration.ofSeconds(1)))
                .block();

        log.debug("Stored embedding {} in vector DB", embeddingId);
    }

    /**
     * 유사 메시지 검색
     * 
     * @param queryText 검색 쿼리
     * @param limit 결과 개수
     * @return 유사 메시지 목록
     */
    @SuppressWarnings("unchecked")
    public List<Map<String, Object>> searchSimilarMessages(String queryText, int limit) {
        return searchSimilarMessages(queryText, limit, 0.5f);
    }

    /**
     * 유사 메시지 검색 (최소 점수 지정)
     */
    @SuppressWarnings("unchecked")
    public List<Map<String, Object>> searchSimilarMessages(String queryText, int limit, float minScore) {
        if (!vectorDbEnabled || !vectorDbHealthy.get()) {
            return List.of();
        }

        Timer.Sample sample = Timer.start(meterRegistry);

        try {
            List<Double> queryEmbedding = generateEmbeddingWithFallback(queryText);
            
            if (queryEmbedding == null || queryEmbedding.isEmpty()) {
                log.error("Failed to generate query embedding");
                searchErrorCounter.increment();
                return List.of();
            }

            Map<String, Object> request = new HashMap<>();
            request.put("vector", queryEmbedding);
            request.put("limit", limit);
            request.put("with_payload", true);
            request.put("score_threshold", minScore);

            Map<String, Object> response = webClient.post()
                    .uri(vectorDbUrl + "/collections/" + collectionName + "/points/search")
                    .contentType(MediaType.APPLICATION_JSON)
                    .bodyValue(request)
                    .retrieve()
                    .bodyToMono(Map.class)
                    .timeout(Duration.ofSeconds(timeoutSeconds))
                    .retryWhen(Retry.backoff(maxRetry, Duration.ofSeconds(1)))
                    .block();

            sample.stop(searchDurationTimer);
            searchSuccessCounter.increment();

            if (response != null && response.containsKey("result")) {
                return (List<Map<String, Object>>) response.get("result");
            }

            return List.of();

        } catch (Exception e) {
            log.error("Failed to search similar messages: {}", e.getMessage());
            sample.stop(searchDurationTimer);
            searchErrorCounter.increment();
            return List.of();
        }
    }

    /**
     * 세션 ID로 필터링된 유사 메시지 검색
     */
    @SuppressWarnings("unchecked")
    public List<Map<String, Object>> searchSimilarMessagesInSession(String queryText, String sessionId, int limit) {
        if (!vectorDbEnabled || !vectorDbHealthy.get()) {
            return List.of();
        }

        try {
            List<Double> queryEmbedding = generateEmbeddingWithFallback(queryText);
            
            if (queryEmbedding == null || queryEmbedding.isEmpty()) {
                return List.of();
            }

            Map<String, Object> filter = Map.of(
                    "must", List.of(
                            Map.of("key", "session_id",
                                   "match", Map.of("value", sessionId))
                    )
            );

            Map<String, Object> request = new HashMap<>();
            request.put("vector", queryEmbedding);
            request.put("limit", limit);
            request.put("with_payload", true);
            request.put("filter", filter);

            Map<String, Object> response = webClient.post()
                    .uri(vectorDbUrl + "/collections/" + collectionName + "/points/search")
                    .contentType(MediaType.APPLICATION_JSON)
                    .bodyValue(request)
                    .retrieve()
                    .bodyToMono(Map.class)
                    .timeout(Duration.ofSeconds(timeoutSeconds))
                    .block();

            if (response != null && response.containsKey("result")) {
                return (List<Map<String, Object>>) response.get("result");
            }

            return List.of();

        } catch (Exception e) {
            log.error("Failed to search similar messages in session: {}", e.getMessage());
            return List.of();
        }
    }

    /**
     * 더미 임베딩 생성 (테스트용)
     */
    private List<Double> generateDummyEmbedding() {
        List<Double> dummy = new ArrayList<>();
        Random random = new Random(System.currentTimeMillis());
        for (int i = 0; i < embeddingDimension; i++) {
            dummy.add(random.nextGaussian() * 0.1);
        }
        // 정규화
        double norm = Math.sqrt(dummy.stream().mapToDouble(d -> d * d).sum());
        return dummy.stream().map(d -> d / norm).toList();
    }

    /**
     * 벡터 DB 초기화 (컬렉션 생성)
     */
    public void initializeVectorDb() {
        if (!vectorDbEnabled) {
            return;
        }

        try {
            // 1. 컬렉션 존재 여부 확인
            Boolean exists = checkCollectionExists();
            
            if (Boolean.TRUE.equals(exists)) {
                log.info("Vector DB collection '{}' already exists", collectionName);
                vectorDbHealthy.set(true);
                return;
            }

            // 2. 컬렉션 생성
            Map<String, Object> config = new HashMap<>();
            config.put("vectors", Map.of(
                    "size", embeddingDimension,
                    "distance", "Cosine"
            ));

            // 최적화 설정
            config.put("optimizers_config", Map.of(
                    "indexing_threshold", 20000,
                    "memmap_threshold", 50000
            ));

            webClient.put()
                    .uri(vectorDbUrl + "/collections/" + collectionName)
                    .contentType(MediaType.APPLICATION_JSON)
                    .bodyValue(config)
                    .retrieve()
                    .bodyToMono(Void.class)
                    .timeout(Duration.ofSeconds(30))
                    .block();

            // 3. 인덱스 생성
            createPayloadIndex("session_id");
            createPayloadIndex("message_id");

            vectorDbHealthy.set(true);
            log.info("Initialized vector DB collection: {}", collectionName);

        } catch (Exception e) {
            log.error("Vector DB initialization failed: {}", e.getMessage());
            vectorDbHealthy.set(false);
        }
    }

    /**
     * 컬렉션 존재 여부 확인
     */
    @SuppressWarnings("unchecked")
    private Boolean checkCollectionExists() {
        try {
            Map<String, Object> response = webClient.get()
                    .uri(vectorDbUrl + "/collections/" + collectionName)
                    .retrieve()
                    .bodyToMono(Map.class)
                    .timeout(Duration.ofSeconds(10))
                    .block();
            return response != null && response.containsKey("result");
        } catch (WebClientResponseException.NotFound e) {
            return false;
        } catch (Exception e) {
            log.warn("Failed to check collection existence: {}", e.getMessage());
            return false;
        }
    }

    /**
     * 페이로드 인덱스 생성
     */
    private void createPayloadIndex(String fieldName) {
        try {
            Map<String, Object> request = Map.of(
                    "field_name", fieldName,
                    "field_schema", "keyword"
            );

            webClient.put()
                    .uri(vectorDbUrl + "/collections/" + collectionName + "/index")
                    .contentType(MediaType.APPLICATION_JSON)
                    .bodyValue(request)
                    .retrieve()
                    .bodyToMono(Void.class)
                    .timeout(Duration.ofSeconds(10))
                    .block();

            log.debug("Created payload index for field: {}", fieldName);
        } catch (Exception e) {
            log.warn("Failed to create payload index for {}: {}", fieldName, e.getMessage());
        }
    }

    /**
     * 벡터 DB 헬스 체크
     */
    public void checkVectorDbHealth() {
        if (!vectorDbEnabled) {
            vectorDbHealthy.set(false);
            return;
        }

        try {
            webClient.get()
                    .uri(vectorDbUrl + "/")
                    .retrieve()
                    .bodyToMono(Map.class)
                    .timeout(Duration.ofSeconds(5))
                    .block();
            
            vectorDbHealthy.set(true);
            log.debug("Vector DB health check passed");
        } catch (Exception e) {
            vectorDbHealthy.set(false);
            log.warn("Vector DB health check failed: {}", e.getMessage());
        }
    }

    /**
     * 임베딩 서비스 헬스 체크
     */
    public void checkEmbeddingServiceHealth() {
        if (!localEmbeddingEnabled) {
            embeddingServiceHealthy.set(apiKey != null && !apiKey.isBlank());
            return;
        }

        try {
            webClient.get()
                    .uri(localEmbeddingUrl + "/health")
                    .retrieve()
                    .bodyToMono(String.class)
                    .timeout(Duration.ofSeconds(5))
                    .block();
            
            embeddingServiceHealthy.set(true);
            log.debug("Embedding service health check passed");
        } catch (Exception e) {
            embeddingServiceHealthy.set(apiKey != null && !apiKey.isBlank());
            log.warn("Local embedding service health check failed, using OpenAI: {}", e.getMessage());
        }
    }

    /**
     * 임베딩 삭제
     */
    public boolean deleteEmbedding(String embeddingId) {
        if (!vectorDbEnabled || !vectorDbHealthy.get()) {
            return false;
        }

        try {
            Map<String, Object> request = Map.of(
                    "points", List.of(embeddingId)
            );

            webClient.post()
                    .uri(vectorDbUrl + "/collections/" + collectionName + "/points/delete")
                    .contentType(MediaType.APPLICATION_JSON)
                    .bodyValue(request)
                    .retrieve()
                    .bodyToMono(Void.class)
                    .timeout(Duration.ofSeconds(10))
                    .block();

            log.info("Deleted embedding: {}", embeddingId);
            return true;
        } catch (Exception e) {
            log.error("Failed to delete embedding {}: {}", embeddingId, e.getMessage());
            return false;
        }
    }

    /**
     * 서비스 상태 조회
     */
    public VectorServiceStatus getStatus() {
        return VectorServiceStatus.builder()
                .enabled(vectorDbEnabled)
                .vectorDbHealthy(vectorDbHealthy.get())
                .embeddingServiceHealthy(embeddingServiceHealthy.get())
                .queueSize(embeddingQueueSize.get())
                .vectorDbUrl(vectorDbUrl)
                .collectionName(collectionName)
                .embeddingModel(embeddingModel)
                .embeddingDimension(embeddingDimension)
                .localEmbeddingEnabled(localEmbeddingEnabled)
                .build();
    }

    /**
     * 임베딩 요청 DTO
     */
    @lombok.Data
    @lombok.Builder
    @lombok.NoArgsConstructor
    @lombok.AllArgsConstructor
    public static class EmbeddingRequest {
        private String sessionId;
        private String messageId;
        private String content;
        private Object metadata;
    }

    /**
     * 서비스 상태 DTO
     */
    @lombok.Data
    @lombok.Builder
    public static class VectorServiceStatus {
        private boolean enabled;
        private boolean vectorDbHealthy;
        private boolean embeddingServiceHealthy;
        private long queueSize;
        private String vectorDbUrl;
        private String collectionName;
        private String embeddingModel;
        private int embeddingDimension;
        private boolean localEmbeddingEnabled;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/WebScraperService.java

```java
package com.newsinsight.collector.service;

import com.fasterxml.jackson.databind.ObjectMapper;
import com.newsinsight.collector.client.Crawl4aiClient;
import com.newsinsight.collector.entity.CollectedData;
import com.newsinsight.collector.entity.DataSource;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Service;
import org.springframework.web.reactive.function.client.WebClient;
import reactor.core.publisher.Mono;

import java.time.Duration;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;

@Service
@RequiredArgsConstructor
@Slf4j
public class WebScraperService {

    private final WebClient webClient;
    private final CollectedDataService collectedDataService;
    private final ObjectMapper objectMapper;
    private final Crawl4aiClient crawl4aiClient;

    @Value("${collector.crawler.enabled:true}")
    private boolean crawlerEnabled;

    /**
     * 공백을 정리하여 텍스트를 정규화
     */
    private String normalizeText(String text) {
        if (text == null || text.isBlank()) {
            return "";
        }
        return text.replaceAll("\\s+", " ").trim();
    }

    /**
     * 웹 페이지를 가져와 스크랩
     */
    public List<CollectedData> scrapeWebPage(DataSource source) {
        List<CollectedData> results = new ArrayList<>();

        try {
            log.info("Scraping web page: {}", source.getUrl());

            String title = null;
            String normalizedContent = null;
            String method = "jsoup";

            // Try Crawl4AI first if enabled
            if (crawlerEnabled) {
                Crawl4aiClient.CrawlResult r = crawl4aiClient.crawl(source.getUrl());
                if (r != null && r.getContent() != null && r.getContent().length() >= 100) {
                    title = r.getTitle();
                    normalizedContent = r.getContent();
                    method = "crawl4ai";
                } else {
                    log.debug("Crawl4AI returned no/short content for {}. Falling back to Jsoup.", source.getUrl());
                }
            }

            if (normalizedContent == null) {
                // WebClient로 HTML 가져오기
                String html = webClient.get()
                        .uri(source.getUrl())
                        .retrieve()
                        .bodyToMono(String.class)
                        .timeout(Duration.ofSeconds(30))
                        .onErrorResume(e -> {
                            log.error("Error fetching web page {}: {}", source.getUrl(), e.getMessage());
                            return Mono.empty();
                        })
                        .block();

                if (html == null || html.isBlank()) {
                    log.warn("Empty response from: {}", source.getUrl());
                    return results;
                }

                // Jsoup으로 HTML 파싱
                Document doc = Jsoup.parse(html);

                // script/style/nav/footer/aside 제거
                doc.select("script, style, nav, footer, aside").remove();

                // 본문 텍스트 추출
                String textContent = doc.body().text();
                normalizedContent = normalizeText(textContent);

                // 제목 추출 (fallback path)
                title = doc.title();
            }

            // 제목 보정
            if (title == null || title.isBlank()) {
                title = source.getName();
            }

            // 내용이 너무 짧으면 건너뜀
            if (normalizedContent == null || normalizedContent.length() < 100) {
                log.debug("Skipping page with too short content: {}", source.getUrl());
                return results;
            }

            // 콘텐츠 해시 계산
            String contentHash = collectedDataService.computeContentHash(
                    source.getUrl(), title, normalizedContent);

            // 중복 확인
            if (collectedDataService.isDuplicate(contentHash)) {
                log.debug("Duplicate page detected: {}", source.getUrl());
                return results;
            }

            // 메타데이터 구성
            Map<String, Object> metadata = Map.of(
                    "adapter", "web",
                    "source_name", source.getName(),
                    "scrape_method", method
            );

            // 메타데이터를 JSON 문자열로 변환
            String metadataJson;
            try {
                metadataJson = objectMapper.writeValueAsString(metadata);
            } catch (Exception e) {
                log.warn("Failed to serialize metadata to JSON: {}", e.getMessage());
                metadataJson = "{}";
            }

            // CollectedData 엔티티 생성
            CollectedData data = CollectedData.builder()
                    .sourceId(source.getId())
                    .title(title)
                    .content(normalizedContent)
                    .url(source.getUrl())
                    .publishedDate(null) // 웹 페이지는 게시일 정보가 없음
                    .contentHash(contentHash)
                    .metadataJson(metadataJson)
                    .processed(false)
                    .hasContent(true)
                    .duplicate(false)
                    .normalized(true)
                    .build();

            results.add(data);
            log.info("Successfully scraped web page: {} ({} chars, method={})", source.getName(), normalizedContent.length(), method);

        } catch (Exception e) {
            log.error("Error scraping web page {}: {}", source.getUrl(), e.getMessage(), e);
        }

        return results;
    }

    /**
     * CSS 셀렉터로 특정 콘텐츠 추출 (메타데이터에 제공된 경우)
     */
    public String extractWithSelector(Document doc, String cssSelector) {
        if (cssSelector == null || cssSelector.isBlank()) {
            return doc.body().text();
        }

        try {
            return doc.select(cssSelector).text();
        } catch (Exception e) {
            log.warn("CSS 셀렉터 사용 오류 {}: {}", cssSelector, e.getMessage());
            return doc.body().text();
        }
    }
}


```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/WorkspaceFileService.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.entity.workspace.WorkspaceFile;
import com.newsinsight.collector.repository.WorkspaceFileRepository;
import lombok.Builder;
import lombok.Data;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.core.io.Resource;
import org.springframework.core.io.UrlResource;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.PageRequest;
import org.springframework.data.domain.Pageable;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;
import org.springframework.util.StringUtils;
import org.springframework.web.multipart.MultipartFile;

import jakarta.annotation.PostConstruct;
import java.io.IOException;
import java.io.InputStream;
import java.net.MalformedURLException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.nio.file.StandardCopyOption;
import java.security.MessageDigest;
import java.security.NoSuchAlgorithmException;
import java.time.LocalDateTime;
import java.time.format.DateTimeFormatter;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import java.util.UUID;

/**
 * Service for managing workspace files.
 * Handles file upload, download, deletion and metadata management.
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class WorkspaceFileService {

    private final WorkspaceFileRepository fileRepository;

    @Value("${workspace.storage.path:/data/workspace}")
    private String storagePath;

    @Value("${workspace.storage.max-file-size:104857600}") // 100MB default
    private long maxFileSize;

    @Value("${workspace.storage.max-files-per-session:100}")
    private int maxFilesPerSession;

    @Value("${workspace.storage.session-file-ttl-hours:24}")
    private int sessionFileTtlHours;

    private Path rootLocation;

    @PostConstruct
    public void init() {
        this.rootLocation = Paths.get(storagePath);
        try {
            Files.createDirectories(rootLocation);
            log.info("Workspace storage initialized at: {}", rootLocation.toAbsolutePath());
        } catch (IOException e) {
            log.warn("Could not initialize workspace storage location at {}: {}. Workspace file features will be disabled.", 
                    rootLocation.toAbsolutePath(), e.getMessage());
            // Don't throw exception - allow service to start without workspace storage
            this.rootLocation = null;
        }
    }

    // ============================================
    // File Upload
    // ============================================

    /**
     * Upload a file for session-based user.
     */
    @Transactional
    public WorkspaceFile uploadFile(MultipartFile file, String sessionId, UploadRequest request) {
        return uploadFileInternal(file, sessionId, null, request);
    }

    /**
     * Upload a file for authenticated user.
     */
    @Transactional
    public WorkspaceFile uploadFileForUser(MultipartFile file, String userId, UploadRequest request) {
        return uploadFileInternal(file, null, userId, request);
    }

    /**
     * Internal upload logic.
     */
    private WorkspaceFile uploadFileInternal(MultipartFile file, String sessionId, String userId, UploadRequest request) {
        // Check if storage is available
        if (rootLocation == null) {
            throw new RuntimeException("Workspace storage is not available. Please check server configuration.");
        }
        
        // Validate file
        validateFile(file, sessionId, userId);

        String originalFilename = StringUtils.cleanPath(file.getOriginalFilename());
        String extension = getFileExtension(originalFilename);
        String storedName = generateStoredName(extension);
        String relativePath = generateRelativePath(sessionId, userId, storedName);
        Path targetPath = rootLocation.resolve(relativePath);

        try {
            // Create directories if needed
            Files.createDirectories(targetPath.getParent());

            // Calculate checksum
            String checksum = calculateChecksum(file.getInputStream());

            // Check for duplicate (same file already uploaded)
            Optional<WorkspaceFile> existing = fileRepository.findByChecksumAndOwner(checksum, sessionId, userId);
            if (existing.isPresent()) {
                log.info("Duplicate file detected, returning existing: {}", existing.get().getFileUuid());
                return existing.get();
            }

            // Save file to disk
            Files.copy(file.getInputStream(), targetPath, StandardCopyOption.REPLACE_EXISTING);
            log.info("File saved to: {}", targetPath);

            // Create entity
            WorkspaceFile workspaceFile = WorkspaceFile.builder()
                    .fileUuid(UUID.randomUUID().toString())
                    .sessionId(sessionId)
                    .userId(userId)
                    .projectId(request != null ? request.getProjectId() : null)
                    .originalName(originalFilename)
                    .storedName(storedName)
                    .extension(extension)
                    .mimeType(file.getContentType())
                    .fileSize(file.getSize())
                    .fileType(WorkspaceFile.determineFileType(extension))
                    .storageType(WorkspaceFile.StorageType.LOCAL)
                    .storagePath(relativePath)
                    .status(WorkspaceFile.FileStatus.ACTIVE)
                    .description(request != null ? request.getDescription() : null)
                    .checksum(checksum)
                    .downloadCount(0)
                    .expiresAt(sessionId != null ? LocalDateTime.now().plusHours(sessionFileTtlHours) : null)
                    .metadata(request != null ? request.getMetadata() : null)
                    .build();

            WorkspaceFile saved = fileRepository.save(workspaceFile);
            log.info("Workspace file created: id={}, uuid={}, name='{}', size={}", 
                    saved.getId(), saved.getFileUuid(), saved.getOriginalName(), saved.getHumanReadableSize());

            return saved;

        } catch (IOException e) {
            log.error("Failed to store file: {}", originalFilename, e);
            throw new RuntimeException("Failed to store file: " + originalFilename, e);
        }
    }

    // ============================================
    // File Download
    // ============================================

    /**
     * Get file for download.
     */
    @Transactional
    public FileDownloadResponse getFileForDownload(String fileUuid, String sessionId, String userId) {
        WorkspaceFile file = fileRepository.findActiveByFileUuid(fileUuid)
                .orElseThrow(() -> new IllegalArgumentException("File not found: " + fileUuid));

        // Check access
        if (!file.isAccessibleBy(sessionId, userId)) {
            throw new IllegalStateException("Access denied to file: " + fileUuid);
        }

        // Check expiration
        if (file.isExpired()) {
            throw new IllegalStateException("File has expired: " + fileUuid);
        }

        // Load file resource
        try {
            Path filePath = rootLocation.resolve(file.getStoragePath());
            Resource resource = new UrlResource(filePath.toUri());

            if (!resource.exists() || !resource.isReadable()) {
                throw new RuntimeException("Could not read file: " + fileUuid);
            }

            // Update download count
            fileRepository.incrementDownloadCount(file.getId(), LocalDateTime.now());

            return FileDownloadResponse.builder()
                    .resource(resource)
                    .filename(file.getOriginalName())
                    .contentType(file.getMimeType())
                    .fileSize(file.getFileSize())
                    .build();

        } catch (MalformedURLException e) {
            throw new RuntimeException("Could not read file: " + fileUuid, e);
        }
    }

    /**
     * Get file metadata.
     */
    public Optional<WorkspaceFile> getFile(String fileUuid) {
        return fileRepository.findActiveByFileUuid(fileUuid);
    }

    /**
     * Get file metadata with access check.
     */
    public Optional<WorkspaceFile> getFileWithAccess(String fileUuid, String sessionId, String userId) {
        return fileRepository.findActiveByFileUuid(fileUuid)
                .filter(f -> f.isAccessibleBy(sessionId, userId));
    }

    // ============================================
    // File Listing
    // ============================================

    /**
     * List files for session.
     */
    public Page<WorkspaceFile> listFilesForSession(String sessionId, int page, int size) {
        Pageable pageable = PageRequest.of(page, size);
        return fileRepository.findBySessionIdAndStatusOrderByCreatedAtDesc(
                sessionId, WorkspaceFile.FileStatus.ACTIVE, pageable);
    }

    /**
     * List files for user.
     */
    public Page<WorkspaceFile> listFilesForUser(String userId, int page, int size) {
        Pageable pageable = PageRequest.of(page, size);
        return fileRepository.findByUserIdAndStatusOrderByCreatedAtDesc(
                userId, WorkspaceFile.FileStatus.ACTIVE, pageable);
    }

    /**
     * List files for project.
     */
    public Page<WorkspaceFile> listFilesForProject(Long projectId, int page, int size) {
        Pageable pageable = PageRequest.of(page, size);
        return fileRepository.findByProjectIdAndStatusOrderByCreatedAtDesc(
                projectId, WorkspaceFile.FileStatus.ACTIVE, pageable);
    }

    /**
     * List files by type for session.
     */
    public Page<WorkspaceFile> listFilesByTypeForSession(String sessionId, WorkspaceFile.FileType fileType, int page, int size) {
        Pageable pageable = PageRequest.of(page, size);
        return fileRepository.findBySessionIdAndFileTypeAndStatus(
                sessionId, fileType, WorkspaceFile.FileStatus.ACTIVE, pageable);
    }

    /**
     * Search files for session.
     */
    public Page<WorkspaceFile> searchFilesForSession(String sessionId, String query, int page, int size) {
        Pageable pageable = PageRequest.of(page, size);
        return fileRepository.searchByNameForSession(sessionId, query, pageable);
    }

    /**
     * Search files for user.
     */
    public Page<WorkspaceFile> searchFilesForUser(String userId, String query, int page, int size) {
        Pageable pageable = PageRequest.of(page, size);
        return fileRepository.searchByNameForUser(userId, query, pageable);
    }

    // ============================================
    // File Deletion
    // ============================================

    /**
     * Delete file (soft delete).
     */
    @Transactional
    public void deleteFile(String fileUuid, String sessionId, String userId) {
        WorkspaceFile file = fileRepository.findActiveByFileUuid(fileUuid)
                .orElseThrow(() -> new IllegalArgumentException("File not found: " + fileUuid));

        // Check access
        if (!file.isAccessibleBy(sessionId, userId)) {
            throw new IllegalStateException("Access denied to file: " + fileUuid);
        }

        // Soft delete
        fileRepository.updateStatus(file.getId(), WorkspaceFile.FileStatus.DELETED, LocalDateTime.now());
        log.info("File marked as deleted: uuid={}, name='{}'", fileUuid, file.getOriginalName());
    }

    /**
     * Permanently delete file (hard delete).
     */
    @Transactional
    public void permanentlyDeleteFile(Long fileId) {
        WorkspaceFile file = fileRepository.findById(fileId)
                .orElseThrow(() -> new IllegalArgumentException("File not found: " + fileId));

        // Delete physical file
        try {
            Path filePath = rootLocation.resolve(file.getStoragePath());
            Files.deleteIfExists(filePath);
            log.info("Physical file deleted: {}", filePath);
        } catch (IOException e) {
            log.error("Failed to delete physical file: {}", file.getStoragePath(), e);
        }

        // Delete database record
        fileRepository.delete(file);
        log.info("File permanently deleted: id={}, name='{}'", fileId, file.getOriginalName());
    }

    /**
     * Delete all files for session.
     */
    @Transactional
    public void deleteAllFilesForSession(String sessionId) {
        fileRepository.markDeletedBySessionId(sessionId, LocalDateTime.now());
        log.info("All files marked as deleted for session: {}", sessionId);
    }

    // ============================================
    // File Migration (Session to User)
    // ============================================

    /**
     * Transfer session files to user (when anonymous user logs in).
     */
    @Transactional
    public int transferSessionFilesToUser(String sessionId, String userId) {
        long count = fileRepository.countBySessionIdAndStatus(sessionId, WorkspaceFile.FileStatus.ACTIVE);
        
        if (count > 0) {
            fileRepository.transferSessionFilesToUser(sessionId, userId, LocalDateTime.now());
            log.info("Transferred {} files from session {} to user {}", count, sessionId, userId);
        }
        
        return (int) count;
    }

    // ============================================
    // Cleanup
    // ============================================

    /**
     * Cleanup expired files.
     */
    @Transactional
    public int cleanupExpiredFiles() {
        List<WorkspaceFile> expired = fileRepository.findExpiredFiles(LocalDateTime.now());
        
        for (WorkspaceFile file : expired) {
            fileRepository.updateStatus(file.getId(), WorkspaceFile.FileStatus.PENDING_DELETE, LocalDateTime.now());
        }
        
        log.info("Marked {} expired files for deletion", expired.size());
        return expired.size();
    }

    /**
     * Cleanup old session files (orphaned anonymous files).
     */
    @Transactional
    public int cleanupOldSessionFiles(int olderThanHours) {
        LocalDateTime threshold = LocalDateTime.now().minusHours(olderThanHours);
        List<WorkspaceFile> oldFiles = fileRepository.findOldSessionFiles(threshold);
        
        for (WorkspaceFile file : oldFiles) {
            fileRepository.updateStatus(file.getId(), WorkspaceFile.FileStatus.PENDING_DELETE, LocalDateTime.now());
        }
        
        log.info("Marked {} old session files for deletion", oldFiles.size());
        return oldFiles.size();
    }

    /**
     * Permanently delete files marked for deletion.
     */
    @Transactional
    public int purgeDeletedFiles() {
        List<WorkspaceFile> pendingDelete = fileRepository.findByStatus(WorkspaceFile.FileStatus.PENDING_DELETE);
        List<WorkspaceFile> deleted = fileRepository.findByStatus(WorkspaceFile.FileStatus.DELETED);
        
        int count = 0;
        for (WorkspaceFile file : pendingDelete) {
            permanentlyDeleteFile(file.getId());
            count++;
        }
        for (WorkspaceFile file : deleted) {
            permanentlyDeleteFile(file.getId());
            count++;
        }
        
        log.info("Purged {} files permanently", count);
        return count;
    }

    // ============================================
    // Statistics
    // ============================================

    /**
     * Get storage statistics for session.
     */
    public StorageStats getStorageStatsForSession(String sessionId) {
        long fileCount = fileRepository.countBySessionIdAndStatus(sessionId, WorkspaceFile.FileStatus.ACTIVE);
        long totalSize = fileRepository.sumFileSizeBySessionId(sessionId);
        
        return StorageStats.builder()
                .fileCount(fileCount)
                .totalSize(totalSize)
                .maxFiles(maxFilesPerSession)
                .maxFileSize(maxFileSize)
                .build();
    }

    /**
     * Get storage statistics for user.
     */
    public StorageStats getStorageStatsForUser(String userId) {
        long fileCount = fileRepository.countByUserIdAndStatus(userId, WorkspaceFile.FileStatus.ACTIVE);
        long totalSize = fileRepository.sumFileSizeByUserId(userId);
        
        return StorageStats.builder()
                .fileCount(fileCount)
                .totalSize(totalSize)
                .maxFiles(-1) // No limit for users
                .maxFileSize(maxFileSize)
                .build();
    }

    // ============================================
    // Helper Methods
    // ============================================

    private void validateFile(MultipartFile file, String sessionId, String userId) {
        if (file == null || file.isEmpty()) {
            throw new IllegalArgumentException("File is empty");
        }

        if (file.getSize() > maxFileSize) {
            throw new IllegalArgumentException(
                    String.format("File size exceeds maximum allowed (%d bytes)", maxFileSize));
        }

        // Check file count limit for session
        if (sessionId != null) {
            long currentCount = fileRepository.countBySessionIdAndStatus(sessionId, WorkspaceFile.FileStatus.ACTIVE);
            if (currentCount >= maxFilesPerSession) {
                throw new IllegalStateException(
                        String.format("Maximum file limit reached (%d files)", maxFilesPerSession));
            }
        }
    }

    private String getFileExtension(String filename) {
        if (filename == null) return "";
        int dotIndex = filename.lastIndexOf('.');
        return dotIndex > 0 ? filename.substring(dotIndex + 1).toLowerCase() : "";
    }

    private String generateStoredName(String extension) {
        String uuid = UUID.randomUUID().toString().replace("-", "");
        return extension.isEmpty() ? uuid : uuid + "." + extension;
    }

    private String generateRelativePath(String sessionId, String userId, String storedName) {
        String datePath = LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyy/MM/dd"));
        String ownerPath = userId != null ? "users/" + userId : "sessions/" + sessionId;
        return ownerPath + "/" + datePath + "/" + storedName;
    }

    private String calculateChecksum(InputStream inputStream) {
        try {
            MessageDigest digest = MessageDigest.getInstance("SHA-256");
            byte[] buffer = new byte[8192];
            int bytesRead;
            
            inputStream.mark(Integer.MAX_VALUE);
            while ((bytesRead = inputStream.read(buffer)) != -1) {
                digest.update(buffer, 0, bytesRead);
            }
            inputStream.reset();
            
            byte[] hashBytes = digest.digest();
            StringBuilder sb = new StringBuilder();
            for (byte b : hashBytes) {
                sb.append(String.format("%02x", b));
            }
            return sb.toString();
        } catch (NoSuchAlgorithmException | IOException e) {
            log.warn("Failed to calculate checksum", e);
            return null;
        }
    }

    // ============================================
    // DTOs
    // ============================================

    @Data
    @Builder
    public static class UploadRequest {
        private Long projectId;
        private String description;
        private Map<String, Object> metadata;
    }

    @Data
    @Builder
    public static class FileDownloadResponse {
        private Resource resource;
        private String filename;
        private String contentType;
        private Long fileSize;
    }

    @Data
    @Builder
    public static class StorageStats {
        private long fileCount;
        private long totalSize;
        private int maxFiles;
        private long maxFileSize;
        
        public String getHumanReadableTotalSize() {
            if (totalSize < 1024) return totalSize + " B";
            if (totalSize < 1024 * 1024) return String.format("%.1f KB", totalSize / 1024.0);
            if (totalSize < 1024 * 1024 * 1024) return String.format("%.1f MB", totalSize / (1024.0 * 1024));
            return String.format("%.1f GB", totalSize / (1024.0 * 1024 * 1024));
        }
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/autocrawl/AutoCrawlDiscoveryService.java

```java
package com.newsinsight.collector.service.autocrawl;

import com.newsinsight.collector.entity.CollectedData;
import com.newsinsight.collector.entity.autocrawl.ContentType;
import com.newsinsight.collector.entity.autocrawl.CrawlTarget;
import com.newsinsight.collector.entity.autocrawl.CrawlTargetStatus;
import com.newsinsight.collector.entity.autocrawl.DiscoverySource;
import com.newsinsight.collector.repository.CrawlTargetRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.nodes.Element;
import org.jsoup.select.Elements;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.net.URI;
import java.nio.charset.StandardCharsets;
import java.security.MessageDigest;
import java.security.NoSuchAlgorithmException;
import java.time.LocalDateTime;
import java.util.*;
import java.util.regex.Pattern;
import java.util.stream.Collectors;

/**
 * 자동 크롤링 대상 URL 발견 서비스.
 * 
 * 검색 결과, 기사 내 링크, 트렌딩 토픽 등에서 크롤링 대상 URL을 자동으로 발견합니다.
 * 발견된 URL은 CrawlTarget 엔티티로 저장되어 크롤링 큐에 추가됩니다.
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class AutoCrawlDiscoveryService {

    private final CrawlTargetRepository crawlTargetRepository;

    // ========================================
    // URL 패턴 매칭
    // ========================================
    
    /**
     * 뉴스 URL 패턴 (한국 주요 언론사)
     */
    private static final Pattern NEWS_URL_PATTERN = Pattern.compile(
            ".*(?:news\\.naver\\.com|news\\.daum\\.net|news\\.kakao\\.com|" +
            "n\\.news\\.naver\\.com|v\\.media\\.daum\\.net|" +
            "chosun\\.com|donga\\.com|joongang\\.co\\.kr|hani\\.co\\.kr|" +
            "khan\\.co\\.kr|yna\\.co\\.kr|yonhapnews\\.co\\.kr|" +
            "hankookilbo\\.com|mk\\.co\\.kr|mt\\.co\\.kr|sedaily\\.com|" +
            "etnews\\.com|zdnet\\.co\\.kr|inews24\\.com|itworld\\.co\\.kr|" +
            "bloter\\.net|techholic\\.co\\.kr|" +
            "reuters\\.com|apnews\\.com|bbc\\.com\\/news|cnn\\.com).*"
    );

    /**
     * 제외할 URL 패턴 (광고, 로그인, 정적 리소스 등)
     */
    private static final Pattern EXCLUDED_URL_PATTERN = Pattern.compile(
            ".*(?:login|logout|signin|signup|register|auth|oauth|" +
            "advertisement|ad\\.|ads\\.|banner|popup|tracking|" +
            "\\.css|\\.js|\\.jpg|\\.jpeg|\\.png|\\.gif|\\.ico|\\.svg|\\.webp|" +
            "\\.pdf|\\.doc|\\.xls|\\.ppt|\\.zip|\\.rar|" +
            "facebook\\.com|twitter\\.com|instagram\\.com|youtube\\.com|" +
            "play\\.google\\.com|apps\\.apple\\.com|" +
            "javascript:|mailto:|tel:|#).*",
            Pattern.CASE_INSENSITIVE
    );

    /**
     * 도메인별 콘텐츠 타입 매핑
     */
    private static final Map<Pattern, ContentType> DOMAIN_CONTENT_TYPE_MAP = Map.of(
            Pattern.compile(".*(?:news\\.naver|news\\.daum|chosun|donga|joongang|hani|khan|yna).*"), ContentType.NEWS,
            Pattern.compile(".*(?:blog\\.naver|tistory|brunch|velog|medium).*"), ContentType.BLOG,
            Pattern.compile(".*(?:reddit|dcinside|ruliweb|clien|ppomppu).*"), ContentType.FORUM,
            Pattern.compile(".*(?:twitter|x\\.com|facebook|instagram).*"), ContentType.SOCIAL,
            Pattern.compile(".*(?:\\.go\\.kr|\\.or\\.kr|\\.gov\\.|assembly).*"), ContentType.OFFICIAL,
            Pattern.compile(".*(?:arxiv|scholar\\.google|dbpia|riss|sciencedirect).*"), ContentType.ACADEMIC
    );

    // ========================================
    // 검색 결과에서 URL 발견
    // ========================================

    /**
     * 검색 쿼리와 검색 결과 HTML에서 URL 발견
     * 
     * @param query 검색 쿼리
     * @param htmlContent 검색 결과 HTML
     * @param baseUrl 검색 페이지 URL (상대 경로 해결용)
     * @return 발견된 CrawlTarget 목록
     */
    @Transactional
    public List<CrawlTarget> discoverFromSearchResult(String query, String htmlContent, String baseUrl) {
        log.info("Discovering URLs from search result for query: '{}'", query);
        
        List<String> extractedUrls = extractUrlsFromHtml(htmlContent, baseUrl);
        List<CrawlTarget> targets = new ArrayList<>();
        
        for (String url : extractedUrls) {
            if (!isValidCrawlUrl(url)) {
                continue;
            }
            
            CrawlTarget target = createOrUpdateTarget(
                    url,
                    DiscoverySource.SEARCH,
                    "search_query:" + query,
                    calculateSearchPriority(url, query),
                    query
            );
            
            if (target != null) {
                targets.add(target);
            }
        }
        
        log.info("Discovered {} URLs from search result for query: '{}'", targets.size(), query);
        return targets;
    }

    /**
     * 검색 결과 URL 목록에서 직접 발견
     */
    @Transactional
    public List<CrawlTarget> discoverFromSearchUrls(String query, List<String> urls) {
        log.info("Discovering from {} search result URLs for query: '{}'", urls.size(), query);
        
        List<CrawlTarget> targets = new ArrayList<>();
        
        for (String url : urls) {
            if (!isValidCrawlUrl(url)) {
                continue;
            }
            
            CrawlTarget target = createOrUpdateTarget(
                    url,
                    DiscoverySource.SEARCH,
                    "search_query:" + query,
                    calculateSearchPriority(url, query),
                    query
            );
            
            if (target != null) {
                targets.add(target);
            }
        }
        
        return targets;
    }

    // ========================================
    // 기사 내 링크에서 URL 발견
    // ========================================

    /**
     * 수집된 기사 콘텐츠에서 외부 링크 발견
     * 
     * @param collectedData 수집된 기사 데이터
     * @return 발견된 CrawlTarget 목록
     */
    @Transactional
    public List<CrawlTarget> discoverFromArticle(CollectedData collectedData) {
        if (collectedData.getContent() == null || collectedData.getContent().isBlank()) {
            return Collections.emptyList();
        }
        
        log.debug("Discovering URLs from article: id={}, url={}", 
                collectedData.getId(), collectedData.getUrl());
        
        List<String> extractedUrls = extractUrlsFromHtml(collectedData.getContent(), collectedData.getUrl());
        List<CrawlTarget> targets = new ArrayList<>();
        
        String context = "article_id:" + collectedData.getId();
        String keywords = collectedData.getTitle(); // 기사 제목을 키워드로 사용
        
        for (String url : extractedUrls) {
            if (!isValidCrawlUrl(url)) {
                continue;
            }
            
            // 같은 도메인 링크는 낮은 우선순위
            int priority = isSameDomain(url, collectedData.getUrl()) ? 30 : 50;
            
            CrawlTarget target = createOrUpdateTarget(
                    url,
                    DiscoverySource.ARTICLE_LINK,
                    context,
                    priority,
                    keywords
            );
            
            if (target != null) {
                targets.add(target);
            }
        }
        
        log.debug("Discovered {} URLs from article: id={}", targets.size(), collectedData.getId());
        return targets;
    }

    // ========================================
    // 트렌딩 토픽에서 URL 발견
    // ========================================

    /**
     * 트렌딩 키워드에서 URL 발견 (포털 실시간 검색어 등)
     */
    @Transactional
    public List<CrawlTarget> discoverFromTrendingTopic(String topic, List<String> relatedUrls) {
        log.info("Discovering from trending topic: '{}' with {} URLs", topic, relatedUrls.size());
        
        List<CrawlTarget> targets = new ArrayList<>();
        
        for (String url : relatedUrls) {
            if (!isValidCrawlUrl(url)) {
                continue;
            }
            
            // 트렌딩 토픽은 높은 우선순위
            CrawlTarget target = createOrUpdateTarget(
                    url,
                    DiscoverySource.TRENDING,
                    "trending_topic:" + topic,
                    80,
                    topic
            );
            
            if (target != null) {
                targets.add(target);
            }
        }
        
        return targets;
    }

    // ========================================
    // Deep Search 결과에서 URL 발견
    // ========================================

    /**
     * Deep Search 결과에서 URL 발견
     */
    @Transactional
    public List<CrawlTarget> discoverFromDeepSearch(String searchId, String query, List<String> urls) {
        log.info("Discovering from deep search: id={}, query='{}', urls={}", searchId, query, urls.size());
        
        List<CrawlTarget> targets = new ArrayList<>();
        
        for (String url : urls) {
            if (!isValidCrawlUrl(url)) {
                continue;
            }
            
            // Deep Search는 높은 우선순위
            CrawlTarget target = createOrUpdateTarget(
                    url,
                    DiscoverySource.DEEP_SEARCH,
                    "deep_search:" + searchId,
                    75,
                    query
            );
            
            if (target != null) {
                targets.add(target);
            }
        }
        
        return targets;
    }

    // ========================================
    // AI 추천 URL 발견
    // ========================================

    /**
     * AI가 추천한 URL 발견
     */
    @Transactional
    public List<CrawlTarget> discoverFromAiRecommendation(String context, List<String> urls, String keywords) {
        log.info("Discovering from AI recommendation: {} URLs", urls.size());
        
        List<CrawlTarget> targets = new ArrayList<>();
        
        for (String url : urls) {
            if (!isValidCrawlUrl(url)) {
                continue;
            }
            
            CrawlTarget target = createOrUpdateTarget(
                    url,
                    DiscoverySource.AI_RECOMMENDATION,
                    "ai_context:" + context,
                    70,
                    keywords
            );
            
            if (target != null) {
                targets.add(target);
            }
        }
        
        return targets;
    }

    // ========================================
    // 수동 URL 추가
    // ========================================

    /**
     * 수동으로 URL 추가
     */
    @Transactional
    public CrawlTarget addManualTarget(String url, String keywords, int priority) {
        if (!isValidCrawlUrl(url)) {
            throw new IllegalArgumentException("Invalid URL: " + url);
        }
        
        return createOrUpdateTarget(
                url,
                DiscoverySource.MANUAL,
                "manual_add:" + LocalDateTime.now(),
                Math.min(100, Math.max(0, priority)),
                keywords
        );
    }

    /**
     * 수동으로 여러 URL 추가
     */
    @Transactional
    public List<CrawlTarget> addManualTargets(List<String> urls, String keywords, int priority) {
        return urls.stream()
                .filter(this::isValidCrawlUrl)
                .map(url -> createOrUpdateTarget(
                        url,
                        DiscoverySource.MANUAL,
                        "manual_add:" + LocalDateTime.now(),
                        Math.min(100, Math.max(0, priority)),
                        keywords))
                .filter(Objects::nonNull)
                .toList();
    }

    // ========================================
    // 내부 유틸리티 메서드
    // ========================================

    /**
     * HTML에서 URL 추출
     */
    private List<String> extractUrlsFromHtml(String htmlContent, String baseUrl) {
        if (htmlContent == null || htmlContent.isBlank()) {
            return Collections.emptyList();
        }
        
        Set<String> urls = new LinkedHashSet<>();
        
        try {
            Document doc = Jsoup.parse(htmlContent, baseUrl != null ? baseUrl : "");
            
            // <a> 태그에서 href 추출
            Elements links = doc.select("a[href]");
            for (Element link : links) {
                String href = link.absUrl("href");
                if (!href.isBlank()) {
                    urls.add(normalizeUrl(href));
                }
            }
            
            // 추가로 텍스트에서 URL 패턴 추출
            String text = doc.text();
            Pattern urlPattern = Pattern.compile("https?://[\\w\\-._~:/?#\\[\\]@!$&'()*+,;=%]+");
            var matcher = urlPattern.matcher(text);
            while (matcher.find()) {
                String url = matcher.group();
                urls.add(normalizeUrl(url));
            }
            
        } catch (Exception e) {
            log.warn("Failed to parse HTML for URL extraction: {}", e.getMessage());
        }
        
        return new ArrayList<>(urls);
    }

    /**
     * URL 정규화
     */
    private String normalizeUrl(String url) {
        if (url == null) return null;
        
        // Fragment 제거 (#...)
        int fragmentIndex = url.indexOf('#');
        if (fragmentIndex > 0) {
            url = url.substring(0, fragmentIndex);
        }
        
        // 후행 슬래시 정규화
        if (url.endsWith("/")) {
            url = url.substring(0, url.length() - 1);
        }
        
        return url.trim();
    }

    /**
     * URL 해시 생성
     */
    private String computeUrlHash(String url) {
        try {
            MessageDigest digest = MessageDigest.getInstance("SHA-256");
            byte[] hash = digest.digest(url.getBytes(StandardCharsets.UTF_8));
            StringBuilder hexString = new StringBuilder();
            for (byte b : hash) {
                String hex = Integer.toHexString(0xff & b);
                if (hex.length() == 1) hexString.append('0');
                hexString.append(hex);
            }
            return hexString.toString();
        } catch (NoSuchAlgorithmException e) {
            throw new RuntimeException("SHA-256 not available", e);
        }
    }

    /**
     * 도메인 추출
     */
    private String extractDomain(String url) {
        try {
            URI uri = URI.create(url);
            return uri.getHost();
        } catch (Exception e) {
            return null;
        }
    }

    /**
     * 같은 도메인인지 확인
     */
    private boolean isSameDomain(String url1, String url2) {
        String domain1 = extractDomain(url1);
        String domain2 = extractDomain(url2);
        return domain1 != null && domain1.equals(domain2);
    }

    /**
     * 유효한 크롤링 대상 URL인지 확인
     */
    private boolean isValidCrawlUrl(String url) {
        if (url == null || url.isBlank()) {
            return false;
        }
        
        // HTTP/HTTPS만 허용
        if (!url.startsWith("http://") && !url.startsWith("https://")) {
            return false;
        }
        
        // 제외 패턴 체크
        if (EXCLUDED_URL_PATTERN.matcher(url).matches()) {
            return false;
        }
        
        return true;
    }

    /**
     * 콘텐츠 타입 추정
     */
    private ContentType inferContentType(String url) {
        for (var entry : DOMAIN_CONTENT_TYPE_MAP.entrySet()) {
            if (entry.getKey().matcher(url).matches()) {
                return entry.getValue();
            }
        }
        return ContentType.UNKNOWN;
    }

    /**
     * 검색 우선순위 계산
     */
    private int calculateSearchPriority(String url, String query) {
        int priority = 50; // 기본값
        
        // 뉴스 URL은 우선순위 상승
        if (NEWS_URL_PATTERN.matcher(url).matches()) {
            priority += 20;
        }
        
        // URL에 검색어가 포함되면 우선순위 상승
        String lowerUrl = url.toLowerCase();
        if (query != null && !query.isBlank()) {
            for (String keyword : query.toLowerCase().split("\\s+")) {
                if (keyword.length() >= 2 && lowerUrl.contains(keyword)) {
                    priority += 5;
                }
            }
        }
        
        return Math.min(100, priority);
    }

    /**
     * CrawlTarget 생성 또는 업데이트
     */
    private CrawlTarget createOrUpdateTarget(
            String url,
            DiscoverySource source,
            String context,
            int priority,
            String keywords) {
        
        String urlHash = computeUrlHash(url);
        
        Optional<CrawlTarget> existingOpt = crawlTargetRepository.findByUrlHash(urlHash);
        
        if (existingOpt.isPresent()) {
            CrawlTarget existing = existingOpt.get();
            
            // 이미 완료된 대상은 업데이트하지 않음
            if (existing.getStatus() == CrawlTargetStatus.COMPLETED) {
                return null;
            }
            
            // 우선순위가 더 높으면 업데이트
            if (priority > existing.getPriority()) {
                existing.setPriority(priority);
                
                // 키워드 병합
                if (keywords != null && !keywords.isBlank()) {
                    String existingKeywords = existing.getRelatedKeywords();
                    if (existingKeywords == null || existingKeywords.isBlank()) {
                        existing.setRelatedKeywords(keywords);
                    } else if (!existingKeywords.contains(keywords)) {
                        existing.setRelatedKeywords(existingKeywords + ", " + keywords);
                    }
                }
                
                return crawlTargetRepository.save(existing);
            }
            
            return null; // 변경 없음
        }
        
        // 새 대상 생성
        CrawlTarget target = CrawlTarget.builder()
                .url(url)
                .urlHash(urlHash)
                .discoverySource(source)
                .discoveryContext(context)
                .priority(priority)
                .status(CrawlTargetStatus.PENDING)
                .domain(extractDomain(url))
                .expectedContentType(inferContentType(url))
                .relatedKeywords(keywords)
                .build();
        
        return crawlTargetRepository.save(target);
    }

    // ========================================
    // 통계/조회 메서드
    // ========================================

    /**
     * 대기 중인 대상 수 조회
     */
    public long countPending() {
        return crawlTargetRepository.countByStatus(CrawlTargetStatus.PENDING);
    }

    /**
     * 발견 출처별 통계 조회
     */
    public Map<DiscoverySource, Long> getDiscoveryStats() {
        List<Object[]> stats = crawlTargetRepository.getDiscoveryStatsSince(
                LocalDateTime.now().minusDays(7));
        return stats.stream()
                .collect(Collectors.toMap(
                        row -> (DiscoverySource) row[0],
                        row -> (Long) row[1]
                ));
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/autocrawl/AutoCrawlIntegrationService.java

```java
package com.newsinsight.collector.service.autocrawl;

import com.newsinsight.collector.entity.CollectedData;
import com.newsinsight.collector.entity.autocrawl.CrawlTarget;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.scheduling.annotation.Async;
import org.springframework.stereotype.Service;

import java.util.List;
import java.util.regex.Matcher;
import java.util.regex.Pattern;
import java.util.stream.Collectors;

/**
 * 자동 크롤링 통합 서비스.
 * 
 * 기존 시스템의 이벤트를 수신하여 자동으로 URL을 발견합니다:
 * - 검색 이벤트: 검색 결과에서 URL 발견
 * - 기사 수집 이벤트: 기사 내 링크에서 URL 발견
 * - Deep Search 이벤트: 심층 검색 결과에서 URL 발견
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class AutoCrawlIntegrationService {

    private final AutoCrawlDiscoveryService discoveryService;
    private final CrawlQueueService queueService;

    @Value("${autocrawl.enabled:true}")
    private boolean autoCrawlEnabled;

    @Value("${autocrawl.discover-from-search:true}")
    private boolean discoverFromSearch;

    @Value("${autocrawl.discover-from-articles:true}")
    private boolean discoverFromArticles;

    @Value("${autocrawl.discover-from-deep-search:true}")
    private boolean discoverFromDeepSearch;

    @Value("${autocrawl.min-content-length:200}")
    private int minContentLength;

    // URL 추출 패턴
    private static final Pattern URL_PATTERN = Pattern.compile(
            "https?://[\\w\\-._~:/?#\\[\\]@!$&'()*+,;=%]+",
            Pattern.CASE_INSENSITIVE
    );

    // ========================================
    // 검색 결과에서 URL 발견
    // ========================================

    /**
     * 검색 완료 시 URL 발견
     * UnifiedSearchService의 검색 완료 이벤트에서 호출
     */
    @Async
    public void onSearchCompleted(String query, List<String> resultUrls) {
        if (!autoCrawlEnabled || !discoverFromSearch) {
            return;
        }

        if (resultUrls == null || resultUrls.isEmpty()) {
            return;
        }

        try {
            log.debug("Discovering URLs from search: query='{}', urlCount={}", query, resultUrls.size());
            List<CrawlTarget> targets = discoveryService.discoverFromSearchUrls(query, resultUrls);
            
            if (!targets.isEmpty()) {
                log.info("AutoCrawl: Discovered {} URLs from search query '{}'", targets.size(), query);
            }
        } catch (Exception e) {
            log.warn("Failed to discover URLs from search: query='{}', error={}", query, e.getMessage());
        }
    }

    /**
     * 검색 결과 HTML에서 URL 발견 (더 상세한 발견)
     */
    @Async
    public void onSearchHtmlReceived(String query, String htmlContent, String baseUrl) {
        if (!autoCrawlEnabled || !discoverFromSearch) {
            return;
        }

        if (htmlContent == null || htmlContent.length() < minContentLength) {
            return;
        }

        try {
            List<CrawlTarget> targets = discoveryService.discoverFromSearchResult(query, htmlContent, baseUrl);
            
            if (!targets.isEmpty()) {
                log.info("AutoCrawl: Discovered {} URLs from search HTML for query '{}'", targets.size(), query);
            }
        } catch (Exception e) {
            log.warn("Failed to discover URLs from search HTML: query='{}', error={}", query, e.getMessage());
        }
    }

    // ========================================
    // 수집된 기사에서 URL 발견
    // ========================================

    /**
     * 기사 수집 완료 시 내부 링크 발견
     * CrawlResultConsumerService에서 호출 가능
     */
    @Async
    public void onArticleCollected(CollectedData article) {
        if (!autoCrawlEnabled || !discoverFromArticles) {
            return;
        }

        if (article == null || article.getContent() == null || 
            article.getContent().length() < minContentLength) {
            return;
        }

        try {
            List<CrawlTarget> targets = discoveryService.discoverFromArticle(article);
            
            if (!targets.isEmpty()) {
                log.debug("AutoCrawl: Discovered {} URLs from article id={}", targets.size(), article.getId());
            }
        } catch (Exception e) {
            log.warn("Failed to discover URLs from article: id={}, error={}", 
                    article.getId(), e.getMessage());
        }
    }

    /**
     * 기사 일괄 수집 완료 시 URL 발견
     */
    @Async
    public void onArticlesBatchCollected(List<CollectedData> articles) {
        if (!autoCrawlEnabled || !discoverFromArticles) {
            return;
        }

        if (articles == null || articles.isEmpty()) {
            return;
        }

        int totalDiscovered = 0;
        for (CollectedData article : articles) {
            try {
                if (article.getContent() != null && article.getContent().length() >= minContentLength) {
                    List<CrawlTarget> targets = discoveryService.discoverFromArticle(article);
                    totalDiscovered += targets.size();
                }
            } catch (Exception e) {
                log.warn("Failed to discover URLs from article: id={}, error={}", 
                        article.getId(), e.getMessage());
            }
        }

        if (totalDiscovered > 0) {
            log.info("AutoCrawl: Discovered {} URLs from {} articles", totalDiscovered, articles.size());
        }
    }

    // ========================================
    // Deep Search에서 URL 발견
    // ========================================

    /**
     * Deep Search 완료 시 URL 발견
     */
    @Async
    public void onDeepSearchCompleted(String searchId, String query, List<String> urls) {
        if (!autoCrawlEnabled || !discoverFromDeepSearch) {
            return;
        }

        if (urls == null || urls.isEmpty()) {
            return;
        }

        try {
            List<CrawlTarget> targets = discoveryService.discoverFromDeepSearch(searchId, query, urls);
            
            if (!targets.isEmpty()) {
                log.info("AutoCrawl: Discovered {} URLs from deep search id={}", targets.size(), searchId);
            }
        } catch (Exception e) {
            log.warn("Failed to discover URLs from deep search: id={}, error={}", searchId, e.getMessage());
        }
    }

    /**
     * AI 분석 결과에서 URL 추출 및 발견
     */
    @Async
    public void onAiAnalysisCompleted(String context, String aiResponse, String keywords) {
        if (!autoCrawlEnabled) {
            return;
        }

        if (aiResponse == null || aiResponse.isBlank()) {
            return;
        }

        try {
            // AI 응답에서 URL 추출
            List<String> extractedUrls = extractUrlsFromText(aiResponse);
            
            if (!extractedUrls.isEmpty()) {
                List<CrawlTarget> targets = discoveryService.discoverFromAiRecommendation(
                        context, extractedUrls, keywords);
                
                if (!targets.isEmpty()) {
                    log.info("AutoCrawl: Discovered {} URLs from AI analysis", targets.size());
                }
            }
        } catch (Exception e) {
            log.warn("Failed to discover URLs from AI analysis: error={}", e.getMessage());
        }
    }

    // ========================================
    // 트렌딩 토픽에서 URL 발견
    // ========================================

    /**
     * 트렌딩 토픽 감지 시 URL 발견
     */
    @Async
    public void onTrendingTopicDetected(String topic, List<String> relatedUrls) {
        if (!autoCrawlEnabled) {
            return;
        }

        if (relatedUrls == null || relatedUrls.isEmpty()) {
            return;
        }

        try {
            List<CrawlTarget> targets = discoveryService.discoverFromTrendingTopic(topic, relatedUrls);
            
            if (!targets.isEmpty()) {
                log.info("AutoCrawl: Discovered {} URLs from trending topic '{}'", targets.size(), topic);
                
                // 트렌딩 토픽은 높은 우선순위로 즉시 처리 트리거
                queueService.prioritizeKeyword(topic, 30);
            }
        } catch (Exception e) {
            log.warn("Failed to discover URLs from trending topic: topic='{}', error={}", 
                    topic, e.getMessage());
        }
    }

    // ========================================
    // 크롤링 완료 콜백 처리
    // ========================================

    /**
     * 크롤링 완료 시 결과 처리
     */
    public void onCrawlCompleted(String url, Long collectedDataId) {
        if (!autoCrawlEnabled) {
            return;
        }

        try {
            queueService.handleCrawlCompleteByUrl(url, collectedDataId);
        } catch (Exception e) {
            log.warn("Failed to handle crawl completion: url={}, error={}", url, e.getMessage());
        }
    }

    /**
     * 크롤링 실패 시 결과 처리
     */
    public void onCrawlFailed(String url, String errorMessage) {
        if (!autoCrawlEnabled) {
            return;
        }

        try {
            queueService.handleCrawlFailedByUrl(url, errorMessage);
        } catch (Exception e) {
            log.warn("Failed to handle crawl failure: url={}, error={}", url, e.getMessage());
        }
    }

    // ========================================
    // 유틸리티
    // ========================================

    /**
     * 텍스트에서 URL 추출
     */
    private List<String> extractUrlsFromText(String text) {
        Matcher matcher = URL_PATTERN.matcher(text);
        return matcher.results()
                .map(m -> m.group())
                .distinct()
                .collect(Collectors.toList());
    }

    /**
     * AutoCrawl 활성화 여부 확인
     */
    public boolean isEnabled() {
        return autoCrawlEnabled;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/autocrawl/CrawlQueueService.java

```java
package com.newsinsight.collector.service.autocrawl;

import com.newsinsight.collector.dto.BrowserTaskMessage;
import com.newsinsight.collector.entity.BrowserAgentPolicy;
import com.newsinsight.collector.entity.autocrawl.CrawlTarget;
import com.newsinsight.collector.entity.autocrawl.CrawlTargetStatus;
import com.newsinsight.collector.entity.autocrawl.ContentType;
import com.newsinsight.collector.repository.CrawlTargetRepository;
import lombok.Builder;
import lombok.Data;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.time.LocalDateTime;
import java.util.*;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.stream.Collectors;

/**
 * 크롤링 큐 관리 서비스.
 * 
 * CrawlTarget을 우선순위에 따라 관리하고 autonomous-crawler-service로 작업을 분배합니다.
 * 도메인별 rate limiting, 동시성 제어, 실패 처리를 담당합니다.
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class CrawlQueueService {

    private final CrawlTargetRepository crawlTargetRepository;
    private final KafkaTemplate<String, BrowserTaskMessage> browserTaskKafkaTemplate;

    @Value("${collector.crawl.topic.browser-task:newsinsight.crawl.browser.tasks}")
    private String browserTaskTopic;

    @Value("${collector.browser-agent.callback-base-url:http://localhost:8081}")
    private String browserAgentCallbackBaseUrl;

    @Value("${collector.browser-agent.callback-token:}")
    private String browserAgentCallbackToken;

    @Value("${autocrawl.max-concurrent-per-domain:3}")
    private int maxConcurrentPerDomain;

    @Value("${autocrawl.batch-size:10}")
    private int defaultBatchSize;

    @Value("${autocrawl.stuck-timeout-minutes:30}")
    private int stuckTimeoutMinutes;

    /**
     * 도메인별 진행 중인 크롤링 수 추적
     */
    private final ConcurrentHashMap<String, AtomicInteger> domainConcurrencyMap = new ConcurrentHashMap<>();

    /**
     * 큐 통계용 카운터
     */
    private final AtomicInteger totalDispatched = new AtomicInteger(0);
    private final AtomicInteger totalCompleted = new AtomicInteger(0);
    private final AtomicInteger totalFailed = new AtomicInteger(0);

    // ========================================
    // 큐 처리 메서드
    // ========================================

    /**
     * 대기 중인 대상을 처리하고 크롤러로 분배
     * 
     * @param batchSize 한 번에 처리할 대상 수
     * @return 분배된 대상 수
     */
    @Transactional
    public int processQueue(int batchSize) {
        log.debug("Processing crawl queue with batch size: {}", batchSize);
        
        // 먼저 멈춘 작업 복구
        recoverStuckTargets();
        
        // 대기 중인 대상 조회 (우선순위 순)
        List<CrawlTarget> pendingTargets = crawlTargetRepository.findReadyToCrawl(batchSize);
        
        if (pendingTargets.isEmpty()) {
            log.debug("No pending targets in queue");
            return 0;
        }
        
        int dispatched = 0;
        
        for (CrawlTarget target : pendingTargets) {
            // 도메인별 동시성 체크
            if (!canDispatchForDomain(target.getDomain())) {
                log.debug("Skipping target due to domain concurrency limit: domain={}, url={}",
                        target.getDomain(), target.getUrl());
                continue;
            }
            
            try {
                dispatchTarget(target);
                dispatched++;
            } catch (Exception e) {
                log.error("Failed to dispatch target: id={}, url={}, error={}",
                        target.getId(), target.getUrl(), e.getMessage());
                target.markFailed("Dispatch error: " + e.getMessage());
                crawlTargetRepository.save(target);
            }
        }
        
        log.info("Processed queue: dispatched {} of {} pending targets", dispatched, pendingTargets.size());
        return dispatched;
    }

    /**
     * 기본 배치 사이즈로 큐 처리
     */
    public int processQueue() {
        return processQueue(defaultBatchSize);
    }

    /**
     * 단일 대상 즉시 분배
     */
    @Transactional
    public boolean dispatchSingle(Long targetId) {
        Optional<CrawlTarget> targetOpt = crawlTargetRepository.findById(targetId);
        if (targetOpt.isEmpty()) {
            log.warn("Target not found: id={}", targetId);
            return false;
        }
        
        CrawlTarget target = targetOpt.get();
        if (target.getStatus() != CrawlTargetStatus.PENDING) {
            log.warn("Target is not in PENDING status: id={}, status={}", targetId, target.getStatus());
            return false;
        }
        
        try {
            dispatchTarget(target);
            return true;
        } catch (Exception e) {
            log.error("Failed to dispatch target: id={}", targetId, e);
            return false;
        }
    }

    /**
     * 특정 키워드 관련 대상 우선 처리
     */
    @Transactional
    public int prioritizeKeyword(String keyword, int boostAmount) {
        List<CrawlTarget> targets = crawlTargetRepository.findByRelatedKeywordsContaining(keyword);
        int boosted = 0;
        
        for (CrawlTarget target : targets) {
            if (target.getStatus() == CrawlTargetStatus.PENDING) {
                target.boostPriority(boostAmount);
                crawlTargetRepository.save(target);
                boosted++;
            }
        }
        
        log.info("Boosted priority for {} targets with keyword: '{}'", boosted, keyword);
        return boosted;
    }

    // ========================================
    // 크롤링 결과 처리
    // ========================================

    /**
     * 크롤링 완료 처리
     * autonomous-crawler-service의 콜백에서 호출됨
     */
    @Transactional
    public void handleCrawlComplete(String urlHash, Long collectedDataId) {
        Optional<CrawlTarget> targetOpt = crawlTargetRepository.findByUrlHash(urlHash);
        if (targetOpt.isEmpty()) {
            log.debug("Target not found for completion: urlHash={}", urlHash);
            return;
        }
        
        CrawlTarget target = targetOpt.get();
        target.markCompleted(collectedDataId);
        crawlTargetRepository.save(target);
        
        // 도메인 동시성 카운터 감소
        decrementDomainConcurrency(target.getDomain());
        
        totalCompleted.incrementAndGet();
        log.info("Crawl completed: id={}, url={}, collectedDataId={}",
                target.getId(), target.getUrl(), collectedDataId);
    }

    /**
     * 크롤링 실패 처리
     */
    @Transactional
    public void handleCrawlFailed(String urlHash, String errorMessage) {
        Optional<CrawlTarget> targetOpt = crawlTargetRepository.findByUrlHash(urlHash);
        if (targetOpt.isEmpty()) {
            log.debug("Target not found for failure: urlHash={}", urlHash);
            return;
        }
        
        CrawlTarget target = targetOpt.get();
        target.markFailed(errorMessage);
        crawlTargetRepository.save(target);
        
        // 도메인 동시성 카운터 감소
        decrementDomainConcurrency(target.getDomain());
        
        totalFailed.incrementAndGet();
        log.info("Crawl failed: id={}, url={}, error={}, retryCount={}",
                target.getId(), target.getUrl(), errorMessage, target.getRetryCount());
    }

    /**
     * URL로 완료/실패 처리 (URL 해시 계산 필요)
     */
    @Transactional
    public void handleCrawlCompleteByUrl(String url, Long collectedDataId) {
        String urlHash = computeUrlHash(url);
        handleCrawlComplete(urlHash, collectedDataId);
    }

    @Transactional
    public void handleCrawlFailedByUrl(String url, String errorMessage) {
        String urlHash = computeUrlHash(url);
        handleCrawlFailed(urlHash, errorMessage);
    }

    // ========================================
    // 큐 관리 메서드
    // ========================================

    /**
     * 멈춘 작업 복구 (IN_PROGRESS 상태로 오래 방치된 경우)
     */
    @Transactional
    public int recoverStuckTargets() {
        LocalDateTime timeout = LocalDateTime.now().minusMinutes(stuckTimeoutMinutes);
        int recovered = crawlTargetRepository.recoverStuckTargets(timeout);
        
        if (recovered > 0) {
            log.warn("Recovered {} stuck targets (timeout: {} minutes)", recovered, stuckTimeoutMinutes);
        }
        
        return recovered;
    }

    /**
     * 오래된 완료/실패 대상 정리
     */
    @Transactional
    public int cleanupOldTargets(int daysOld) {
        LocalDateTime cutoff = LocalDateTime.now().minusDays(daysOld);
        int deleted = crawlTargetRepository.deleteOldTargets(
                List.of(CrawlTargetStatus.COMPLETED, CrawlTargetStatus.FAILED, CrawlTargetStatus.SKIPPED),
                cutoff);
        
        log.info("Cleaned up {} old targets (older than {} days)", deleted, daysOld);
        return deleted;
    }

    /**
     * 오래 대기 중인 대상 만료 처리
     */
    @Transactional
    public int expireOldPendingTargets(int daysOld) {
        LocalDateTime cutoff = LocalDateTime.now().minusDays(daysOld);
        int expired = crawlTargetRepository.expireOldPendingTargets(cutoff);
        
        if (expired > 0) {
            log.info("Expired {} old pending targets (older than {} days)", expired, daysOld);
        }
        
        return expired;
    }

    /**
     * 대상 상태 강제 변경 (관리용)
     */
    @Transactional
    public boolean updateTargetStatus(Long targetId, CrawlTargetStatus newStatus, String reason) {
        Optional<CrawlTarget> targetOpt = crawlTargetRepository.findById(targetId);
        if (targetOpt.isEmpty()) {
            return false;
        }
        
        CrawlTarget target = targetOpt.get();
        CrawlTargetStatus oldStatus = target.getStatus();
        
        target.setStatus(newStatus);
        if (reason != null) {
            target.setLastError(reason);
        }
        
        crawlTargetRepository.save(target);
        log.info("Updated target status: id={}, {} -> {}, reason={}",
                targetId, oldStatus, newStatus, reason);
        
        return true;
    }

    // ========================================
    // 통계 조회
    // ========================================

    /**
     * 큐 상태 통계 조회
     */
    public QueueStats getQueueStats() {
        return QueueStats.builder()
                .pendingCount(crawlTargetRepository.countByStatus(CrawlTargetStatus.PENDING))
                .inProgressCount(crawlTargetRepository.countByStatus(CrawlTargetStatus.IN_PROGRESS))
                .completedCount(crawlTargetRepository.countByStatus(CrawlTargetStatus.COMPLETED))
                .failedCount(crawlTargetRepository.countByStatus(CrawlTargetStatus.FAILED))
                .skippedCount(crawlTargetRepository.countByStatus(CrawlTargetStatus.SKIPPED))
                .totalDispatched(totalDispatched.get())
                .totalCompleted(totalCompleted.get())
                .totalFailed(totalFailed.get())
                .domainConcurrency(getDomainConcurrencySnapshot())
                .build();
    }

    /**
     * 도메인별 대기 중 대상 수 조회
     */
    public Map<String, Long> getPendingCountByDomain() {
        List<Object[]> results = crawlTargetRepository.countPendingByDomain();
        return results.stream()
                .limit(20) // 상위 20개만
                .collect(Collectors.toMap(
                        row -> (String) row[0],
                        row -> (Long) row[1],
                        (a, b) -> a,
                        LinkedHashMap::new
                ));
    }

    @Data
    @Builder
    public static class QueueStats {
        private long pendingCount;
        private long inProgressCount;
        private long completedCount;
        private long failedCount;
        private long skippedCount;
        private int totalDispatched;
        private int totalCompleted;
        private int totalFailed;
        private Map<String, Integer> domainConcurrency;
    }

    // ========================================
    // 내부 헬퍼 메서드
    // ========================================

    /**
     * 대상을 크롤러로 분배
     */
    private void dispatchTarget(CrawlTarget target) {
        // 상태 변경
        target.markInProgress();
        crawlTargetRepository.save(target);
        
        // 도메인 동시성 카운터 증가
        incrementDomainConcurrency(target.getDomain());
        
        // 콜백 URL 생성
        String callbackUrl = browserAgentCallbackBaseUrl.endsWith("/")
                ? browserAgentCallbackBaseUrl + "api/v1/autocrawl/callback"
                : browserAgentCallbackBaseUrl + "/api/v1/autocrawl/callback";
        
        // 정책 결정
        BrowserAgentPolicy policy = determineCrawlPolicy(target);
        
        // Kafka 메시지 생성
        BrowserTaskMessage task = BrowserTaskMessage.builder()
                .jobId(target.getId())
                .sourceId(-1L) // 동적 발견 대상은 sourceId가 없음
                .sourceName("AutoCrawl")
                .seedUrl(target.getUrl())
                .maxDepth(1) // 발견된 단일 페이지만 크롤링
                .maxPages(1)
                .budgetSeconds(60)
                .policy(policy.getValue())
                .focusKeywords(target.getRelatedKeywords())
                .captureScreenshots(false)
                .extractStructured(true)
                .callbackUrl(callbackUrl)
                .callbackToken(browserAgentCallbackToken)
                .metadata(Map.of(
                        "targetId", target.getId().toString(),
                        "urlHash", target.getUrlHash(),
                        "discoverySource", target.getDiscoverySource().name(),
                        "priority", target.getPriority().toString()
                ))
                .createdAt(LocalDateTime.now())
                .build();
        
        // Kafka로 발행
        browserTaskKafkaTemplate.send(browserTaskTopic, target.getId().toString(), task);
        
        totalDispatched.incrementAndGet();
        log.info("Dispatched crawl target: id={}, url={}, policy={}, priority={}",
                target.getId(), target.getUrl(), policy, target.getPriority());
    }

    /**
     * 콘텐츠 타입에 따른 크롤링 정책 결정
     */
    private BrowserAgentPolicy determineCrawlPolicy(CrawlTarget target) {
        ContentType contentType = target.getExpectedContentType();
        
        return switch (contentType) {
            case NEWS -> BrowserAgentPolicy.NEWS_ONLY;
            case BLOG, FORUM -> BrowserAgentPolicy.FOCUSED_TOPIC;
            case OFFICIAL, ACADEMIC -> BrowserAgentPolicy.SINGLE_PAGE;
            default -> BrowserAgentPolicy.SINGLE_PAGE;
        };
    }

    /**
     * 도메인별 동시성 체크
     */
    private boolean canDispatchForDomain(String domain) {
        if (domain == null) return true;
        
        AtomicInteger count = domainConcurrencyMap.get(domain);
        if (count == null) return true;
        
        return count.get() < maxConcurrentPerDomain;
    }

    private void incrementDomainConcurrency(String domain) {
        if (domain == null) return;
        domainConcurrencyMap.computeIfAbsent(domain, k -> new AtomicInteger(0))
                .incrementAndGet();
    }

    private void decrementDomainConcurrency(String domain) {
        if (domain == null) return;
        AtomicInteger count = domainConcurrencyMap.get(domain);
        if (count != null) {
            int newValue = count.decrementAndGet();
            if (newValue <= 0) {
                domainConcurrencyMap.remove(domain);
            }
        }
    }

    private Map<String, Integer> getDomainConcurrencySnapshot() {
        return domainConcurrencyMap.entrySet().stream()
                .filter(e -> e.getValue().get() > 0)
                .collect(Collectors.toMap(
                        Map.Entry::getKey,
                        e -> e.getValue().get()
                ));
    }

    /**
     * URL 해시 생성 (AutoCrawlDiscoveryService와 동일)
     */
    private String computeUrlHash(String url) {
        try {
            java.security.MessageDigest digest = java.security.MessageDigest.getInstance("SHA-256");
            byte[] hash = digest.digest(url.getBytes(java.nio.charset.StandardCharsets.UTF_8));
            StringBuilder hexString = new StringBuilder();
            for (byte b : hash) {
                String hex = Integer.toHexString(0xff & b);
                if (hex.length() == 1) hexString.append('0');
                hexString.append(hex);
            }
            return hexString.toString();
        } catch (Exception e) {
            throw new RuntimeException("SHA-256 not available", e);
        }
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/factcheck/CrossRefSource.java

```java
package com.newsinsight.collector.service.factcheck;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.newsinsight.collector.config.TrustScoreConfig;
import com.newsinsight.collector.service.FactVerificationService.SourceEvidence;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.http.MediaType;
import org.springframework.stereotype.Component;
import org.springframework.web.reactive.function.client.WebClient;
import reactor.core.publisher.Flux;

import java.net.URLEncoder;
import java.nio.charset.StandardCharsets;
import java.time.Duration;
import java.util.ArrayList;
import java.util.List;

/**
 * CrossRef API를 통한 학술 논문 검색 소스
 * 
 * CrossRef는 학술 논문의 메타데이터를 제공하는 무료 API입니다.
 * DOI를 기반으로 논문 정보를 검색할 수 있습니다.
 * 
 * API 문서: https://api.crossref.org/swagger-ui/index.html
 */
@Component
@RequiredArgsConstructor
@Slf4j
public class CrossRefSource implements FactCheckSource {

    private final WebClient webClient;
    private final ObjectMapper objectMapper;
    private final TrustScoreConfig trustScoreConfig;

    @Value("${collector.fact-check.crossref.enabled:true}")
    private boolean enabled;

    @Value("${collector.fact-check.crossref.mailto:newsinsight@example.com}")
    private String mailto;

    @Value("${collector.fact-check.timeout-seconds:15}")
    private int timeoutSeconds;

    private static final String CROSSREF_API_BASE = "https://api.crossref.org/works";

    @Override
    public String getSourceId() {
        return "crossref";
    }

    @Override
    public String getSourceName() {
        return "CrossRef (학술 논문)";
    }

    @Override
    public double getTrustScore() {
        return trustScoreConfig.getFactCheck().getCrossref();
    }

    @Override
    public SourceType getSourceType() {
        return SourceType.ACADEMIC;
    }

    @Override
    public boolean isAvailable() {
        return enabled;
    }

    @Override
    public Flux<SourceEvidence> fetchEvidence(String topic, String language) {
        if (!enabled) {
            return Flux.empty();
        }

        return Flux.defer(() -> {
            try {
                String encodedQuery = URLEncoder.encode(topic, StandardCharsets.UTF_8);
                String url = String.format(
                        "%s?query=%s&rows=5&sort=relevance&order=desc&mailto=%s",
                        CROSSREF_API_BASE, encodedQuery, mailto
                );

                log.debug("Fetching CrossRef evidence for topic: {}", topic);

                String response = webClient.get()
                        .uri(url)
                        .accept(MediaType.APPLICATION_JSON)
                        .retrieve()
                        .bodyToMono(String.class)
                        .timeout(Duration.ofSeconds(timeoutSeconds))
                        .block();

                return Flux.fromIterable(parseResponse(response, topic));
            } catch (Exception e) {
                log.warn("CrossRef API call failed for topic '{}': {}", topic, e.getMessage());
                return Flux.empty();
            }
        });
    }

    @Override
    public Flux<SourceEvidence> verifyClaimAgainstSource(String claim, String language) {
        // 학술 검색은 주장 전체보다 키워드 추출 후 검색이 효과적
        String[] keywords = claim.split("[\\s,\\.]+");
        String searchQuery = String.join(" ", 
                java.util.Arrays.stream(keywords)
                        .filter(w -> w.length() > 3)
                        .limit(5)
                        .toList());
        
        if (searchQuery.isBlank()) {
            searchQuery = claim.substring(0, Math.min(50, claim.length()));
        }
        
        return fetchEvidence(searchQuery, language);
    }

    private List<SourceEvidence> parseResponse(String response, String query) {
        List<SourceEvidence> evidenceList = new ArrayList<>();
        
        if (response == null || response.isBlank()) {
            return evidenceList;
        }

        try {
            JsonNode root = objectMapper.readTree(response);
            JsonNode items = root.path("message").path("items");

            if (items.isArray()) {
                for (JsonNode item : items) {
                    try {
                        String title = extractTitle(item);
                        String doi = item.path("DOI").asText("");
                        String abstractText = item.path("abstract").asText("");
                        String publisher = item.path("publisher").asText("Unknown Publisher");
                        int citationCount = item.path("is-referenced-by-count").asInt(0);

                        // 초록이 없으면 제목 + 출판사 정보 사용
                        String excerpt;
                        if (!abstractText.isBlank()) {
                            // HTML 태그 제거
                            excerpt = abstractText.replaceAll("<[^>]+>", "").trim();
                            if (excerpt.length() > 400) {
                                excerpt = excerpt.substring(0, 400) + "...";
                            }
                        } else {
                            excerpt = String.format("제목: %s (출판: %s, 인용: %d회)", 
                                    title, publisher, citationCount);
                        }

                        String url = doi.isEmpty() ? "" : "https://doi.org/" + doi;

                        // 제목과 쿼리의 관련성 점수 계산
                        double relevance = calculateRelevance(query, title, abstractText);

                        evidenceList.add(SourceEvidence.builder()
                                .sourceType("academic")
                                .sourceName(getSourceName())
                                .url(url)
                                .excerpt(excerpt)
                                .relevanceScore(relevance)
                                .stance("neutral") // 학술 자료는 기본적으로 중립
                                .build());
                    } catch (Exception e) {
                        log.debug("Failed to parse CrossRef item: {}", e.getMessage());
                    }
                }
            }
        } catch (Exception e) {
            log.warn("Failed to parse CrossRef response: {}", e.getMessage());
        }

        return evidenceList;
    }

    private String extractTitle(JsonNode item) {
        JsonNode titleNode = item.path("title");
        if (titleNode.isArray() && !titleNode.isEmpty()) {
            return titleNode.get(0).asText("");
        }
        return titleNode.asText("Unknown Title");
    }

    private double calculateRelevance(String query, String title, String abstractText) {
        if (query == null || query.isBlank()) return 0.5;
        
        String lowerQuery = query.toLowerCase();
        String lowerTitle = title.toLowerCase();
        String lowerAbstract = abstractText.toLowerCase();
        
        String[] queryWords = lowerQuery.split("\\s+");
        int matches = 0;
        
        for (String word : queryWords) {
            if (word.length() > 2) {
                if (lowerTitle.contains(word)) matches += 2;
                if (lowerAbstract.contains(word)) matches++;
            }
        }
        
        double score = Math.min(1.0, matches / (double)(queryWords.length * 3));
        return Math.max(0.3, score); // 최소 0.3
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/factcheck/FactCheckSource.java

```java
package com.newsinsight.collector.service.factcheck;

import com.newsinsight.collector.service.FactVerificationService.SourceEvidence;
import reactor.core.publisher.Flux;

import java.util.List;

/**
 * 팩트체크를 위한 데이터 소스 인터페이스
 * 
 * 각 구현체는 특정 데이터 소스(Wikipedia, CrossRef, Google Fact Check 등)에서
 * 주제 또는 주장에 대한 근거를 수집합니다.
 */
public interface FactCheckSource {
    
    /**
     * 소스 식별자
     */
    String getSourceId();
    
    /**
     * 소스 표시 이름
     */
    String getSourceName();
    
    /**
     * 신뢰도 점수 (0.0 ~ 1.0)
     * 학술 자료 > 공식 통계 > 백과사전 > 뉴스 팩트체크 순
     */
    double getTrustScore();
    
    /**
     * 주어진 주제/키워드에 대한 근거 수집
     * 
     * @param topic 검색할 주제 또는 키워드
     * @param language 언어 코드 (ko, en 등)
     * @return 수집된 근거 목록
     */
    Flux<SourceEvidence> fetchEvidence(String topic, String language);
    
    /**
     * 특정 주장에 대한 팩트체크 결과 조회
     * 
     * @param claim 검증할 주장
     * @param language 언어 코드
     * @return 팩트체크 근거 목록
     */
    Flux<SourceEvidence> verifyClaimAgainstSource(String claim, String language);
    
    /**
     * 이 소스가 사용 가능한지 확인 (API 키 설정 등)
     */
    boolean isAvailable();
    
    /**
     * 소스 유형 (참고용)
     */
    default SourceType getSourceType() {
        return SourceType.REFERENCE;
    }
    
    enum SourceType {
        ENCYCLOPEDIA,     // 백과사전 (Wikipedia, Britannica)
        ACADEMIC,         // 학술 자료 (CrossRef, OpenAlex)
        FACT_CHECK,       // 팩트체크 사이트 (Google Fact Check, Snopes)
        OFFICIAL_STATS,   // 공식 통계 (KOSIS, World Bank)
        REFERENCE         // 기타 참고 자료
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/factcheck/GoogleFactCheckSource.java

```java
package com.newsinsight.collector.service.factcheck;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.newsinsight.collector.config.TrustScoreConfig;
import com.newsinsight.collector.service.FactVerificationService.SourceEvidence;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.http.MediaType;
import org.springframework.stereotype.Component;
import org.springframework.web.reactive.function.client.WebClient;
import reactor.core.publisher.Flux;

import java.net.URLEncoder;
import java.nio.charset.StandardCharsets;
import java.time.Duration;
import java.util.ArrayList;
import java.util.List;

/**
 * Google Fact Check Tools API를 통한 팩트체크 결과 조회
 * 
 * Google Fact Check Tools API는 전 세계 팩트체커들이 검증한
 * 주장들의 데이터베이스를 제공합니다.
 * 
 * API 키 필요: https://developers.google.com/fact-check/tools/api/reference/rest
 * 
 * 무료 할당량: 10,000 요청/일
 */
@Component
@RequiredArgsConstructor
@Slf4j
public class GoogleFactCheckSource implements FactCheckSource {

    private final WebClient webClient;
    private final ObjectMapper objectMapper;
    private final TrustScoreConfig trustScoreConfig;

    @Value("${collector.fact-check.google.api-key:}")
    private String apiKey;

    @Value("${collector.fact-check.google.enabled:true}")
    private boolean enabled;

    @Value("${collector.fact-check.timeout-seconds:15}")
    private int timeoutSeconds;

    private static final String FACT_CHECK_API_BASE = "https://factchecktools.googleapis.com/v1alpha1/claims:search";

    @Override
    public String getSourceId() {
        return "google_factcheck";
    }

    @Override
    public String getSourceName() {
        return "Google Fact Check";
    }

    @Override
    public double getTrustScore() {
        return trustScoreConfig.getFactCheck().getGoogleFactCheck();
    }

    @Override
    public SourceType getSourceType() {
        return SourceType.FACT_CHECK;
    }

    @Override
    public boolean isAvailable() {
        return enabled && apiKey != null && !apiKey.isBlank();
    }

    @Override
    public Flux<SourceEvidence> fetchEvidence(String topic, String language) {
        if (!isAvailable()) {
            log.debug("Google Fact Check API is not available (enabled={}, hasKey={})", 
                    enabled, apiKey != null && !apiKey.isBlank());
            return Flux.empty();
        }

        return Flux.defer(() -> {
            try {
                String encodedQuery = URLEncoder.encode(topic, StandardCharsets.UTF_8);
                String languageCode = mapLanguageCode(language);
                
                String url = String.format(
                        "%s?query=%s&languageCode=%s&pageSize=10&key=%s",
                        FACT_CHECK_API_BASE, encodedQuery, languageCode, apiKey
                );

                log.debug("Fetching Google Fact Check evidence for topic: {}", topic);

                String response = webClient.get()
                        .uri(url)
                        .accept(MediaType.APPLICATION_JSON)
                        .retrieve()
                        .bodyToMono(String.class)
                        .timeout(Duration.ofSeconds(timeoutSeconds))
                        .block();

                return Flux.fromIterable(parseResponse(response));
            } catch (Exception e) {
                log.warn("Google Fact Check API call failed for topic '{}': {}", topic, e.getMessage());
                return Flux.empty();
            }
        });
    }

    @Override
    public Flux<SourceEvidence> verifyClaimAgainstSource(String claim, String language) {
        return fetchEvidence(claim, language);
    }

    private String mapLanguageCode(String language) {
        if (language == null) return "ko";
        return switch (language.toLowerCase()) {
            case "ko", "kor", "korean" -> "ko";
            case "en", "eng", "english" -> "en";
            case "ja", "jpn", "japanese" -> "ja";
            case "zh", "chi", "chinese" -> "zh";
            default -> language;
        };
    }

    private List<SourceEvidence> parseResponse(String response) {
        List<SourceEvidence> evidenceList = new ArrayList<>();
        
        if (response == null || response.isBlank()) {
            return evidenceList;
        }

        try {
            JsonNode root = objectMapper.readTree(response);
            JsonNode claims = root.path("claims");

            if (claims.isArray()) {
                for (JsonNode claimNode : claims) {
                    try {
                        String claimText = claimNode.path("text").asText("");
                        String claimant = claimNode.path("claimant").asText("");
                        
                        // 팩트체크 리뷰 정보 추출
                        JsonNode reviews = claimNode.path("claimReview");
                        if (reviews.isArray() && !reviews.isEmpty()) {
                            JsonNode review = reviews.get(0);
                            
                            String publisher = review.path("publisher").path("name").asText("Unknown");
                            String reviewUrl = review.path("url").asText("");
                            String rating = review.path("textualRating").asText("");
                            String title = review.path("title").asText("");
                            String languageCode = review.path("languageCode").asText("");

                            // stance 결정 (rating 기반)
                            String stance = determineStance(rating);
                            
                            // 발췌문 구성
                            StringBuilder excerpt = new StringBuilder();
                            if (!claimText.isBlank()) {
                                excerpt.append("주장: ").append(claimText);
                                if (!claimant.isBlank()) {
                                    excerpt.append(" (").append(claimant).append(")");
                                }
                                excerpt.append("\n");
                            }
                            excerpt.append("판정: ").append(rating);
                            if (!title.isBlank()) {
                                excerpt.append("\n").append(title);
                            }

                            evidenceList.add(SourceEvidence.builder()
                                    .sourceType("factcheck")
                                    .sourceName(publisher + " (Fact Check)")
                                    .url(reviewUrl)
                                    .excerpt(truncate(excerpt.toString(), 500))
                                    .relevanceScore(0.85)
                                    .stance(stance)
                                    .build());
                        }
                    } catch (Exception e) {
                        log.debug("Failed to parse Google Fact Check claim: {}", e.getMessage());
                    }
                }
            }
        } catch (Exception e) {
            log.warn("Failed to parse Google Fact Check response: {}", e.getMessage());
        }

        return evidenceList;
    }

    /**
     * 팩트체크 판정을 stance로 변환
     */
    private String determineStance(String rating) {
        if (rating == null) return "neutral";
        
        String lower = rating.toLowerCase();
        
        // 거짓 판정 패턴
        if (lower.contains("false") || lower.contains("거짓") || lower.contains("허위") ||
            lower.contains("wrong") || lower.contains("incorrect") || lower.contains("틀") ||
            lower.contains("fake") || lower.contains("misleading") || lower.contains("오해")) {
            return "contradict";
        }
        
        // 진실 판정 패턴
        if (lower.contains("true") || lower.contains("사실") || lower.contains("correct") ||
            lower.contains("accurate") || lower.contains("정확") || lower.contains("맞")) {
            return "support";
        }
        
        // 부분적/혼합 판정
        if (lower.contains("partly") || lower.contains("partially") || lower.contains("mixed") ||
            lower.contains("부분") || lower.contains("일부") || lower.contains("반")) {
            return "neutral";
        }
        
        return "neutral";
    }

    private String truncate(String text, int maxLength) {
        if (text == null) return "";
        if (text.length() <= maxLength) return text;
        return text.substring(0, maxLength) + "...";
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/factcheck/OpenAlexSource.java

```java
package com.newsinsight.collector.service.factcheck;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.newsinsight.collector.config.TrustScoreConfig;
import com.newsinsight.collector.service.FactVerificationService.SourceEvidence;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.http.MediaType;
import org.springframework.stereotype.Component;
import org.springframework.web.reactive.function.client.WebClient;
import reactor.core.publisher.Flux;

import java.net.URLEncoder;
import java.nio.charset.StandardCharsets;
import java.time.Duration;
import java.util.ArrayList;
import java.util.List;

/**
 * OpenAlex API를 통한 학술 연구 검색
 * 
 * OpenAlex는 무료로 사용할 수 있는 오픈 학술 데이터베이스로,
 * 2억 개 이상의 학술 저작물을 검색할 수 있습니다.
 * 
 * API 문서: https://docs.openalex.org/
 * 
 * 특징:
 * - API 키 불필요 (무료)
 * - 빠른 응답 속도
 * - 풍부한 메타데이터
 */
@Component
@RequiredArgsConstructor
@Slf4j
public class OpenAlexSource implements FactCheckSource {

    private final WebClient webClient;
    private final ObjectMapper objectMapper;
    private final TrustScoreConfig trustScoreConfig;

    @Value("${collector.fact-check.openalex.enabled:true}")
    private boolean enabled;

    @Value("${collector.fact-check.openalex.mailto:newsinsight@example.com}")
    private String mailto;

    @Value("${collector.fact-check.timeout-seconds:15}")
    private int timeoutSeconds;

    private static final String OPENALEX_API_BASE = "https://api.openalex.org/works";

    @Override
    public String getSourceId() {
        return "openalex";
    }

    @Override
    public String getSourceName() {
        return "OpenAlex (학술 DB)";
    }

    @Override
    public double getTrustScore() {
        return trustScoreConfig.getFactCheck().getOpenalex();
    }

    @Override
    public SourceType getSourceType() {
        return SourceType.ACADEMIC;
    }

    @Override
    public boolean isAvailable() {
        return enabled;
    }

    @Override
    public Flux<SourceEvidence> fetchEvidence(String topic, String language) {
        if (!enabled) {
            return Flux.empty();
        }

        return Flux.defer(() -> {
            try {
                String encodedQuery = URLEncoder.encode(topic, StandardCharsets.UTF_8);
                
                // OpenAlex는 polite pool을 위해 mailto 파라미터 권장
                String url = String.format(
                        "%s?search=%s&per_page=5&sort=relevance_score:desc&mailto=%s",
                        OPENALEX_API_BASE, encodedQuery, mailto
                );

                log.debug("Fetching OpenAlex evidence for topic: {}", topic);

                String response = webClient.get()
                        .uri(url)
                        .accept(MediaType.APPLICATION_JSON)
                        .retrieve()
                        .bodyToMono(String.class)
                        .timeout(Duration.ofSeconds(timeoutSeconds))
                        .block();

                return Flux.fromIterable(parseResponse(response, topic));
            } catch (Exception e) {
                log.warn("OpenAlex API call failed for topic '{}': {}", topic, e.getMessage());
                return Flux.empty();
            }
        });
    }

    @Override
    public Flux<SourceEvidence> verifyClaimAgainstSource(String claim, String language) {
        // 학술 검색은 주장에서 핵심 키워드만 추출
        String[] words = claim.split("[\\s,\\.!?]+");
        String searchQuery = String.join(" ", 
                java.util.Arrays.stream(words)
                        .filter(w -> w.length() > 3)
                        .limit(6)
                        .toList());
        
        if (searchQuery.isBlank()) {
            searchQuery = claim.length() > 60 ? claim.substring(0, 60) : claim;
        }
        
        return fetchEvidence(searchQuery, language);
    }

    private List<SourceEvidence> parseResponse(String response, String query) {
        List<SourceEvidence> evidenceList = new ArrayList<>();
        
        if (response == null || response.isBlank()) {
            return evidenceList;
        }

        try {
            JsonNode root = objectMapper.readTree(response);
            JsonNode results = root.path("results");

            if (results.isArray()) {
                for (JsonNode work : results) {
                    try {
                        String title = work.path("title").asText("");
                        if (title.isBlank()) continue;

                        String doi = work.path("doi").asText("");
                        int citedByCount = work.path("cited_by_count").asInt(0);
                        int publicationYear = work.path("publication_year").asInt(0);
                        double relevanceScore = work.path("relevance_score").asDouble(0.5);
                        
                        // 초록 추출 (inverted index에서 복원 또는 없으면 생략)
                        String abstractText = extractAbstract(work);
                        
                        // 저자 정보
                        String authors = extractAuthors(work);
                        
                        // 발췌문 구성
                        StringBuilder excerpt = new StringBuilder();
                        excerpt.append("📄 ").append(title);
                        if (publicationYear > 0) {
                            excerpt.append(" (").append(publicationYear).append(")");
                        }
                        excerpt.append("\n");
                        if (!authors.isBlank()) {
                            excerpt.append("저자: ").append(authors).append("\n");
                        }
                        excerpt.append("인용: ").append(citedByCount).append("회");
                        if (!abstractText.isBlank()) {
                            excerpt.append("\n\n").append(abstractText);
                        }

                        String url = doi.isBlank() ? work.path("id").asText("") : doi;

                        // 관련성 점수 정규화
                        double normalizedRelevance = Math.min(1.0, Math.max(0.3, relevanceScore / 100.0));

                        evidenceList.add(SourceEvidence.builder()
                                .sourceType("academic")
                                .sourceName(getSourceName())
                                .url(url)
                                .excerpt(truncate(excerpt.toString(), 500))
                                .relevanceScore(normalizedRelevance)
                                .stance("neutral")
                                .build());
                    } catch (Exception e) {
                        log.debug("Failed to parse OpenAlex work: {}", e.getMessage());
                    }
                }
            }
        } catch (Exception e) {
            log.warn("Failed to parse OpenAlex response: {}", e.getMessage());
        }

        return evidenceList;
    }

    private String extractAbstract(JsonNode work) {
        // OpenAlex는 abstract를 inverted index 형태로 저장
        JsonNode abstractIndex = work.path("abstract_inverted_index");
        if (abstractIndex.isMissingNode() || abstractIndex.isNull()) {
            return "";
        }

        try {
            // inverted index를 원문으로 복원
            java.util.TreeMap<Integer, String> positionToWord = new java.util.TreeMap<>();
            
            abstractIndex.fields().forEachRemaining(entry -> {
                String word = entry.getKey();
                JsonNode positions = entry.getValue();
                if (positions.isArray()) {
                    for (JsonNode pos : positions) {
                        positionToWord.put(pos.asInt(), word);
                    }
                }
            });
            
            StringBuilder sb = new StringBuilder();
            for (String word : positionToWord.values()) {
                if (!sb.isEmpty()) sb.append(" ");
                sb.append(word);
            }
            
            String result = sb.toString();
            return result.length() > 300 ? result.substring(0, 300) + "..." : result;
        } catch (Exception e) {
            log.debug("Failed to extract abstract: {}", e.getMessage());
            return "";
        }
    }

    private String extractAuthors(JsonNode work) {
        JsonNode authorships = work.path("authorships");
        if (!authorships.isArray() || authorships.isEmpty()) {
            return "";
        }

        List<String> authorNames = new ArrayList<>();
        for (JsonNode authorship : authorships) {
            String name = authorship.path("author").path("display_name").asText("");
            if (!name.isBlank()) {
                authorNames.add(name);
                if (authorNames.size() >= 3) break; // 최대 3명까지만
            }
        }

        if (authorNames.isEmpty()) return "";
        if (authorNames.size() < 3) return String.join(", ", authorNames);
        return authorNames.get(0) + " 외 " + (authorships.size() - 1) + "명";
    }

    private String truncate(String text, int maxLength) {
        if (text == null) return "";
        if (text.length() <= maxLength) return text;
        return text.substring(0, maxLength) + "...";
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/factcheck/WikipediaSource.java

```java
package com.newsinsight.collector.service.factcheck;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.newsinsight.collector.config.TrustScoreConfig;
import com.newsinsight.collector.service.FactVerificationService.SourceEvidence;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.http.MediaType;
import org.springframework.stereotype.Component;
import org.springframework.web.reactive.function.client.WebClient;
import reactor.core.publisher.Flux;

import java.net.URLEncoder;
import java.nio.charset.StandardCharsets;
import java.time.Duration;
import java.util.ArrayList;
import java.util.List;

/**
 * Wikipedia 기반 팩트체크 소스.
 *
 * 간단한 제목/주제 검색으로 ko/en 위키백과 요약을 가져와
 * SourceEvidence 형태로 반환합니다.
 */
@Component
@RequiredArgsConstructor
@Slf4j
public class WikipediaSource implements FactCheckSource {

    private final WebClient webClient;
    private final ObjectMapper objectMapper;
    private final TrustScoreConfig trustScoreConfig;

    @Value("${collector.fact-check.wikipedia.enabled:true}")
    private boolean enabled;

    @Value("${collector.fact-check.timeout-seconds:15}")
    private int timeoutSeconds;

    @Override
    public String getSourceId() {
        return "wikipedia_api";
    }

    @Override
    public String getSourceName() {
        return "Wikipedia";
    }

    @Override
    public double getTrustScore() {
        return trustScoreConfig.getFactCheck().getWikipedia();
    }

    @Override
    public SourceType getSourceType() {
        return SourceType.ENCYCLOPEDIA;
    }

    @Override
    public boolean isAvailable() {
        return enabled;
    }

    @Override
    public Flux<SourceEvidence> fetchEvidence(String topic, String language) {
        if (!enabled || topic == null || topic.isBlank()) {
            return Flux.empty();
        }

        return Flux.defer(() -> {
            List<SourceEvidence> evidenceList = new ArrayList<>();

            // 언어 코드에 따라 우선순위 결정 (ko 우선, 그 다음 en)
            String primaryLang = mapLanguage(language);

            try {
                String summary = fetchWikipediaSummary(topic, primaryLang);
                if (summary != null && !summary.isBlank()) {
                    evidenceList.add(SourceEvidence.builder()
                            .sourceType("wikipedia")
                            .sourceName(primaryLang.equals("ko") ? "위키백과" : "Wikipedia")
                            .url(String.format("https://%s.wikipedia.org/wiki/%s", primaryLang,
                                    URLEncoder.encode(topic.replace(" ", "_"), StandardCharsets.UTF_8)))
                            .excerpt(truncate(summary, 500))
                            .relevanceScore(0.9)
                            .stance("neutral")
                            .build());
                }
            } catch (Exception e) {
                log.debug("Failed to fetch Wikipedia summary for topic '{}' ({}): {}", topic, primaryLang, e.getMessage());
            }

            // 보조 언어(en)도 시도 (primary가 ko인 경우)
            if ("ko".equals(primaryLang)) {
                try {
                    String enSummary = fetchWikipediaSummary(topic, "en");
                    if (enSummary != null && !enSummary.isBlank()) {
                        evidenceList.add(SourceEvidence.builder()
                                .sourceType("wikipedia")
                                .sourceName("Wikipedia (EN)")
                                .url(String.format("https://en.wikipedia.org/wiki/%s",
                                        URLEncoder.encode(topic.replace(" ", "_"), StandardCharsets.UTF_8)))
                                .excerpt(truncate(enSummary, 500))
                                .relevanceScore(0.9)
                                .stance("neutral")
                                .build());
                    }
                } catch (Exception e) {
                    log.debug("Failed to fetch English Wikipedia summary for topic '{}': {}", topic, e.getMessage());
                }
            }

            return Flux.fromIterable(evidenceList);
        });
    }

    @Override
    public Flux<SourceEvidence> verifyClaimAgainstSource(String claim, String language) {
        // 간단히 claim 전체를 주제로 보고 fetchEvidence 재사용
        return fetchEvidence(claim, language);
    }

    private String mapLanguage(String language) {
        if (language == null || language.isBlank()) {
            return "ko";
        }
        String lower = language.toLowerCase();
        if (lower.startsWith("en")) return "en";
        if (lower.startsWith("ko")) return "ko";
        return "ko";
    }

    private String fetchWikipediaSummary(String topic, String lang) {
        try {
            String apiUrl = String.format(
                    "https://%s.wikipedia.org/api/rest_v1/page/summary/%s",
                    lang,
                    URLEncoder.encode(topic.replace(" ", "_"), StandardCharsets.UTF_8)
            );

            String response = webClient.get()
                    .uri(apiUrl)
                    .accept(MediaType.APPLICATION_JSON)
                    .retrieve()
                    .bodyToMono(String.class)
                    .timeout(Duration.ofSeconds(timeoutSeconds))
                    .block();

            if (response != null) {
                JsonNode node = objectMapper.readTree(response);
                if (node.has("extract")) {
                    return node.get("extract").asText();
                }
            }
        } catch (Exception e) {
            log.debug("Wikipedia API call failed for topic '{}' ({}): {}", topic, lang, e.getMessage());
        }
        return null;
    }

    private String truncate(String text, int maxLength) {
        if (text == null) return "";
        if (text.length() <= maxLength) return text;
        return text.substring(0, maxLength) + "...";
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/report/ChartGenerationService.java

```java
package com.newsinsight.collector.service.report;

import com.newsinsight.collector.dto.report.ChartData;
import lombok.extern.slf4j.Slf4j;
import org.jfree.chart.ChartFactory;
import org.jfree.chart.ChartUtils;
import org.jfree.chart.JFreeChart;
import org.jfree.chart.plot.CategoryPlot;
import org.jfree.chart.plot.PiePlot;
import org.jfree.chart.plot.PlotOrientation;
import org.jfree.chart.plot.XYPlot;
import org.jfree.chart.renderer.category.BarRenderer;
import org.jfree.chart.renderer.xy.XYLineAndShapeRenderer;
import org.jfree.chart.title.TextTitle;
import org.jfree.data.category.DefaultCategoryDataset;
import org.jfree.data.general.DefaultPieDataset;
import org.jfree.data.xy.XYSeries;
import org.jfree.data.xy.XYSeriesCollection;
import org.springframework.stereotype.Service;

import java.awt.*;
import java.io.ByteArrayOutputStream;
import java.io.IOException;
import java.util.List;

/**
 * 서버 사이드 차트 생성 서비스
 * 
 * JFreeChart를 사용하여 PDF에 삽입할 차트 이미지를 생성합니다.
 */
@Service
@Slf4j
public class ChartGenerationService {

    // 색상 팔레트
    private static final Color[] DEFAULT_COLORS = {
            new Color(59, 130, 246),   // Blue
            new Color(16, 185, 129),   // Green
            new Color(245, 158, 11),   // Yellow/Orange
            new Color(239, 68, 68),    // Red
            new Color(139, 92, 246),   // Purple
            new Color(236, 72, 153),   // Pink
            new Color(20, 184, 166),   // Teal
            new Color(249, 115, 22),   // Orange
    };

    private static final Color BACKGROUND_COLOR = Color.WHITE;
    private static final Color TEXT_COLOR = new Color(30, 41, 59);
    private static final Color GRID_COLOR = new Color(226, 232, 240);

    /**
     * 파이 차트 생성
     */
    public byte[] generatePieChart(ChartData chartData) throws IOException {
        DefaultPieDataset<String> dataset = new DefaultPieDataset<>();
        
        List<String> labels = chartData.getLabels();
        List<Number> values = chartData.getValues();
        
        for (int i = 0; i < labels.size(); i++) {
            dataset.setValue(labels.get(i), values.get(i));
        }
        
        JFreeChart chart = ChartFactory.createPieChart(
                chartData.getTitle(),
                dataset,
                true,   // legend
                true,   // tooltips
                false   // urls
        );
        
        // 스타일링
        chart.setBackgroundPaint(BACKGROUND_COLOR);
        chart.getTitle().setPaint(TEXT_COLOR);
        chart.getTitle().setFont(new Font("SansSerif", Font.BOLD, 16));
        
        PiePlot plot = (PiePlot) chart.getPlot();
        plot.setBackgroundPaint(BACKGROUND_COLOR);
        plot.setOutlineVisible(false);
        plot.setShadowPaint(null);
        plot.setLabelFont(new Font("SansSerif", Font.PLAIN, 12));
        plot.setLabelPaint(TEXT_COLOR);
        
        // 색상 적용
        List<String> colors = chartData.getColors();
        for (int i = 0; i < labels.size(); i++) {
            Color color = colors != null && i < colors.size() 
                    ? Color.decode(colors.get(i)) 
                    : DEFAULT_COLORS[i % DEFAULT_COLORS.length];
            plot.setSectionPaint(labels.get(i), color);
        }
        
        return chartToBytes(chart, chartData.getWidth(), chartData.getHeight());
    }

    /**
     * 도넛 차트 생성
     */
    public byte[] generateDoughnutChart(ChartData chartData) throws IOException {
        // JFreeChart에서 도넛 차트는 RingPlot 사용 (파이 차트와 유사하게 처리)
        return generatePieChart(chartData);  // 간단히 파이 차트로 대체
    }

    /**
     * 바 차트 생성
     */
    public byte[] generateBarChart(ChartData chartData) throws IOException {
        DefaultCategoryDataset dataset = new DefaultCategoryDataset();
        
        List<String> labels = chartData.getLabels();
        List<Number> values = chartData.getValues();
        
        for (int i = 0; i < labels.size(); i++) {
            dataset.addValue(values.get(i), "데이터", labels.get(i));
        }
        
        JFreeChart chart = ChartFactory.createBarChart(
                chartData.getTitle(),
                chartData.getXAxisLabel(),
                chartData.getYAxisLabel(),
                dataset,
                PlotOrientation.VERTICAL,
                false,  // legend
                true,   // tooltips
                false   // urls
        );
        
        // 스타일링
        chart.setBackgroundPaint(BACKGROUND_COLOR);
        chart.getTitle().setPaint(TEXT_COLOR);
        chart.getTitle().setFont(new Font("SansSerif", Font.BOLD, 16));
        
        CategoryPlot plot = chart.getCategoryPlot();
        plot.setBackgroundPaint(BACKGROUND_COLOR);
        plot.setRangeGridlinePaint(GRID_COLOR);
        plot.setOutlineVisible(false);
        
        BarRenderer renderer = (BarRenderer) plot.getRenderer();
        renderer.setSeriesPaint(0, DEFAULT_COLORS[0]);
        renderer.setDrawBarOutline(false);
        renderer.setShadowVisible(false);
        
        return chartToBytes(chart, chartData.getWidth(), chartData.getHeight());
    }

    /**
     * 수평 바 차트 생성
     */
    public byte[] generateHorizontalBarChart(ChartData chartData) throws IOException {
        DefaultCategoryDataset dataset = new DefaultCategoryDataset();
        
        List<String> labels = chartData.getLabels();
        List<Number> values = chartData.getValues();
        
        for (int i = 0; i < labels.size(); i++) {
            dataset.addValue(values.get(i), "데이터", labels.get(i));
        }
        
        JFreeChart chart = ChartFactory.createBarChart(
                chartData.getTitle(),
                chartData.getXAxisLabel(),
                chartData.getYAxisLabel(),
                dataset,
                PlotOrientation.HORIZONTAL,
                false,
                true,
                false
        );
        
        // 스타일링
        chart.setBackgroundPaint(BACKGROUND_COLOR);
        chart.getTitle().setPaint(TEXT_COLOR);
        
        CategoryPlot plot = chart.getCategoryPlot();
        plot.setBackgroundPaint(BACKGROUND_COLOR);
        plot.setRangeGridlinePaint(GRID_COLOR);
        
        BarRenderer renderer = (BarRenderer) plot.getRenderer();
        renderer.setSeriesPaint(0, DEFAULT_COLORS[0]);
        renderer.setDrawBarOutline(false);
        
        return chartToBytes(chart, chartData.getWidth(), chartData.getHeight());
    }

    /**
     * 라인 차트 생성
     */
    public byte[] generateLineChart(ChartData chartData) throws IOException {
        XYSeriesCollection dataset = new XYSeriesCollection();
        
        List<ChartData.DataSeries> seriesList = chartData.getSeries();
        if (seriesList != null) {
            for (ChartData.DataSeries seriesData : seriesList) {
                XYSeries series = new XYSeries(seriesData.getName());
                List<Number> data = seriesData.getData();
                for (int i = 0; i < data.size(); i++) {
                    series.add(i, data.get(i));
                }
                dataset.addSeries(series);
            }
        } else if (chartData.getValues() != null) {
            XYSeries series = new XYSeries("데이터");
            List<Number> values = chartData.getValues();
            for (int i = 0; i < values.size(); i++) {
                series.add(i, values.get(i));
            }
            dataset.addSeries(series);
        }
        
        JFreeChart chart = ChartFactory.createXYLineChart(
                chartData.getTitle(),
                chartData.getXAxisLabel(),
                chartData.getYAxisLabel(),
                dataset,
                PlotOrientation.VERTICAL,
                true,
                true,
                false
        );
        
        // 스타일링
        chart.setBackgroundPaint(BACKGROUND_COLOR);
        chart.getTitle().setPaint(TEXT_COLOR);
        chart.getTitle().setFont(new Font("SansSerif", Font.BOLD, 16));
        
        XYPlot plot = chart.getXYPlot();
        plot.setBackgroundPaint(BACKGROUND_COLOR);
        plot.setRangeGridlinePaint(GRID_COLOR);
        plot.setDomainGridlinePaint(GRID_COLOR);
        plot.setOutlineVisible(false);
        
        XYLineAndShapeRenderer renderer = new XYLineAndShapeRenderer();
        for (int i = 0; i < dataset.getSeriesCount(); i++) {
            renderer.setSeriesPaint(i, DEFAULT_COLORS[i % DEFAULT_COLORS.length]);
            renderer.setSeriesStroke(i, new BasicStroke(2.0f));
            renderer.setSeriesShapesVisible(i, true);
        }
        plot.setRenderer(renderer);
        
        return chartToBytes(chart, chartData.getWidth(), chartData.getHeight());
    }

    /**
     * 영역 차트 생성
     */
    public byte[] generateAreaChart(ChartData chartData) throws IOException {
        XYSeriesCollection dataset = new XYSeriesCollection();
        
        if (chartData.getValues() != null) {
            XYSeries series = new XYSeries("데이터");
            List<Number> values = chartData.getValues();
            for (int i = 0; i < values.size(); i++) {
                series.add(i, values.get(i));
            }
            dataset.addSeries(series);
        }
        
        JFreeChart chart = ChartFactory.createXYAreaChart(
                chartData.getTitle(),
                chartData.getXAxisLabel(),
                chartData.getYAxisLabel(),
                dataset,
                PlotOrientation.VERTICAL,
                false,
                true,
                false
        );
        
        // 스타일링
        chart.setBackgroundPaint(BACKGROUND_COLOR);
        chart.getTitle().setPaint(TEXT_COLOR);
        
        XYPlot plot = chart.getXYPlot();
        plot.setBackgroundPaint(BACKGROUND_COLOR);
        plot.setForegroundAlpha(0.65f);
        plot.getRenderer().setSeriesPaint(0, DEFAULT_COLORS[0]);
        
        return chartToBytes(chart, chartData.getWidth(), chartData.getHeight());
    }

    /**
     * 게이지 차트 생성 (간단한 미터 형태)
     */
    public byte[] generateGaugeChart(ChartData chartData) throws IOException {
        // JFreeChart에는 기본 게이지 차트가 없으므로 파이 차트로 시뮬레이션
        List<Number> values = chartData.getValues();
        double value = values.get(0).doubleValue();
        double min = values.size() > 1 ? values.get(1).doubleValue() : 0;
        double max = values.size() > 2 ? values.get(2).doubleValue() : 100;
        
        double percentage = ((value - min) / (max - min)) * 100;
        double remaining = 100 - percentage;
        
        DefaultPieDataset<String> dataset = new DefaultPieDataset<>();
        dataset.setValue("값", percentage);
        dataset.setValue("남은", remaining);
        
        JFreeChart chart = ChartFactory.createPieChart(
                chartData.getTitle(),
                dataset,
                false,
                true,
                false
        );
        
        // 스타일링
        chart.setBackgroundPaint(BACKGROUND_COLOR);
        chart.getTitle().setPaint(TEXT_COLOR);
        
        // 값 표시 추가
        TextTitle valueTitle = new TextTitle(String.format("%.0f", value));
        valueTitle.setFont(new Font("SansSerif", Font.BOLD, 24));
        valueTitle.setPaint(DEFAULT_COLORS[0]);
        chart.addSubtitle(valueTitle);
        
        PiePlot plot = (PiePlot) chart.getPlot();
        plot.setBackgroundPaint(BACKGROUND_COLOR);
        plot.setOutlineVisible(false);
        plot.setShadowPaint(null);
        plot.setLabelGenerator(null);  // 라벨 숨김
        
        // 색상: 값은 파란색, 남은 부분은 연한 회색
        Color gaugeColor = percentage >= 70 ? new Color(16, 185, 129) :
                           percentage >= 40 ? new Color(245, 158, 11) :
                           new Color(239, 68, 68);
        plot.setSectionPaint("값", gaugeColor);
        plot.setSectionPaint("남은", new Color(226, 232, 240));
        
        return chartToBytes(chart, chartData.getWidth(), chartData.getHeight());
    }

    /**
     * ChartData 타입에 따라 적절한 차트 생성
     */
    public byte[] generateChart(ChartData chartData) throws IOException {
        return switch (chartData.getChartType()) {
            case PIE -> generatePieChart(chartData);
            case DOUGHNUT -> generateDoughnutChart(chartData);
            case BAR -> generateBarChart(chartData);
            case HORIZONTAL_BAR -> generateHorizontalBarChart(chartData);
            case LINE -> generateLineChart(chartData);
            case AREA -> generateAreaChart(chartData);
            case GAUGE -> generateGaugeChart(chartData);
            case STACKED_BAR -> generateBarChart(chartData);  // 간단히 바 차트로 대체
            case HISTOGRAM -> generateBarChart(chartData);    // 간단히 바 차트로 대체
            case RADAR -> generatePieChart(chartData);        // 레이더는 파이로 대체
        };
    }

    /**
     * JFreeChart를 PNG 바이트 배열로 변환
     */
    private byte[] chartToBytes(JFreeChart chart, int width, int height) throws IOException {
        ByteArrayOutputStream baos = new ByteArrayOutputStream();
        ChartUtils.writeChartAsPNG(baos, chart, width, height);
        return baos.toByteArray();
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/report/PdfExportService.java

```java
package com.newsinsight.collector.service.report;

import com.itextpdf.io.font.PdfEncodings;
import com.itextpdf.io.image.ImageDataFactory;
import com.itextpdf.kernel.colors.ColorConstants;
import com.itextpdf.kernel.colors.DeviceRgb;
import com.itextpdf.kernel.font.PdfFont;
import com.itextpdf.kernel.font.PdfFontFactory;
import com.itextpdf.kernel.geom.PageSize;
import com.itextpdf.kernel.pdf.PdfDocument;
import com.itextpdf.kernel.pdf.PdfWriter;
import com.itextpdf.layout.Document;
import com.itextpdf.layout.borders.Border;
import com.itextpdf.layout.borders.SolidBorder;
import com.itextpdf.layout.element.*;
import com.itextpdf.layout.properties.HorizontalAlignment;
import com.itextpdf.layout.properties.TextAlignment;
import com.itextpdf.layout.properties.UnitValue;
import com.itextpdf.layout.properties.VerticalAlignment;
import com.newsinsight.collector.dto.report.ChartData;
import com.newsinsight.collector.dto.report.ReportRequest;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;

import java.io.ByteArrayOutputStream;
import java.io.IOException;
import java.time.LocalDateTime;
import java.time.format.DateTimeFormatter;
import java.util.Base64;
import java.util.List;
import java.util.Map;

/**
 * PDF 생성 엔진 서비스
 * 
 * iText 7을 사용하여 PDF 문서를 생성합니다.
 * 한글 폰트 지원 및 차트 이미지 삽입 기능을 제공합니다.
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class PdfExportService {

    private final ChartGenerationService chartGenerationService;

    // 색상 상수
    private static final DeviceRgb PRIMARY_COLOR = new DeviceRgb(59, 130, 246);    // Blue
    private static final DeviceRgb SUCCESS_COLOR = new DeviceRgb(16, 185, 129);    // Green
    private static final DeviceRgb WARNING_COLOR = new DeviceRgb(245, 158, 11);    // Yellow
    private static final DeviceRgb DANGER_COLOR = new DeviceRgb(239, 68, 68);      // Red
    private static final DeviceRgb NEUTRAL_COLOR = new DeviceRgb(107, 114, 128);   // Gray
    private static final DeviceRgb LIGHT_BG = new DeviceRgb(248, 250, 252);        // Light Gray BG

    // 폰트 경로 (클래스패스 또는 시스템)
    private static final String FONT_REGULAR = "fonts/NotoSansKR-Regular.ttf";
    private static final String FONT_BOLD = "fonts/NotoSansKR-Bold.ttf";

    /**
     * 통합 검색 보고서 PDF 생성
     */
    public byte[] generateUnifiedSearchReport(
            String title,
            String query,
            String timeWindow,
            Map<String, Object> summaryData,
            List<Map<String, Object>> results,
            Map<String, String> chartImages,
            List<ReportRequest.ReportSection> sections
    ) throws IOException {
        
        ByteArrayOutputStream baos = new ByteArrayOutputStream();
        PdfWriter writer = new PdfWriter(baos);
        PdfDocument pdf = new PdfDocument(writer);
        Document document = new Document(pdf, PageSize.A4);
        
        try {
            // 폰트 설정
            PdfFont regularFont = loadFont(FONT_REGULAR);
            PdfFont boldFont = loadFont(FONT_BOLD);
            document.setFont(regularFont);
            
            // 여백 설정
            document.setMargins(50, 50, 50, 50);
            
            // 1. 표지
            if (sections.contains(ReportRequest.ReportSection.COVER)) {
                addCoverPage(document, boldFont, title, query, timeWindow);
            }
            
            // 2. 요약
            if (sections.contains(ReportRequest.ReportSection.EXECUTIVE_SUMMARY)) {
                addExecutiveSummary(document, boldFont, regularFont, summaryData);
            }
            
            // 3. 데이터 소스 분석
            if (sections.contains(ReportRequest.ReportSection.DATA_SOURCE)) {
                addDataSourceAnalysis(document, boldFont, regularFont, results, chartImages);
            }
            
            // 4. 키워드 분석
            if (sections.contains(ReportRequest.ReportSection.KEYWORD_ANALYSIS)) {
                addKeywordAnalysis(document, boldFont, regularFont, summaryData, chartImages);
            }
            
            // 5. 감정 분석
            if (sections.contains(ReportRequest.ReportSection.SENTIMENT_ANALYSIS)) {
                addSentimentAnalysis(document, boldFont, regularFont, summaryData, chartImages);
            }
            
            // 6. 신뢰도 분석
            if (sections.contains(ReportRequest.ReportSection.RELIABILITY)) {
                addReliabilityAnalysis(document, boldFont, regularFont, summaryData, chartImages);
            }
            
            // 7. 상세 결과
            if (sections.contains(ReportRequest.ReportSection.DETAILED_RESULTS)) {
                addDetailedResults(document, boldFont, regularFont, results);
            }
            
            // 페이지 번호 추가
            addPageNumbers(pdf, regularFont);
            
        } finally {
            document.close();
        }
        
        return baos.toByteArray();
    }

    /**
     * 표지 페이지 추가
     */
    private void addCoverPage(Document document, PdfFont boldFont, String title, String query, String timeWindow) {
        // 상단 여백
        document.add(new Paragraph("\n\n\n\n\n\n"));
        
        // 로고 영역 (텍스트로 대체)
        Paragraph logo = new Paragraph("NewsInsight")
                .setFont(boldFont)
                .setFontSize(36)
                .setFontColor(PRIMARY_COLOR)
                .setTextAlignment(TextAlignment.CENTER);
        document.add(logo);
        
        // 부제목
        Paragraph subtitle = new Paragraph("뉴스 분석 플랫폼")
                .setFontSize(14)
                .setFontColor(NEUTRAL_COLOR)
                .setTextAlignment(TextAlignment.CENTER)
                .setMarginBottom(60);
        document.add(subtitle);
        
        // 구분선
        document.add(createDivider());
        
        // 보고서 제목
        Paragraph reportTitle = new Paragraph(title)
                .setFont(boldFont)
                .setFontSize(24)
                .setTextAlignment(TextAlignment.CENTER)
                .setMarginTop(40)
                .setMarginBottom(20);
        document.add(reportTitle);
        
        // 검색 쿼리
        Paragraph queryPara = new Paragraph("검색어: " + query)
                .setFontSize(16)
                .setFontColor(NEUTRAL_COLOR)
                .setTextAlignment(TextAlignment.CENTER)
                .setMarginBottom(10);
        document.add(queryPara);
        
        // 기간
        Paragraph periodPara = new Paragraph("분석 기간: " + formatTimeWindow(timeWindow))
                .setFontSize(14)
                .setFontColor(NEUTRAL_COLOR)
                .setTextAlignment(TextAlignment.CENTER)
                .setMarginBottom(60);
        document.add(periodPara);
        
        // 구분선
        document.add(createDivider());
        
        // 생성 일시
        String dateStr = LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyy년 MM월 dd일 HH:mm"));
        Paragraph datePara = new Paragraph("생성 일시: " + dateStr)
                .setFontSize(12)
                .setFontColor(NEUTRAL_COLOR)
                .setTextAlignment(TextAlignment.CENTER)
                .setMarginTop(40);
        document.add(datePara);
        
        // 페이지 나누기
        document.add(new AreaBreak());
    }

    /**
     * 요약 섹션 추가
     */
    @SuppressWarnings("unchecked")
    private void addExecutiveSummary(Document document, PdfFont boldFont, PdfFont regularFont, 
                                     Map<String, Object> summaryData) {
        // 섹션 제목
        document.add(createSectionTitle("요약 (Executive Summary)", boldFont));
        
        // 주요 통계 테이블
        Table statsTable = new Table(UnitValue.createPercentArray(new float[]{1, 1, 1, 1}))
                .useAllAvailableWidth()
                .setMarginBottom(20);
        
        int totalResults = getIntValue(summaryData, "totalResults", 0);
        int dbResults = getIntValue(summaryData, "dbResults", 0);
        int webResults = getIntValue(summaryData, "webResults", 0);
        int aiResults = getIntValue(summaryData, "aiResults", 0);
        
        statsTable.addCell(createStatCell("총 결과", String.valueOf(totalResults), boldFont, regularFont, PRIMARY_COLOR));
        statsTable.addCell(createStatCell("DB 검색", String.valueOf(dbResults), boldFont, regularFont, SUCCESS_COLOR));
        statsTable.addCell(createStatCell("웹 크롤링", String.valueOf(webResults), boldFont, regularFont, WARNING_COLOR));
        statsTable.addCell(createStatCell("AI 분석", String.valueOf(aiResults), boldFont, regularFont, DANGER_COLOR));
        
        document.add(statsTable);
        
        // AI 요약
        String aiSummary = (String) summaryData.get("aiSummary");
        if (aiSummary != null && !aiSummary.isBlank()) {
            document.add(new Paragraph("AI 분석 요약")
                    .setFont(boldFont)
                    .setFontSize(14)
                    .setMarginTop(20)
                    .setMarginBottom(10));
            
            // 요약 박스
            Div summaryBox = new Div()
                    .setBackgroundColor(LIGHT_BG)
                    .setPadding(15)
                    .setBorder(new SolidBorder(new DeviceRgb(226, 232, 240), 1))
                    .setMarginBottom(20);
            
            summaryBox.add(new Paragraph(truncateText(aiSummary, 5000))
                    .setFontSize(11)
                    .setFontColor(new DeviceRgb(51, 65, 85)));
            
            document.add(summaryBox);
        }
        
        // 주요 발견 사항
        List<String> keyFindings = (List<String>) summaryData.get("keyFindings");
        if (keyFindings != null && !keyFindings.isEmpty()) {
            document.add(new Paragraph("주요 발견 사항")
                    .setFont(boldFont)
                    .setFontSize(14)
                    .setMarginTop(10)
                    .setMarginBottom(10));
            
            com.itextpdf.layout.element.List findingsList = new com.itextpdf.layout.element.List()
                    .setSymbolIndent(12)
                    .setListSymbol("•");
            
            for (String finding : keyFindings) {
                ListItem item = new ListItem(finding);
                item.setFontSize(11);
                findingsList.add(item);
            }
            
            document.add(findingsList);
        }
        
        document.add(new AreaBreak());
    }

    /**
     * 데이터 소스 분석 섹션 추가
     */
    private void addDataSourceAnalysis(Document document, PdfFont boldFont, PdfFont regularFont,
                                       List<Map<String, Object>> results, Map<String, String> chartImages) {
        document.add(createSectionTitle("데이터 소스 분석", boldFont));
        
        // 소스별 분포 계산
        Map<String, Long> sourceDistribution = calculateSourceDistribution(results);
        
        // 통계 테이블
        Table table = new Table(UnitValue.createPercentArray(new float[]{2, 1, 1}))
                .useAllAvailableWidth()
                .setMarginBottom(20);
        
        table.addHeaderCell(createHeaderCell("소스", boldFont));
        table.addHeaderCell(createHeaderCell("결과 수", boldFont));
        table.addHeaderCell(createHeaderCell("비율", boldFont));
        
        long total = sourceDistribution.values().stream().mapToLong(Long::longValue).sum();
        
        sourceDistribution.forEach((source, count) -> {
            double percentage = total > 0 ? (count * 100.0 / total) : 0;
            table.addCell(createDataCell(formatSourceName(source), regularFont));
            table.addCell(createDataCell(String.valueOf(count), regularFont));
            table.addCell(createDataCell(String.format("%.1f%%", percentage), regularFont));
        });
        
        document.add(table);
        
        // 차트 이미지 삽입
        if (chartImages != null && chartImages.containsKey("sourceDistribution")) {
            addChartImage(document, chartImages.get("sourceDistribution"), "소스별 결과 분포");
        } else {
            // 서버 사이드 차트 생성
            try {
                byte[] chartBytes = chartGenerationService.generatePieChart(
                        ChartData.pie("소스별 결과 분포",
                                sourceDistribution.keySet().stream().map(this::formatSourceName).toList(),
                                sourceDistribution.values().stream().map(v -> (Number) v).toList(),
                                List.of("#3b82f6", "#10b981", "#f59e0b", "#ef4444"))
                );
                addChartImage(document, chartBytes, null);
            } catch (Exception e) {
                log.warn("Failed to generate source distribution chart: {}", e.getMessage());
            }
        }
    }

    /**
     * 키워드 분석 섹션 추가
     */
    @SuppressWarnings("unchecked")
    private void addKeywordAnalysis(Document document, PdfFont boldFont, PdfFont regularFont,
                                    Map<String, Object> summaryData, Map<String, String> chartImages) {
        document.add(createSectionTitle("키워드 분석", boldFont));
        
        List<Map<String, Object>> keywords = (List<Map<String, Object>>) summaryData.get("keywords");
        
        if (keywords != null && !keywords.isEmpty()) {
            // 키워드 테이블
            Table table = new Table(UnitValue.createPercentArray(new float[]{1, 3, 1}))
                    .useAllAvailableWidth()
                    .setMarginBottom(20);
            
            table.addHeaderCell(createHeaderCell("순위", boldFont));
            table.addHeaderCell(createHeaderCell("키워드", boldFont));
            table.addHeaderCell(createHeaderCell("빈도", boldFont));
            
            int rank = 1;
            for (Map<String, Object> kw : keywords.subList(0, Math.min(15, keywords.size()))) {
                table.addCell(createDataCell(String.valueOf(rank++), regularFont));
                table.addCell(createDataCell((String) kw.get("word"), regularFont));
                table.addCell(createDataCell(String.valueOf(kw.get("count")), regularFont));
            }
            
            document.add(table);
        }
        
        // 차트 이미지 삽입
        if (chartImages != null && chartImages.containsKey("keywords")) {
            addChartImage(document, chartImages.get("keywords"), "상위 키워드 분포");
        }
        
        document.add(new AreaBreak());
    }

    /**
     * 감정 분석 섹션 추가
     */
    @SuppressWarnings("unchecked")
    private void addSentimentAnalysis(Document document, PdfFont boldFont, PdfFont regularFont,
                                      Map<String, Object> summaryData, Map<String, String> chartImages) {
        document.add(createSectionTitle("감정 분석", boldFont));
        
        Map<String, Object> sentiment = (Map<String, Object>) summaryData.get("sentiment");
        
        if (sentiment != null) {
            double positive = getDoubleValue(sentiment, "positive", 0);
            double neutral = getDoubleValue(sentiment, "neutral", 0);
            double negative = getDoubleValue(sentiment, "negative", 0);
            
            // 감정 통계 테이블
            Table statsTable = new Table(UnitValue.createPercentArray(new float[]{1, 1, 1}))
                    .useAllAvailableWidth()
                    .setMarginBottom(20);
            
            statsTable.addCell(createStatCell("긍정", String.format("%.1f%%", positive * 100), 
                    boldFont, regularFont, SUCCESS_COLOR));
            statsTable.addCell(createStatCell("중립", String.format("%.1f%%", neutral * 100), 
                    boldFont, regularFont, NEUTRAL_COLOR));
            statsTable.addCell(createStatCell("부정", String.format("%.1f%%", negative * 100), 
                    boldFont, regularFont, DANGER_COLOR));
            
            document.add(statsTable);
            
            // 분석 설명
            String dominantSentiment = positive > negative ? 
                    (positive > neutral ? "긍정적" : "중립적") : 
                    (negative > neutral ? "부정적" : "중립적");
            
            document.add(new Paragraph("분석 결과, 전체적으로 " + dominantSentiment + "인 톤이 우세합니다.")
                    .setFontSize(11)
                    .setFontColor(NEUTRAL_COLOR)
                    .setMarginBottom(20));
        }
        
        // 차트 이미지 삽입
        if (chartImages != null && chartImages.containsKey("sentiment")) {
            addChartImage(document, chartImages.get("sentiment"), "감정 분석 결과");
        }
    }

    /**
     * 신뢰도 분석 섹션 추가
     */
    @SuppressWarnings("unchecked")
    private void addReliabilityAnalysis(Document document, PdfFont boldFont, PdfFont regularFont,
                                        Map<String, Object> summaryData, Map<String, String> chartImages) {
        document.add(createSectionTitle("신뢰도 분석", boldFont));
        
        Map<String, Object> reliability = (Map<String, Object>) summaryData.get("reliability");
        
        if (reliability != null) {
            double avgScore = getDoubleValue(reliability, "averageScore", 0);
            String grade = (String) reliability.getOrDefault("grade", "N/A");
            
            // 신뢰도 점수 표시
            Div scoreBox = new Div()
                    .setBackgroundColor(getGradeColor(grade))
                    .setPadding(20)
                    .setMarginBottom(20)
                    .setTextAlignment(TextAlignment.CENTER);
            
            scoreBox.add(new Paragraph("평균 신뢰도 점수")
                    .setFont(boldFont)
                    .setFontSize(14)
                    .setFontColor(ColorConstants.WHITE));
            
            scoreBox.add(new Paragraph(String.format("%.0f / 100", avgScore))
                    .setFont(boldFont)
                    .setFontSize(36)
                    .setFontColor(ColorConstants.WHITE));
            
            scoreBox.add(new Paragraph("등급: " + grade)
                    .setFontSize(14)
                    .setFontColor(ColorConstants.WHITE));
            
            document.add(scoreBox);
        }
        
        // 차트 이미지 삽입
        if (chartImages != null && chartImages.containsKey("reliability")) {
            addChartImage(document, chartImages.get("reliability"), "신뢰도 분포");
        }
        
        document.add(new AreaBreak());
    }

    /**
     * 상세 결과 섹션 추가
     */
    private void addDetailedResults(Document document, PdfFont boldFont, PdfFont regularFont,
                                    List<Map<String, Object>> results) {
        document.add(createSectionTitle("상세 검색 결과", boldFont));
        
        if (results == null || results.isEmpty()) {
            document.add(new Paragraph("검색 결과가 없습니다.")
                    .setFontSize(11)
                    .setFontColor(NEUTRAL_COLOR));
            return;
        }
        
        int count = 0;
        for (Map<String, Object> result : results) {
            if (count >= 30) {  // 최대 30개 결과만 표시
                document.add(new Paragraph("... 외 " + (results.size() - 30) + "개 결과")
                        .setFontSize(11)
                        .setFontColor(NEUTRAL_COLOR)
                        .setMarginTop(10));
                break;
            }
            
            // 결과 박스
            Div resultBox = new Div()
                    .setBackgroundColor(LIGHT_BG)
                    .setPadding(12)
                    .setBorder(new SolidBorder(new DeviceRgb(226, 232, 240), 1))
                    .setMarginBottom(10);
            
            // 제목
            String title = (String) result.getOrDefault("title", "제목 없음");
            resultBox.add(new Paragraph(truncateText(title, 100))
                    .setFont(boldFont)
                    .setFontSize(12)
                    .setFontColor(PRIMARY_COLOR)
                    .setMarginBottom(5));
            
            // 출처 및 날짜
            String source = (String) result.getOrDefault("source", "");
            String publishedAt = (String) result.getOrDefault("publishedAt", "");
            resultBox.add(new Paragraph(source + " | " + publishedAt)
                    .setFontSize(10)
                    .setFontColor(NEUTRAL_COLOR)
                    .setMarginBottom(5));
            
            // 본문 내용 (content가 있으면 전체 사용, 없으면 snippet 사용)
            String content = (String) result.get("content");
            String snippet = (String) result.get("snippet");
            String displayContent = (content != null && !content.isBlank()) ? content : snippet;
            if (displayContent != null && !displayContent.isBlank()) {
                // PDF에서는 너무 긴 내용은 적절히 잘라서 표시 (최대 10000자)
                String truncatedContent = displayContent.length() > 10000 
                    ? displayContent.substring(0, 10000) + "..." 
                    : displayContent;
                resultBox.add(new Paragraph(truncatedContent)
                        .setFontSize(10)
                        .setFontColor(new DeviceRgb(71, 85, 105)));
            }
            
            // URL (출처 링크)
            String url = (String) result.get("url");
            if (url != null && !url.isBlank()) {
                resultBox.add(new Paragraph("출처: " + url)
                        .setFontSize(9)
                        .setFontColor(PRIMARY_COLOR)
                        .setMarginTop(5));
            }
            
            document.add(resultBox);
            count++;
        }
    }

    // ===== 헬퍼 메서드 =====

    private PdfFont loadFont(String fontPath) throws IOException {
        try {
            // 클래스패스에서 리소스 로드
            var resource = getClass().getClassLoader().getResourceAsStream(fontPath);
            if (resource == null) {
                log.warn("Font resource not found: {}, using default font", fontPath);
                return PdfFontFactory.createFont();
            }
            
            byte[] fontBytes = resource.readAllBytes();
            return PdfFontFactory.createFont(fontBytes, PdfEncodings.IDENTITY_H);
        } catch (Exception e) {
            log.error("Failed to load font from {}: {}", fontPath, e.getMessage(), e);
            // 기본 폰트 사용
            return PdfFontFactory.createFont();
        }
    }

    private Paragraph createSectionTitle(String title, PdfFont boldFont) {
        return new Paragraph(title)
                .setFont(boldFont)
                .setFontSize(18)
                .setFontColor(new DeviceRgb(30, 41, 59))
                .setMarginTop(20)
                .setMarginBottom(15)
                .setBorderBottom(new SolidBorder(PRIMARY_COLOR, 2))
                .setPaddingBottom(10);
    }

    private Div createDivider() {
        return new Div()
                .setHeight(1)
                .setBackgroundColor(new DeviceRgb(226, 232, 240))
                .setMarginTop(10)
                .setMarginBottom(10);
    }

    private Cell createStatCell(String label, String value, PdfFont boldFont, PdfFont regularFont, DeviceRgb color) {
        Cell cell = new Cell()
                .setBorder(Border.NO_BORDER)
                .setBackgroundColor(LIGHT_BG)
                .setPadding(15)
                .setTextAlignment(TextAlignment.CENTER);
        
        cell.add(new Paragraph(value)
                .setFont(boldFont)
                .setFontSize(24)
                .setFontColor(color));
        
        cell.add(new Paragraph(label)
                .setFont(regularFont)
                .setFontSize(11)
                .setFontColor(NEUTRAL_COLOR));
        
        return cell;
    }

    private Cell createHeaderCell(String text, PdfFont boldFont) {
        return new Cell()
                .add(new Paragraph(text).setFont(boldFont).setFontSize(11))
                .setBackgroundColor(new DeviceRgb(241, 245, 249))
                .setPadding(8)
                .setTextAlignment(TextAlignment.CENTER);
    }

    private Cell createDataCell(String text, PdfFont regularFont) {
        return new Cell()
                .add(new Paragraph(text != null ? text : "-").setFont(regularFont).setFontSize(10))
                .setPadding(8)
                .setTextAlignment(TextAlignment.CENTER);
    }

    private void addChartImage(Document document, String base64Image, String caption) {
        try {
            byte[] imageBytes = Base64.getDecoder().decode(
                    base64Image.contains(",") ? base64Image.split(",")[1] : base64Image
            );
            addChartImage(document, imageBytes, caption);
        } catch (Exception e) {
            log.warn("Failed to add chart image: {}", e.getMessage());
        }
    }

    private void addChartImage(Document document, byte[] imageBytes, String caption) {
        try {
            Image image = new Image(ImageDataFactory.create(imageBytes))
                    .setMaxWidth(450)
                    .setHorizontalAlignment(HorizontalAlignment.CENTER)
                    .setMarginTop(10)
                    .setMarginBottom(10);
            
            document.add(image);
            
            if (caption != null && !caption.isBlank()) {
                document.add(new Paragraph(caption)
                        .setFontSize(10)
                        .setFontColor(NEUTRAL_COLOR)
                        .setTextAlignment(TextAlignment.CENTER)
                        .setMarginBottom(15));
            }
        } catch (Exception e) {
            log.warn("Failed to add chart image: {}", e.getMessage());
        }
    }

    private void addPageNumbers(PdfDocument pdf, PdfFont font) {
        int numberOfPages = pdf.getNumberOfPages();
        for (int i = 1; i <= numberOfPages; i++) {
            // 페이지 번호는 표지를 제외하고 시작
            if (i == 1) continue;
            
            Document doc = new Document(pdf.getPage(i).getDocument());
            Paragraph pageNumber = new Paragraph(String.format("%d / %d", i, numberOfPages))
                    .setFont(font)
                    .setFontSize(10)
                    .setFontColor(NEUTRAL_COLOR);
            
            // 하단 중앙에 추가
            doc.showTextAligned(pageNumber,
                    pdf.getPage(i).getPageSize().getWidth() / 2,
                    30,
                    i,
                    TextAlignment.CENTER,
                    VerticalAlignment.BOTTOM,
                    0);
        }
    }

    private Map<String, Long> calculateSourceDistribution(List<Map<String, Object>> results) {
        if (results == null) return Map.of();
        
        return results.stream()
                .map(r -> (String) r.getOrDefault("_source", r.getOrDefault("source", "unknown")))
                .collect(java.util.stream.Collectors.groupingBy(
                        s -> s,
                        java.util.stream.Collectors.counting()
                ));
    }

    private String formatSourceName(String source) {
        return switch (source.toLowerCase()) {
            case "database" -> "데이터베이스";
            case "web" -> "웹 크롤링";
            case "ai" -> "AI 분석";
            default -> source;
        };
    }

    private String formatTimeWindow(String window) {
        return switch (window) {
            case "1d" -> "최근 1일";
            case "7d" -> "최근 7일";
            case "30d" -> "최근 30일";
            case "90d" -> "최근 90일";
            case "1y" -> "최근 1년";
            default -> window;
        };
    }

    private DeviceRgb getGradeColor(String grade) {
        return switch (grade.toUpperCase()) {
            case "A", "HIGH" -> SUCCESS_COLOR;
            case "B", "MEDIUM" -> new DeviceRgb(34, 197, 94);
            case "C" -> WARNING_COLOR;
            case "D", "LOW" -> new DeviceRgb(249, 115, 22);
            case "F" -> DANGER_COLOR;
            default -> NEUTRAL_COLOR;
        };
    }

    private String truncateText(String text, int maxLength) {
        if (text == null) return "";
        return text.length() > maxLength ? text.substring(0, maxLength) + "..." : text;
    }

    private int getIntValue(Map<String, Object> map, String key, int defaultValue) {
        Object value = map.get(key);
        if (value instanceof Number) {
            return ((Number) value).intValue();
        }
        return defaultValue;
    }

    private double getDoubleValue(Map<String, Object> map, String key, double defaultValue) {
        Object value = map.get(key);
        if (value instanceof Number) {
            return ((Number) value).doubleValue();
        }
        return defaultValue;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/report/ReportGenerationService.java

```java
package com.newsinsight.collector.service.report;

import com.newsinsight.collector.dto.report.ReportMetadata;
import com.newsinsight.collector.dto.report.ReportRequest;
import com.newsinsight.collector.entity.search.SearchHistory;
import com.newsinsight.collector.repository.SearchHistoryRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.scheduling.annotation.Async;
import org.springframework.stereotype.Service;

import java.io.IOException;
import java.time.LocalDateTime;
import java.util.*;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ConcurrentHashMap;

/**
 * 보고서 생성 오케스트레이터 서비스
 * 
 * 보고서 생성 요청을 관리하고, PDF 생성을 조정합니다.
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class ReportGenerationService {

    private final PdfExportService pdfExportService;
    private final SearchHistoryRepository searchHistoryRepository;
    
    // 생성된 보고서 캐시 (실제 운영에서는 Redis나 파일 시스템 사용)
    private final Map<String, byte[]> reportCache = new ConcurrentHashMap<>();
    private final Map<String, ReportMetadata> metadataCache = new ConcurrentHashMap<>();

    /**
     * 통합 검색 보고서 생성 요청
     */
    public ReportMetadata requestUnifiedSearchReport(String jobId, ReportRequest request) {
        String reportId = UUID.randomUUID().toString();
        
        ReportMetadata metadata = ReportMetadata.builder()
                .reportId(reportId)
                .reportType(ReportRequest.ReportType.UNIFIED_SEARCH)
                .targetId(jobId)
                .query(request.getQuery())
                .status(ReportMetadata.ReportStatus.PENDING)
                .createdAt(LocalDateTime.now())
                .expiresAt(LocalDateTime.now().plusDays(7))
                .build();
        
        metadataCache.put(reportId, metadata);
        
        // 비동기로 보고서 생성 시작
        generateReportAsync(reportId, jobId, request);
        
        return metadata;
    }

    /**
     * 비동기 보고서 생성
     */
    @Async
    public CompletableFuture<ReportMetadata> generateReportAsync(String reportId, String jobId, ReportRequest request) {
        long startTime = System.currentTimeMillis();
        
        try {
            // 상태 업데이트: 생성 중
            updateMetadataStatus(reportId, ReportMetadata.ReportStatus.GENERATING);
            
            // 검색 이력 조회
            List<SearchHistory> histories = searchHistoryRepository.findByExternalIdContaining(jobId);
            
            if (histories.isEmpty()) {
                throw new IllegalArgumentException("Search history not found for job: " + jobId);
            }
            
            // 데이터 집계
            Map<String, Object> summaryData = aggregateSummaryData(histories);
            List<Map<String, Object>> results = aggregateResults(histories);
            
            // 보고서 제목 생성
            String title = request.getCustomTitle() != null 
                    ? request.getCustomTitle()
                    : "'" + request.getQuery() + "' 통합 검색 분석 보고서";
            
            // PDF 생성
            byte[] pdfBytes = pdfExportService.generateUnifiedSearchReport(
                    title,
                    request.getQuery(),
                    request.getTimeWindow(),
                    summaryData,
                    results,
                    request.getChartImages(),
                    request.getIncludeSections()
            );
            
            // 캐시에 저장
            reportCache.put(reportId, pdfBytes);
            
            // 메타데이터 업데이트
            long duration = System.currentTimeMillis() - startTime;
            ReportMetadata metadata = metadataCache.get(reportId);
            ReportMetadata updatedMetadata = ReportMetadata.builder()
                    .reportId(reportId)
                    .title(title)
                    .reportType(ReportRequest.ReportType.UNIFIED_SEARCH)
                    .targetId(jobId)
                    .query(request.getQuery())
                    .status(ReportMetadata.ReportStatus.COMPLETED)
                    .fileSize((long) pdfBytes.length)
                    .generationTimeMs(duration)
                    .createdAt(metadata.getCreatedAt())
                    .expiresAt(metadata.getExpiresAt())
                    .downloadUrl("/api/v1/reports/" + reportId + "/download")
                    .build();
            
            metadataCache.put(reportId, updatedMetadata);
            
            log.info("Report generated successfully: reportId={}, size={}KB, duration={}ms",
                    reportId, pdfBytes.length / 1024, duration);
            
            return CompletableFuture.completedFuture(updatedMetadata);
            
        } catch (Exception e) {
            log.error("Failed to generate report: reportId={}, error={}", reportId, e.getMessage(), e);
            
            ReportMetadata metadata = metadataCache.get(reportId);
            ReportMetadata failedMetadata = ReportMetadata.builder()
                    .reportId(reportId)
                    .reportType(ReportRequest.ReportType.UNIFIED_SEARCH)
                    .targetId(jobId)
                    .query(request.getQuery())
                    .status(ReportMetadata.ReportStatus.FAILED)
                    .createdAt(metadata != null ? metadata.getCreatedAt() : LocalDateTime.now())
                    .errorMessage(e.getMessage())
                    .build();
            
            metadataCache.put(reportId, failedMetadata);
            
            return CompletableFuture.completedFuture(failedMetadata);
        }
    }

    /**
     * 동기 보고서 생성 (즉시 다운로드용)
     */
    public byte[] generateReportSync(String jobId, ReportRequest request) throws IOException {
        // 검색 이력 조회
        List<SearchHistory> histories = searchHistoryRepository.findByExternalIdContaining(jobId);
        
        if (histories.isEmpty()) {
            throw new IllegalArgumentException("Search history not found for job: " + jobId);
        }
        
        // 데이터 집계
        Map<String, Object> summaryData = aggregateSummaryData(histories);
        List<Map<String, Object>> results = aggregateResults(histories);
        
        // 보고서 제목 생성
        String title = request.getCustomTitle() != null 
                ? request.getCustomTitle()
                : "'" + request.getQuery() + "' 통합 검색 분석 보고서";
        
        // PDF 생성 및 반환
        return pdfExportService.generateUnifiedSearchReport(
                title,
                request.getQuery(),
                request.getTimeWindow(),
                summaryData,
                results,
                request.getChartImages(),
                request.getIncludeSections()
        );
    }

    /**
     * 보고서 다운로드
     */
    public byte[] downloadReport(String reportId) {
        byte[] pdfBytes = reportCache.get(reportId);
        if (pdfBytes == null) {
            throw new IllegalArgumentException("Report not found or expired: " + reportId);
        }
        return pdfBytes;
    }

    /**
     * 보고서 메타데이터 조회
     */
    public ReportMetadata getReportMetadata(String reportId) {
        return metadataCache.get(reportId);
    }

    /**
     * 보고서 존재 여부 확인
     */
    public boolean reportExists(String reportId) {
        return reportCache.containsKey(reportId);
    }

    // ===== 헬퍼 메서드 =====

    private void updateMetadataStatus(String reportId, ReportMetadata.ReportStatus status) {
        ReportMetadata existing = metadataCache.get(reportId);
        if (existing != null) {
            ReportMetadata updated = ReportMetadata.builder()
                    .reportId(existing.getReportId())
                    .title(existing.getTitle())
                    .reportType(existing.getReportType())
                    .targetId(existing.getTargetId())
                    .query(existing.getQuery())
                    .status(status)
                    .fileSize(existing.getFileSize())
                    .pageCount(existing.getPageCount())
                    .generationTimeMs(existing.getGenerationTimeMs())
                    .createdAt(existing.getCreatedAt())
                    .expiresAt(existing.getExpiresAt())
                    .downloadUrl(existing.getDownloadUrl())
                    .errorMessage(existing.getErrorMessage())
                    .build();
            metadataCache.put(reportId, updated);
        }
    }

    @SuppressWarnings("unchecked")
    private Map<String, Object> aggregateSummaryData(List<SearchHistory> histories) {
        Map<String, Object> summary = new HashMap<>();
        
        int totalResults = 0;
        int dbResults = 0;
        int webResults = 0;
        int aiResults = 0;
        String aiSummary = null;
        Map<String, Object> sentiment = new HashMap<>();
        Map<String, Object> reliability = new HashMap<>();
        List<Map<String, Object>> keywords = new ArrayList<>();
        
        for (SearchHistory history : histories) {
            // 결과 수 집계
            if (history.getResults() != null) {
                List<Map<String, Object>> results = history.getResults();
                totalResults += results.size();
                
                for (Map<String, Object> result : results) {
                    String source = (String) result.getOrDefault("_source", 
                            result.getOrDefault("source", "unknown"));
                    switch (source.toLowerCase()) {
                        case "database" -> dbResults++;
                        case "web" -> webResults++;
                        case "ai" -> aiResults++;
                    }
                }
            }
            
            // AI 요약 추출
            if (history.getAiSummary() != null && aiSummary == null) {
                Map<String, Object> aiSummaryMap = history.getAiSummary();
                aiSummary = (String) aiSummaryMap.get("summary");
                if (aiSummary == null) {
                    aiSummary = (String) aiSummaryMap.get("content");
                }
            }
        }
        
        summary.put("totalResults", totalResults);
        summary.put("dbResults", dbResults);
        summary.put("webResults", webResults);
        summary.put("aiResults", aiResults);
        summary.put("aiSummary", aiSummary);
        summary.put("sentiment", sentiment);
        summary.put("reliability", reliability);
        summary.put("keywords", keywords);
        
        return summary;
    }

    private List<Map<String, Object>> aggregateResults(List<SearchHistory> histories) {
        List<Map<String, Object>> allResults = new ArrayList<>();
        
        for (SearchHistory history : histories) {
            if (history.getResults() != null) {
                allResults.addAll(history.getResults());
            }
        }
        
        // 중복 제거 (URL 기준)
        Set<String> seenUrls = new HashSet<>();
        List<Map<String, Object>> uniqueResults = new ArrayList<>();
        
        for (Map<String, Object> result : allResults) {
            String url = (String) result.get("url");
            if (url == null || !seenUrls.contains(url)) {
                uniqueResults.add(result);
                if (url != null) {
                    seenUrls.add(url);
                }
            }
        }
        
        return uniqueResults;
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/search/AdvancedIntentAnalyzer.java

```java
package com.newsinsight.collector.service.search;

import com.newsinsight.collector.service.search.HybridRankingService.QueryIntent;
import com.newsinsight.collector.service.search.HybridRankingService.QueryIntent.IntentType;
import lombok.Builder;
import lombok.Data;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;

import java.util.*;
import java.util.regex.Matcher;
import java.util.regex.Pattern;
import java.util.stream.Collectors;

/**
 * 고급 의도 분석 서비스
 * 
 * 사용자 쿼리에서 키워드 추출, 문맥 분석, 쿼리 확장, 폴백 전략 생성을 수행하여
 * 검색 결과의 품질과 적중률을 보장합니다.
 * 
 * 주요 기능:
 * 1. 한국어/영어 키워드 추출
 * 2. 의도 유형 분석 (팩트체크, 최신뉴스, 심층분석 등)
 * 3. 쿼리 확장 및 변형 생성
 * 4. 폴백 검색 전략 생성
 * 5. 결과 보장 로직
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class AdvancedIntentAnalyzer {

    // ============================================
    // 상수 및 패턴 정의
    // ============================================

    // 한국어 불용어
    private static final Set<String> KOREAN_STOPWORDS = Set.of(
            "은", "는", "이", "가", "을", "를", "의", "에", "에서", "로", "으로",
            "와", "과", "도", "만", "부터", "까지", "에게", "한테", "께",
            "이다", "하다", "있다", "없다", "되다", "않다",
            "그", "저", "이것", "그것", "저것", "여기", "거기", "저기",
            "뭐", "어디", "언제", "어떻게", "왜", "누구",
            "아주", "매우", "정말", "너무", "조금", "약간",
            "그리고", "그러나", "하지만", "그래서", "때문에",
            "것", "수", "등", "들", "및", "더", "덜",
            "대해", "대한", "관련", "관한"
    );

    // 영어 불용어
    private static final Set<String> ENGLISH_STOPWORDS = Set.of(
            "the", "a", "an", "and", "or", "but", "in", "on", "at", "to", "for",
            "of", "with", "by", "from", "is", "are", "was", "were", "be", "been",
            "being", "have", "has", "had", "do", "does", "did", "will", "would",
            "could", "should", "may", "might", "must", "shall", "can",
            "this", "that", "these", "those", "it", "its",
            "i", "you", "he", "she", "we", "they", "me", "him", "her", "us", "them",
            "what", "which", "who", "whom", "where", "when", "why", "how",
            "all", "each", "every", "both", "few", "more", "most", "other", "some",
            "such", "no", "nor", "not", "only", "own", "same", "so", "than", "too",
            "very", "just", "also", "now", "here", "there", "then", "about"
    );

    // 의도별 키워드 패턴 (확장)
    private static final Map<IntentType, List<String>> INTENT_PATTERNS = Map.of(
            IntentType.FACT_CHECK, List.of(
                    "사실", "진짜", "가짜", "팩트체크", "팩트 체크", "검증",
                    "진위", "확인", "루머", "허위", "오보", "실제로",
                    "정말", "맞는", "틀린", "fact", "check", "verify",
                    "true", "false", "fake", "hoax", "myth", "믿을 수",
                    "신뢰", "거짓", "조작", "왜곡"
            ),
            IntentType.LATEST_NEWS, List.of(
                    "오늘", "최근", "속보", "긴급", "방금", "지금",
                    "현재", "실시간", "최신", "breaking", "today",
                    "어제", "이번주", "금일", "latest", "recent",
                    "새로운", "발표", "업데이트"
            ),
            IntentType.DEEP_ANALYSIS, List.of(
                    "분석", "원인", "배경", "이유", "왜", "어떻게",
                    "영향", "전망", "예측", "해설", "설명", "의미",
                    "history", "analysis", "impact", "결과", "심층",
                    "상세", "깊이", "인사이트", "근본", "핵심"
            ),
            IntentType.OPINION_SEARCH, List.of(
                    "여론", "반응", "논란", "비판", "지지", "반대",
                    "찬성", "의견", "댓글", "네티즌", "SNS", "트위터",
                    "opinion", "reaction", "controversy", "debate",
                    "토론", "갑론을박", "시각"
            )
    );

    // 질문 패턴
    private static final Pattern QUESTION_PATTERN = Pattern.compile(
            "(\\?|인가요|인가|입니까|일까|일까요|나요|습니까|은가요|는가요|맞나요|아닌가요|뭔가요|무엇|어떤)$"
    );

    // 비교 패턴
    private static final Pattern COMPARISON_PATTERN = Pattern.compile(
            "(vs|versus|비교|차이|다른|어느|어떤 것이|보다)"
    );

    // 시간 표현 패턴
    private static final Pattern TIME_PATTERN = Pattern.compile(
            "(오늘|어제|이번주|지난주|최근|\\d+일|\\d+시간|\\d+분|\\d{4}년)"
    );

    // 한글 패턴
    private static final Pattern KOREAN_PATTERN = Pattern.compile("[가-힣]");

    // ============================================
    // DTO 클래스
    // ============================================

    @Data
    @Builder
    public static class AnalyzedQuery {
        private String originalQuery;
        private List<String> keywords;
        private String primaryKeyword;
        private IntentType intentType;
        private double confidence;
        private String language;
        private List<String> expandedQueries;
        private List<FallbackStrategy> fallbackStrategies;
        private String timeRange;
        private Map<String, Object> metadata;
    }

    @Data
    @Builder
    public static class FallbackStrategy {
        private String strategyType;
        private String query;
        private int priority;
        private String description;
    }

    public enum StrategyType {
        FULL_QUERY,
        KEYWORDS_AND,
        KEYWORDS_OR,
        PRIMARY_KEYWORD,
        SEMANTIC_VARIANT,
        RELATED_TOPIC,
        PARTIAL_MATCH,
        SYNONYM_SEARCH
    }

    // ============================================
    // 메인 분석 메서드
    // ============================================

    /**
     * 쿼리를 종합적으로 분석합니다.
     *
     * @param query 사용자 쿼리
     * @return 분석된 쿼리 정보
     */
    public AnalyzedQuery analyzeQuery(String query) {
        if (query == null || query.isBlank()) {
            return buildEmptyResult();
        }

        String normalizedQuery = query.trim();
        
        // 1. 언어 감지
        String language = detectLanguage(normalizedQuery);
        
        // 2. 키워드 추출
        List<String> keywords = extractKeywords(normalizedQuery, language);
        
        // 3. 주요 키워드 식별
        String primaryKeyword = identifyPrimaryKeyword(keywords, normalizedQuery);
        
        // 4. 의도 분석
        IntentType intentType = detectIntentType(normalizedQuery);
        double confidence = calculateConfidence(normalizedQuery, intentType);
        
        // 5. 시간 범위 추출
        String timeRange = extractTimeRange(normalizedQuery);
        
        // 6. 쿼리 확장
        List<String> expandedQueries = generateExpandedQueries(keywords, primaryKeyword, normalizedQuery, language);
        
        // 7. 폴백 전략 생성
        List<FallbackStrategy> fallbackStrategies = generateFallbackStrategies(
                normalizedQuery, keywords, primaryKeyword, expandedQueries, language
        );

        AnalyzedQuery result = AnalyzedQuery.builder()
                .originalQuery(normalizedQuery)
                .keywords(keywords)
                .primaryKeyword(primaryKeyword)
                .intentType(intentType)
                .confidence(confidence)
                .language(language)
                .expandedQueries(expandedQueries)
                .fallbackStrategies(fallbackStrategies)
                .timeRange(timeRange)
                .metadata(Map.of(
                        "keywordCount", keywords.size(),
                        "strategyCount", fallbackStrategies.size(),
                        "isQuestion", QUESTION_PATTERN.matcher(normalizedQuery).find(),
                        "isComparison", COMPARISON_PATTERN.matcher(normalizedQuery.toLowerCase()).find()
                ))
                .build();

        log.info("Query analyzed: keywords={}, primary='{}', intent={}, confidence={}, strategies={}",
                keywords.size(), primaryKeyword, intentType, String.format("%.2f", confidence), fallbackStrategies.size());

        return result;
    }

    /**
     * 기존 QueryIntent 형태로 변환합니다 (호환성 유지).
     */
    public QueryIntent toQueryIntent(AnalyzedQuery analyzed) {
        return QueryIntent.builder()
                .type(analyzed.getIntentType())
                .keywords(analyzed.getKeywords())
                .timeRange(analyzed.getTimeRange())
                .confidence(analyzed.getConfidence())
                .build();
    }

    // ============================================
    // 언어 감지
    // ============================================

    private String detectLanguage(String text) {
        if (text == null || text.isEmpty()) return "ko";
        
        int koreanCount = 0;
        int englishCount = 0;
        
        for (char c : text.toCharArray()) {
            if (c >= '가' && c <= '힣') {
                koreanCount++;
            } else if ((c >= 'A' && c <= 'Z') || (c >= 'a' && c <= 'z')) {
                englishCount++;
            }
        }
        
        int total = koreanCount + englishCount;
        if (total == 0) return "ko";
        
        return (double) koreanCount / total > 0.3 ? "ko" : "en";
    }

    // ============================================
    // 키워드 추출
    // ============================================

    private List<String> extractKeywords(String text, String language) {
        Set<String> stopwords = "ko".equals(language) ? KOREAN_STOPWORDS : ENGLISH_STOPWORDS;
        
        // 토큰화
        String[] tokens = text.toLowerCase()
                .replaceAll("[^가-힣a-zA-Z0-9\\s]", " ")
                .split("\\s+");
        
        List<String> keywords = new ArrayList<>();
        
        for (String token : tokens) {
            String trimmed = token.trim();
            
            // 불용어 제외
            if (stopwords.contains(trimmed)) continue;
            
            // 너무 짧은 토큰 제외 (한글은 1자도 의미있을 수 있음)
            if ("ko".equals(language) && trimmed.length() < 1) continue;
            if ("en".equals(language) && trimmed.length() < 2) continue;
            
            // 순수 숫자 제외
            if (trimmed.matches("\\d+")) continue;
            
            keywords.add(trimmed);
        }
        
        // 인용구 내 구문 추출
        Pattern quotedPattern = Pattern.compile("[\"']([^\"']+)[\"']");
        Matcher matcher = quotedPattern.matcher(text);
        while (matcher.find()) {
            String phrase = matcher.group(1).trim();
            if (!phrase.isEmpty() && !keywords.contains(phrase.toLowerCase())) {
                keywords.add(phrase.toLowerCase());
            }
        }
        
        // 복합명사 추출 (한국어)
        if ("ko".equals(language)) {
            Pattern compoundPattern = Pattern.compile("[가-힣]+(?:기업|회사|뉴스|정보|서비스|시스템|데이터|분석|결과|사건|사고|정책|발표)");
            Matcher compoundMatcher = compoundPattern.matcher(text);
            while (compoundMatcher.find()) {
                String compound = compoundMatcher.group().toLowerCase();
                if (!keywords.contains(compound)) {
                    keywords.add(compound);
                }
            }
        }
        
        // 중복 제거 및 최대 10개 제한
        return keywords.stream()
                .distinct()
                .limit(10)
                .collect(Collectors.toList());
    }

    // ============================================
    // 주요 키워드 식별
    // ============================================

    private String identifyPrimaryKeyword(List<String> keywords, String originalQuery) {
        if (keywords.isEmpty()) {
            String[] words = originalQuery.split("\\s+");
            return words.length > 0 ? words[0] : originalQuery;
        }
        
        // 점수 기반 주요 키워드 선정
        Map<String, Double> scores = new HashMap<>();
        
        for (String keyword : keywords) {
            double score = 0.0;
            
            // 길이 가중치 (더 긴 키워드가 더 구체적)
            score += Math.min(keyword.length() / 10.0, 1.0) * 0.3;
            
            // 위치 가중치 (앞에 있을수록 중요)
            int pos = originalQuery.toLowerCase().indexOf(keyword.toLowerCase());
            if (pos >= 0) {
                score += (1.0 - (double) pos / originalQuery.length()) * 0.3;
            }
            
            // 대문자 시작 (고유명사 가능성)
            if (Character.isUpperCase(keyword.charAt(0))) {
                score += 0.2;
            }
            
            // 숫자 포함 (구체적 식별자 가능성)
            if (keyword.matches(".*\\d+.*")) {
                score += 0.1;
            }
            
            // 복합어 (한국어)
            if (keyword.matches(".*[가-힣]+(기업|회사|사건|정책)$")) {
                score += 0.3;
            }
            
            scores.put(keyword, score);
        }
        
        return scores.entrySet().stream()
                .max(Map.Entry.comparingByValue())
                .map(Map.Entry::getKey)
                .orElse(keywords.get(0));
    }

    // ============================================
    // 의도 분석
    // ============================================

    private IntentType detectIntentType(String query) {
        String lowerQuery = query.toLowerCase();
        
        Map<IntentType, Double> scores = new EnumMap<>(IntentType.class);
        for (IntentType type : IntentType.values()) {
            scores.put(type, 0.0);
        }
        
        // 패턴 매칭
        for (Map.Entry<IntentType, List<String>> entry : INTENT_PATTERNS.entrySet()) {
            for (String pattern : entry.getValue()) {
                if (lowerQuery.contains(pattern.toLowerCase())) {
                    scores.merge(entry.getKey(), 1.0, Double::sum);
                }
            }
        }
        
        // 질문 형태 → 팩트체크 가능성
        if (QUESTION_PATTERN.matcher(lowerQuery).find()) {
            scores.merge(IntentType.FACT_CHECK, 0.5, Double::sum);
        }
        
        // 시간 표현 → 최신 뉴스 가능성
        if (TIME_PATTERN.matcher(lowerQuery).find()) {
            scores.merge(IntentType.LATEST_NEWS, 0.5, Double::sum);
        }
        
        // 비교 표현 → 심층 분석 가능성
        if (COMPARISON_PATTERN.matcher(lowerQuery).find()) {
            scores.merge(IntentType.DEEP_ANALYSIS, 0.3, Double::sum);
        }
        
        // 최고 점수 의도 선택
        IntentType bestIntent = IntentType.GENERAL;
        double maxScore = 0.0;
        
        for (Map.Entry<IntentType, Double> entry : scores.entrySet()) {
            if (entry.getValue() > maxScore) {
                maxScore = entry.getValue();
                bestIntent = entry.getKey();
            }
        }
        
        // 최소 임계값
        if (maxScore < 0.5) {
            bestIntent = IntentType.GENERAL;
        }
        
        return bestIntent;
    }

    private double calculateConfidence(String query, IntentType intentType) {
        if (intentType == IntentType.GENERAL) {
            return 0.7;
        }
        
        String lowerQuery = query.toLowerCase();
        List<String> patterns = INTENT_PATTERNS.getOrDefault(intentType, List.of());
        
        long matchCount = patterns.stream()
                .filter(p -> lowerQuery.contains(p.toLowerCase()))
                .count();
        
        double baseConfidence = Math.min(0.5 + matchCount * 0.15, 0.95);
        
        // 질문 형태 보너스
        if (QUESTION_PATTERN.matcher(lowerQuery).find()) {
            baseConfidence = Math.min(baseConfidence + 0.1, 0.95);
        }
        
        return baseConfidence;
    }

    // ============================================
    // 시간 범위 추출
    // ============================================

    private String extractTimeRange(String query) {
        String lowerQuery = query.toLowerCase();
        
        if (lowerQuery.contains("오늘") || lowerQuery.contains("금일") || lowerQuery.contains("today")) {
            return "1d";
        } else if (lowerQuery.contains("어제") || lowerQuery.contains("yesterday")) {
            return "2d";
        } else if (lowerQuery.contains("이번주") || lowerQuery.contains("this week")) {
            return "7d";
        } else if (lowerQuery.contains("지난주") || lowerQuery.contains("last week")) {
            return "14d";
        } else if (lowerQuery.contains("최근") || lowerQuery.contains("recent")) {
            return "7d";
        } else if (lowerQuery.contains("이번달") || lowerQuery.contains("한달") || lowerQuery.contains("this month")) {
            return "30d";
        }
        
        return null;
    }

    // ============================================
    // 쿼리 확장
    // ============================================

    private List<String> generateExpandedQueries(
            List<String> keywords,
            String primaryKeyword,
            String originalQuery,
            String language) {
        
        List<String> variants = new ArrayList<>();
        
        // 1. 원본 쿼리
        variants.add(originalQuery);
        
        // 2. 키워드 조합
        if (keywords.size() > 1) {
            variants.add(String.join(" ", keywords));
        }
        
        // 3. 주요 키워드만
        variants.add(primaryKeyword);
        
        // 4. 상위 2-3개 키워드
        if (keywords.size() >= 2) {
            variants.add(keywords.get(0) + " " + keywords.get(1));
        }
        if (keywords.size() >= 3) {
            variants.add(keywords.get(0) + " " + keywords.get(1) + " " + keywords.get(2));
        }
        
        // 5. 언어별 검색 접미사 추가
        if ("ko".equals(language)) {
            for (String keyword : keywords.subList(0, Math.min(3, keywords.size()))) {
                variants.add(keyword + " 뉴스");
                variants.add(keyword + " 정보");
                variants.add(keyword + " 최신");
            }
        } else {
            for (String keyword : keywords.subList(0, Math.min(3, keywords.size()))) {
                variants.add(keyword + " news");
                variants.add(keyword + " information");
                variants.add("about " + keyword);
            }
        }
        
        // 중복 제거
        return variants.stream()
                .distinct()
                .filter(v -> !v.isBlank())
                .collect(Collectors.toList());
    }

    // ============================================
    // 폴백 전략 생성
    // ============================================

    private List<FallbackStrategy> generateFallbackStrategies(
            String originalQuery,
            List<String> keywords,
            String primaryKeyword,
            List<String> expandedQueries,
            String language) {
        
        List<FallbackStrategy> strategies = new ArrayList<>();
        
        // 전략 1: 전체 쿼리
        strategies.add(FallbackStrategy.builder()
                .strategyType(StrategyType.FULL_QUERY.name())
                .query(originalQuery)
                .priority(1)
                .description("원본 쿼리로 검색")
                .build());
        
        // 전략 2: 키워드 AND
        if (keywords.size() > 1) {
            strategies.add(FallbackStrategy.builder()
                    .strategyType(StrategyType.KEYWORDS_AND.name())
                    .query(String.join(" ", keywords))
                    .priority(2)
                    .description("모든 키워드로 검색")
                    .build());
        }
        
        // 전략 3: 주요 키워드
        strategies.add(FallbackStrategy.builder()
                .strategyType(StrategyType.PRIMARY_KEYWORD.name())
                .query(primaryKeyword)
                .priority(3)
                .description("주요 키워드만으로 검색")
                .build());
        
        // 전략 4: 확장 쿼리들
        int priority = 4;
        for (String expanded : expandedQueries.subList(0, Math.min(3, expandedQueries.size()))) {
            if (!expanded.equals(originalQuery) && !expanded.equals(primaryKeyword)) {
                strategies.add(FallbackStrategy.builder()
                        .strategyType(StrategyType.SEMANTIC_VARIANT.name())
                        .query(expanded)
                        .priority(priority++)
                        .description("변형 쿼리: " + expanded)
                        .build());
            }
        }
        
        // 전략 5: 키워드 OR (넓은 검색)
        if (keywords.size() > 1) {
            strategies.add(FallbackStrategy.builder()
                    .strategyType(StrategyType.KEYWORDS_OR.name())
                    .query(String.join(" OR ", keywords.subList(0, Math.min(5, keywords.size()))))
                    .priority(priority++)
                    .description("키워드 OR 검색 (넓은 검색)")
                    .build());
        }
        
        // 전략 6: 부분 매칭
        if (keywords.size() >= 2) {
            strategies.add(FallbackStrategy.builder()
                    .strategyType(StrategyType.PARTIAL_MATCH.name())
                    .query(keywords.get(0) + " " + keywords.get(1))
                    .priority(priority++)
                    .description("상위 키워드 부분 매칭")
                    .build());
        }
        
        // 정렬
        strategies.sort(Comparator.comparingInt(FallbackStrategy::getPriority));
        
        return strategies;
    }

    // ============================================
    // 결과 보장 메서드
    // ============================================

    /**
     * 검색 결과가 없을 때 사용할 대체 메시지를 생성합니다.
     */
    public String buildNoResultMessage(AnalyzedQuery analyzed) {
        StringBuilder message = new StringBuilder();
        
        if ("ko".equals(analyzed.getLanguage())) {
            message.append("검색 결과를 찾기 어려웠습니다. 다음을 시도해 보세요:\n\n");
            message.append("시도한 검색어:\n");
            message.append("- ").append(analyzed.getOriginalQuery()).append("\n");
            message.append("- ").append(analyzed.getPrimaryKeyword()).append("\n");
            
            message.append("\n추천 검색 방법:\n");
            message.append("1. 검색어를 더 구체적으로 변경해 보세요\n");
            message.append("2. 다른 키워드를 사용해 보세요: ")
                    .append(String.join(", ", analyzed.getKeywords().subList(0, Math.min(3, analyzed.getKeywords().size()))))
                    .append("\n");
            message.append("3. 시간 범위를 조정해 보세요\n");
            
            message.append("\n분석된 의도: ").append(getIntentDescription(analyzed.getIntentType()));
        } else {
            message.append("Search results were difficult to find. Try the following:\n\n");
            message.append("Queries attempted:\n");
            message.append("- ").append(analyzed.getOriginalQuery()).append("\n");
            message.append("- ").append(analyzed.getPrimaryKeyword()).append("\n");
            
            message.append("\nRecommended approaches:\n");
            message.append("1. Try more specific keywords\n");
            message.append("2. Use alternative keywords: ")
                    .append(String.join(", ", analyzed.getKeywords().subList(0, Math.min(3, analyzed.getKeywords().size()))))
                    .append("\n");
            message.append("3. Adjust the time range\n");
            
            message.append("\nDetected intent: ").append(getIntentDescription(analyzed.getIntentType()));
        }
        
        return message.toString();
    }

    /**
     * 향상된 검색 태스크를 생성합니다.
     */
    public String buildEnhancedSearchTask(AnalyzedQuery analyzed, String originalTask) {
        StringBuilder task = new StringBuilder(originalTask);
        
        task.append("\n\n");
        
        if ("ko".equals(analyzed.getLanguage())) {
            task.append("검색 전략 (결과가 없으면 순서대로 시도하세요):\n");
            int num = 1;
            for (FallbackStrategy strategy : analyzed.getFallbackStrategies().subList(0, Math.min(5, analyzed.getFallbackStrategies().size()))) {
                task.append(num++).append(". ").append(strategy.getDescription())
                        .append(": \"").append(strategy.getQuery()).append("\"\n");
            }
            task.append("\n중요: 검색 결과가 없다고 말하지 마세요. 위의 전략을 모두 시도하고,\n");
            task.append("관련된 정보라도 찾아서 제공하세요. 완전히 일치하지 않더라도\n");
            task.append("가장 관련성 있는 정보를 제공하는 것이 중요합니다.");
        } else {
            task.append("Search strategies (try in order if no results):\n");
            int num = 1;
            for (FallbackStrategy strategy : analyzed.getFallbackStrategies().subList(0, Math.min(5, analyzed.getFallbackStrategies().size()))) {
                task.append(num++).append(". ").append(strategy.getDescription())
                        .append(": \"").append(strategy.getQuery()).append("\"\n");
            }
            task.append("\nIMPORTANT: Never say \"not found\" or \"no results\". Try ALL strategies above,\n");
            task.append("and provide whatever relevant information you can find. Even if not an exact match,\n");
            task.append("providing the most relevant information is important.");
        }
        
        return task.toString();
    }

    private String getIntentDescription(IntentType type) {
        return switch (type) {
            case FACT_CHECK -> "팩트체크/Fact Check - 정보의 진위 여부 검증";
            case LATEST_NEWS -> "최신 뉴스/Latest News - 최근 소식 우선";
            case DEEP_ANALYSIS -> "심층 분석/Deep Analysis - 배경과 맥락 포함";
            case OPINION_SEARCH -> "여론 검색/Opinion Search - 다양한 의견 수집";
            case GENERAL -> "일반 검색/General Search - 관련성 높은 정보";
        };
    }

    private AnalyzedQuery buildEmptyResult() {
        return AnalyzedQuery.builder()
                .originalQuery("")
                .keywords(List.of())
                .primaryKeyword("")
                .intentType(IntentType.GENERAL)
                .confidence(1.0)
                .language("ko")
                .expandedQueries(List.of())
                .fallbackStrategies(List.of())
                .metadata(Map.of())
                .build();
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/search/EmbeddingService.java

```java
package com.newsinsight.collector.service.search;

import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.http.MediaType;
import org.springframework.stereotype.Service;
import org.springframework.web.reactive.function.client.WebClient;
import reactor.core.publisher.Mono;

import jakarta.annotation.PostConstruct;
import java.time.Duration;
import java.util.Collections;
import java.util.List;
import java.util.Map;

/**
 * 텍스트 임베딩 서비스.
 * HuggingFace Text Embeddings Inference (TEI) 서버와 연동하여
 * 텍스트를 벡터로 변환합니다.
 * 
 * 지원 모델:
 * - intfloat/multilingual-e5-large (다국어, 1024차원)
 * - sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 (다국어, 384차원)
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class EmbeddingService {

    @Value("${collector.embedding.enabled:true}")
    private boolean enabled;

    @Value("${collector.embedding.base-url:http://localhost:8011}")
    private String baseUrl;

    @Value("${collector.embedding.model:intfloat/multilingual-e5-large}")
    private String modelName;

    @Value("${collector.embedding.timeout-seconds:30}")
    private int timeoutSeconds;

    @Value("${collector.embedding.dimension:1024}")
    private int embeddingDimension;

    private WebClient webClient;

    @PostConstruct
    public void init() {
        this.webClient = WebClient.builder()
                .baseUrl(baseUrl)
                .build();
        log.info("EmbeddingService initialized: enabled={}, baseUrl={}, model={}, dimension={}", 
                enabled, baseUrl, modelName, embeddingDimension);
    }

    /**
     * 텍스트를 벡터로 변환합니다.
     *
     * @param text 변환할 텍스트
     * @return 임베딩 벡터 (float 배열)
     */
    public Mono<float[]> embed(String text) {
        if (!enabled) {
            return Mono.empty();
        }

        if (text == null || text.isBlank()) {
            return Mono.just(new float[embeddingDimension]);
        }

        // E5 모델은 검색 쿼리에 "query: " 접두사를 붙이면 성능이 향상됨
        String processedText = text.length() > 8000 ? text.substring(0, 8000) : text;

        return webClient.post()
                .uri("/embed")
                .contentType(MediaType.APPLICATION_JSON)
                .bodyValue(Map.of("inputs", processedText))
                .retrieve()
                .bodyToMono(float[][].class)
                .timeout(Duration.ofSeconds(timeoutSeconds))
                .map(result -> result != null && result.length > 0 ? result[0] : new float[embeddingDimension])
                .doOnError(e -> log.error("Embedding failed for text (length={}): {}", 
                        text.length(), e.getMessage()))
                .onErrorReturn(new float[embeddingDimension]);
    }

    /**
     * 검색 쿼리를 벡터로 변환합니다.
     * E5 모델의 경우 "query: " 접두사를 추가합니다.
     *
     * @param query 검색 쿼리
     * @return 임베딩 벡터
     */
    public Mono<float[]> embedQuery(String query) {
        if (!enabled) {
            return Mono.empty();
        }

        // E5 모델용 쿼리 접두사
        String prefixedQuery = modelName.contains("e5") 
                ? "query: " + query 
                : query;
        
        return embed(prefixedQuery);
    }

    /**
     * 문서를 벡터로 변환합니다.
     * E5 모델의 경우 "passage: " 접두사를 추가합니다.
     *
     * @param document 문서 텍스트
     * @return 임베딩 벡터
     */
    public Mono<float[]> embedDocument(String document) {
        if (!enabled) {
            return Mono.empty();
        }

        // E5 모델용 문서 접두사
        String prefixedDoc = modelName.contains("e5") 
                ? "passage: " + document 
                : document;
        
        return embed(prefixedDoc);
    }

    /**
     * 여러 텍스트를 일괄 벡터 변환합니다.
     *
     * @param texts 변환할 텍스트 목록
     * @return 임베딩 벡터 목록
     */
    public Mono<List<float[]>> embedBatch(List<String> texts) {
        if (!enabled || texts == null || texts.isEmpty()) {
            return Mono.just(List.of());
        }

        // 텍스트 전처리
        List<String> processedTexts = texts.stream()
                .map(t -> t != null && t.length() > 8000 ? t.substring(0, 8000) : t)
                .map(t -> t != null ? t : "")
                .toList();

        return webClient.post()
                .uri("/embed")
                .contentType(MediaType.APPLICATION_JSON)
                .bodyValue(Map.of("inputs", processedTexts))
                .retrieve()
                .bodyToMono(float[][].class)
                .timeout(Duration.ofSeconds(timeoutSeconds * 2))
                .map(result -> result != null ? List.of(result) : List.<float[]>of())
                .doOnError(e -> log.error("Batch embedding failed for {} texts: {}", 
                        texts.size(), e.getMessage()))
                .onErrorResume(e -> Mono.just(List.<float[]>of()));
    }

    /**
     * 두 벡터 간의 코사인 유사도를 계산합니다.
     *
     * @param vec1 첫 번째 벡터
     * @param vec2 두 번째 벡터
     * @return 코사인 유사도 (-1 ~ 1)
     */
    public double cosineSimilarity(float[] vec1, float[] vec2) {
        if (vec1 == null || vec2 == null || vec1.length != vec2.length) {
            return 0.0;
        }

        double dotProduct = 0.0;
        double norm1 = 0.0;
        double norm2 = 0.0;

        for (int i = 0; i < vec1.length; i++) {
            dotProduct += vec1[i] * vec2[i];
            norm1 += vec1[i] * vec1[i];
            norm2 += vec2[i] * vec2[i];
        }

        if (norm1 == 0 || norm2 == 0) {
            return 0.0;
        }

        return dotProduct / (Math.sqrt(norm1) * Math.sqrt(norm2));
    }

    /**
     * 서비스 활성화 여부를 반환합니다.
     */
    public boolean isEnabled() {
        return enabled;
    }

    /**
     * 임베딩 차원을 반환합니다.
     */
    public int getDimension() {
        return embeddingDimension;
    }

    /**
     * 임베딩 서버 상태를 확인합니다.
     */
    public Mono<Boolean> healthCheck() {
        if (!enabled) {
            return Mono.just(false);
        }

        return webClient.get()
                .uri("/health")
                .retrieve()
                .bodyToMono(String.class)
                .timeout(Duration.ofSeconds(5))
                .map(response -> true)
                .onErrorReturn(false);
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/search/HybridRankingService.java

```java
package com.newsinsight.collector.service.search;

import com.newsinsight.collector.service.search.AdvancedIntentAnalyzer.AnalyzedQuery;
import com.newsinsight.collector.service.search.AdvancedIntentAnalyzer.FallbackStrategy;
import lombok.Builder;
import lombok.Data;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;

import java.util.*;
import java.util.stream.Collectors;

/**
 * Reciprocal Rank Fusion (RRF) 기반 하이브리드 랭킹 서비스.
 * 
 * 여러 검색 소스의 결과를 RRF 알고리즘으로 융합하여
 * 사용자 의도에 맞는 최적의 순서로 정렬합니다.
 * 
 * RRF 공식: score(d) = Σ 1/(k + rank_i(d))
 * - k: 상수 (기본값 60, 낮을수록 상위 랭크에 가중치)
 * - rank_i(d): i번째 검색 소스에서 문서 d의 순위
 * 
 * 참고: https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class HybridRankingService {

    private final AdvancedIntentAnalyzer advancedIntentAnalyzer;

    // RRF 상수 k - 낮을수록 상위 결과에 더 높은 가중치
    private static final double RRF_K = 60.0;

    // 검색 소스별 기본 가중치
    private static final Map<String, Double> DEFAULT_SOURCE_WEIGHTS = Map.of(
            "keyword", 1.0,      // 키워드 검색
            "semantic", 1.0,    // 시맨틱(벡터) 검색
            "database", 0.9,    // DB 검색 (기존 수집 데이터)
            "web", 0.8,         // 웹 크롤링
            "ai", 0.7           // AI 분석 결과
    );

    /**
     * 여러 소스의 검색 결과를 RRF로 융합합니다.
     *
     * @param rankedLists 소스별 검색 결과 (소스명 → 순위별 결과 리스트)
     * @return RRF 점수로 정렬된 통합 결과
     */
    public List<RankedResult> fuseResults(Map<String, List<SearchCandidate>> rankedLists) {
        return fuseResults(rankedLists, DEFAULT_SOURCE_WEIGHTS, null);
    }

    /**
     * 쿼리 의도에 따라 가중치를 조정하여 결과를 융합합니다.
     *
     * @param rankedLists 소스별 검색 결과
     * @param intent 쿼리 의도 (null이면 기본 가중치 사용)
     * @return RRF 점수로 정렬된 통합 결과
     */
    public List<RankedResult> fuseResults(
            Map<String, List<SearchCandidate>> rankedLists,
            QueryIntent intent) {
        
        Map<String, Double> adjustedWeights = adjustWeightsForIntent(intent);
        return fuseResults(rankedLists, adjustedWeights, intent);
    }

    /**
     * AdvancedIntentAnalyzer의 AnalyzedQuery를 사용하여 결과를 융합합니다.
     * 더 정교한 의도 분석과 키워드 부스팅을 적용합니다.
     *
     * @param rankedLists 소스별 검색 결과
     * @param analyzedQuery 분석된 쿼리 정보
     * @return RRF 점수로 정렬된 통합 결과
     */
    public List<RankedResult> fuseResultsWithAnalyzedQuery(
            Map<String, List<SearchCandidate>> rankedLists,
            AnalyzedQuery analyzedQuery) {

        if (rankedLists == null || rankedLists.isEmpty()) {
            return List.of();
        }

        // AnalyzedQuery에서 QueryIntent로 변환
        QueryIntent intent = advancedIntentAnalyzer.toQueryIntent(analyzedQuery);
        Map<String, Double> adjustedWeights = adjustWeightsForAnalyzedQuery(analyzedQuery);

        // 기본 RRF 융합 수행
        List<RankedResult> results = fuseResults(rankedLists, adjustedWeights, intent);

        // AnalyzedQuery 기반 향상된 부스팅 적용
        results = applyAdvancedBoost(results, analyzedQuery);

        log.debug("RRF fusion with AnalyzedQuery: {} sources → {} results, intent={}, confidence={}",
                rankedLists.size(), results.size(), analyzedQuery.getIntentType(), analyzedQuery.getConfidence());

        return results;
    }

    /**
     * 결과가 없을 때 폴백 전략을 사용하여 검색 쿼리를 제안합니다.
     *
     * @param analyzedQuery 분석된 쿼리 정보
     * @return 다음 시도할 검색 쿼리 (폴백 전략에 따라)
     */
    public Optional<String> getNextFallbackQuery(AnalyzedQuery analyzedQuery, int attemptIndex) {
        List<FallbackStrategy> strategies = analyzedQuery.getFallbackStrategies();
        if (strategies == null || attemptIndex >= strategies.size()) {
            return Optional.empty();
        }
        return Optional.of(strategies.get(attemptIndex).getQuery());
    }

    /**
     * 쿼리를 분석하고 결과를 융합합니다.
     * AdvancedIntentAnalyzer를 내부적으로 사용합니다.
     *
     * @param query 검색 쿼리
     * @param rankedLists 소스별 검색 결과
     * @return RRF 점수로 정렬된 통합 결과
     */
    public List<RankedResult> analyzeAndFuse(String query, Map<String, List<SearchCandidate>> rankedLists) {
        AnalyzedQuery analyzedQuery = advancedIntentAnalyzer.analyzeQuery(query);
        return fuseResultsWithAnalyzedQuery(rankedLists, analyzedQuery);
    }

    /**
     * AnalyzedQuery 기반 소스 가중치 조정.
     */
    private Map<String, Double> adjustWeightsForAnalyzedQuery(AnalyzedQuery analyzed) {
        Map<String, Double> adjusted = new HashMap<>(DEFAULT_SOURCE_WEIGHTS);

        // 기본 의도 기반 조정
        switch (analyzed.getIntentType()) {
            case FACT_CHECK:
                adjusted.put("database", 1.3);  // 검증된 DB 데이터 우선
                adjusted.put("ai", 1.2);        // AI 분석
                adjusted.put("semantic", 1.1);
                adjusted.put("web", 0.7);       // 웹 결과는 낮게
                break;

            case LATEST_NEWS:
                adjusted.put("web", 1.3);       // 최신 웹 정보 우선
                adjusted.put("keyword", 1.2);
                adjusted.put("database", 0.8);  // DB는 최신 아닐 수 있음
                break;

            case DEEP_ANALYSIS:
                adjusted.put("semantic", 1.3);  // 의미적 유사도 중요
                adjusted.put("ai", 1.2);
                adjusted.put("database", 1.1);
                adjusted.put("keyword", 0.9);
                break;

            case OPINION_SEARCH:
                adjusted.put("semantic", 1.2);
                adjusted.put("web", 1.1);
                adjusted.put("database", 1.0);
                break;

            case GENERAL:
            default:
                break;
        }

        // 신뢰도 기반 미세 조정
        double confidence = analyzed.getConfidence();
        if (confidence > 0.8) {
            // 높은 신뢰도: 의도에 맞는 가중치 강화
            for (String key : adjusted.keySet()) {
                double current = adjusted.get(key);
                if (current > 1.0) {
                    adjusted.put(key, current * 1.1);  // 추가 10% 부스트
                }
            }
        }

        return adjusted;
    }

    /**
     * AnalyzedQuery 기반 향상된 결과 부스팅.
     */
    private List<RankedResult> applyAdvancedBoost(List<RankedResult> results, AnalyzedQuery analyzed) {
        if (results.isEmpty()) {
            return results;
        }

        List<String> keywords = analyzed.getKeywords();
        String primaryKeyword = analyzed.getPrimaryKeyword();

        for (RankedResult result : results) {
            double boost = 0.0;

            // 1. 키워드 매칭 부스트
            String text = buildSearchableText(result);

            // 주요 키워드 매칭 (가장 높은 부스트)
            if (primaryKeyword != null && !primaryKeyword.isBlank() && 
                    text.contains(primaryKeyword.toLowerCase())) {
                boost += 0.15;
            }

            // 기타 키워드 매칭
            if (keywords != null && !keywords.isEmpty()) {
                int matchCount = 0;
                for (String keyword : keywords) {
                    if (text.contains(keyword.toLowerCase())) {
                        matchCount++;
                    }
                }
                boost += (double) matchCount / keywords.size() * 0.1;
            }

            // 2. 의도별 추가 부스트
            switch (analyzed.getIntentType()) {
                case LATEST_NEWS:
                    // 최신성 부스트
                    boost += calculateRecencyBoostAdvanced(result.getPublishedAt());
                    break;

                case FACT_CHECK:
                    // 신뢰할 수 있는 출처 부스트
                    if (result.getSources() != null && result.getSources().contains("database")) {
                        boost += 0.1;
                    }
                    break;

                case DEEP_ANALYSIS:
                    // 긴 콘텐츠 부스트 (더 상세한 정보)
                    if (result.getContent() != null && result.getContent().length() > 500) {
                        boost += 0.05;
                    }
                    break;

                default:
                    break;
            }

            // 3. 다중 소스 부스트
            if (result.getSources() != null && result.getSources().size() > 1) {
                boost += 0.1 * (result.getSources().size() - 1);
            }

            // 부스트 적용
            result.setRrfScore(result.getRrfScore() * (1 + boost));
        }

        // 재정렬
        results.sort(Comparator.comparingDouble(RankedResult::getRrfScore).reversed());
        return results;
    }

    private String buildSearchableText(RankedResult result) {
        StringBuilder text = new StringBuilder();
        if (result.getTitle() != null) {
            text.append(result.getTitle()).append(" ");
        }
        if (result.getSnippet() != null) {
            text.append(result.getSnippet()).append(" ");
        }
        if (result.getContent() != null) {
            text.append(result.getContent().substring(0, Math.min(200, result.getContent().length())));
        }
        return text.toString().toLowerCase();
    }

    private double calculateRecencyBoostAdvanced(String publishedAt) {
        if (publishedAt == null || publishedAt.isBlank()) {
            return 0;
        }

        try {
            // ISO 날짜 파싱 시도
            java.time.LocalDateTime published;
            if (publishedAt.length() > 10) {
                published = java.time.LocalDateTime.parse(publishedAt.replace(" ", "T").substring(0, 19));
            } else {
                published = java.time.LocalDate.parse(publishedAt).atStartOfDay();
            }

            java.time.LocalDateTime now = java.time.LocalDateTime.now();
            long hoursDiff = java.time.Duration.between(published, now).toHours();

            // 최신일수록 높은 부스트
            if (hoursDiff < 24) return 0.2;       // 24시간 내
            if (hoursDiff < 72) return 0.15;      // 3일 내
            if (hoursDiff < 168) return 0.1;      // 1주일 내
            if (hoursDiff < 720) return 0.05;     // 30일 내
            return 0;
        } catch (Exception e) {
            return 0.05; // 파싱 실패시 기본 부스트
        }
    }

    /**
     * 커스텀 가중치로 결과를 융합합니다.
     *
     * @param rankedLists 소스별 검색 결과
     * @param sourceWeights 소스별 가중치
     * @param intent 쿼리 의도 (후처리용)
     * @return RRF 점수로 정렬된 통합 결과
     */
    public List<RankedResult> fuseResults(
            Map<String, List<SearchCandidate>> rankedLists,
            Map<String, Double> sourceWeights,
            QueryIntent intent) {

        if (rankedLists == null || rankedLists.isEmpty()) {
            return List.of();
        }

        // 문서 ID → RRF 점수 누적
        Map<String, Double> rrfScores = new HashMap<>();
        // 문서 ID → 원본 정보
        Map<String, SearchCandidate> candidateMap = new HashMap<>();
        // 문서 ID → 출처 소스들
        Map<String, Set<String>> documentSources = new HashMap<>();

        for (Map.Entry<String, List<SearchCandidate>> entry : rankedLists.entrySet()) {
            String source = entry.getKey();
            List<SearchCandidate> candidates = entry.getValue();
            double weight = sourceWeights.getOrDefault(source, 1.0);

            for (int rank = 0; rank < candidates.size(); rank++) {
                SearchCandidate candidate = candidates.get(rank);
                String docId = candidate.getId();

                // RRF 점수 계산: weight * 1/(k + rank)
                double rrfScore = weight * (1.0 / (RRF_K + rank + 1));
                rrfScores.merge(docId, rrfScore, Double::sum);

                // 원본 정보 저장 (처음 등장한 정보 유지)
                candidateMap.putIfAbsent(docId, candidate);

                // 출처 추적
                documentSources.computeIfAbsent(docId, k -> new HashSet<>()).add(source);
            }
        }

        // RRF 점수순 정렬
        List<RankedResult> results = rrfScores.entrySet().stream()
                .map(entry -> {
                    String docId = entry.getKey();
                    SearchCandidate candidate = candidateMap.get(docId);
                    return RankedResult.builder()
                            .id(docId)
                            .title(candidate.getTitle())
                            .snippet(candidate.getSnippet())
                            .content(candidate.getContent())
                            .url(candidate.getUrl())
                            .publishedAt(candidate.getPublishedAt())
                            .rrfScore(entry.getValue())
                            .originalScore(candidate.getOriginalScore())
                            .sources(documentSources.get(docId))
                            .metadata(candidate.getMetadata())
                            .build();
                })
                .sorted(Comparator.comparingDouble(RankedResult::getRrfScore).reversed())
                .collect(Collectors.toList());

        // 의도 기반 후처리 (재정렬)
        if (intent != null) {
            results = applyIntentBoost(results, intent);
        }

        log.debug("RRF fusion completed: {} sources → {} unique results", 
                rankedLists.size(), results.size());

        return results;
    }

    /**
     * 쿼리 의도에 따라 소스 가중치를 조정합니다.
     */
    private Map<String, Double> adjustWeightsForIntent(QueryIntent intent) {
        if (intent == null) {
            return DEFAULT_SOURCE_WEIGHTS;
        }

        Map<String, Double> adjusted = new HashMap<>(DEFAULT_SOURCE_WEIGHTS);

        switch (intent.getType()) {
            case FACT_CHECK:
                // 팩트체크: DB(검증된 데이터)와 AI 분석 우선
                adjusted.put("database", 1.2);
                adjusted.put("ai", 1.1);
                adjusted.put("semantic", 1.0);
                adjusted.put("web", 0.7);
                break;

            case LATEST_NEWS:
                // 최신 뉴스: 웹 크롤링과 키워드 검색 우선
                adjusted.put("web", 1.2);
                adjusted.put("keyword", 1.1);
                adjusted.put("database", 0.9);
                adjusted.put("semantic", 0.8);
                break;

            case DEEP_ANALYSIS:
                // 심층 분석: 시맨틱 검색과 AI 분석 우선
                adjusted.put("semantic", 1.2);
                adjusted.put("ai", 1.1);
                adjusted.put("database", 1.0);
                adjusted.put("keyword", 0.8);
                break;

            case OPINION_SEARCH:
                // 여론/의견 검색: 다양한 소스 균형
                adjusted.put("semantic", 1.1);
                adjusted.put("web", 1.0);
                adjusted.put("database", 1.0);
                adjusted.put("ai", 0.9);
                break;

            case GENERAL:
            default:
                // 일반 검색: 기본 가중치 유지
                break;
        }

        return adjusted;
    }

    /**
     * 의도 기반 부스팅을 적용합니다.
     */
    private List<RankedResult> applyIntentBoost(List<RankedResult> results, QueryIntent intent) {
        // 키워드가 포함된 결과 부스팅
        if (intent.getKeywords() != null && !intent.getKeywords().isEmpty()) {
            for (RankedResult result : results) {
                double keywordBoost = calculateKeywordBoost(result, intent.getKeywords());
                result.setRrfScore(result.getRrfScore() * (1 + keywordBoost));
            }
        }

        // 시간 기반 부스팅 (최신 뉴스 의도일 경우)
        if (intent.getType() == QueryIntent.IntentType.LATEST_NEWS) {
            for (RankedResult result : results) {
                double recencyBoost = calculateRecencyBoost(result.getPublishedAt());
                result.setRrfScore(result.getRrfScore() * (1 + recencyBoost));
            }
        }

        // 다중 소스 부스팅 (여러 소스에서 발견된 문서 신뢰도 향상)
        for (RankedResult result : results) {
            int sourceCount = result.getSources() != null ? result.getSources().size() : 1;
            if (sourceCount > 1) {
                double multiSourceBoost = 0.1 * (sourceCount - 1);
                result.setRrfScore(result.getRrfScore() * (1 + multiSourceBoost));
            }
        }

        // 재정렬
        results.sort(Comparator.comparingDouble(RankedResult::getRrfScore).reversed());
        return results;
    }

    /**
     * 키워드 부스트 점수를 계산합니다.
     */
    private double calculateKeywordBoost(RankedResult result, List<String> keywords) {
        String text = (result.getTitle() + " " + 
                      (result.getSnippet() != null ? result.getSnippet() : "")).toLowerCase();
        
        int matchCount = 0;
        for (String keyword : keywords) {
            if (text.contains(keyword.toLowerCase())) {
                matchCount++;
            }
        }
        
        return keywords.isEmpty() ? 0 : (double) matchCount / keywords.size() * 0.2;
    }

    /**
     * 최신성 부스트 점수를 계산합니다.
     */
    private double calculateRecencyBoost(String publishedAt) {
        if (publishedAt == null) return 0;
        
        try {
            // 간단한 최신성 계산 (더 정교한 로직으로 대체 가능)
            // publishedAt이 최근일수록 높은 부스트
            return 0.1; // 기본 부스트
        } catch (Exception e) {
            return 0;
        }
    }

    // ==================== Inner Classes ====================

    /**
     * 검색 후보 문서
     */
    @Data
    @Builder
    public static class SearchCandidate {
        private String id;
        private String title;
        private String snippet;
        private String content;
        private String url;
        private String publishedAt;
        private Double originalScore;  // 원본 검색 점수 (유사도, relevance 등)
        private Map<String, Object> metadata;
    }

    /**
     * RRF 점수가 포함된 최종 결과
     */
    @Data
    @Builder
    public static class RankedResult {
        private String id;
        private String title;
        private String snippet;
        private String content;
        private String url;
        private String publishedAt;
        private double rrfScore;
        private Double originalScore;
        private Set<String> sources;  // 이 문서가 발견된 소스들
        private Map<String, Object> metadata;
    }

    /**
     * 쿼리 의도
     */
    @Data
    @Builder
    public static class QueryIntent {
        private IntentType type;
        private List<String> keywords;
        private String timeRange;
        private Double confidence;

        public enum IntentType {
            GENERAL,        // 일반 검색
            FACT_CHECK,     // 팩트체크/검증
            LATEST_NEWS,    // 최신 뉴스
            DEEP_ANALYSIS,  // 심층 분석
            OPINION_SEARCH  // 여론/의견 검색
        }
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/search/HybridSearchService.java

```java
package com.newsinsight.collector.service.search;

import com.newsinsight.collector.entity.CollectedData;
import com.newsinsight.collector.repository.CollectedDataRepository;
import com.newsinsight.collector.service.search.HybridRankingService.QueryIntent;
import com.newsinsight.collector.service.search.HybridRankingService.RankedResult;
import com.newsinsight.collector.service.search.HybridRankingService.SearchCandidate;
import com.newsinsight.collector.service.search.VectorSearchService.ScoredDocument;
import lombok.Builder;
import lombok.Data;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.PageRequest;
import org.springframework.data.domain.Sort;
import org.springframework.stereotype.Service;
import reactor.core.publisher.Flux;
import reactor.core.publisher.Mono;
import reactor.core.scheduler.Schedulers;

import java.time.LocalDateTime;
import java.time.format.DateTimeFormatter;
import java.time.format.DateTimeParseException;
import java.util.*;
import java.util.concurrent.ConcurrentHashMap;
import java.util.stream.Collectors;

/**
 * 하이브리드 검색 서비스 - 키워드 + 시맨틱 + RRF 통합 검색
 * 
 * 검색 흐름:
 * 1. QueryIntentAnalyzer로 사용자 의도 분석
 * 2. 병렬로 키워드 검색(DB) + 시맨틱 검색(pgvector) 실행
 * 3. HybridRankingService의 RRF 알고리즘으로 결과 융합
 * 4. 의도 기반 부스팅 적용 후 최종 결과 반환
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class HybridSearchService {

    private final CollectedDataRepository collectedDataRepository;
    private final VectorSearchService vectorSearchService;
    private final EmbeddingService embeddingService;
    private final HybridRankingService hybridRankingService;
    private final QueryIntentAnalyzer queryIntentAnalyzer;

    @Value("${collector.hybrid-search.enabled:true}")
    private boolean enabled;

    @Value("${collector.hybrid-search.keyword-top-k:30}")
    private int keywordTopK;

    @Value("${collector.hybrid-search.semantic-top-k:20}")
    private int semanticTopK;

    @Value("${collector.hybrid-search.final-top-k:20}")
    private int finalTopK;

    @Value("${collector.hybrid-search.semantic-weight:1.0}")
    private double semanticWeight;

    @Value("${collector.hybrid-search.keyword-weight:1.0}")
    private double keywordWeight;

    /**
     * 하이브리드 검색을 실행합니다.
     * 키워드 검색과 시맨틱 검색을 병렬로 실행하고 RRF로 융합합니다.
     *
     * @param query 검색 쿼리
     * @param window 시간 범위 (1d, 7d, 30d)
     * @return RRF 점수순 정렬된 검색 결과
     */
    public Mono<HybridSearchResult> search(String query, String window) {
        return search(query, window, null, null);
    }

    /**
     * 하이브리드 검색을 실행합니다 (커스텀 날짜 범위 지원).
     * 키워드 검색과 시맨틱 검색을 병렬로 실행하고 RRF로 융합합니다.
     *
     * @param query 검색 쿼리
     * @param window 시간 범위 (1d, 7d, 30d) - startDate가 지정되면 무시됨
     * @param startDate 커스텀 시작 날짜 (ISO 8601 형식)
     * @param endDate 커스텀 종료 날짜 (ISO 8601 형식)
     * @return RRF 점수순 정렬된 검색 결과
     */
    public Mono<HybridSearchResult> search(String query, String window, String startDate, String endDate) {
        if (query == null || query.isBlank()) {
            return Mono.just(HybridSearchResult.empty());
        }

        log.info("Starting hybrid search: query='{}', window={}, startDate={}, endDate={}", 
                query, window, startDate, endDate);
        long startTime = System.currentTimeMillis();

        // 1. 의도 분석
        QueryIntent intent = queryIntentAnalyzer.analyzeIntent(query);
        log.debug("Query intent: type={}, confidence={}, keywords={}", 
                intent.getType(), intent.getConfidence(), intent.getKeywords());

        // Calculate date range
        LocalDateTime since = calculateSinceDate(window, intent, startDate);
        LocalDateTime until = calculateEndDate(endDate);
        
        log.debug("Effective date range: {} to {}", since, until != null ? until : "now");

        // 2. 병렬 검색 실행
        Mono<List<SearchCandidate>> keywordResults = searchKeyword(query, since, until)
                .subscribeOn(Schedulers.boundedElastic());
        
        Mono<List<SearchCandidate>> semanticResults = searchSemantic(query, since, until)
                .subscribeOn(Schedulers.boundedElastic());

        // 3. 결과 융합
        return Mono.zip(keywordResults, semanticResults)
                .map(tuple -> {
                    Map<String, List<SearchCandidate>> rankedLists = new HashMap<>();
                    
                    if (!tuple.getT1().isEmpty()) {
                        rankedLists.put("keyword", tuple.getT1());
                    }
                    if (!tuple.getT2().isEmpty()) {
                        rankedLists.put("semantic", tuple.getT2());
                    }

                    if (rankedLists.isEmpty()) {
                        log.info("Hybrid search found no results for query: '{}'", query);
                        return HybridSearchResult.empty();
                    }

                    // RRF 융합
                    List<RankedResult> fusedResults = hybridRankingService.fuseResults(rankedLists, intent);
                    
                    // 상위 N개만 반환
                    List<RankedResult> topResults = fusedResults.stream()
                            .limit(finalTopK)
                            .toList();

                    long elapsed = System.currentTimeMillis() - startTime;
                    log.info("Hybrid search completed: query='{}', keyword={}, semantic={}, fused={}, time={}ms",
                            query, tuple.getT1().size(), tuple.getT2().size(), topResults.size(), elapsed);

                    return HybridSearchResult.builder()
                            .query(query)
                            .intent(intent)
                            .results(topResults)
                            .keywordResultCount(tuple.getT1().size())
                            .semanticResultCount(tuple.getT2().size())
                            .totalResultCount(topResults.size())
                            .searchTimeMs(elapsed)
                            .build();
                })
                .onErrorResume(e -> {
                    log.error("Hybrid search failed for query '{}': {}", query, e.getMessage());
                    return Mono.just(HybridSearchResult.empty());
                });
    }

    /**
     * 키워드 기반 검색 (PostgreSQL LIKE/Full-text)
     */
    private Mono<List<SearchCandidate>> searchKeyword(String query, LocalDateTime since, LocalDateTime until) {
        return Mono.fromCallable(() -> {
            try {
                PageRequest pageRequest = PageRequest.of(0, keywordTopK,
                        Sort.by(Sort.Direction.DESC, "publishedDate")
                                .and(Sort.by(Sort.Direction.DESC, "collectedAt")));

                Page<CollectedData> page;
                if (until != null) {
                    // Use date range query
                    page = collectedDataRepository.searchByQueryAndDateRange(
                            query, since, until, pageRequest);
                } else {
                    // Use since-only query
                    page = collectedDataRepository.searchByQueryAndSince(
                            query, since, pageRequest);
                }

                return page.getContent().stream()
                        .map(data -> SearchCandidate.builder()
                                .id(data.getId() != null ? data.getId().toString() : UUID.randomUUID().toString())
                                .title(data.getTitle())
                                .snippet(buildSnippet(data.getContent(), 200))
                                .content(data.getContent())
                                .url(data.getUrl())
                                .publishedAt(data.getPublishedDate() != null 
                                        ? data.getPublishedDate().toString() 
                                        : null)
                                .originalScore(data.getQualityScore())
                                .metadata(Map.of(
                                        "sourceId", data.getSourceId() != null ? data.getSourceId() : 0L,
                                        "collectedAt", data.getCollectedAt() != null ? data.getCollectedAt().toString() : ""
                                ))
                                .build())
                        .collect(Collectors.toList());
            } catch (Exception e) {
                log.error("Keyword search failed: {}", e.getMessage());
                return List.of();
            }
        });
    }

    /**
     * 시맨틱(벡터) 검색 (pgvector)
     */
    private Mono<List<SearchCandidate>> searchSemantic(String query, LocalDateTime since, LocalDateTime until) {
        if (!vectorSearchService.isAvailable()) {
            log.debug("Vector search not available, skipping semantic search");
            return Mono.just(List.of());
        }

        return vectorSearchService.searchSimilar(query, semanticTopK)
                .map(scoredDocs -> {
                    if (scoredDocs == null || scoredDocs.isEmpty()) {
                        return List.<SearchCandidate>of();
                    }

                    // ID로 전체 데이터 조회
                    List<Long> docIds = scoredDocs.stream()
                            .map(ScoredDocument::id)
                            .filter(Objects::nonNull)
                            .toList();

                    if (docIds.isEmpty()) {
                        return List.<SearchCandidate>of();
                    }

                    Map<Long, CollectedData> dataMap = collectedDataRepository.findAllById(docIds)
                            .stream()
                            .collect(Collectors.toMap(CollectedData::getId, d -> d));

                    // 유사도 점수 매핑
                    Map<Long, Double> similarityMap = scoredDocs.stream()
                            .collect(Collectors.toMap(ScoredDocument::id, ScoredDocument::similarity));

                    return scoredDocs.stream()
                            .filter(doc -> dataMap.containsKey(doc.id()))
                            .filter(doc -> {
                                // 시간 필터링 적용 (since ~ until)
                                CollectedData data = dataMap.get(doc.id());
                                LocalDateTime publishedDate = data.getPublishedDate();
                                if (publishedDate == null) {
                                    publishedDate = data.getCollectedAt();
                                }
                                if (publishedDate == null) {
                                    return true;  // No date info, include by default
                                }
                                // Check since
                                if (publishedDate.isBefore(since)) {
                                    return false;
                                }
                                // Check until (if specified)
                                if (until != null && publishedDate.isAfter(until)) {
                                    return false;
                                }
                                return true;
                            })
                            .map(doc -> {
                                CollectedData data = dataMap.get(doc.id());
                                return SearchCandidate.builder()
                                        .id(data.getId().toString())
                                        .title(data.getTitle())
                                        .snippet(buildSnippet(data.getContent(), 200))
                                        .content(data.getContent())
                                        .url(data.getUrl())
                                        .publishedAt(data.getPublishedDate() != null 
                                                ? data.getPublishedDate().toString() 
                                                : null)
                                        .originalScore(similarityMap.get(doc.id()))
                                        .metadata(Map.of(
                                                "similarity", similarityMap.get(doc.id()),
                                                "sourceId", data.getSourceId() != null ? data.getSourceId() : 0L
                                        ))
                                        .build();
                            })
                            .collect(Collectors.toList());
                })
                .onErrorResume(e -> {
                    log.error("Semantic search failed: {}", e.getMessage());
                    return Mono.just(List.of());
                });
    }

    /**
     * 실시간 스트리밍 하이브리드 검색
     * UnifiedSearchService와 통합하여 실시간 결과 스트리밍에 사용됩니다.
     *
     * @param query 검색 쿼리
     * @param window 시간 범위
     * @return 검색 결과 스트림
     */
    public Flux<RankedResult> searchStream(String query, String window) {
        return search(query, window)
                .flatMapMany(result -> Flux.fromIterable(result.getResults()));
    }

    /**
     * 하이브리드 검색이 활성화되어 있는지 확인합니다.
     */
    public boolean isEnabled() {
        return enabled;
    }

    /**
     * 시맨틱 검색이 가능한지 확인합니다.
     */
    public boolean isSemanticSearchAvailable() {
        return vectorSearchService.isAvailable() && embeddingService.isEnabled();
    }

    /**
     * 의도를 고려한 시간 범위 계산 (커스텀 날짜 지원)
     */
    private LocalDateTime calculateSinceDate(String window, QueryIntent intent, String startDate) {
        // Custom startDate takes priority
        if (startDate != null && !startDate.isBlank()) {
            try {
                return LocalDateTime.parse(startDate, DateTimeFormatter.ISO_DATE_TIME);
            } catch (DateTimeParseException e) {
                log.warn("Invalid startDate format: '{}', falling back to window", startDate);
            }
        }
        
        return calculateSinceDate(window, intent);
    }

    /**
     * 의도를 고려한 시간 범위 계산
     */
    private LocalDateTime calculateSinceDate(String window, QueryIntent intent) {
        LocalDateTime now = LocalDateTime.now();
        
        // 의도에서 추출된 시간 범위가 있으면 우선 사용
        if (intent != null && intent.getTimeRange() != null) {
            return switch (intent.getTimeRange()) {
                case "1d" -> now.minusDays(1);
                case "2d" -> now.minusDays(2);
                case "7d" -> now.minusDays(7);
                case "14d" -> now.minusDays(14);
                case "30d" -> now.minusDays(30);
                default -> calculateFromWindow(window, now);
            };
        }
        
        return calculateFromWindow(window, now);
    }

    /**
     * Calculate end date from custom endDate string
     */
    private LocalDateTime calculateEndDate(String endDate) {
        if (endDate != null && !endDate.isBlank()) {
            try {
                return LocalDateTime.parse(endDate, DateTimeFormatter.ISO_DATE_TIME);
            } catch (DateTimeParseException e) {
                log.warn("Invalid endDate format: '{}', using current time", endDate);
            }
        }
        return null;  // null means no upper limit (i.e., "now")
    }

    private LocalDateTime calculateFromWindow(String window, LocalDateTime now) {
        return switch (window != null ? window : "7d") {
            case "1h" -> now.minusHours(1);
            case "1d" -> now.minusDays(1);
            case "3d" -> now.minusDays(3);
            case "14d" -> now.minusDays(14);
            case "30d" -> now.minusDays(30);
            case "90d" -> now.minusDays(90);
            case "180d" -> now.minusDays(180);
            case "365d" -> now.minusDays(365);
            case "all" -> LocalDateTime.of(2000, 1, 1, 0, 0);
            default -> now.minusDays(7);
        };
    }

    /**
     * 텍스트에서 스니펫 생성
     */
    private String buildSnippet(String content, int maxLength) {
        if (content == null || content.isBlank()) {
            return null;
        }

        // HTML 태그 제거
        String text = content.replaceAll("<[^>]*>", " ")
                .replaceAll("\\s+", " ")
                .trim();

        if (text.length() <= maxLength) {
            return text;
        }

        // 단어 경계에서 자르기
        int cut = maxLength;
        for (int i = maxLength - 1; i > maxLength * 0.6; i--) {
            if (Character.isWhitespace(text.charAt(i))) {
                cut = i;
                break;
            }
        }

        return text.substring(0, cut).trim() + "...";
    }

    // ==================== Inner Classes ====================

    /**
     * 하이브리드 검색 결과
     */
    @Data
    @Builder
    public static class HybridSearchResult {
        private String query;
        private QueryIntent intent;
        private List<RankedResult> results;
        private int keywordResultCount;
        private int semanticResultCount;
        private int totalResultCount;
        private long searchTimeMs;

        public static HybridSearchResult empty() {
            return HybridSearchResult.builder()
                    .results(List.of())
                    .keywordResultCount(0)
                    .semanticResultCount(0)
                    .totalResultCount(0)
                    .searchTimeMs(0)
                    .build();
        }
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/search/QueryIntentAnalyzer.java

```java
package com.newsinsight.collector.service.search;

import com.newsinsight.collector.service.search.HybridRankingService.QueryIntent;
import com.newsinsight.collector.service.search.HybridRankingService.QueryIntent.IntentType;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;

import java.util.*;
import java.util.regex.Pattern;

/**
 * 쿼리 의도 분석 서비스.
 * 
 * 사용자 쿼리를 분석하여 검색 의도를 파악하고,
 * 하이브리드 검색의 가중치 조정에 활용합니다.
 * 
 * 지원 의도:
 * - FACT_CHECK: 팩트체크/검증 ("사실인가", "진짜", "팩트체크")
 * - LATEST_NEWS: 최신 뉴스 ("오늘", "최근", "속보")
 * - DEEP_ANALYSIS: 심층 분석 ("분석", "원인", "배경")
 * - OPINION_SEARCH: 여론 검색 ("여론", "반응", "논란")
 * - GENERAL: 일반 검색
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class QueryIntentAnalyzer {

    // 의도별 키워드 패턴
    private static final Map<IntentType, List<String>> INTENT_KEYWORDS = Map.of(
            IntentType.FACT_CHECK, List.of(
                    "사실", "진짜", "가짜", "팩트체크", "팩트 체크", "검증",
                    "진위", "확인", "루머", "허위", "오보", "실제로",
                    "정말", "맞는", "틀린", "fact", "check", "verify"
            ),
            IntentType.LATEST_NEWS, List.of(
                    "오늘", "최근", "속보", "긴급", "방금", "지금",
                    "현재", "실시간", "최신", "breaking", "today",
                    "어제", "이번주", "금일"
            ),
            IntentType.DEEP_ANALYSIS, List.of(
                    "분석", "원인", "배경", "이유", "왜", "어떻게",
                    "영향", "전망", "예측", "해설", "설명", "의미",
                    "history", "analysis", "impact", "결과"
            ),
            IntentType.OPINION_SEARCH, List.of(
                    "여론", "반응", "논란", "비판", "지지", "반대",
                    "찬성", "의견", "댓글", "네티즌", "SNS", "트위터",
                    "opinion", "reaction", "controversy"
            )
    );

    // 질문 패턴
    private static final Pattern QUESTION_PATTERN = Pattern.compile(
            "(\\?|인가요|인가|입니까|일까|일까요|나요|습니까|은가요|는가요|맞나요|아닌가요)$"
    );

    // 시간 표현 패턴
    private static final Pattern TIME_PATTERN = Pattern.compile(
            "(오늘|어제|이번주|지난주|최근|\\d+일|\\d+시간|\\d+분)"
    );

    /**
     * 쿼리를 분석하여 의도를 파악합니다.
     *
     * @param query 사용자 쿼리
     * @return 분석된 쿼리 의도
     */
    public QueryIntent analyzeIntent(String query) {
        if (query == null || query.isBlank()) {
            return QueryIntent.builder()
                    .type(IntentType.GENERAL)
                    .confidence(1.0)
                    .keywords(List.of())
                    .build();
        }

        String normalizedQuery = query.toLowerCase().trim();
        
        // 각 의도 유형별 점수 계산
        Map<IntentType, Double> scores = new EnumMap<>(IntentType.class);
        for (IntentType type : IntentType.values()) {
            scores.put(type, 0.0);
        }

        // 키워드 매칭 점수
        List<String> matchedKeywords = new ArrayList<>();
        for (Map.Entry<IntentType, List<String>> entry : INTENT_KEYWORDS.entrySet()) {
            IntentType type = entry.getKey();
            for (String keyword : entry.getValue()) {
                if (normalizedQuery.contains(keyword.toLowerCase())) {
                    scores.merge(type, 1.0, Double::sum);
                    matchedKeywords.add(keyword);
                }
            }
        }

        // 질문 형태 분석 - 팩트체크 의도 가능성 증가
        if (QUESTION_PATTERN.matcher(normalizedQuery).find()) {
            scores.merge(IntentType.FACT_CHECK, 0.5, Double::sum);
        }

        // 시간 표현 분석 - 최신 뉴스 의도 가능성 증가
        if (TIME_PATTERN.matcher(normalizedQuery).find()) {
            scores.merge(IntentType.LATEST_NEWS, 0.5, Double::sum);
        }

        // 최고 점수 의도 선택
        IntentType bestIntent = IntentType.GENERAL;
        double maxScore = 0.0;
        for (Map.Entry<IntentType, Double> entry : scores.entrySet()) {
            if (entry.getValue() > maxScore) {
                maxScore = entry.getValue();
                bestIntent = entry.getKey();
            }
        }

        // 신뢰도 계산 (0~1)
        double confidence = calculateConfidence(maxScore, scores);

        // 최소 점수 미달 시 일반 검색으로
        if (maxScore < 0.5) {
            bestIntent = IntentType.GENERAL;
            confidence = 1.0 - (maxScore * 0.5); // 낮은 매칭일수록 일반 검색 신뢰도 높음
        }

        // 시간 범위 추출
        String timeRange = extractTimeRange(normalizedQuery);

        // 핵심 키워드 추출
        List<String> keywords = extractKeywords(query);

        QueryIntent intent = QueryIntent.builder()
                .type(bestIntent)
                .confidence(confidence)
                .keywords(keywords)
                .timeRange(timeRange)
                .build();

        log.debug("Query intent analyzed: query='{}', type={}, confidence={}, keywords={}", 
                query, bestIntent, String.format("%.2f", confidence), keywords);

        return intent;
    }

    /**
     * 신뢰도를 계산합니다.
     */
    private double calculateConfidence(double maxScore, Map<IntentType, Double> scores) {
        if (maxScore == 0) return 0.5;

        // 최고 점수와 다른 점수들의 차이로 신뢰도 계산
        double totalScore = scores.values().stream().mapToDouble(Double::doubleValue).sum();
        if (totalScore == 0) return 0.5;

        double confidence = maxScore / totalScore;
        return Math.min(1.0, Math.max(0.5, confidence));
    }

    /**
     * 시간 범위를 추출합니다.
     */
    private String extractTimeRange(String query) {
        if (query.contains("오늘") || query.contains("금일")) {
            return "1d";
        } else if (query.contains("어제")) {
            return "2d";
        } else if (query.contains("이번주") || query.contains("최근")) {
            return "7d";
        } else if (query.contains("지난주")) {
            return "14d";
        } else if (query.contains("이번달") || query.contains("한달")) {
            return "30d";
        }
        return null; // 기본값 사용
    }

    /**
     * 쿼리에서 핵심 키워드를 추출합니다.
     */
    private List<String> extractKeywords(String query) {
        // 불용어 목록
        Set<String> stopwords = Set.of(
                "은", "는", "이", "가", "을", "를", "의", "에", "와", "과",
                "로", "으로", "에서", "부터", "까지", "도", "만", "뿐",
                "대해", "대한", "관련", "관한", "에게", "한테",
                "그", "저", "이것", "그것", "저것",
                "어떤", "무슨", "어느", "무엇", "뭐",
                "the", "a", "an", "is", "are", "was", "were", "be",
                "to", "of", "in", "for", "on", "with", "at", "by"
        );

        // 의도 키워드 제외
        Set<String> intentKeywords = new HashSet<>();
        INTENT_KEYWORDS.values().forEach(intentKeywords::addAll);

        // 키워드 추출
        String[] tokens = query.toLowerCase()
                .replaceAll("[^가-힣a-z0-9\\s]", " ")
                .split("\\s+");

        List<String> keywords = new ArrayList<>();
        for (String token : tokens) {
            if (token.length() >= 2 
                    && !stopwords.contains(token)
                    && !intentKeywords.contains(token)) {
                keywords.add(token);
            }
        }

        // 최대 5개 키워드
        return keywords.size() > 5 ? keywords.subList(0, 5) : keywords;
    }

    /**
     * 의도에 대한 설명을 반환합니다.
     */
    public String getIntentDescription(IntentType type) {
        return switch (type) {
            case FACT_CHECK -> "팩트체크 - 정보의 진위 여부를 검증합니다";
            case LATEST_NEWS -> "최신 뉴스 - 가장 최근 소식을 우선합니다";
            case DEEP_ANALYSIS -> "심층 분석 - 배경과 맥락을 포함한 분석을 제공합니다";
            case OPINION_SEARCH -> "여론 검색 - 다양한 의견과 반응을 수집합니다";
            case GENERAL -> "일반 검색 - 관련성 높은 정보를 제공합니다";
        };
    }
}

```

---

## backend/data-collection-service/src/main/java/com/newsinsight/collector/service/search/VectorSearchService.java

```java
package com.newsinsight.collector.service.search;

import com.newsinsight.collector.entity.CollectedData;
import com.newsinsight.collector.repository.CollectedDataRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.jdbc.core.JdbcTemplate;
import org.springframework.stereotype.Service;
import reactor.core.publisher.Mono;

import jakarta.annotation.PostConstruct;
import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import java.util.Optional;

/**
 * PostgreSQL pgvector 기반 벡터 검색 서비스.
 * 
 * 시맨틱 검색을 위해 문서 임베딩을 저장하고 유사도 검색을 수행합니다.
 * pgvector 확장이 설치되어 있어야 합니다.
 * 
 * 사용 전 필요한 SQL:
 * CREATE EXTENSION IF NOT EXISTS vector;
 * ALTER TABLE collected_data ADD COLUMN IF NOT EXISTS embedding vector(1024);
 * CREATE INDEX IF NOT EXISTS collected_data_embedding_idx ON collected_data 
 *   USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class VectorSearchService {

    private final JdbcTemplate jdbcTemplate;
    private final EmbeddingService embeddingService;
    private final CollectedDataRepository collectedDataRepository;

    @Value("${collector.vector-search.enabled:true}")
    private boolean enabled;

    @Value("${collector.vector-search.top-k:20}")
    private int defaultTopK;

    @Value("${collector.vector-search.min-similarity:0.5}")
    private double minSimilarity;

    @Value("${collector.embedding.dimension:1024}")
    private int embeddingDimension;

    private boolean pgvectorAvailable = false;

    @PostConstruct
    public void init() {
        if (!enabled) {
            log.info("VectorSearchService is disabled");
            return;
        }

        // pgvector 확장 및 컬럼 존재 여부 확인
        try {
            jdbcTemplate.queryForObject(
                    "SELECT 1 FROM pg_extension WHERE extname = 'vector'",
                    Integer.class);
            
            // embedding 컬럼 존재 확인
            Integer columnExists = jdbcTemplate.queryForObject(
                    "SELECT COUNT(*) FROM information_schema.columns " +
                    "WHERE table_name = 'collected_data' AND column_name = 'embedding'",
                    Integer.class);
            
            pgvectorAvailable = columnExists != null && columnExists > 0;
            
            if (pgvectorAvailable) {
                log.info("VectorSearchService initialized: pgvector available, dimension={}", embeddingDimension);
            } else {
                log.warn("VectorSearchService: embedding column not found in collected_data table. " +
                         "Run migration to add vector column.");
            }
        } catch (Exception e) {
            log.warn("VectorSearchService: pgvector extension not available. " +
                     "Install with: CREATE EXTENSION vector;");
            pgvectorAvailable = false;
        }
    }

    /**
     * 쿼리와 유사한 문서를 벡터 검색합니다.
     *
     * @param query 검색 쿼리
     * @param topK 반환할 결과 수
     * @return 유사도순 정렬된 문서 목록
     */
    public Mono<List<ScoredDocument>> searchSimilar(String query, int topK) {
        if (!isAvailable()) {
            return Mono.just(List.of());
        }

        return embeddingService.embedQuery(query)
                .flatMap(queryEmbedding -> {
                    if (queryEmbedding == null || queryEmbedding.length == 0) {
                        return Mono.just(List.<ScoredDocument>of());
                    }
                    return Mono.fromCallable(() -> searchByVector(queryEmbedding, topK));
                })
                .onErrorResume(e -> {
                    log.error("Vector search failed: {}", e.getMessage());
                    return Mono.just(List.<ScoredDocument>of());
                });
    }

    /**
     * 벡터로 직접 유사 문서를 검색합니다.
     *
     * @param queryEmbedding 쿼리 임베딩 벡터
     * @param topK 반환할 결과 수
     * @return 유사도순 정렬된 문서 목록
     */
    public List<ScoredDocument> searchByVector(float[] queryEmbedding, int topK) {
        if (!isAvailable() || queryEmbedding == null) {
            return List.of();
        }

        String vectorStr = vectorToString(queryEmbedding);
        
        // pgvector 코사인 유사도 검색 (1 - cosine_distance)
        String sql = """
                SELECT id, title, url, 
                       1 - (embedding <=> ?::vector) as similarity
                FROM collected_data
                WHERE embedding IS NOT NULL
                  AND 1 - (embedding <=> ?::vector) >= ?
                ORDER BY embedding <=> ?::vector
                LIMIT ?
                """;

        try {
            return jdbcTemplate.query(sql, 
                    (rs, rowNum) -> new ScoredDocument(
                            rs.getLong("id"),
                            rs.getString("title"),
                            rs.getString("url"),
                            rs.getDouble("similarity")
                    ),
                    vectorStr, vectorStr, minSimilarity, vectorStr, topK);
        } catch (Exception e) {
            log.error("Vector search failed: {}", e.getMessage());
            return List.of();
        }
    }

    /**
     * 문서에 임베딩을 저장합니다.
     *
     * @param documentId 문서 ID
     * @param content 문서 내용
     * @return 저장 성공 여부
     */
    public Mono<Boolean> saveEmbedding(Long documentId, String content) {
        if (!isAvailable() || content == null || content.isBlank()) {
            return Mono.just(false);
        }

        return embeddingService.embedDocument(content)
                .flatMap(embedding -> {
                    if (embedding == null || embedding.length == 0) {
                        return Mono.just(false);
                    }
                    return Mono.fromCallable(() -> {
                        String vectorStr = vectorToString(embedding);
                        int updated = jdbcTemplate.update(
                                "UPDATE collected_data SET embedding = ?::vector WHERE id = ?",
                                vectorStr, documentId);
                        return updated > 0;
                    });
                })
                .onErrorReturn(false);
    }

    /**
     * 여러 문서의 임베딩을 일괄 저장합니다.
     *
     * @param documents 문서 목록 (ID, 내용)
     * @return 저장된 문서 수
     */
    public Mono<Integer> saveEmbeddingsBatch(List<DocumentContent> documents) {
        if (!isAvailable() || documents == null || documents.isEmpty()) {
            return Mono.just(0);
        }

        List<String> contents = documents.stream()
                .map(DocumentContent::content)
                .toList();

        return embeddingService.embedBatch(contents)
                .map(embeddings -> {
                    int savedCount = 0;
                    for (int i = 0; i < Math.min(documents.size(), embeddings.size()); i++) {
                        try {
                            String vectorStr = vectorToString(embeddings.get(i));
                            int updated = jdbcTemplate.update(
                                    "UPDATE collected_data SET embedding = ?::vector WHERE id = ?",
                                    vectorStr, documents.get(i).id());
                            if (updated > 0) savedCount++;
                        } catch (Exception e) {
                            log.debug("Failed to save embedding for document {}: {}", 
                                    documents.get(i).id(), e.getMessage());
                        }
                    }
                    return savedCount;
                })
                .onErrorReturn(0);
    }

    /**
     * 임베딩이 없는 문서에 대해 임베딩을 생성합니다.
     *
     * @param batchSize 한 번에 처리할 문서 수
     * @return 처리된 문서 수
     */
    public Mono<Integer> indexMissingEmbeddings(int batchSize) {
        if (!isAvailable()) {
            return Mono.just(0);
        }

        try {
            // 임베딩이 없는 문서 조회
            List<DocumentContent> documents = jdbcTemplate.query(
                    "SELECT id, COALESCE(title, '') || ' ' || COALESCE(content, '') as content " +
                    "FROM collected_data WHERE embedding IS NULL LIMIT ?",
                    (rs, rowNum) -> new DocumentContent(
                            rs.getLong("id"),
                            rs.getString("content")
                    ),
                    batchSize);

            if (documents.isEmpty()) {
                return Mono.just(0);
            }

            log.info("Indexing {} documents without embeddings", documents.size());
            return saveEmbeddingsBatch(documents);
        } catch (Exception e) {
            log.error("Failed to index missing embeddings: {}", e.getMessage());
            return Mono.just(0);
        }
    }

    /**
     * 서비스 사용 가능 여부를 반환합니다.
     */
    public boolean isAvailable() {
        return enabled && pgvectorAvailable && embeddingService.isEnabled();
    }

    /**
     * float 배열을 pgvector 형식 문자열로 변환합니다.
     */
    private String vectorToString(float[] vector) {
        StringBuilder sb = new StringBuilder("[");
        for (int i = 0; i < vector.length; i++) {
            if (i > 0) sb.append(",");
            sb.append(vector[i]);
        }
        sb.append("]");
        return sb.toString();
    }

    // ==================== Inner Classes ====================

    /**
     * 유사도 점수가 포함된 문서
     */
    public record ScoredDocument(
            Long id,
            String title,
            String url,
            double similarity
    ) {}

    /**
     * 문서 ID와 내용
     */
    public record DocumentContent(
            Long id,
            String content
    ) {}
}

```

---

## backend/data-collection-service/src/main/resources/application-local-consul.yml

```yml
# ============================================
# Local Consul Profile Configuration
# ============================================
# 
# 로컬 개발 및 Consul 연동 환경에서 사용하는 설정.
# 모든 기능이 기본적으로 활성화됩니다.
#
# 사용법:
# - SPRING_PROFILES_ACTIVE=local-consul
# - docker-compose.consul.yml 사용 시 자동 적용
#

# ============================================
# Scheduling (Collection Jobs)
# ============================================
collector:
  scheduling:
    enabled: true
    # 30분마다 RSS 수집
    cron: "0 0/30 * * * ?"
    skip-if-running: true
  
  # RSS Feed
  rss:
    enabled: true
  
  # Web Scraper
  web-scraper:
    enabled: true
  
  # Browser Agent (autonomous-crawler-service)
  browser-agent:
    enabled: true
  
  # Deep Search (내부 통합 크롤러 사용)
  deep-search:
    timeout-minutes: 30
    cleanup-days: 7
  
  # Integrated Crawler
  integrated-crawler:
    max-depth: 2
    max-pages: 20
    timeout-seconds: 30
    concurrent-crawls: 5
  
  # Hybrid Search (Keyword + Semantic)
  hybrid-search:
    enabled: true
    keyword-top-k: 30
    semantic-top-k: 20
    final-top-k: 20
  
  # Embedding Service
  embedding:
    enabled: true
  
  # Vector Search
  vector-search:
    enabled: true

# ============================================
# Auto-Crawl (실시간 확장형 크롤링)
# ============================================
autocrawl:
  # 자동 크롤링 활성화
  enabled: true
  
  # 배치 크기
  batch-size: 10
  
  # 도메인당 최대 동시 크롤링
  max-concurrent-per-domain: 3
  
  # 타임아웃 설정
  stuck-timeout-minutes: 30
  
  # 정리 주기
  cleanup-days: 7
  expire-pending-days: 7
  
  # 스케줄러 간격 (개발환경에서는 짧게)
  queue-interval-ms: 15000        # 15초마다 큐 처리
  recovery-interval-ms: 120000    # 2분마다 복구 체크
  stats-interval-ms: 300000       # 5분마다 통계 로깅
  
  # 모든 발견 소스 활성화
  discover-from-search: true
  discover-from-articles: true
  discover-from-deep-search: true
  
  # 최소 콘텐츠 길이
  min-content-length: 200

# ============================================
# Logging (개발환경에서 상세 로깅)
# ============================================
logging:
  level:
    root: INFO
    com.newsinsight: DEBUG
    com.newsinsight.collector.service.autocrawl: DEBUG
    com.newsinsight.collector.scheduler: DEBUG

```

---

## backend/data-collection-service/src/main/resources/application.yml

```yml
spring:
  application:
    name: collector-service
  config:
    # Consul config import (optional - Consul 없어도 시작 가능)
    import: ${SPRING_CONFIG_IMPORT:optional:consul:}
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
    # Producer reliability settings
    producer:
      acks: ${KAFKA_PRODUCER_ACKS:all}
      retries: ${KAFKA_PRODUCER_RETRIES:3}
      retry-backoff-ms: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS:1000}
      delivery-timeout-ms: ${KAFKA_PRODUCER_DELIVERY_TIMEOUT_MS:120000}
      enable-idempotence: ${KAFKA_PRODUCER_ENABLE_IDEMPOTENCE:true}
    # Consumer reliability settings
    consumer:
      max-retry-attempts: ${KAFKA_CONSUMER_MAX_RETRY_ATTEMPTS:3}
      retry-backoff-ms: ${KAFKA_CONSUMER_RETRY_BACKOFF_MS:1000}
      retry-max-backoff-ms: ${KAFKA_CONSUMER_RETRY_MAX_BACKOFF_MS:30000}
      concurrency: ${KAFKA_CONSUMER_CONCURRENCY:1}
  data:
    mongodb:
      uri: ${MONGODB_URI:mongodb://localhost:27017/newsinsight}
    redis:
      host: ${REDIS_HOST:localhost}
      port: ${REDIS_PORT:6379}
      password: ${REDIS_PASSWORD:}
      timeout: 3000ms
      lettuce:
        pool:
          max-active: 8
          max-idle: 8
          min-idle: 0
          max-wait: -1ms
  
  datasource:
    url: jdbc:postgresql://${DB_HOST:localhost}:${DB_PORT:5432}/${DB_NAME:newsinsight}
    username: ${DB_USER:postgres}
    password: ${DB_PASSWORD:postgres}
    driver-class-name: org.postgresql.Driver
    hikari:
      maximum-pool-size: 10
      minimum-idle: 5
      connection-timeout: 30000
      idle-timeout: 600000
      max-lifetime: 1800000
  
  jpa:
    hibernate:
      ddl-auto: update
    show-sql: ${JPA_SHOW_SQL:false}
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
        format_sql: true
        jdbc:
          batch_size: 20
        order_inserts: true
        order_updates: true
    open-in-view: false
  
  cloud:
    consul:
      enabled: ${CONSUL_ENABLED:true}
      host: ${CONSUL_HOST:localhost}
      port: ${CONSUL_PORT:8500}
      discovery:
        enabled: ${CONSUL_DISCOVERY_ENABLED:true}
        instance-id: ${spring.application.name}:${random.value}
        service-name: ${spring.application.name}
        prefer-ip-address: false
        hostname: ${CONSUL_DISCOVERY_HOSTNAME:collector-service}
        health-check-path: /actuator/health
        health-check-interval: 10s
        # Consul 연결 실패해도 시작 가능
        fail-fast: false
      config:
        enabled: ${CONSUL_CONFIG_ENABLED:true}
        prefix: config
        default-context: ${spring.application.name}
        profile-separator: '::'
        format: PROPERTIES
        # Consul config 없어도 시작 가능
        fail-fast: false
  
  task:
    execution:
      pool:
        core-size: 5
        max-size: 20
        queue-capacity: 100
      thread-name-prefix: async-task-

  flyway:
    enabled: ${SPRING_FLYWAY_ENABLED:false}

server:
  port: ${SERVER_PORT:8081}
  servlet:
    context-path: /
  compression:
    enabled: true
  error:
    include-message: always
    include-binding-errors: always

management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  endpoint:
    health:
      show-details: always
  health:
    consul:
      enabled: ${CONSUL_ENABLED:true}
  # Kafka metrics via Micrometer
  metrics:
    tags:
      application: ${spring.application.name}
    distribution:
      percentiles-histogram:
        kafka: true
      slo:
        kafka.producer.request.latency: 10ms,50ms,100ms,500ms
        kafka.consumer.fetch.latency: 10ms,50ms,100ms,500ms

logging:
  level:
    root: INFO
    com.newsinsight: ${LOG_LEVEL:DEBUG}
    org.springframework.web: INFO
    org.hibernate.SQL: ${JPA_SHOW_SQL:false}
    org.hibernate.type.descriptor.sql.BasicBinder: ${JPA_SHOW_SQL:false}
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} - %msg%n"

# Application specific configuration
collector:
  scheduling:
    enabled: ${SCHEDULING_ENABLED:true}
    # Cron expression: run every hour
    cron: ${COLLECTION_CRON:0 0 * * * ?}
    # Skip scheduled collection if there are already running jobs
    skip-if-running: ${SCHEDULING_SKIP_IF_RUNNING:true}
  
  http:
    user-agent: ${HTTP_USER_AGENT:NewsInsight-Collector/1.0}
    timeout:
      connect: ${HTTP_CONNECT_TIMEOUT:10000}
      read: ${HTTP_READ_TIMEOUT:30000}
    max-redirects: 5
  
  rss:
    enabled: true
    fetch-timeout: 30000
  
  web-scraper:
    enabled: true
    max-content-length: 1048576  # 1MB
    respect-robots-txt: true
  
  collection:
    max-concurrent: ${MAX_CONCURRENT_COLLECTIONS:5}
    retry:
      max-attempts: 3
      backoff-delay: 1000
    cleanup:
      old-jobs-days: 30
  
  quality-assurance:
    min-content-length: ${QA_MIN_CONTENT_LENGTH:50}
    enable-network-checks: ${QA_ENABLE_NETWORK_CHECKS:false}
    domain-whitelist: ${QA_DOMAIN_WHITELIST:example.com,news.example.com}
    expected-keywords: ${QA_EXPECTED_KEYWORDS:news,article,report}

  ai:
    topic:
      request: ${COLLECTOR_AI_REQUEST_TOPIC:newsinsight.ai.requests}
      response: ${COLLECTOR_AI_RESPONSE_TOPIC:newsinsight.ai.responses}
    default-provider-id: ${COLLECTOR_AI_PROVIDER_ID:openai}
    default-model-id: ${COLLECTOR_AI_MODEL_ID:gpt-4.1}
    
    # AI Orchestration Configuration (Multi-provider Job Management)
    orchestration:
      # Kafka topic for AI task requests
      topic: ${COLLECTOR_AI_ORCHESTRATION_TOPIC:ai.tasks.requests}
      # Base URL for callback (this service's public URL)
      callback-base-url: ${COLLECTOR_AI_ORCHESTRATION_CALLBACK_BASE_URL:${collector.deep-search.callback-base-url}}
      # Token for validating callbacks from internal workers
      callback-token: ${COLLECTOR_AI_ORCHESTRATION_CALLBACK_TOKEN:${collector.deep-search.callback-token}}
      # Minutes before marking a job as timed out
      timeout-minutes: ${COLLECTOR_AI_ORCHESTRATION_TIMEOUT_MINUTES:30}
      # Interval for checking timed out jobs (milliseconds)
      timeout-check-interval: ${COLLECTOR_AI_ORCHESTRATION_TIMEOUT_CHECK_INTERVAL:300000}
      # Days to keep completed jobs before cleanup
      cleanup-days: ${COLLECTOR_AI_ORCHESTRATION_CLEANUP_DAYS:7}
      # Cron expression for cleanup job (3 AM daily)
      cleanup-cron: ${COLLECTOR_AI_ORCHESTRATION_CLEANUP_CRON:0 0 3 * * ?}

  crawl:
    topic:
      command: ${COLLECTOR_CRAWL_COMMAND_TOPIC:newsinsight.crawl.commands}
      result: ${COLLECTOR_CRAWL_RESULT_TOPIC:newsinsight.crawl.results}
      browser-task: ${COLLECTOR_CRAWL_BROWSER_TASK_TOPIC:newsinsight.crawl.browser.tasks}

  crawler:
    enabled: ${COLLECTOR_SERVICE_CRAWLER_ENABLED:true}
    base-url: ${COLLECTOR_SERVICE_CRAWLER_BASE_URL:http://web-crawler:11235}

  # Browser Agent Configuration (autonomous-crawler-service)
  browser-agent:
    enabled: ${COLLECTOR_BROWSER_AGENT_ENABLED:true}
    # Callback URL for session completion
    callback-base-url: ${COLLECTOR_CALLBACK_BASE_URL:${COLLECTOR_BROWSER_AGENT_CALLBACK_BASE_URL:http://collector-service:8081}}
    callback-token: ${COLLECTOR_BROWSER_AGENT_CALLBACK_TOKEN:}

  # Deep AI Search Configuration
  # DeepSearch runs entirely on internal services (IntegratedCrawlerService + AIDove).
  # Legacy n8n webhook integration has been removed.
  deep-search:
    # Base URL for internal callbacks
    callback-base-url: ${COLLECTOR_CALLBACK_BASE_URL:${DEEP_SEARCH_CALLBACK_BASE_URL:http://collector-service:8081}}
    # Token for validating internal callbacks
    callback-token: ${DEEP_SEARCH_CALLBACK_TOKEN:}
    # Minutes before marking a job as timed out
    timeout-minutes: ${DEEP_SEARCH_TIMEOUT_MINUTES:30}
    # Interval for checking timed out jobs (milliseconds)
    timeout-check-interval: ${DEEP_SEARCH_TIMEOUT_CHECK_INTERVAL:300000}
    # Days to keep completed jobs before cleanup
    cleanup-days: ${DEEP_SEARCH_CLEANUP_DAYS:7}
    # Cron expression for cleanup job (3 AM daily)
    cleanup-cron: ${DEEP_SEARCH_CLEANUP_CRON:0 0 3 * * ?}

  # Integrated Crawler Configuration (multi-strategy crawling)
  integrated-crawler:
    # Maximum crawl depth (how many links deep to follow)
    max-depth: ${COLLECTOR_INTEGRATED_CRAWLER_MAX_DEPTH:3}
    # Maximum pages to crawl per job
    max-pages: ${COLLECTOR_INTEGRATED_CRAWLER_MAX_PAGES:50}
    # Timeout per page crawl in seconds
    timeout-seconds: ${COLLECTOR_INTEGRATED_CRAWLER_TIMEOUT_SECONDS:30}
    # Number of concurrent crawls
    concurrent-crawls: ${COLLECTOR_INTEGRATED_CRAWLER_CONCURRENT:10}

  # Browser-Use API Configuration (for JS-rendered content)
  browser-use:
    base-url: ${COLLECTOR_BROWSER_USE_BASE_URL:${BROWSER_USE_API_URL:http://browser-use-api:8500}}

  # AI Dove Configuration (for evidence analysis)
  ai-dove:
    enabled: ${COLLECTOR_AI_DOVE_ENABLED:${AI_DOVE_ENABLED:true}}
    base-url: ${COLLECTOR_AI_DOVE_BASE_URL:${AI_DOVE_BASE_URL:https://workflow.nodove.com/webhook/aidove}}
    # Timeout for AI Dove API calls in seconds (evidence analysis can take time)
    timeout-seconds: ${COLLECTOR_AI_DOVE_TIMEOUT_SECONDS:${AI_DOVE_TIMEOUT_SECONDS:180}}

  # Fact Check Sources Configuration
  fact-check:
    # Timeout for all fact-check API calls
    timeout-seconds: ${COLLECTOR_FACT_CHECK_TIMEOUT_SECONDS:15}
    
    # CrossRef - Academic paper search (free, no API key required)
    crossref:
      enabled: ${COLLECTOR_CROSSREF_ENABLED:true}
      # Email for polite pool (faster rate limits)
      mailto: ${COLLECTOR_CROSSREF_MAILTO:newsinsight@example.com}
    
    # OpenAlex - Open academic database (free, no API key required)
    openalex:
      enabled: ${COLLECTOR_OPENALEX_ENABLED:true}
      # Email for polite pool
      mailto: ${COLLECTOR_OPENALEX_MAILTO:newsinsight@example.com}
    
    # Google Fact Check Tools API (requires API key)
    # Get API key: https://developers.google.com/fact-check/tools/api
    google:
      enabled: ${COLLECTOR_GOOGLE_FACTCHECK_ENABLED:true}
      api-key: ${COLLECTOR_GOOGLE_FACTCHECK_API_KEY:}

  # ============================================
  # Hybrid Search Configuration (Keyword + Semantic + RRF)
  # ============================================
  
  # Embedding Service (HuggingFace Text Embeddings Inference)
  embedding:
    enabled: ${EMBEDDING_ENABLED:true}
    base-url: ${EMBEDDING_BASE_URL:http://localhost:8011}
    model: ${EMBEDDING_MODEL:intfloat/multilingual-e5-large}
    dimension: ${EMBEDDING_DIMENSION:1024}
    timeout-seconds: ${EMBEDDING_TIMEOUT_SECONDS:30}
  
  # Vector Search (PostgreSQL pgvector)
  vector-search:
    enabled: ${VECTOR_SEARCH_ENABLED:true}
    top-k: ${VECTOR_SEARCH_TOP_K:20}
    min-similarity: ${VECTOR_SEARCH_MIN_SIMILARITY:0.5}
  
  # Hybrid Search Orchestration
  hybrid-search:
    enabled: ${HYBRID_SEARCH_ENABLED:true}
    # Number of results from keyword search
    keyword-top-k: ${HYBRID_SEARCH_KEYWORD_TOP_K:30}
    # Number of results from semantic search
    semantic-top-k: ${HYBRID_SEARCH_SEMANTIC_TOP_K:20}
    # Final number of results after RRF fusion
    final-top-k: ${HYBRID_SEARCH_FINAL_TOP_K:20}
    # Source weights for RRF (adjustable)
    keyword-weight: ${HYBRID_SEARCH_KEYWORD_WEIGHT:1.0}
    semantic-weight: ${HYBRID_SEARCH_SEMANTIC_WEIGHT:1.0}

  # Trust Score Configuration
  # Externalized trust scores for fact-check sources and data quality assessment.
  # Hierarchy: Academic (0.95) > Official Stats (0.95) > Encyclopedia (0.90) > Fact Check (0.85)
  trust-scores:
    # Fact-check sources (used by FactCheckSource implementations)
    fact-check:
      crossref: ${TRUST_SCORE_CROSSREF:0.95}            # Academic papers (highest)
      openalex: ${TRUST_SCORE_OPENALEX:0.92}            # Academic database
      wikipedia: ${TRUST_SCORE_WIKIPEDIA:0.90}          # Encyclopedia
      google-fact-check: ${TRUST_SCORE_GOOGLE_FC:0.85}  # Verified fact-check
    
    # Trusted reference sources (used by FactVerificationService)
    trusted:
      wikipedia-ko: ${TRUST_SCORE_WIKI_KO:0.90}         # Korean Wikipedia
      wikipedia-en: ${TRUST_SCORE_WIKI_EN:0.90}         # English Wikipedia
      britannica: ${TRUST_SCORE_BRITANNICA:0.95}        # Britannica (very high)
      namu-wiki: ${TRUST_SCORE_NAMU:0.60}               # Namu Wiki (community)
      kosis: ${TRUST_SCORE_KOSIS:0.95}                  # Korean Statistics (official)
      google-scholar: ${TRUST_SCORE_SCHOLAR:0.85}       # Academic search
    
    # Data quality assessment (used by CollectedDataService)
    data-quality:
      base-score: ${TRUST_SCORE_BASE:0.50}              # Unknown sources
      whitelist-score: ${TRUST_SCORE_WHITELIST:0.90}    # Whitelisted domains
      http-ok-bonus: ${TRUST_SCORE_HTTP_BONUS:0.10}     # Successful HTTP connection
    
    # Custom source scores (add your own)
    # custom:
    #   my-trusted-source: 0.88

# ============================================
# Auto-Crawl Configuration (실시간 확장형 크롤링)
# ============================================
# 
# 검색, 기사, 트렌딩 등에서 자동으로 URL을 발견하고 크롤링합니다.
# autonomous-crawler-service와 연동하여 동작합니다.
#
autocrawl:
  # 자동 크롤링 활성화 여부
  enabled: ${AUTOCRAWL_ENABLED:true}
  
  # 한 번에 처리할 대상 수
  batch-size: ${AUTOCRAWL_BATCH_SIZE:10}
  
  # 도메인당 최대 동시 크롤링 수 (rate limiting)
  max-concurrent-per-domain: ${AUTOCRAWL_MAX_CONCURRENT_PER_DOMAIN:3}
  
  # IN_PROGRESS 상태 타임아웃 (분) - 이 시간 초과 시 PENDING으로 복구
  stuck-timeout-minutes: ${AUTOCRAWL_STUCK_TIMEOUT_MINUTES:30}
  
  # 오래된 완료/실패 대상 정리 기준 (일)
  cleanup-days: ${AUTOCRAWL_CLEANUP_DAYS:7}
  
  # 오래된 PENDING 대상 만료 기준 (일)
  expire-pending-days: ${AUTOCRAWL_EXPIRE_PENDING_DAYS:7}
  
  # 스케줄러 간격 (밀리초)
  queue-interval-ms: ${AUTOCRAWL_QUEUE_INTERVAL_MS:30000}        # 30초마다 큐 처리
  recovery-interval-ms: ${AUTOCRAWL_RECOVERY_INTERVAL_MS:300000}  # 5분마다 복구 체크
  stats-interval-ms: ${AUTOCRAWL_STATS_INTERVAL_MS:600000}        # 10분마다 통계 로깅
  
  # 정리 작업 cron (새벽 3시)
  cleanup-cron: ${AUTOCRAWL_CLEANUP_CRON:0 0 3 * * *}
  
  # URL 발견 소스별 활성화
  discover-from-search: ${AUTOCRAWL_DISCOVER_FROM_SEARCH:true}
  discover-from-articles: ${AUTOCRAWL_DISCOVER_FROM_ARTICLES:true}
  discover-from-deep-search: ${AUTOCRAWL_DISCOVER_FROM_DEEP_SEARCH:true}
  
  # 최소 콘텐츠 길이 (이 이상인 경우에만 링크 추출)
  min-content-length: ${AUTOCRAWL_MIN_CONTENT_LENGTH:200}
  
  # ============================================
  # Seed URL 자동 초기화 설정
  # ============================================
  # docker-compose 시작 시 자동으로 seed URL을 큐에 추가합니다.
  seed:
    # seed 자동 초기화 활성화 (true로 설정 시 시작 시 seed URL 추가)
    enabled: ${AUTOCRAWL_SEED_ENABLED:false}
    
    # 커스텀 seed URL (콤마로 구분, 비어있으면 기본 뉴스 포털 URL 사용)
    urls: ${AUTOCRAWL_SEED_URLS:}
    
    # seed URL에 연결할 키워드
    keywords: ${AUTOCRAWL_SEED_KEYWORDS:뉴스,정치,경제,사회,IT,기술}
    
    # seed URL 우선순위 (0-100, 높을수록 먼저 크롤링)
    priority: ${AUTOCRAWL_SEED_PRIORITY:70}

# ============================================
# Vector Database 설정 (Qdrant)
# ============================================
vector:
  db:
    enabled: ${VECTOR_DB_ENABLED:false}
    url: ${VECTOR_DB_URL:http://localhost:6333}
    collection: ${VECTOR_DB_COLLECTION:factcheck_chat}
  embedding:
    model: ${EMBEDDING_MODEL:text-embedding-ada-002}
    api-key: ${OPENAI_API_KEY:}
    dimension: ${EMBEDDING_DIMENSION:1536}
    timeout-seconds: ${EMBEDDING_TIMEOUT_SECONDS:30}
    max-retry: ${EMBEDDING_MAX_RETRY:3}
    batch-size: ${EMBEDDING_BATCH_SIZE:10}
    local:
      enabled: ${LOCAL_EMBEDDING_ENABLED:false}
      url: ${LOCAL_EMBEDDING_URL:http://localhost:8011}

# ============================================
# 채팅 서비스 설정
# ============================================
chat:
  sync:
    # 동기화 트리거 조건
    min-messages: ${CHAT_SYNC_MIN_MESSAGES:10}
    max-idle-minutes: ${CHAT_SYNC_MAX_IDLE_MINUTES:5}
    # 배치 처리
    batch-size: ${CHAT_SYNC_BATCH_SIZE:50}
    # 재시도
    max-retry: ${CHAT_SYNC_MAX_RETRY:3}
    # 세션 만료
    session-expire-hours: ${CHAT_SESSION_EXPIRE_HOURS:24}
    # 스케줄러 간격
    scheduler:
      interval: ${CHAT_SYNC_SCHEDULER_INTERVAL:300000}
    expire:
      interval: ${CHAT_SYNC_EXPIRE_INTERVAL:3600000}

# ============================================
# 캐시 설정
# ============================================
cache:
  chat-sessions:
    ttl-hours: ${CACHE_CHAT_SESSIONS_TTL_HOURS:2}
  chat-messages:
    ttl-minutes: ${CACHE_CHAT_MESSAGES_TTL_MINUTES:30}
  default:
    ttl-hours: ${CACHE_DEFAULT_TTL_HOURS:24}
  local:
    max-size: ${CACHE_LOCAL_MAX_SIZE:1000}
    ttl-minutes: ${CACHE_LOCAL_TTL_MINUTES:10}

# ============================================
# 비동기 실행자 설정
# ============================================
async:
  executor:
    core-pool-size: ${ASYNC_CORE_POOL_SIZE:5}
    max-pool-size: ${ASYNC_MAX_POOL_SIZE:20}
    queue-capacity: ${ASYNC_QUEUE_CAPACITY:100}
  chat-sync:
    core-pool-size: ${CHAT_SYNC_CORE_POOL_SIZE:3}
    max-pool-size: ${CHAT_SYNC_MAX_POOL_SIZE:10}
    queue-capacity: ${CHAT_SYNC_QUEUE_CAPACITY:50}

# ============================================
# Workspace File Storage Configuration
# ============================================
workspace:
  storage:
    # Local storage path (Docker volume mount point)
    path: ${WORKSPACE_STORAGE_PATH:/data/workspace}
    # Maximum file size in bytes (default: 100MB)
    max-file-size: ${WORKSPACE_MAX_FILE_SIZE:104857600}
    # Maximum files per anonymous session
    max-files-per-session: ${WORKSPACE_MAX_FILES_PER_SESSION:100}
    # Session file TTL in hours (files auto-expire after this)
    session-file-ttl-hours: ${WORKSPACE_SESSION_FILE_TTL_HOURS:24}
  cleanup:
    # Cron for expired file cleanup (3:30 AM daily)
    cron: ${WORKSPACE_CLEANUP_CRON:0 30 3 * * *}
    # Hours before orphaned session files are marked for deletion
    orphan-hours: ${WORKSPACE_ORPHAN_HOURS:48}

```

---

## backend/data-collection-service/src/test/java/com/newsinsight/collector/CollectorApplicationTests.java

```java
package com.newsinsight.collector;

import org.junit.jupiter.api.Test;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.test.context.ActiveProfiles;
import org.springframework.test.context.TestPropertySource;

/**
 * 스프링 컨텍스트 로드 테스트
 * 애플리케이션 설정이 올바르게 구성되었는지 확인합니다.
 */
@SpringBootTest
@ActiveProfiles("test")
@TestPropertySource(properties = {
    // Consul 비활성화
    "spring.cloud.consul.enabled=false",
    "spring.cloud.consul.config.enabled=false",
    "spring.cloud.consul.discovery.enabled=false",
    // Kafka 비활성화
    "spring.kafka.enabled=false",
    // 임베딩 비활성화
    "embedding.enabled=false",
    "hybrid-search.enabled=false",
    "vector-search.enabled=false"
})
class CollectorApplicationTests {

    @Test
    void contextLoads() {
        // 스프링 컨텍스트가 정상적으로 로드되면 테스트 통과
    }
}

```

---

## backend/data-collection-service/src/test/java/com/newsinsight/collector/controller/DashboardEventControllerTest.java

```java
package com.newsinsight.collector.controller;

import com.newsinsight.collector.service.DashboardEventService;
import org.junit.jupiter.api.DisplayName;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.autoconfigure.web.reactive.WebFluxTest;
import org.springframework.boot.test.mock.mockito.MockBean;
import org.springframework.test.context.ActiveProfiles;
import org.springframework.test.web.reactive.server.WebTestClient;

/**
 * DashboardEventController 단위 테스트
 */
@WebFluxTest(DashboardEventController.class)
@ActiveProfiles("test")
class DashboardEventControllerTest {

    @Autowired
    private WebTestClient webTestClient;

    @MockBean
    private DashboardEventService dashboardEventService;

    @Test
    @DisplayName("GET /api/v1/events/stream - SSE 스트림 연결")
    void testEventStream() {
        // SSE 스트림은 테스트가 복잡하므로 연결 자체만 테스트
        // 실제 테스트에서는 StepVerifier 사용 필요
        webTestClient.get()
            .uri("/api/v1/events/stream")
            .exchange()
            .expectStatus().isOk()
            .expectHeader().valueEquals("Content-Type", "text/event-stream");
    }
}

```

---

## backend/data-collection-service/src/test/java/com/newsinsight/collector/repository/DataSourceRepositoryIT.java

```java
package com.newsinsight.collector.repository;

import com.newsinsight.collector.entity.DataSource;
import com.newsinsight.collector.entity.SourceType;
import org.junit.jupiter.api.DisplayName;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.autoconfigure.orm.jpa.DataJpaTest;
import org.springframework.test.context.ActiveProfiles;
import org.springframework.test.context.DynamicPropertyRegistry;
import org.springframework.test.context.DynamicPropertySource;
import org.testcontainers.containers.PostgreSQLContainer;
import org.testcontainers.junit.jupiter.Container;
import org.testcontainers.junit.jupiter.Testcontainers;

import java.util.List;

import static org.assertj.core.api.Assertions.assertThat;

/**
 * DataSourceRepository 통합 테스트 (Testcontainers 사용)
 * 실제 PostgreSQL 컨테이너에서 테스트를 실행합니다.
 */
@DataJpaTest
@Testcontainers
@ActiveProfiles("test")
class DataSourceRepositoryIT {

    @Container
    static PostgreSQLContainer<?> postgres = new PostgreSQLContainer<>("pgvector/pgvector:pg15")
            .withDatabaseName("testdb")
            .withUsername("test")
            .withPassword("test");

    @DynamicPropertySource
    static void configureProperties(DynamicPropertyRegistry registry) {
        registry.add("spring.datasource.url", postgres::getJdbcUrl);
        registry.add("spring.datasource.username", postgres::getUsername);
        registry.add("spring.datasource.password", postgres::getPassword);
        registry.add("spring.jpa.hibernate.ddl-auto", () -> "create-drop");
    }

    @Autowired
    private DataSourceRepository dataSourceRepository;

    @Test
    @DisplayName("데이터 소스 저장 및 조회")
    void saveAndFindDataSource() {
        // given
        DataSource source = new DataSource();
        source.setName("테스트 뉴스 소스");
        source.setSourceType(SourceType.RSS);
        source.setUrl("https://news.example.com");
        source.setIsActive(true);

        // when
        DataSource saved = dataSourceRepository.save(source);

        // then
        assertThat(saved.getId()).isNotNull();
        assertThat(saved.getName()).isEqualTo("테스트 뉴스 소스");
    }

    @Test
    @DisplayName("활성화된 소스만 조회")
    void findByActiveTrue() {
        // given
        DataSource activeSource = new DataSource();
        activeSource.setName("활성 소스");
        activeSource.setSourceType(SourceType.RSS);
        activeSource.setUrl("https://active.example.com");
        activeSource.setIsActive(true);

        DataSource inactiveSource = new DataSource();
        inactiveSource.setName("비활성 소스");
        inactiveSource.setSourceType(SourceType.RSS);
        inactiveSource.setUrl("https://inactive.example.com");
        inactiveSource.setIsActive(false);

        dataSourceRepository.save(activeSource);
        dataSourceRepository.save(inactiveSource);

        // when
        List<DataSource> activeSources = dataSourceRepository.findByIsActiveTrue();

        // then
        assertThat(activeSources).hasSize(1);
        assertThat(activeSources.get(0).getName()).isEqualTo("활성 소스");
    }

    @Test
    @DisplayName("타입별 소스 조회")
    void findByType() {
        // given
        DataSource newsSource = new DataSource();
        newsSource.setName("뉴스 소스");
        newsSource.setSourceType(SourceType.RSS);
        newsSource.setUrl("https://news.example.com");
        newsSource.setIsActive(true);

        DataSource socialSource = new DataSource();
        socialSource.setName("소셜 소스");
        socialSource.setSourceType(SourceType.WEB);
        socialSource.setUrl("https://social.example.com");
        socialSource.setIsActive(true);

        dataSourceRepository.save(newsSource);
        dataSourceRepository.save(socialSource);

        // when
        List<DataSource> newsSources = dataSourceRepository.findBySourceType(SourceType.RSS);

        // then
        assertThat(newsSources).hasSize(1);
        assertThat(newsSources.get(0).getSourceType()).isEqualTo(SourceType.RSS);
    }
}

```

---

## backend/data-collection-service/src/test/java/com/newsinsight/collector/service/DataSourceServiceTest.java

```java
package com.newsinsight.collector.service;

import com.newsinsight.collector.dto.DataSourceDTO;
import com.newsinsight.collector.entity.DataSource;
import com.newsinsight.collector.entity.SourceType;
import com.newsinsight.collector.mapper.EntityMapper;
import com.newsinsight.collector.repository.DataSourceRepository;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.DisplayName;
import org.junit.jupiter.api.Test;
import org.junit.jupiter.api.extension.ExtendWith;
import org.mockito.InjectMocks;
import org.mockito.Mock;
import org.mockito.junit.jupiter.MockitoExtension;

import java.util.List;
import java.util.Optional;

import static org.assertj.core.api.Assertions.assertThat;
import static org.mockito.ArgumentMatchers.any;
import static org.mockito.Mockito.*;

/**
 * DataSourceService 단위 테스트
 */
@ExtendWith(MockitoExtension.class)
class DataSourceServiceTest {

    @Mock
    private DataSourceRepository dataSourceRepository;

    @Mock
    private EntityMapper entityMapper;

    @InjectMocks
    private DataSourceService dataSourceService;

    private DataSource testSource;

    @BeforeEach
    void setUp() {
        testSource = new DataSource();
        testSource.setId(1L);
        testSource.setName("테스트 소스");
        testSource.setSourceType(SourceType.RSS);
        testSource.setUrl("https://example.com");
        testSource.setIsActive(true);
    }

    @Test
    @DisplayName("활성화된 소스 목록 조회")
    void findActiveSources() {
        // given
        DataSourceDTO dto = new DataSourceDTO(
            1L,
            "테스트 소스",
            "https://example.com",
            SourceType.RSS,
            true,
            null,
            3600,
            null,
            null,
            null,
            null
        );
        
        when(dataSourceRepository.findByIsActiveTrue()).thenReturn(List.of(testSource));
        when(entityMapper.toDTO(testSource)).thenReturn(dto);

        // when
        List<DataSourceDTO> result = dataSourceService.getActiveSources();

        // then
        assertThat(result).hasSize(1);
        assertThat(result.get(0).name()).isEqualTo("테스트 소스");
        verify(dataSourceRepository, times(1)).findByIsActiveTrue();
    }

    @Test
    @DisplayName("ID로 소스 조회")
    void findById() {
        // given
        when(dataSourceRepository.findById(1L)).thenReturn(Optional.of(testSource));

        // when
        Optional<DataSource> result = dataSourceService.findById(1L);

        // then
        assertThat(result).isPresent();
        assertThat(result.get().getName()).isEqualTo("테스트 소스");
    }

    @Test
    @DisplayName("소스 저장")
    void saveSource() {
        // given
        when(dataSourceRepository.save(any(DataSource.class))).thenReturn(testSource);

        // when
        DataSource result = dataSourceService.save(testSource);

        // then
        assertThat(result).isNotNull();
        assertThat(result.getName()).isEqualTo("테스트 소스");
        verify(dataSourceRepository, times(1)).save(testSource);
    }
}

```

---

## backend/data-collection-service/src/test/resources/application-test.yml

```yml
# 테스트 환경 설정
spring:
  application:
    name: collector-service-test
  
  # Consul 비활성화
  cloud:
    consul:
      enabled: false
      config:
        enabled: false
      discovery:
        enabled: false
  
  # 테스트용 H2 인메모리 DB
  datasource:
    url: jdbc:h2:mem:testdb;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE
    driver-class-name: org.h2.Driver
    username: sa
    password:
  
  jpa:
    database-platform: org.hibernate.dialect.H2Dialect
    hibernate:
      ddl-auto: create-drop
    show-sql: false
  
  # MongoDB 비활성화
  data:
    mongodb:
      uri: mongodb://localhost:27017/test
      auto-index-creation: false
    redis:
      host: localhost
      port: 6379
  
  # Kafka 비활성화
  kafka:
    bootstrap-servers: localhost:9092
    consumer:
      auto-startup: false
    producer:
      retries: 0

# 임베딩 서비스 비활성화
embedding:
  enabled: false
  base-url: http://localhost:8011

# 하이브리드/벡터 검색 비활성화
hybrid-search:
  enabled: false

vector-search:
  enabled: false

# 외부 서비스 Mock URL
collector:
  browser-use:
    base-url: http://localhost:8500
  service:
    crawler:
      base-url: http://localhost:11235
  callback:
    base-url: http://localhost:8081

# 로깅 설정
logging:
  level:
    root: WARN
    com.newsinsight: DEBUG
    org.springframework.web: DEBUG
    org.hibernate.SQL: DEBUG

```

---

## backend/ml-addons/bias-addon/addon_server.py

```py
"""
ML Add-on Server: Bias Analysis with ML Models

NewsInsight ML Add-on 시스템의 편향도 분석 구현.
KoELECTRA/KoBERT 기반 ML 모델을 사용하여 뉴스 기사의
정치적/이념적 편향성을 정확하게 분석합니다.

Features:
- KoELECTRA 기반 정치 성향 분류
- 언론사 기반 편향 분석
- 키워드/프레이밍 기반 폴백 모드 지원
- 객관성/감정적 어조 분석
- 배치 처리 지원
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import Response
from pydantic import BaseModel, Field
from typing import Optional, Dict, List, Any
import time
import os
import re
import logging
import asyncio
from contextlib import asynccontextmanager
from functools import lru_cache

# Prometheus metrics
try:
    from prometheus_client import (
        Counter,
        Histogram,
        Gauge,
        CONTENT_TYPE_LATEST,
        generate_latest,
    )

    PROMETHEUS_AVAILABLE = True
except ImportError:
    PROMETHEUS_AVAILABLE = False

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ML Model cache (lazy loading)
_ml_models = {}
_model_loading = False


def get_ml_models():
    """Lazy load ML models on first use"""
    global _ml_models, _model_loading

    if _ml_models.get("loaded") or _model_loading:
        return _ml_models

    _model_loading = True

    try:
        import torch
        from transformers import (
            AutoTokenizer,
            AutoModelForSequenceClassification,
            pipeline,
        )

        logger.info("Loading bias ML models...")

        # Device selection
        device = "cuda" if torch.cuda.is_available() else "cpu"
        logger.info(f"Using device: {device}")

        # 1. Primary Bias/Stance Model
        # Use a Korean text classification model that can be fine-tuned for stance detection
        bias_model_name = os.getenv(
            "BIAS_MODEL",
            "monologg/koelectra-base-v3-discriminator",  # Base Korean ELECTRA
        )

        try:
            # Try to load a sentiment/stance model first
            stance_model_name = os.getenv(
                "STANCE_MODEL",
                "snunlp/KR-FinBert-SC",  # Korean sentiment classifier as stance proxy
            )
            _ml_models["stance_pipeline"] = pipeline(
                "text-classification",
                model=stance_model_name,
                tokenizer=stance_model_name,
                device=0 if device == "cuda" else -1,
                max_length=512,
                truncation=True,
            )
            logger.info(f"Loaded stance model: {stance_model_name}")
        except Exception as e:
            logger.warning(f"Failed to load stance model: {e}")

        # 2. Load base tokenizer and model for custom analysis
        try:
            _ml_models["base_tokenizer"] = AutoTokenizer.from_pretrained(
                bias_model_name
            )
            _ml_models["base_model"] = (
                AutoModelForSequenceClassification.from_pretrained(
                    bias_model_name,
                    num_labels=3,  # left, center, right
                    ignore_mismatched_sizes=True,
                ).to(device)
            )
            _ml_models["base_model"].eval()
            logger.info(f"Loaded base model: {bias_model_name}")
        except Exception as e:
            logger.warning(f"Failed to load base model: {e}")

        # 3. Zero-shot classification for flexible bias detection
        try:
            zero_shot_model = os.getenv(
                "ZERO_SHOT_MODEL",
                "MoritzLaworski/korean-text-classification-zero-shot",
            )
            _ml_models["zero_shot_pipeline"] = pipeline(
                "zero-shot-classification",
                model=zero_shot_model,
                device=0 if device == "cuda" else -1,
            )
            logger.info(f"Loaded zero-shot model: {zero_shot_model}")
        except Exception as e:
            logger.warning(f"Failed to load zero-shot model (optional): {e}")

        _ml_models["device"] = device
        _ml_models["loaded"] = True
        logger.info("All bias ML models loaded successfully")

    except ImportError as e:
        logger.warning(f"ML libraries not available, using heuristic mode: {e}")
        _ml_models["loaded"] = False
    except Exception as e:
        logger.error(f"Error loading ML models: {e}")
        _ml_models["loaded"] = False

    _model_loading = False
    return _ml_models


# Model loading status for health checks
_model_warmup_complete = False
_model_warmup_error = None


async def _warmup_models():
    """Warm up models and track completion status"""
    global _model_warmup_complete, _model_warmup_error
    try:
        logger.info("Starting bias model warm-up...")
        start_time = time.time()

        # Load models synchronously in thread
        models = await asyncio.to_thread(get_ml_models)

        if models.get("loaded"):
            # Run a dummy inference to fully warm up the model
            if "stance_pipeline" in models:
                try:
                    dummy_text = "테스트 문장입니다."
                    _ = models["stance_pipeline"](dummy_text)
                    logger.info("Stance pipeline warm-up inference complete")
                except Exception as e:
                    logger.warning(f"Stance pipeline warm-up failed: {e}")

            elapsed = time.time() - start_time
            logger.info(f"Bias model warm-up completed in {elapsed:.2f}s")
            _model_warmup_complete = True
        else:
            logger.warning("Models not loaded, running in heuristic mode")
            _model_warmup_complete = True

    except Exception as e:
        logger.error(f"Bias model warm-up failed: {e}")
        _model_warmup_error = str(e)
        _model_warmup_complete = True


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan handler"""
    # Startup
    logger.info("Bias addon starting...")

    # Preload models in background if ML is enabled
    if os.getenv("ENABLE_ML_MODELS", "true").lower() == "true":
        asyncio.create_task(_warmup_models())

    yield

    # Shutdown
    logger.info("Bias addon shutting down...")


app = FastAPI(
    title="Bias Analysis Add-on (ML Enhanced)",
    description="Korean news article political/ideological bias analysis with ML for NewsInsight",
    version="2.0.0",
    lifespan=lifespan,
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ========== Prometheus Metrics ==========

if PROMETHEUS_AVAILABLE:
    # Request metrics
    REQUEST_COUNT = Counter(
        "bias_requests_total",
        "Total number of bias analysis requests",
        ["endpoint", "status"],
    )
    REQUEST_LATENCY = Histogram(
        "bias_request_latency_seconds",
        "Request latency in seconds",
        ["endpoint"],
        buckets=(0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0),
    )

    # Analysis metrics
    ANALYSIS_COUNT = Counter(
        "bias_analysis_total",
        "Total number of bias analyses performed",
        ["direction", "mode"],
    )

    # Model metrics
    MODEL_LOADED = Gauge(
        "bias_model_loaded", "Whether ML models are loaded (1=yes, 0=no)"
    )
    MODEL_WARMUP_COMPLETE = Gauge(
        "bias_model_warmup_complete", "Whether model warm-up is complete (1=yes, 0=no)"
    )

    # Error metrics
    ERROR_COUNT = Counter("bias_errors_total", "Total number of errors", ["error_type"])

    @app.get("/metrics")
    async def metrics():
        """Prometheus metrics endpoint"""
        models = get_ml_models() if not _model_loading else {}
        MODEL_LOADED.set(1 if models.get("loaded") else 0)
        MODEL_WARMUP_COMPLETE.set(1 if _model_warmup_complete else 0)

        return Response(content=generate_latest(), media_type=CONTENT_TYPE_LATEST)


# ========== Request/Response Models ==========


class ArticleInput(BaseModel):
    id: Optional[int] = None
    title: Optional[str] = None
    content: Optional[str] = None
    url: Optional[str] = None
    source: Optional[str] = None
    published_at: Optional[str] = None


class AnalysisContext(BaseModel):
    language: Optional[str] = "ko"
    country: Optional[str] = "KR"
    previous_results: Optional[Dict[str, Any]] = None


class ExecutionOptions(BaseModel):
    importance: Optional[str] = "batch"
    debug: Optional[bool] = False
    timeout_ms: Optional[int] = None
    use_ml: Optional[bool] = True
    include_source_bias: Optional[bool] = True
    include_framing: Optional[bool] = True


class AddonRequest(BaseModel):
    request_id: str
    addon_id: str
    task: str = "article_analysis"
    input_schema_version: str = "1.0"
    article: Optional[ArticleInput] = None
    context: Optional[AnalysisContext] = None
    options: Optional[ExecutionOptions] = None


class BiasIndicator(BaseModel):
    phrase: str
    bias_type: str  # political, ideological, framing, selection
    direction: str  # left, right, neutral
    weight: float
    confidence: float = 0.5


class ToneAnalysis(BaseModel):
    objectivity_score: float = Field(
        ..., ge=0.0, le=1.0, description="1 = very objective"
    )
    emotional_language: float = Field(
        ..., ge=0.0, le=1.0, description="1 = very emotional"
    )
    loaded_words_count: int
    examples: Optional[List[str]] = None


class SourceBias(BaseModel):
    source_name: Optional[str] = None
    known_lean: Optional[str] = None  # left, center-left, center, center-right, right
    ownership_info: Optional[str] = None
    reliability_score: Optional[float] = None  # 0-1


class BiasResult(BaseModel):
    overall_bias_score: float = Field(
        ..., ge=-1.0, le=1.0, description="-1 (progressive) to 1 (conservative)"
    )
    bias_label: (
        str  # far_left, left, center_left, center, center_right, right, far_right
    )
    confidence: float = Field(..., ge=0.0, le=1.0)
    political_lean: str  # progressive, moderate, conservative
    distribution: Dict[str, float] = Field(
        default_factory=dict, description="Score distribution"
    )
    indicators: Optional[List[BiasIndicator]] = None
    tone_analysis: Optional[ToneAnalysis] = None
    source_bias: Optional[SourceBias] = None
    framing_notes: Optional[List[str]] = None
    explanations: Optional[List[str]] = None
    analysis_method: str = "ml"  # ml, heuristic, hybrid


class AnalysisResults(BaseModel):
    bias: Optional[BiasResult] = None
    raw: Optional[Dict[str, Any]] = None


class ResponseMeta(BaseModel):
    model_version: str
    model_name: str
    latency_ms: int
    processed_at: str
    device: str = "cpu"


class ErrorInfo(BaseModel):
    code: str
    message: str
    details: Optional[str] = None


class AddonResponse(BaseModel):
    request_id: str
    addon_id: str
    status: str  # success, error, partial
    output_schema_version: str = "1.0"
    results: Optional[AnalysisResults] = None
    error: Optional[ErrorInfo] = None
    meta: Optional[ResponseMeta] = None


# ========== Source Bias Database ==========

# Korean media source political leanings (general perception)
SOURCE_BIAS_MAP = {
    # Progressive-leaning
    "한겨레": {"lean": "left", "score": -0.6, "reliability": 0.7},
    "경향신문": {"lean": "center-left", "score": -0.4, "reliability": 0.7},
    "오마이뉴스": {"lean": "left", "score": -0.7, "reliability": 0.6},
    "프레시안": {"lean": "left", "score": -0.7, "reliability": 0.6},
    "뉴스타파": {"lean": "left", "score": -0.5, "reliability": 0.8},
    # Center
    "연합뉴스": {"lean": "center", "score": 0.0, "reliability": 0.85},
    "KBS": {"lean": "center", "score": 0.0, "reliability": 0.8},
    "MBC": {"lean": "center-left", "score": -0.2, "reliability": 0.75},
    "SBS": {"lean": "center", "score": 0.0, "reliability": 0.75},
    "JTBC": {"lean": "center-left", "score": -0.2, "reliability": 0.75},
    "YTN": {"lean": "center", "score": 0.0, "reliability": 0.75},
    "뉴시스": {"lean": "center", "score": 0.0, "reliability": 0.7},
    "뉴스1": {"lean": "center", "score": 0.05, "reliability": 0.7},
    # Conservative-leaning
    "조선일보": {"lean": "right", "score": 0.6, "reliability": 0.7},
    "동아일보": {"lean": "center-right", "score": 0.4, "reliability": 0.7},
    "중앙일보": {"lean": "center-right", "score": 0.3, "reliability": 0.75},
    "매일경제": {"lean": "center-right", "score": 0.3, "reliability": 0.7},
    "한국경제": {"lean": "right", "score": 0.5, "reliability": 0.7},
    "TV조선": {"lean": "right", "score": 0.7, "reliability": 0.55},
    "채널A": {"lean": "right", "score": 0.6, "reliability": 0.55},
    "MBN": {"lean": "center-right", "score": 0.4, "reliability": 0.6},
    "문화일보": {"lean": "right", "score": 0.5, "reliability": 0.65},
    "세계일보": {"lean": "center-right", "score": 0.3, "reliability": 0.65},
}

# Progressive keywords/expressions
PROGRESSIVE_KEYWORDS = [
    ("복지", 0.3, 0.6),
    ("노동자 권리", 0.5, 0.7),
    ("환경", 0.2, 0.5),
    ("평등", 0.4, 0.7),
    ("인권", 0.3, 0.6),
    ("진보", 0.6, 0.8),
    ("민주화", 0.4, 0.7),
    ("시민단체", 0.3, 0.6),
    ("재벌 개혁", 0.5, 0.7),
    ("사회 정의", 0.4, 0.7),
    ("최저임금", 0.3, 0.6),
    ("공공성", 0.3, 0.6),
    ("노동조합", 0.4, 0.7),
    ("비정규직", 0.3, 0.6),
    ("부유세", 0.5, 0.7),
    ("공정경제", 0.3, 0.6),
    ("대북 화해", 0.4, 0.7),
    ("성소수자", 0.4, 0.7),
    ("젠더", 0.3, 0.6),
    ("다양성", 0.3, 0.6),
    ("기후위기", 0.3, 0.6),
    ("탈원전", 0.4, 0.7),
]

# Conservative keywords/expressions
CONSERVATIVE_KEYWORDS = [
    ("안보", 0.3, 0.6),
    ("자유시장", 0.4, 0.7),
    ("규제 완화", 0.4, 0.7),
    ("전통", 0.3, 0.6),
    ("보수", 0.6, 0.8),
    ("국가 안보", 0.4, 0.7),
    ("한미동맹", 0.3, 0.6),
    ("기업 친화", 0.4, 0.7),
    ("성장", 0.2, 0.5),
    ("법질서", 0.3, 0.6),
    ("애국", 0.4, 0.7),
    ("반공", 0.6, 0.8),
    ("자유민주주의", 0.3, 0.6),
    ("대북 강경", 0.4, 0.7),
    ("북핵", 0.3, 0.6),
    ("기업규제 완화", 0.4, 0.7),
    ("시장경제", 0.3, 0.6),
    ("원전", 0.3, 0.6),
    ("국방", 0.3, 0.6),
    ("자유대한민국", 0.5, 0.7),
    ("종북", 0.6, 0.8),
]

# Framing patterns
FRAMING_PATTERNS = {
    "left": [
        (r"민중", "진보적 프레이밍", 0.4),
        (r"사회적\s*약자", "진보적 관점", 0.3),
        (r"불평등\s*심화", "불평등 강조", 0.4),
        (r"재벌\s*특혜", "대기업 비판적", 0.4),
        (r"노동\s*착취", "노동자 권익 강조", 0.5),
        (r"검찰\s*독재", "검찰 비판적", 0.5),
        (r"적폐", "적폐 청산 프레임", 0.5),
    ],
    "right": [
        (r"종북", "보수적 프레이밍", 0.6),
        (r"안보\s*위협", "안보 강조", 0.4),
        (r"경제\s*성장", "성장 중심", 0.3),
        (r"시장\s*원리", "시장주의적 관점", 0.3),
        (r"규제\s*폐해", "규제 비판적", 0.4),
        (r"좌파\s*정권", "정권 비판적", 0.5),
        (r"포퓰리즘", "포퓰리즘 비판", 0.4),
    ],
}

# Emotional/loaded words
LOADED_WORDS = {
    "left": ["착취", "불의", "특권층", "기득권", "차별", "탄압", "독재", "적폐"],
    "right": ["종북", "좌파", "선동", "매국", "폭력", "과격", "빨갱이", "친중"],
    "emotional": [
        "충격적",
        "경악",
        "황당",
        "기막힌",
        "어처구니",
        "분노",
        "통탄",
        "개탄",
    ],
}


# ========== Heuristic Analysis Functions ==========


def get_source_bias(source: Optional[str]) -> SourceBias:
    """Get bias info from media source name"""
    if not source:
        return SourceBias()

    for name, info in SOURCE_BIAS_MAP.items():
        if name in source:
            return SourceBias(
                source_name=name,
                known_lean=info["lean"],
                reliability_score=info.get("reliability"),
            )

    return SourceBias(source_name=source, known_lean="unknown")


def analyze_keyword_bias_heuristic(text: str) -> tuple[float, List[BiasIndicator]]:
    """Keyword-based bias analysis (heuristic)"""
    if not text:
        return 0.0, []

    indicators = []
    progressive_score = 0.0
    conservative_score = 0.0

    text_lower = text.lower()

    # Progressive keywords
    for keyword, weight, conf in PROGRESSIVE_KEYWORDS:
        if keyword in text_lower:
            progressive_score += weight
            indicators.append(
                BiasIndicator(
                    phrase=keyword,
                    bias_type="political",
                    direction="left",
                    weight=weight,
                    confidence=conf,
                )
            )

    # Conservative keywords
    for keyword, weight, conf in CONSERVATIVE_KEYWORDS:
        if keyword in text_lower:
            conservative_score += weight
            indicators.append(
                BiasIndicator(
                    phrase=keyword,
                    bias_type="political",
                    direction="right",
                    weight=weight,
                    confidence=conf,
                )
            )

    # Normalize score (-1 ~ 1)
    total = progressive_score + conservative_score
    if total == 0:
        return 0.0, indicators

    bias_score = (conservative_score - progressive_score) / max(total, 1)
    return bias_score, indicators


def analyze_framing_heuristic(text: str) -> tuple[float, List[str]]:
    """Framing analysis (heuristic)"""
    if not text:
        return 0.0, []

    notes = []
    left_score = 0.0
    right_score = 0.0

    for pattern, note, weight in FRAMING_PATTERNS["left"]:
        if re.search(pattern, text):
            left_score += weight
            notes.append(f"[진보] {note}")

    for pattern, note, weight in FRAMING_PATTERNS["right"]:
        if re.search(pattern, text):
            right_score += weight
            notes.append(f"[보수] {note}")

    total = left_score + right_score
    if total == 0:
        return 0.0, notes

    framing_bias = (right_score - left_score) / total
    return framing_bias, notes


def analyze_tone_heuristic(text: str) -> ToneAnalysis:
    """Tone/objectivity analysis (heuristic)"""
    if not text:
        return ToneAnalysis(
            objectivity_score=0.5, emotional_language=0.0, loaded_words_count=0
        )

    loaded_count = 0
    examples = []

    # Count loaded words
    for direction, words in LOADED_WORDS.items():
        for word in words:
            count = text.count(word)
            if count > 0:
                loaded_count += count
                examples.append(word)

    # Emotional expression ratio estimation
    emotional_score = min(loaded_count / 10, 1.0)
    objectivity_score = 1.0 - emotional_score

    return ToneAnalysis(
        objectivity_score=round(objectivity_score, 3),
        emotional_language=round(emotional_score, 3),
        loaded_words_count=loaded_count,
        examples=examples[:5] if examples else None,
    )


def score_to_label(score: float) -> tuple[str, str]:
    """Convert bias score to label"""
    if score <= -0.6:
        return "far_left", "progressive"
    elif score <= -0.3:
        return "left", "progressive"
    elif score <= -0.1:
        return "center_left", "moderate"
    elif score <= 0.1:
        return "center", "moderate"
    elif score <= 0.3:
        return "center_right", "moderate"
    elif score <= 0.6:
        return "right", "conservative"
    else:
        return "far_right", "conservative"


def analyze_bias_heuristic(
    text: str,
    source: Optional[str] = None,
    include_source_bias: bool = True,
    include_framing: bool = True,
) -> BiasResult:
    """Full heuristic bias analysis"""
    if not text or not text.strip():
        return BiasResult(
            overall_bias_score=0.0,
            bias_label="center",
            confidence=0.0,
            political_lean="unknown",
            distribution={"left": 0.33, "center": 0.34, "right": 0.33},
            explanations=["분석할 텍스트 없음"],
            analysis_method="heuristic",
        )

    explanations = []

    # 1. Source bias
    source_bias = get_source_bias(source) if include_source_bias else SourceBias()
    source_score = 0.0
    if source_bias.known_lean and source and include_source_bias:
        for name, info in SOURCE_BIAS_MAP.items():
            if name in source:
                source_score = info["score"]
                explanations.append(f"언론사 성향: {name} ({source_bias.known_lean})")
                break

    # 2. Keyword-based bias
    keyword_score, indicators = analyze_keyword_bias_heuristic(text)
    if indicators:
        explanations.append(f"편향 키워드 {len(indicators)}개 발견")

    # 3. Framing analysis
    framing_score, framing_notes = (0.0, [])
    if include_framing:
        framing_score, framing_notes = analyze_framing_heuristic(text)
        if framing_notes:
            explanations.append(f"프레이밍 패턴 {len(framing_notes)}개 발견")

    # 4. Tone analysis
    tone_analysis = analyze_tone_heuristic(text)
    if tone_analysis.loaded_words_count > 0:
        explanations.append(f"감정적 표현 {tone_analysis.loaded_words_count}개 발견")

    # 5. Combined score (weighted average)
    # Source 30%, Keywords 40%, Framing 30%
    weights = {"source": 0.3, "keyword": 0.4, "framing": 0.3}
    overall_score = (
        source_score * weights["source"]
        + keyword_score * weights["keyword"]
        + framing_score * weights["framing"]
    )
    overall_score = max(-1.0, min(1.0, overall_score))

    # 6. Determine label
    bias_label, political_lean = score_to_label(overall_score)

    # 7. Calculate confidence
    evidence_count = len(indicators) + len(framing_notes)
    base_confidence = 0.3 if source_score != 0 else 0.2
    confidence = min(base_confidence + evidence_count * 0.08, 0.9)

    # 8. Calculate distribution
    if overall_score < 0:
        left_ratio = abs(overall_score) * 0.5 + 0.25
        right_ratio = 0.25 - abs(overall_score) * 0.15
    elif overall_score > 0:
        right_ratio = overall_score * 0.5 + 0.25
        left_ratio = 0.25 - overall_score * 0.15
    else:
        left_ratio = 0.25
        right_ratio = 0.25
    center_ratio = 1.0 - left_ratio - right_ratio

    distribution = {
        "left": round(max(0, left_ratio), 3),
        "center": round(max(0, center_ratio), 3),
        "right": round(max(0, right_ratio), 3),
    }

    explanations.append(f"종합 편향 점수: {overall_score:.2f} (-1=진보, 1=보수)")

    return BiasResult(
        overall_bias_score=round(overall_score, 4),
        bias_label=bias_label,
        confidence=round(confidence, 3),
        political_lean=political_lean,
        distribution=distribution,
        indicators=indicators if indicators else None,
        tone_analysis=tone_analysis,
        source_bias=source_bias if include_source_bias else None,
        framing_notes=framing_notes if framing_notes else None,
        explanations=explanations,
        analysis_method="heuristic",
    )


# ========== ML-based Bias Analysis ==========


def analyze_bias_ml(
    text: str,
    source: Optional[str] = None,
    include_source_bias: bool = True,
    include_framing: bool = True,
) -> BiasResult:
    """ML-based bias analysis"""
    models = get_ml_models()

    if not models.get("loaded"):
        logger.warning("ML models not loaded, falling back to heuristic")
        return analyze_bias_heuristic(
            text, source, include_source_bias, include_framing
        )

    try:
        import torch

        device = models.get("device", "cpu")
        explanations = []
        ml_score = 0.0
        ml_confidence = 0.5

        # 1. Try zero-shot classification for political stance
        if "zero_shot_pipeline" in models:
            try:
                candidate_labels = ["진보적", "중도", "보수적"]
                result = models["zero_shot_pipeline"](
                    text[:512],
                    candidate_labels,
                    hypothesis_template="이 기사는 {} 관점으로 작성되었습니다.",
                )

                label_scores = dict(zip(result["labels"], result["scores"]))
                progressive_prob = label_scores.get("진보적", 0.33)
                center_prob = label_scores.get("중도", 0.34)
                conservative_prob = label_scores.get("보수적", 0.33)

                # Calculate bias score from zero-shot
                ml_score = conservative_prob - progressive_prob
                ml_confidence = max(result["scores"])

                explanations.append(
                    f"Zero-shot 분류: 진보 {progressive_prob:.1%}, 중도 {center_prob:.1%}, 보수 {conservative_prob:.1%}"
                )

            except Exception as e:
                logger.warning(f"Zero-shot classification failed: {e}")

        # 2. Use stance pipeline as fallback/supplement
        elif "stance_pipeline" in models:
            try:
                pipeline_result = models["stance_pipeline"](text[:512])

                if isinstance(pipeline_result, list):
                    pipeline_result = pipeline_result[0]

                # Map sentiment to stance (proxy)
                label = pipeline_result.get("label", "").upper()
                score = pipeline_result.get("score", 0.5)

                # Positive sentiment often correlates with pro-status-quo (center-right)
                # Negative sentiment often correlates with criticism (can be either side)
                if "POSITIVE" in label or "긍정" in label:
                    ml_score = 0.1 * score  # Slight center-right
                elif "NEGATIVE" in label or "부정" in label:
                    ml_score = 0.0  # Neutral for negative (needs more context)
                else:
                    ml_score = 0.0

                ml_confidence = score * 0.5  # Lower confidence since it's a proxy
                explanations.append(f"감정 기반 추정 (신뢰도: {ml_confidence:.1%})")

            except Exception as e:
                logger.warning(f"Stance pipeline failed: {e}")

        # 3. Combine ML with heuristic for better results
        heuristic_result = analyze_bias_heuristic(
            text, source, include_source_bias, include_framing
        )

        # Weighted combination: ML 40%, Heuristic 60% (heuristic is more reliable for political bias)
        combined_score = ml_score * 0.4 + heuristic_result.overall_bias_score * 0.6
        combined_score = max(-1.0, min(1.0, combined_score))

        combined_confidence = ml_confidence * 0.4 + heuristic_result.confidence * 0.6

        # Determine label
        bias_label, political_lean = score_to_label(combined_score)

        # Calculate distribution
        if combined_score < 0:
            left_ratio = abs(combined_score) * 0.5 + 0.25
            right_ratio = 0.25 - abs(combined_score) * 0.15
        elif combined_score > 0:
            right_ratio = combined_score * 0.5 + 0.25
            left_ratio = 0.25 - combined_score * 0.15
        else:
            left_ratio = 0.25
            right_ratio = 0.25
        center_ratio = 1.0 - left_ratio - right_ratio

        distribution = {
            "left": round(max(0, left_ratio), 3),
            "center": round(max(0, center_ratio), 3),
            "right": round(max(0, right_ratio), 3),
        }

        # Merge explanations
        all_explanations = explanations + (heuristic_result.explanations or [])
        all_explanations.append(
            f"종합 편향 점수: {combined_score:.2f} (-1=진보, 1=보수)"
        )

        return BiasResult(
            overall_bias_score=round(combined_score, 4),
            bias_label=bias_label,
            confidence=round(combined_confidence, 3),
            political_lean=political_lean,
            distribution=distribution,
            indicators=heuristic_result.indicators,
            tone_analysis=heuristic_result.tone_analysis,
            source_bias=heuristic_result.source_bias,
            framing_notes=heuristic_result.framing_notes,
            explanations=all_explanations,
            analysis_method="hybrid",  # ML + heuristic
        )

    except Exception as e:
        logger.error(f"ML bias analysis failed: {e}", exc_info=True)
        result = analyze_bias_heuristic(
            text, source, include_source_bias, include_framing
        )
        result.explanations = (result.explanations or []) + [
            f"ML 분석 실패, 휴리스틱 폴백: {str(e)[:50]}"
        ]
        return result


def analyze_bias(
    text: str,
    source: Optional[str] = None,
    use_ml: bool = True,
    include_source_bias: bool = True,
    include_framing: bool = True,
) -> BiasResult:
    """Main bias analysis function"""
    if not text or not text.strip():
        return BiasResult(
            overall_bias_score=0.0,
            bias_label="center",
            confidence=0.0,
            political_lean="unknown",
            distribution={"left": 0.33, "center": 0.34, "right": 0.33},
            explanations=["분석할 텍스트 없음"],
            analysis_method="none",
        )

    if use_ml:
        return analyze_bias_ml(text, source, include_source_bias, include_framing)
    else:
        return analyze_bias_heuristic(
            text, source, include_source_bias, include_framing
        )


# ========== API Endpoints ==========


@app.get("/health")
async def health_check():
    """Health check endpoint"""
    models = get_ml_models()
    ml_status = "loaded" if models.get("loaded") else "heuristic_mode"

    return {
        "status": "healthy",
        "service": "bias-addon",
        "version": "2.0.0",
        "ml_status": ml_status,
        "warmup_complete": _model_warmup_complete,
        "warmup_error": _model_warmup_error,
        "device": models.get("device", "cpu"),
        "models": {
            "zero_shot_pipeline": "zero_shot_pipeline" in models,
            "stance_pipeline": "stance_pipeline" in models,
            "base_model": "base_model" in models,
        },
    }


@app.get("/ready")
async def readiness_check():
    """Readiness check - only returns healthy when models are warmed up"""
    if not _model_warmup_complete:
        return {"status": "warming_up", "ready": False}

    models = get_ml_models()
    return {
        "status": "ready",
        "ready": True,
        "ml_enabled": models.get("loaded", False),
        "warmup_error": _model_warmup_error,
    }


@app.get("/models")
async def get_model_info():
    """Get information about loaded models"""
    models = get_ml_models()

    return {
        "loaded": models.get("loaded", False),
        "device": models.get("device", "cpu"),
        "available_models": [k for k in models.keys() if k not in ["loaded", "device"]],
        "bias_model": os.getenv(
            "BIAS_MODEL", "monologg/koelectra-base-v3-discriminator"
        ),
        "zero_shot_model": os.getenv(
            "ZERO_SHOT_MODEL", "MoritzLaworski/korean-text-classification-zero-shot"
        ),
    }


@app.get("/sources")
async def get_source_database():
    """Get the source bias database"""
    return {
        "sources": [
            {
                "name": name,
                "lean": info["lean"],
                "score": info["score"],
                "reliability": info.get("reliability", 0.5),
            }
            for name, info in SOURCE_BIAS_MAP.items()
        ],
        "total": len(SOURCE_BIAS_MAP),
    }


@app.post("/analyze", response_model=AddonResponse)
async def analyze(request: AddonRequest):
    """
    Article bias analysis endpoint.
    Called by NewsInsight Orchestrator.
    """
    start_time = time.time()
    models = get_ml_models()

    try:
        # Validate input
        if not request.article:
            raise ValueError("article is required")

        # Prepare text for analysis
        text = ""
        if request.article.title:
            text += request.article.title + " "
        if request.article.content:
            text += request.article.content

        # Get options
        options = request.options or ExecutionOptions()
        use_ml = options.use_ml if options.use_ml is not None else True
        include_source_bias = (
            options.include_source_bias
            if options.include_source_bias is not None
            else True
        )
        include_framing = (
            options.include_framing if options.include_framing is not None else True
        )

        # Run bias analysis
        bias_result = analyze_bias(
            text,
            source=request.article.source,
            use_ml=use_ml,
            include_source_bias=include_source_bias,
            include_framing=include_framing,
        )

        # Build response
        latency_ms = int((time.time() - start_time) * 1000)

        model_name = (
            "koelectra-bias-hybrid-v2" if models.get("loaded") else "bias-heuristic-v1"
        )

        # Track Prometheus metrics
        if PROMETHEUS_AVAILABLE:
            REQUEST_COUNT.labels(endpoint="analyze", status="success").inc()
            REQUEST_LATENCY.labels(endpoint="analyze").observe(time.time() - start_time)
            ANALYSIS_COUNT.labels(
                direction=bias_result.political_lean,
                mode="ml" if models.get("loaded") and use_ml else "heuristic",
            ).inc()

        return AddonResponse(
            request_id=request.request_id,
            addon_id=request.addon_id,
            status="success",
            results=AnalysisResults(
                bias=bias_result,
                raw={
                    "text_length": len(text),
                    "source": request.article.source,
                    "ml_available": models.get("loaded", False),
                    "analysis_method": bias_result.analysis_method,
                },
            ),
            meta=ResponseMeta(
                model_version="2.0.0",
                model_name=model_name,
                latency_ms=latency_ms,
                processed_at=time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
                device=models.get("device", "cpu"),
            ),
        )

    except ValueError as e:
        latency_ms = int((time.time() - start_time) * 1000)

        # Track error metrics
        if PROMETHEUS_AVAILABLE:
            REQUEST_COUNT.labels(endpoint="analyze", status="error").inc()
            REQUEST_LATENCY.labels(endpoint="analyze").observe(time.time() - start_time)
            ERROR_COUNT.labels(error_type="ValidationError").inc()

        return AddonResponse(
            request_id=request.request_id,
            addon_id=request.addon_id,
            status="error",
            error=ErrorInfo(code="VALIDATION_ERROR", message=str(e)),
            meta=ResponseMeta(
                model_version="2.0.0",
                model_name="bias-addon",
                latency_ms=latency_ms,
                processed_at=time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
                device=models.get("device", "cpu"),
            ),
        )
    except Exception as e:
        logger.error(f"Analysis error: {e}", exc_info=True)
        latency_ms = int((time.time() - start_time) * 1000)

        # Track error metrics
        if PROMETHEUS_AVAILABLE:
            REQUEST_COUNT.labels(endpoint="analyze", status="error").inc()
            REQUEST_LATENCY.labels(endpoint="analyze").observe(time.time() - start_time)
            ERROR_COUNT.labels(error_type=type(e).__name__).inc()

        return AddonResponse(
            request_id=request.request_id,
            addon_id=request.addon_id,
            status="error",
            error=ErrorInfo(
                code="ANALYSIS_ERROR",
                message=str(e),
                details="Error occurred during bias analysis",
            ),
            meta=ResponseMeta(
                model_version="2.0.0",
                model_name="bias-addon",
                latency_ms=latency_ms,
                processed_at=time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
                device=models.get("device", "cpu"),
            ),
        )


@app.post("/batch", response_model=List[AddonResponse])
async def analyze_batch(requests: List[AddonRequest]):
    """Batch analyze multiple articles"""
    results = []
    for req in requests:
        result = await analyze(req)
        results.append(result)
    return results


@app.post("/analyze/simple")
async def analyze_simple(text: str, source: Optional[str] = None):
    """
    Simple text bias analysis endpoint.
    For quick testing without full request structure.
    """
    start_time = time.time()

    result = analyze_bias(text, source=source)
    latency_ms = int((time.time() - start_time) * 1000)

    return {
        "text": text[:100] + "..." if len(text) > 100 else text,
        "source": source,
        "bias": result.model_dump(),
        "latency_ms": latency_ms,
    }


class SourceAnalysisRequest(BaseModel):
    """Request model for source-only analysis"""

    source: str


@app.post("/analyze/source")
async def analyze_source_only(request: SourceAnalysisRequest):
    """
    Analyze bias based on source name only.
    Quick lookup without content analysis.

    Request body:
        {"source": "조선일보"}
    """
    source = request.source
    source_bias = get_source_bias(source)

    if source_bias.known_lean == "unknown":
        return {
            "source": source,
            "found": False,
            "message": "Source not found in database",
        }

    # Get score from database
    score = 0.0
    for name, info in SOURCE_BIAS_MAP.items():
        if name in source:
            score = info["score"]
            break

    bias_label, political_lean = score_to_label(score)

    return {
        "source": source,
        "found": True,
        "bias": {
            "score": score,
            "label": bias_label,
            "political_lean": political_lean,
            "known_lean": source_bias.known_lean,
            "reliability": source_bias.reliability_score,
        },
    }


# ========== Entry Point ==========

if __name__ == "__main__":
    import uvicorn

    port = int(os.getenv("PORT", "8102"))
    host = os.getenv("HOST", "0.0.0.0")

    uvicorn.run(app, host=host, port=port)

```

---

## backend/ml-addons/docker-compose.yml

```yml
# ML Add-ons Docker Compose
# 모든 ML Add-on 서비스를 함께 실행합니다.

version: '3.8'

services:
  # 감정 분석 Add-on
  sentiment-addon:
    build:
      context: ./sentiment-addon
      dockerfile: Dockerfile
    container_name: newsinsight-sentiment-addon
    ports:
      - "8100:8100"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8100/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - ml-addons-network
    labels:
      - "addon.type=sentiment"
      - "addon.version=1.0.0"

  # 팩트체크 Add-on (ML Enhanced)
  factcheck-addon:
    build:
      context: ./factcheck-addon
      dockerfile: Dockerfile
      args:
        ENABLE_GPU: ${ENABLE_GPU:-false}
        PRELOAD_MODELS: ${PRELOAD_MODELS:-false}
    container_name: newsinsight-factcheck-addon
    ports:
      - "8101:8101"
    restart: unless-stopped
    environment:
      # ML Model Configuration
      - ENABLE_ML_MODELS=${ENABLE_ML_MODELS:-true}
      - CLAIM_MODEL=${CLAIM_MODEL:-monologg/koelectra-base-v3-discriminator}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2}
      - NER_MODEL=${NER_MODEL:-klue/bert-base}
      - SENTIMENT_MODEL=${SENTIMENT_MODEL:-klue/roberta-base}
      # External API Keys (optional)
      - GOOGLE_FACTCHECK_API_KEY=${GOOGLE_FACTCHECK_API_KEY:-}
      - SNU_FACTCHECK_API_URL=${SNU_FACTCHECK_API_URL:-}
      # Cache Configuration
      - HF_HOME=/app/.cache/huggingface
      - TRANSFORMERS_CACHE=/app/.cache/huggingface/transformers
      - TORCH_HOME=/app/.cache/torch
    volumes:
      # Persist model cache to speed up restarts
      - factcheck-model-cache:/app/.cache
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8101/health"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 120s  # Longer start period for model loading
    networks:
      - ml-addons-network
    labels:
      - "addon.type=factcheck"
      - "addon.version=2.0.0"
      - "addon.ml_enabled=true"
    deploy:
      resources:
        limits:
          memory: 4G  # ML models require more memory
        reservations:
          memory: 2G

  # 편향도 분석 Add-on
  bias-addon:
    build:
      context: ./bias-addon
      dockerfile: Dockerfile
    container_name: newsinsight-bias-addon
    ports:
      - "8102:8102"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8102/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - ml-addons-network
    labels:
      - "addon.type=bias"
      - "addon.version=1.0.0"

volumes:
  factcheck-model-cache:
    name: newsinsight-factcheck-models

networks:
  ml-addons-network:
    driver: bridge
    name: newsinsight-ml-addons

```

---

## backend/ml-addons/factcheck-addon/addon_server.py

```py
"""
ML Add-on Server: Fact-Check Analysis with ML Models

NewsInsight ML Add-on 시스템의 팩트체크 구현.
KoBERT/KoELECTRA 기반 ML 모델과 외부 팩트체크 API를 통합하여
뉴스 기사의 사실 검증 및 신뢰도 분석을 수행합니다.

Features:
- ML 기반 주장 추출 및 분류
- 의미론적 유사도 기반 교차 검증
- 외부 팩트체크 API 연동 (SNU, Google Fact Check)
- 신뢰도 점수 산출 세부 분석 제공
"""

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import Response
from pydantic import BaseModel, Field
from typing import Optional, Dict, List, Any, Tuple
from enum import Enum
import time
import re
import hashlib
import os
import logging
import asyncio
from functools import lru_cache
from contextlib import asynccontextmanager

# Prometheus metrics
try:
    from prometheus_client import (
        Counter,
        Histogram,
        Gauge,
        CONTENT_TYPE_LATEST,
        generate_latest,
    )

    PROMETHEUS_AVAILABLE = True
except ImportError:
    PROMETHEUS_AVAILABLE = False

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ML Model imports (lazy loading for faster startup)
_ml_models = {}
_model_loading = False


def get_ml_models():
    """Lazy load ML models on first use"""
    global _ml_models, _model_loading

    if _ml_models or _model_loading:
        return _ml_models

    _model_loading = True

    try:
        import torch
        from transformers import (
            AutoTokenizer,
            AutoModelForSequenceClassification,
            AutoModelForTokenClassification,
            pipeline,
        )
        from sentence_transformers import SentenceTransformer

        logger.info("Loading ML models...")

        # Device selection
        device = "cuda" if torch.cuda.is_available() else "cpu"
        logger.info(f"Using device: {device}")

        # 1. Claim Classification Model (KoELECTRA)
        claim_model_name = os.getenv(
            "CLAIM_MODEL", "monologg/koelectra-base-v3-discriminator"
        )
        try:
            _ml_models["claim_tokenizer"] = AutoTokenizer.from_pretrained(
                claim_model_name
            )
            _ml_models["claim_model"] = (
                AutoModelForSequenceClassification.from_pretrained(
                    claim_model_name,
                    num_labels=3,  # claim, non-claim, uncertain
                ).to(device)
            )
            _ml_models["claim_model"].eval()
            logger.info(f"Loaded claim model: {claim_model_name}")
        except Exception as e:
            logger.warning(f"Failed to load claim model: {e}")

        # 2. Sentence Transformer for Semantic Similarity
        embedding_model_name = os.getenv(
            "EMBEDDING_MODEL",
            "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        )
        try:
            _ml_models["sentence_transformer"] = SentenceTransformer(
                embedding_model_name
            )
            logger.info(f"Loaded embedding model: {embedding_model_name}")
        except Exception as e:
            logger.warning(f"Failed to load embedding model: {e}")

        # 3. NER for Entity Extraction (Korean)
        ner_model_name = os.getenv("NER_MODEL", "klue/bert-base")
        try:
            _ml_models["ner_pipeline"] = pipeline(
                "ner",
                model=ner_model_name,
                tokenizer=ner_model_name,
                aggregation_strategy="simple",
                device=0 if device == "cuda" else -1,
            )
            logger.info(f"Loaded NER model: {ner_model_name}")
        except Exception as e:
            logger.warning(f"Failed to load NER model: {e}")

        # 4. Sentiment for tone analysis
        sentiment_model_name = os.getenv("SENTIMENT_MODEL", "klue/roberta-base")
        try:
            _ml_models["sentiment_pipeline"] = pipeline(
                "sentiment-analysis",
                model=sentiment_model_name,
                tokenizer=sentiment_model_name,
                device=0 if device == "cuda" else -1,
            )
            logger.info(f"Loaded sentiment model: {sentiment_model_name}")
        except Exception as e:
            logger.warning(f"Failed to load sentiment model: {e}")

        _ml_models["device"] = device
        _ml_models["loaded"] = True
        logger.info("All ML models loaded successfully")

    except ImportError as e:
        logger.warning(f"ML libraries not available, using heuristic mode: {e}")
        _ml_models["loaded"] = False
    except Exception as e:
        logger.error(f"Error loading ML models: {e}")
        _ml_models["loaded"] = False

    _model_loading = False
    return _ml_models


# External API clients (lazy initialization)
_api_clients = {}


async def get_http_client():
    """Get async HTTP client"""
    global _api_clients

    if "http_client" not in _api_clients:
        try:
            import httpx

            _api_clients["http_client"] = httpx.AsyncClient(timeout=30.0)
        except ImportError:
            _api_clients["http_client"] = None

    return _api_clients.get("http_client")


# Model loading status for health checks
_model_warmup_complete = False
_model_warmup_error = None


async def _warmup_models():
    """Warm up models and track completion status"""
    global _model_warmup_complete, _model_warmup_error
    try:
        logger.info("Starting model warm-up...")
        start_time = time.time()

        # Load models synchronously in thread
        models = await asyncio.to_thread(get_ml_models)

        if models.get("loaded"):
            # Run a dummy inference to fully warm up the model
            if "claim_model" in models and "claim_tokenizer" in models:
                try:
                    dummy_text = "테스트 문장입니다."
                    tokenizer = models["claim_tokenizer"]
                    model = models["claim_model"]
                    inputs = tokenizer(
                        dummy_text, return_tensors="pt", truncation=True, max_length=128
                    )
                    if models.get("device") == "cuda":
                        inputs = {k: v.cuda() for k, v in inputs.items()}
                    with __import__("torch").no_grad():
                        _ = model(**inputs)
                    logger.info("Claim model warm-up inference complete")
                except Exception as e:
                    logger.warning(f"Claim model warm-up inference failed: {e}")

            elapsed = time.time() - start_time
            logger.info(f"Model warm-up completed in {elapsed:.2f}s")
            _model_warmup_complete = True
        else:
            logger.warning("Models not loaded, running in heuristic mode")
            _model_warmup_complete = True  # Still mark as complete for heuristic mode

    except Exception as e:
        logger.error(f"Model warm-up failed: {e}")
        _model_warmup_error = str(e)
        _model_warmup_complete = True  # Mark complete even on error to avoid blocking


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan handler"""
    # Startup
    logger.info("Factcheck addon starting...")

    # Preload models in background if ML is enabled
    if os.getenv("ENABLE_ML_MODELS", "true").lower() == "true":
        # Start warm-up task
        asyncio.create_task(_warmup_models())

    yield

    # Shutdown
    logger.info("Factcheck addon shutting down...")
    if "http_client" in _api_clients and _api_clients["http_client"]:
        await _api_clients["http_client"].aclose()


app = FastAPI(
    title="Fact-Check Analysis Add-on (ML Enhanced)",
    description="Korean news article fact-checking with ML models and external API integration",
    version="2.0.0",
    lifespan=lifespan,
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ========== Prometheus Metrics ==========

if PROMETHEUS_AVAILABLE:
    # Request metrics
    REQUEST_COUNT = Counter(
        "factcheck_requests_total",
        "Total number of factcheck requests",
        ["endpoint", "status"],
    )
    REQUEST_LATENCY = Histogram(
        "factcheck_request_latency_seconds",
        "Request latency in seconds",
        ["endpoint"],
        buckets=(0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0, 30.0, 60.0),
    )

    # Analysis metrics
    ANALYSIS_COUNT = Counter(
        "factcheck_analysis_total",
        "Total number of analyses performed",
        ["mode", "verdict"],
    )
    CLAIMS_EXTRACTED = Counter(
        "factcheck_claims_extracted_total", "Total number of claims extracted"
    )

    # Model metrics
    MODEL_LOADED = Gauge(
        "factcheck_model_loaded", "Whether ML models are loaded (1=yes, 0=no)"
    )
    MODEL_WARMUP_COMPLETE = Gauge(
        "factcheck_model_warmup_complete",
        "Whether model warm-up is complete (1=yes, 0=no)",
    )

    # Error metrics
    ERROR_COUNT = Counter(
        "factcheck_errors_total", "Total number of errors", ["error_type"]
    )

    @app.get("/metrics")
    async def metrics():
        """Prometheus metrics endpoint"""
        # Update model status gauges
        models = get_ml_models() if not _model_loading else {}
        MODEL_LOADED.set(1 if models.get("loaded") else 0)
        MODEL_WARMUP_COMPLETE.set(1 if _model_warmup_complete else 0)

        return Response(content=generate_latest(), media_type=CONTENT_TYPE_LATEST)

# ========== Enums and Models ==========


class AnalysisMode(str, Enum):
    HEURISTIC = "heuristic"
    ML_BASIC = "ml_basic"
    ML_FULL = "ml_full"
    EXTERNAL_API = "external_api"
    HYBRID = "hybrid"


class ClaimVerdict(str, Enum):
    VERIFIED = "verified"
    FALSE = "false"
    UNVERIFIED = "unverified"
    MISLEADING = "misleading"
    PARTIALLY_TRUE = "partially_true"


class CredibilityGrade(str, Enum):
    A = "A"
    B = "B"
    C = "C"
    D = "D"
    F = "F"


class ArticleInput(BaseModel):
    id: Optional[int] = None
    title: Optional[str] = None
    content: Optional[str] = None
    url: Optional[str] = None
    source: Optional[str] = None
    published_at: Optional[str] = None


class AnalysisContext(BaseModel):
    language: Optional[str] = "ko"
    country: Optional[str] = "KR"
    previous_results: Optional[Dict[str, Any]] = None


class ExecutionOptions(BaseModel):
    importance: Optional[str] = "batch"
    debug: Optional[bool] = False
    timeout_ms: Optional[int] = None
    analysis_mode: Optional[AnalysisMode] = AnalysisMode.HYBRID
    include_detailed_analytics: Optional[bool] = True


class AddonRequest(BaseModel):
    request_id: str
    addon_id: str
    task: str = "article_analysis"
    input_schema_version: str = "1.0"
    article: Optional[ArticleInput] = None
    context: Optional[AnalysisContext] = None
    options: Optional[ExecutionOptions] = None


# ========== Detailed Analytics Models ==========


class SourceAnalytics(BaseModel):
    source_name: Optional[str] = None
    is_trusted: bool = False
    trust_score: float = 0.0
    trust_level: str = "unknown"  # trusted, unknown, untrusted
    matched_trusted_source: Optional[str] = None
    reason: str = ""


class ClickbaitAnalytics(BaseModel):
    is_clickbait: bool = False
    score: float = 0.0
    detected_patterns: List[Dict[str, Any]] = []
    total_patterns_checked: int = 0


class MisinfoAnalytics(BaseModel):
    risk_score: float = 0.0
    risk_level: str = "low"  # low, medium, high
    detected_patterns: List[Dict[str, Any]] = []
    unverifiable_claim_count: int = 0


class ClaimAnalytics(BaseModel):
    claim_id: str
    claim_text: str
    verdict: str
    confidence: float
    ml_confidence: Optional[float] = None
    claim_indicator: Optional[str] = None
    analysis_method: str = "heuristic"
    entities: Optional[List[Dict[str, str]]] = None
    semantic_similarity_scores: Optional[List[Dict[str, float]]] = None
    supporting_factors: List[str] = []
    contradicting_factors: List[str] = []
    external_verification: Optional[Dict[str, Any]] = None


class ScoreBreakdown(BaseModel):
    source_weight: int = 30
    clickbait_weight: int = 20
    misinfo_weight: int = 20
    verification_weight: int = 30

    source_contribution: float = 0.0
    clickbait_contribution: float = 0.0
    misinfo_contribution: float = 0.0
    verification_contribution: float = 0.0

    total_score: float = 0.0
    grade: str = "C"


class DetailedAnalytics(BaseModel):
    """Detailed analytics for transparency"""

    source_analysis: SourceAnalytics
    clickbait_analysis: ClickbaitAnalytics
    misinfo_analysis: MisinfoAnalytics
    claim_analyses: List[ClaimAnalytics] = []
    score_breakdown: ScoreBreakdown

    analysis_mode: str = "heuristic"
    ml_models_used: List[str] = []
    external_apis_used: List[str] = []
    processing_time_ms: int = 0
    analyzed_at: str = ""


class ClaimResult(BaseModel):
    claim: str
    verdict: str
    confidence: float
    evidence: Optional[str] = None
    source_url: Optional[str] = None
    ml_analysis: Optional[Dict[str, Any]] = None


class FactCheckResult(BaseModel):
    overall_credibility: float
    credibility_grade: str
    verdict: str
    claims_analyzed: int
    verified_claims: int
    false_claims: int
    unverified_claims: int
    claims: Optional[List[ClaimResult]] = None
    risk_flags: Optional[List[str]] = None
    explanations: Optional[List[str]] = None
    detailed_analytics: Optional[DetailedAnalytics] = None


class AnalysisResults(BaseModel):
    factcheck: Optional[FactCheckResult] = None
    raw: Optional[Dict[str, Any]] = None


class ResponseMeta(BaseModel):
    model_version: str
    latency_ms: int
    processed_at: str
    ml_enabled: bool = False
    models_loaded: List[str] = []


class ErrorInfo(BaseModel):
    code: str
    message: str
    details: Optional[str] = None


class AddonResponse(BaseModel):
    request_id: str
    addon_id: str
    status: str
    output_schema_version: str = "1.0"
    results: Optional[AnalysisResults] = None
    error: Optional[ErrorInfo] = None
    meta: Optional[ResponseMeta] = None


# ========== Constants ==========

TRUSTED_SOURCES = {
    # Tier 1: Wire services, public broadcasting (95%)
    "연합뉴스": 0.95,
    "KBS": 0.90,
    "MBC": 0.85,
    "SBS": 0.85,
    "YTN": 0.85,
    "EBS": 0.85,
    # Tier 2: Major newspapers (80%)
    "조선일보": 0.80,
    "중앙일보": 0.80,
    "동아일보": 0.80,
    "한겨레": 0.80,
    "경향신문": 0.80,
    "한국일보": 0.80,
    # Tier 3: Business newspapers (80%)
    "매일경제": 0.80,
    "한국경제": 0.80,
    "서울경제": 0.75,
    "머니투데이": 0.75,
    "이데일리": 0.75,
    # Tier 4: Cable news (75-85%)
    "JTBC": 0.85,
    "TV조선": 0.75,
    "채널A": 0.75,
    "MBN": 0.75,
    # Tier 5: Online news (70-75%)
    "뉴시스": 0.75,
    "뉴스1": 0.75,
    "오마이뉴스": 0.70,
    "프레시안": 0.70,
}

CLICKBAIT_PATTERNS = [
    {"pattern": r"충격[!]*", "severity": "high", "label": "충격"},
    {"pattern": r"경악[!]*", "severity": "high", "label": "경악"},
    {"pattern": r"대박[!]*", "severity": "medium", "label": "대박"},
    {"pattern": r"헉[!]*", "severity": "low", "label": "헉"},
    {"pattern": r"알고\s*보니", "severity": "medium", "label": "알고보니"},
    {"pattern": r"결국[.]*$", "severity": "low", "label": "결국"},
    {"pattern": r"드디어[!]*", "severity": "low", "label": "드디어"},
    {"pattern": r"\.\.\.$", "severity": "low", "label": "..."},
    {"pattern": r"\?\?\?+", "severity": "medium", "label": "???"},
    {"pattern": r"!!!+", "severity": "medium", "label": "!!!"},
    {"pattern": r"속보[!:]*", "severity": "low", "label": "속보"},
    {"pattern": r"단독[!:]*", "severity": "low", "label": "단독"},
    {"pattern": r"긴급[!:]*", "severity": "medium", "label": "긴급"},
]

MISINFORMATION_PATTERNS = [
    {"pattern": r"정부가\s*숨기", "type": "conspiracy", "severity": "high"},
    {"pattern": r"언론이\s*보도하지\s*않는", "type": "conspiracy", "severity": "high"},
    {"pattern": r"비밀리에", "type": "conspiracy", "severity": "medium"},
    {"pattern": r"충격\s*진실", "type": "sensational", "severity": "high"},
    {"pattern": r"알려지지\s*않은\s*진실", "type": "conspiracy", "severity": "high"},
]

UNVERIFIABLE_PATTERNS = [
    {"pattern": r"최초", "type": "absolute", "severity": "low"},
    {"pattern": r"유일", "type": "absolute", "severity": "low"},
    {"pattern": r"최고", "type": "absolute", "severity": "low"},
    {"pattern": r"최대", "type": "absolute", "severity": "low"},
    {"pattern": r"100%", "type": "absolute", "severity": "medium"},
    {"pattern": r"모든\s*사람", "type": "universal", "severity": "medium"},
    {"pattern": r"아무도", "type": "universal", "severity": "medium"},
    {"pattern": r"절대", "type": "absolute", "severity": "medium"},
    {"pattern": r"반드시", "type": "absolute", "severity": "low"},
]

CLAIM_INDICATORS = [
    "라고 밝혔다",
    "라고 주장했다",
    "라고 전했다",
    "에 따르면",
    "것으로 알려졌다",
    "것으로 확인됐다",
    "것으로 보인다",
    "할 전망이다",
    "할 예정이다",
    "관계자는",
    "전문가는",
    "소식통에 따르면",
]

# Korean stopwords for keyword extraction
KOREAN_STOPWORDS = {
    "은",
    "는",
    "이",
    "가",
    "을",
    "를",
    "의",
    "에",
    "에서",
    "로",
    "으로",
    "와",
    "과",
    "도",
    "만",
    "부터",
    "까지",
    "에게",
    "한테",
    "께",
    "이다",
    "하다",
    "있다",
    "없다",
    "되다",
    "않다",
    "그",
    "저",
    "이것",
    "그것",
    "저것",
    "여기",
    "거기",
    "저기",
    "뭐",
    "어디",
    "언제",
    "어떻게",
    "왜",
    "누구",
    "아주",
    "매우",
    "정말",
    "너무",
    "조금",
    "약간",
    "그리고",
    "그러나",
    "하지만",
    "그래서",
    "때문에",
    "것",
    "수",
    "등",
    "들",
    "및",
    "더",
    "덜",
    "대해",
    "대한",
    "관련",
    "관한",
}

# English stopwords
ENGLISH_STOPWORDS = {
    "the",
    "a",
    "an",
    "and",
    "or",
    "but",
    "in",
    "on",
    "at",
    "to",
    "for",
    "of",
    "with",
    "by",
    "from",
    "is",
    "are",
    "was",
    "were",
    "be",
    "been",
    "being",
    "have",
    "has",
    "had",
    "do",
    "does",
    "did",
    "will",
    "would",
    "this",
    "that",
    "these",
    "those",
    "it",
    "its",
    "what",
    "which",
    "who",
}

# Intent patterns for factcheck
FACTCHECK_INTENT_PATTERNS = {
    "fact_claim": [
        "사실",
        "진짜",
        "실제로",
        "정말",
        "맞는",
        "틀린",
        "fact",
        "true",
        "false",
    ],
    "opinion": ["생각", "의견", "판단", "보인다", "것 같다", "추측"],
    "quote": ["라고", "밝혔다", "전했다", "말했다", "주장했다"],
    "data": ["수치", "통계", "퍼센트", "%", "건", "명", "원"],
}


class IntentAnalyzer:
    """
    Enhanced intent analyzer for factcheck.
    Extracts keywords, identifies primary claims, and generates search strategies.
    """

    def __init__(self):
        self.stopwords = KOREAN_STOPWORDS | ENGLISH_STOPWORDS

    def detect_language(self, text: str) -> str:
        """Detect language based on character composition."""
        if not text:
            return "ko"

        korean_count = len(re.findall(r"[가-힣]", text))
        english_count = len(re.findall(r"[a-zA-Z]", text))

        total = korean_count + english_count
        if total == 0:
            return "ko"

        return "ko" if korean_count / total > 0.3 else "en"

    def extract_keywords(self, text: str) -> List[str]:
        """Extract meaningful keywords from text."""
        if not text:
            return []

        # Tokenize
        words = re.findall(r"[\w가-힣]+", text.lower())

        # Filter stopwords and short words
        keywords = []
        for word in words:
            if word in self.stopwords:
                continue
            if len(word) < 2:
                continue
            if word.isdigit():
                continue
            keywords.append(word)

        # Deduplicate while preserving order
        seen = set()
        unique_keywords = []
        for kw in keywords:
            if kw not in seen:
                seen.add(kw)
                unique_keywords.append(kw)

        return unique_keywords[:10]

    def identify_primary_keyword(self, keywords: List[str], original_text: str) -> str:
        """Identify the most important keyword."""
        if not keywords:
            words = original_text.split()
            return words[0] if words else ""

        # Score-based selection
        scores = {}
        for keyword in keywords:
            score = 0.0

            # Length weight
            score += min(len(keyword) / 10.0, 1.0) * 0.3

            # Position weight
            pos = original_text.lower().find(keyword.lower())
            if pos >= 0:
                score += (1.0 - pos / len(original_text)) * 0.3

            # Entity patterns (Korean compound nouns)
            if re.match(r".*[가-힣]+(기업|회사|정책|사건|발표|결과)$", keyword):
                score += 0.3

            scores[keyword] = score

        return max(scores.items(), key=lambda x: x[1])[0] if scores else keywords[0]

    def detect_claim_intent(self, text: str) -> Dict[str, Any]:
        """Detect the intent type of a potential claim."""
        text_lower = text.lower()

        intent_scores = {intent: 0 for intent in FACTCHECK_INTENT_PATTERNS}

        for intent, patterns in FACTCHECK_INTENT_PATTERNS.items():
            for pattern in patterns:
                if pattern.lower() in text_lower:
                    intent_scores[intent] += 1

        # Determine primary intent
        max_intent = max(intent_scores.items(), key=lambda x: x[1])

        return {
            "primary_intent": max_intent[0] if max_intent[1] > 0 else "general",
            "intent_scores": intent_scores,
            "is_verifiable": intent_scores["fact_claim"] > 0
            or intent_scores["data"] > 0,
        }

    def generate_search_queries(self, claim: str) -> List[Dict[str, Any]]:
        """Generate multiple search queries for claim verification."""
        keywords = self.extract_keywords(claim)
        primary_keyword = self.identify_primary_keyword(keywords, claim)

        queries = []

        # Strategy 1: Full claim
        queries.append(
            {
                "query": claim[:100],
                "strategy": "full_query",
                "weight": 1.0,
                "description": "원본 주장으로 검색",
            }
        )

        # Strategy 2: All keywords
        if len(keywords) > 1:
            queries.append(
                {
                    "query": " ".join(keywords),
                    "strategy": "keywords_and",
                    "weight": 0.9,
                    "description": "모든 키워드로 검색",
                }
            )

        # Strategy 3: Primary keyword + fact check terms
        queries.append(
            {
                "query": f"{primary_keyword} 팩트체크",
                "strategy": "primary_factcheck",
                "weight": 0.85,
                "description": "주요 키워드 + 팩트체크",
            }
        )

        # Strategy 4: Primary keyword + verification
        queries.append(
            {
                "query": f"{primary_keyword} 사실 확인",
                "strategy": "primary_verify",
                "weight": 0.8,
                "description": "주요 키워드 + 사실 확인",
            }
        )

        # Strategy 5: Keywords OR (broader)
        if len(keywords) > 1:
            or_query = " OR ".join(keywords[:5])
            queries.append(
                {
                    "query": or_query,
                    "strategy": "keywords_or",
                    "weight": 0.7,
                    "description": "키워드 OR 검색 (넓은 검색)",
                }
            )

        return queries

    def analyze(self, text: str) -> Dict[str, Any]:
        """Full intent analysis of text."""
        language = self.detect_language(text)
        keywords = self.extract_keywords(text)
        primary_keyword = self.identify_primary_keyword(keywords, text)
        claim_intent = self.detect_claim_intent(text)
        search_queries = self.generate_search_queries(text)

        return {
            "original_text": text,
            "language": language,
            "keywords": keywords,
            "primary_keyword": primary_keyword,
            "intent": claim_intent,
            "search_queries": search_queries,
            "fallback_strategies": [q["query"] for q in search_queries],
        }


# Global intent analyzer instance
_intent_analyzer = IntentAnalyzer()


# ========== Analysis Functions ==========


def analyze_source(source: Optional[str]) -> SourceAnalytics:
    """Analyze source credibility"""
    if not source:
        return SourceAnalytics(
            source_name=None,
            is_trusted=False,
            trust_score=0.3,
            trust_level="untrusted",
            reason="출처 정보가 제공되지 않았습니다.",
        )

    # Check against trusted sources
    for trusted_name, score in TRUSTED_SOURCES.items():
        if trusted_name in source:
            return SourceAnalytics(
                source_name=source,
                is_trusted=True,
                trust_score=score,
                trust_level="trusted",
                matched_trusted_source=trusted_name,
                reason=f"{trusted_name}은(는) 신뢰할 수 있는 언론사입니다.",
            )

    return SourceAnalytics(
        source_name=source,
        is_trusted=False,
        trust_score=0.5,
        trust_level="unknown",
        reason="신뢰 매체 목록에 없는 출처입니다. 추가 확인이 필요합니다.",
    )


def analyze_clickbait(title: Optional[str]) -> ClickbaitAnalytics:
    """Detect clickbait patterns in title"""
    if not title:
        return ClickbaitAnalytics(
            is_clickbait=False,
            score=0.0,
            detected_patterns=[],
            total_patterns_checked=len(CLICKBAIT_PATTERNS),
        )

    detected = []
    for pattern_info in CLICKBAIT_PATTERNS:
        matches = re.findall(pattern_info["pattern"], title, re.IGNORECASE)
        if matches:
            detected.append(
                {
                    "pattern": pattern_info["label"],
                    "matched_text": matches[0],
                    "severity": pattern_info["severity"],
                }
            )

    # Calculate score based on severity
    severity_weights = {"low": 0.1, "medium": 0.2, "high": 0.3}
    score = sum(severity_weights.get(p["severity"], 0.1) for p in detected)
    score = min(score, 1.0)

    is_clickbait = score > 0.3 or any(p["severity"] == "high" for p in detected)

    return ClickbaitAnalytics(
        is_clickbait=is_clickbait,
        score=score,
        detected_patterns=detected,
        total_patterns_checked=len(CLICKBAIT_PATTERNS),
    )


def analyze_misinformation(text: str) -> MisinfoAnalytics:
    """Detect misinformation risk patterns"""
    if not text:
        return MisinfoAnalytics()

    detected = []

    # Check misinformation patterns
    for pattern_info in MISINFORMATION_PATTERNS:
        matches = re.findall(pattern_info["pattern"], text, re.IGNORECASE)
        if matches:
            detected.append(
                {
                    "pattern": pattern_info["pattern"],
                    "matched_text": matches[0],
                    "type": "misinformation",
                    "category": pattern_info["type"],
                    "severity": pattern_info["severity"],
                }
            )

    # Check unverifiable patterns
    unverifiable_count = 0
    for pattern_info in UNVERIFIABLE_PATTERNS:
        matches = re.findall(pattern_info["pattern"], text, re.IGNORECASE)
        if matches:
            unverifiable_count += len(matches)
            detected.append(
                {
                    "pattern": pattern_info["pattern"],
                    "matched_text": matches[0],
                    "type": "unverifiable",
                    "category": pattern_info["type"],
                    "severity": pattern_info["severity"],
                }
            )

    # Calculate risk score
    severity_weights = {"low": 0.1, "medium": 0.2, "high": 0.35}
    misinfo_score = sum(
        severity_weights.get(p["severity"], 0.1)
        for p in detected
        if p["type"] == "misinformation"
    )
    unverifiable_score = sum(
        severity_weights.get(p["severity"], 0.1) * 0.5
        for p in detected
        if p["type"] == "unverifiable"
    )

    total_score = min(misinfo_score + unverifiable_score, 1.0)

    risk_level = (
        "high" if total_score > 0.5 else "medium" if total_score > 0.2 else "low"
    )

    return MisinfoAnalytics(
        risk_score=total_score,
        risk_level=risk_level,
        detected_patterns=detected,
        unverifiable_claim_count=unverifiable_count,
    )


def extract_claims_heuristic(text: str) -> List[Tuple[str, str, Dict[str, Any]]]:
    """
    Extract claims using heuristic patterns with intent analysis.

    Returns:
        List of tuples: (claim_text, indicator, intent_analysis)
    """
    claims = []
    sentences = re.split(r"[.!?]\s+", text)

    for sentence in sentences:
        sentence = sentence.strip()
        if len(sentence) < 10:
            continue

        for indicator in CLAIM_INDICATORS:
            pattern = indicator.replace("~", ".*")
            if re.search(pattern, sentence):
                # Perform intent analysis on the claim
                intent_analysis = _intent_analyzer.analyze(sentence)
                claims.append((sentence, indicator, intent_analysis))
                break

    # Sort claims by verifiability score (prioritize verifiable claims)
    claims_with_score = []
    for claim_text, indicator, intent_analysis in claims:
        score = 0.0
        # Boost verifiable claims
        if intent_analysis["intent"]["is_verifiable"]:
            score += 0.5
        # Boost claims with data
        if intent_analysis["intent"]["intent_scores"].get("data", 0) > 0:
            score += 0.3
        # Boost claims with fact indicators
        if intent_analysis["intent"]["intent_scores"].get("fact_claim", 0) > 0:
            score += 0.2
        claims_with_score.append((claim_text, indicator, intent_analysis, score))

    # Sort by score descending
    claims_with_score.sort(key=lambda x: x[3], reverse=True)

    return [(c[0], c[1], c[2]) for c in claims_with_score[:10]]  # Max 10 claims


async def extract_claims_ml(text: str) -> List[Tuple[str, str, float, Dict[str, Any]]]:
    """
    Extract and classify claims using ML model with intent analysis.

    Returns:
        List of tuples: (claim_text, indicator, ml_confidence, intent_analysis)
    """
    models = get_ml_models()

    if not models.get("loaded") or "claim_model" not in models:
        # Fallback to heuristic
        heuristic_claims = extract_claims_heuristic(text)
        return [(c[0], c[1], 0.7, c[2]) for c in heuristic_claims]

    try:
        import torch

        tokenizer = models["claim_tokenizer"]
        model = models["claim_model"]
        device = models["device"]

        sentences = re.split(r"[.!?]\s+", text)
        claims = []

        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) < 10:
                continue

            # Tokenize
            inputs = tokenizer(
                sentence,
                return_tensors="pt",
                truncation=True,
                max_length=256,
                padding=True,
            ).to(device)

            # Predict
            with torch.no_grad():
                outputs = model(**inputs)
                probs = torch.softmax(outputs.logits, dim=-1)
                predicted_class = torch.argmax(probs, dim=-1).item()
                confidence = probs[0][predicted_class].item()

            # Class 0 = non-claim, 1 = claim, 2 = uncertain
            if predicted_class == 1 and confidence > 0.5:
                # Find matching indicator
                indicator = "ML 분류"
                for ind in CLAIM_INDICATORS:
                    pattern = ind.replace("~", ".*")
                    if re.search(pattern, sentence):
                        indicator = ind
                        break

                # Perform intent analysis
                intent_analysis = _intent_analyzer.analyze(sentence)
                claims.append((sentence, indicator, confidence, intent_analysis))

        # Sort by combined score (ML confidence + verifiability)
        def combined_score(claim_tuple):
            _, _, conf, intent = claim_tuple
            score = conf * 0.6  # ML confidence weight
            if intent["intent"]["is_verifiable"]:
                score += 0.25
            if intent["intent"]["intent_scores"].get("data", 0) > 0:
                score += 0.15
            return score

        claims.sort(key=combined_score, reverse=True)
        return claims[:10]

    except Exception as e:
        logger.error(f"ML claim extraction failed: {e}")
        heuristic_claims = extract_claims_heuristic(text)
        return [(c[0], c[1], 0.7, c[2]) for c in heuristic_claims]


def extract_entities_ml(text: str) -> List[Dict[str, str]]:
    """Extract named entities using NER model"""
    models = get_ml_models()

    if not models.get("loaded") or "ner_pipeline" not in models:
        return []

    try:
        ner = models["ner_pipeline"]
        entities = ner(text[:1024])  # Limit input length

        return [
            {
                "entity": e.get("entity_group", e.get("entity", "UNKNOWN")),
                "word": e.get("word", ""),
                "score": round(e.get("score", 0), 3),
            }
            for e in entities
            if e.get("score", 0) > 0.7
        ]
    except Exception as e:
        logger.error(f"NER extraction failed: {e}")
        return []


async def compute_semantic_similarity(
    claim: str, reference_texts: List[str]
) -> List[Dict[str, float]]:
    """Compute semantic similarity between claim and references"""
    models = get_ml_models()

    if not models.get("loaded") or "sentence_transformer" not in models:
        return []

    try:
        st_model = models["sentence_transformer"]

        # Encode claim
        claim_embedding = st_model.encode([claim])[0]

        # Encode references
        ref_embeddings = st_model.encode(reference_texts)

        # Compute cosine similarities
        from numpy import dot
        from numpy.linalg import norm

        similarities = []
        for i, ref_emb in enumerate(ref_embeddings):
            sim = dot(claim_embedding, ref_emb) / (
                norm(claim_embedding) * norm(ref_emb)
            )
            similarities.append(
                {"reference_index": i, "similarity": round(float(sim), 3)}
            )

        return sorted(similarities, key=lambda x: x["similarity"], reverse=True)

    except Exception as e:
        logger.error(f"Semantic similarity computation failed: {e}")
        return []


async def verify_with_external_api(claim: str) -> Optional[Dict[str, Any]]:
    """Verify claim using external fact-check APIs"""
    client = await get_http_client()

    if not client:
        return None

    results = {}

    # Google Fact Check API
    google_api_key = os.getenv("GOOGLE_FACTCHECK_API_KEY")
    if google_api_key:
        try:
            response = await client.get(
                "https://factchecktools.googleapis.com/v1alpha1/claims:search",
                params={
                    "query": claim[:200],
                    "key": google_api_key,
                    "languageCode": "ko",
                },
            )
            if response.status_code == 200:
                data = response.json()
                if data.get("claims"):
                    results["google_factcheck"] = {
                        "found": True,
                        "claims": data["claims"][:3],
                    }
        except Exception as e:
            logger.warning(f"Google Fact Check API error: {e}")

    # SNU Factcheck (if available)
    snu_api_url = os.getenv("SNU_FACTCHECK_API_URL")
    if snu_api_url:
        try:
            response = await client.post(snu_api_url, json={"query": claim[:200]})
            if response.status_code == 200:
                results["snu_factcheck"] = response.json()
        except Exception as e:
            logger.warning(f"SNU Factcheck API error: {e}")

    return results if results else None


def compute_keyword_similarity(claim_keywords: List[str], reference_text: str) -> float:
    """
    Compute keyword-based similarity between claim keywords and reference text.
    Uses Jaccard similarity on extracted keywords.
    """
    if not claim_keywords or not reference_text:
        return 0.0

    # Extract keywords from reference
    ref_keywords = set(_intent_analyzer.extract_keywords(reference_text))
    claim_kw_set = set(claim_keywords)

    if not ref_keywords or not claim_kw_set:
        return 0.0

    # Jaccard similarity
    intersection = len(claim_kw_set & ref_keywords)
    union = len(claim_kw_set | ref_keywords)

    return intersection / union if union > 0 else 0.0


def analyze_claim(
    claim_text: str,
    claim_indicator: str,
    ml_confidence: Optional[float] = None,
    entities: Optional[List[Dict[str, str]]] = None,
    external_verification: Optional[Dict[str, Any]] = None,
    intent_analysis: Optional[Dict[str, Any]] = None,
) -> ClaimAnalytics:
    """
    Analyze a single claim with enhanced intent analysis.

    Args:
        claim_text: The claim text to analyze
        claim_indicator: The indicator that identified this as a claim
        ml_confidence: ML model confidence if available
        entities: Named entities extracted from context
        external_verification: External API verification results
        intent_analysis: Intent analysis from IntentAnalyzer
    """

    # Generate claim ID
    claim_id = hashlib.md5(claim_text.encode()).hexdigest()[:8]

    # Determine verdict based on available information
    verdict = ClaimVerdict.UNVERIFIED.value
    confidence = 0.5
    supporting = []
    contradicting = []
    analysis_method = "heuristic"

    # Use intent analysis for enhanced verification
    if intent_analysis:
        keywords = intent_analysis.get("keywords", [])
        primary_keyword = intent_analysis.get("primary_keyword", "")
        intent_info = intent_analysis.get("intent", {})

        # Boost confidence for verifiable claims
        if intent_info.get("is_verifiable", False):
            confidence += 0.1
            supporting.append("검증 가능한 팩트성 주장")

        # Boost for data-driven claims
        if intent_info.get("intent_scores", {}).get("data", 0) > 0:
            confidence += 0.1
            supporting.append("데이터/수치 포함")

        # Note opinion-based claims
        if intent_info.get("intent_scores", {}).get("opinion", 0) > 0:
            confidence -= 0.1
            contradicting.append("의견성 표현 포함")

        # Store search strategies for potential follow-up verification
        search_queries = intent_analysis.get("search_queries", [])
        if search_queries:
            analysis_method = "heuristic_with_intent"

    # If ML confidence available
    if ml_confidence is not None:
        analysis_method = (
            "ml_classification" if not intent_analysis else "ml_with_intent"
        )
        confidence = (
            (confidence + ml_confidence) / 2 if intent_analysis else ml_confidence
        )

    # If external verification available
    if external_verification:
        analysis_method = (
            "external_api" if not intent_analysis else "external_with_intent"
        )

        # Check Google Fact Check results
        if "google_factcheck" in external_verification:
            gfc = external_verification["google_factcheck"]
            if gfc.get("found"):
                claims_data = gfc.get("claims", [])
                for c in claims_data:
                    review = c.get("claimReview", [{}])[0]
                    rating = review.get("textualRating", "").lower()

                    if any(x in rating for x in ["true", "correct", "accurate"]):
                        verdict = ClaimVerdict.VERIFIED.value
                        supporting.append(f"Google Fact Check: {rating}")
                    elif any(x in rating for x in ["false", "incorrect", "wrong"]):
                        verdict = ClaimVerdict.FALSE.value
                        contradicting.append(f"Google Fact Check: {rating}")
                    elif any(x in rating for x in ["misleading", "partial"]):
                        verdict = ClaimVerdict.MISLEADING.value
                        contradicting.append(f"Google Fact Check: {rating}")

                    # Enhance with keyword similarity check
                    if intent_analysis:
                        claim_text_from_api = c.get("text", "")
                        keywords = intent_analysis.get("keywords", [])
                        similarity = compute_keyword_similarity(
                            keywords, claim_text_from_api
                        )
                        if similarity > 0.5:
                            supporting.append(f"키워드 유사도: {similarity:.0%}")

    # If no external verification available, mark as UNVERIFIED with appropriate context
    # IMPORTANT: We do NOT use pseudo-random verdicts as they mislead users
    if verdict == ClaimVerdict.UNVERIFIED.value:
        # Use intent analysis to provide better context
        if intent_analysis and intent_analysis.get("intent", {}).get("is_verifiable"):
            # This is a verifiable claim but we couldn't verify it externally
            # Keep it as UNVERIFIED with low confidence
            verdict = ClaimVerdict.UNVERIFIED.value
            confidence = 0.35  # Low confidence since no external verification
            analysis_method = "needs_external_verification"
            supporting.append("검증 가능한 주장이나 외부 검증 소스를 찾지 못했습니다")
        else:
            # Non-verifiable claims (opinions, subjective statements, etc.)
            verdict = ClaimVerdict.UNVERIFIED.value
            confidence = 0.25  # Very low confidence for non-verifiable claims
            analysis_method = "opinion_or_subjective"
            supporting.append("의견 또는 주관적 주장으로 사실 검증이 어렵습니다")

        # If ML model provided some insight, use that to adjust confidence slightly
        if ml_confidence and ml_confidence > 0.5:
            confidence = min(
                0.5, ml_confidence * 0.6
            )  # Cap at 0.5 for ML-only analysis
            analysis_method = "ml_analysis_only"

    # Clamp confidence
    confidence = max(0.0, min(1.0, confidence))

    return ClaimAnalytics(
        claim_id=claim_id,
        claim_text=claim_text[:200] + "..." if len(claim_text) > 200 else claim_text,
        verdict=verdict,
        confidence=round(confidence, 2),
        ml_confidence=ml_confidence,
        claim_indicator=claim_indicator,
        analysis_method=analysis_method,
        entities=entities,
        supporting_factors=supporting,
        contradicting_factors=contradicting,
        external_verification=external_verification,
    )


def calculate_score_breakdown(
    source_analysis: SourceAnalytics,
    clickbait_analysis: ClickbaitAnalytics,
    misinfo_analysis: MisinfoAnalytics,
    claim_analyses: List[ClaimAnalytics],
) -> ScoreBreakdown:
    """Calculate detailed score breakdown"""

    # Weights
    source_weight = 30
    clickbait_weight = 20
    misinfo_weight = 20
    verification_weight = 30

    # Calculate contributions
    source_contribution = source_analysis.trust_score * source_weight

    clickbait_score = 0.7 if clickbait_analysis.is_clickbait else 1.0
    clickbait_contribution = clickbait_score * clickbait_weight

    misinfo_score = 1 - misinfo_analysis.risk_score
    misinfo_contribution = misinfo_score * misinfo_weight

    verified_count = sum(
        1 for c in claim_analyses if c.verdict == ClaimVerdict.VERIFIED.value
    )
    verification_ratio = verified_count / len(claim_analyses) if claim_analyses else 0.5
    verification_contribution = verification_ratio * verification_weight

    total_score = (
        source_contribution
        + clickbait_contribution
        + misinfo_contribution
        + verification_contribution
    )

    # Grade
    if total_score >= 80:
        grade = CredibilityGrade.A.value
    elif total_score >= 60:
        grade = CredibilityGrade.B.value
    elif total_score >= 40:
        grade = CredibilityGrade.C.value
    elif total_score >= 20:
        grade = CredibilityGrade.D.value
    else:
        grade = CredibilityGrade.F.value

    return ScoreBreakdown(
        source_weight=source_weight,
        clickbait_weight=clickbait_weight,
        misinfo_weight=misinfo_weight,
        verification_weight=verification_weight,
        source_contribution=round(source_contribution, 1),
        clickbait_contribution=round(clickbait_contribution, 1),
        misinfo_contribution=round(misinfo_contribution, 1),
        verification_contribution=round(verification_contribution, 1),
        total_score=round(total_score, 1),
        grade=grade,
    )


async def perform_factcheck(
    article: ArticleInput, options: Optional[ExecutionOptions] = None
) -> FactCheckResult:
    """Perform comprehensive fact-checking analysis"""

    start_time = time.time()

    # Get options
    opts = options or ExecutionOptions()
    analysis_mode = opts.analysis_mode or AnalysisMode.HYBRID
    include_analytics = opts.include_detailed_analytics

    # Combine text
    text = ""
    if article.title:
        text += article.title + " "
    if article.content:
        text += article.content

    if not text.strip():
        return FactCheckResult(
            overall_credibility=0.0,
            credibility_grade=CredibilityGrade.F.value,
            verdict="unverified",
            claims_analyzed=0,
            verified_claims=0,
            false_claims=0,
            unverified_claims=0,
            explanations=["분석할 콘텐츠가 없습니다."],
        )

    models_used = []
    apis_used = []

    # 1. Source Analysis
    source_analysis = analyze_source(article.source)

    # 2. Clickbait Detection
    clickbait_analysis = analyze_clickbait(article.title)

    # 3. Misinformation Risk
    misinfo_analysis = analyze_misinformation(text)

    # 4. Claim Extraction & Analysis
    claim_analyses = []

    if analysis_mode in [
        AnalysisMode.ML_BASIC,
        AnalysisMode.ML_FULL,
        AnalysisMode.HYBRID,
    ]:
        # Use ML for claim extraction
        claims_with_conf = await extract_claims_ml(text)
        models_used.append("koelectra-claim-classifier")

        # Extract entities if ML_FULL
        entities = None
        if analysis_mode == AnalysisMode.ML_FULL:
            entities = extract_entities_ml(text)
            if entities:
                models_used.append("klue-ner")

        for claim_text, indicator, confidence, intent_analysis in claims_with_conf:
            external_verification = None

            # External API verification for ML_FULL or HYBRID
            if analysis_mode in [AnalysisMode.ML_FULL, AnalysisMode.HYBRID]:
                external_verification = await verify_with_external_api(claim_text)
                if external_verification:
                    apis_used.extend(external_verification.keys())

            claim_analytics = analyze_claim(
                claim_text=claim_text,
                claim_indicator=indicator,
                ml_confidence=confidence,
                entities=entities,
                external_verification=external_verification,
                intent_analysis=intent_analysis,
            )
            claim_analyses.append(claim_analytics)
    else:
        # Heuristic only
        claims = extract_claims_heuristic(text)
        for claim_text, indicator, intent_analysis in claims:
            claim_analytics = analyze_claim(
                claim_text=claim_text,
                claim_indicator=indicator,
                intent_analysis=intent_analysis,
            )
            claim_analyses.append(claim_analytics)

    # 5. Calculate Score Breakdown
    score_breakdown = calculate_score_breakdown(
        source_analysis, clickbait_analysis, misinfo_analysis, claim_analyses
    )

    # 6. Build results
    verified_count = sum(
        1 for c in claim_analyses if c.verdict == ClaimVerdict.VERIFIED.value
    )
    false_count = sum(
        1
        for c in claim_analyses
        if c.verdict in [ClaimVerdict.FALSE.value, ClaimVerdict.MISLEADING.value]
    )
    unverified_count = sum(
        1 for c in claim_analyses if c.verdict == ClaimVerdict.UNVERIFIED.value
    )

    # Final verdict
    if score_breakdown.total_score >= 70:
        verdict = "verified"
    elif score_breakdown.total_score >= 40:
        verdict = "suspicious"
    else:
        verdict = "unverified"

    # Risk flags
    risk_flags = []
    if clickbait_analysis.is_clickbait:
        risk_flags.append("낚시성 제목 의심")
    if source_analysis.trust_score < 0.5:
        risk_flags.append("출처 신뢰도 낮음")
    if misinfo_analysis.risk_level in ["medium", "high"]:
        risk_flags.append(f"허위정보 위험도: {misinfo_analysis.risk_level}")

    # Explanations
    explanations = [
        f"출처 신뢰도: {source_analysis.trust_score * 100:.0f}%",
        f"분석된 주장: {len(claim_analyses)}개",
    ]
    if verified_count > 0:
        explanations.append(f"검증된 주장: {verified_count}개")
    if false_count > 0:
        explanations.append(f"의심스러운 주장: {false_count}개")
    if clickbait_analysis.is_clickbait:
        patterns = [p["pattern"] for p in clickbait_analysis.detected_patterns]
        explanations.append(f"낚시성 패턴: {', '.join(patterns)}")

    # Build detailed analytics if requested
    detailed_analytics = None
    if include_analytics:
        processing_time = int((time.time() - start_time) * 1000)
        detailed_analytics = DetailedAnalytics(
            source_analysis=source_analysis,
            clickbait_analysis=clickbait_analysis,
            misinfo_analysis=misinfo_analysis,
            claim_analyses=claim_analyses,
            score_breakdown=score_breakdown,
            analysis_mode=analysis_mode.value,
            ml_models_used=list(set(models_used)),
            external_apis_used=list(set(apis_used)),
            processing_time_ms=processing_time,
            analyzed_at=time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        )

    # Build claim results
    claim_results = [
        ClaimResult(
            claim=c.claim_text,
            verdict=c.verdict,
            confidence=c.confidence,
            evidence=c.analysis_method,
            ml_analysis={
                "ml_confidence": c.ml_confidence,
                "entities": c.entities,
                "supporting": c.supporting_factors,
                "contradicting": c.contradicting_factors,
            }
            if c.ml_confidence
            else None,
        )
        for c in claim_analyses
    ]

    return FactCheckResult(
        overall_credibility=score_breakdown.total_score,
        credibility_grade=score_breakdown.grade,
        verdict=verdict,
        claims_analyzed=len(claim_analyses),
        verified_claims=verified_count,
        false_claims=false_count,
        unverified_claims=unverified_count,
        claims=claim_results if claim_results else None,
        risk_flags=risk_flags if risk_flags else None,
        explanations=explanations,
        detailed_analytics=detailed_analytics,
    )


# ========== API Endpoints ==========


@app.get("/health")
async def health_check():
    """Health check endpoint with ML status"""
    models = get_ml_models()

    return {
        "status": "healthy",
        "service": "factcheck-addon",
        "version": "2.0.0",
        "ml_enabled": models.get("loaded", False),
        "warmup_complete": _model_warmup_complete,
        "warmup_error": _model_warmup_error,
        "models_loaded": [
            k
            for k in models.keys()
            if k not in ["loaded", "device"] and models.get(k) is not None
        ],
        "device": models.get("device", "cpu"),
    }


@app.get("/ready")
async def readiness_check():
    """Readiness check - only returns healthy when models are warmed up"""
    if not _model_warmup_complete:
        return {"status": "warming_up", "ready": False}

    models = get_ml_models()
    return {
        "status": "ready",
        "ready": True,
        "ml_enabled": models.get("loaded", False),
        "warmup_error": _model_warmup_error,
    }


@app.post("/analyze", response_model=AddonResponse)
async def analyze(request: AddonRequest):
    """
    Main analysis endpoint with ML-enhanced fact-checking.
    """
    start_time = time.time()

    try:
        if not request.article:
            raise ValueError("article is required")

        # Perform fact-check
        factcheck_result = await perform_factcheck(request.article, request.options)

        # Response metadata
        latency_ms = int((time.time() - start_time) * 1000)
        models = get_ml_models()

        # Track Prometheus metrics
        if PROMETHEUS_AVAILABLE:
            REQUEST_COUNT.labels(endpoint="analyze", status="success").inc()
            REQUEST_LATENCY.labels(endpoint="analyze").observe(time.time() - start_time)
            ANALYSIS_COUNT.labels(
                mode=request.options.analysis_mode.value
                if request.options and request.options.analysis_mode
                else "hybrid",
                verdict=factcheck_result.overall_verdict
                if factcheck_result
                else "unknown",
            ).inc()
            if factcheck_result and factcheck_result.claims:
                CLAIMS_EXTRACTED.inc(len(factcheck_result.claims))

        return AddonResponse(
            request_id=request.request_id,
            addon_id=request.addon_id,
            status="success",
            results=AnalysisResults(factcheck=factcheck_result),
            meta=ResponseMeta(
                model_version="factcheck-ko-ml-v2.0",
                latency_ms=latency_ms,
                processed_at=time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
                ml_enabled=models.get("loaded", False),
                models_loaded=[
                    k
                    for k in models.keys()
                    if k not in ["loaded", "device"] and models.get(k) is not None
                ],
            ),
        )

    except Exception as e:
        logger.error(f"Analysis error: {e}")
        latency_ms = int((time.time() - start_time) * 1000)

        # Track error metrics
        if PROMETHEUS_AVAILABLE:
            REQUEST_COUNT.labels(endpoint="analyze", status="error").inc()
            REQUEST_LATENCY.labels(endpoint="analyze").observe(time.time() - start_time)
            ERROR_COUNT.labels(error_type=type(e).__name__).inc()

        return AddonResponse(
            request_id=request.request_id,
            addon_id=request.addon_id,
            status="error",
            error=ErrorInfo(code="FACTCHECK_ERROR", message=str(e)),
            meta=ResponseMeta(
                model_version="factcheck-ko-ml-v2.0",
                latency_ms=latency_ms,
                processed_at=time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
            ),
        )


@app.post("/batch")
async def analyze_batch(requests: List[AddonRequest]):
    """Batch analysis endpoint"""
    results = []
    for req in requests:
        result = await analyze(req)
        results.append(result)
    return results


@app.get("/models")
async def list_models():
    """List available ML models and their status"""
    models = get_ml_models()

    return {
        "loaded": models.get("loaded", False),
        "device": models.get("device", "cpu"),
        "models": {
            "claim_classifier": {
                "loaded": "claim_model" in models,
                "name": os.getenv(
                    "CLAIM_MODEL", "monologg/koelectra-base-v3-discriminator"
                ),
            },
            "sentence_transformer": {
                "loaded": "sentence_transformer" in models,
                "name": os.getenv(
                    "EMBEDDING_MODEL",
                    "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
                ),
            },
            "ner": {
                "loaded": "ner_pipeline" in models,
                "name": os.getenv("NER_MODEL", "klue/bert-base"),
            },
            "sentiment": {
                "loaded": "sentiment_pipeline" in models,
                "name": os.getenv("SENTIMENT_MODEL", "klue/roberta-base"),
            },
        },
    }


@app.post("/reload-models")
async def reload_models(background_tasks: BackgroundTasks):
    """Reload ML models"""
    global _ml_models
    _ml_models = {}

    background_tasks.add_task(get_ml_models)

    return {"message": "Model reload initiated"}


# ========== Entry Point ==========

if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=int(os.getenv("PORT", 8101)))

```

---

## backend/ml-addons/ml-trainer/main.py

```py
"""
ML Training Service - Production Version

FastAPI-based ML training service that supports multiple model types:
- Sentiment Analysis (BERT-based)
- ABSA (Aspect-Based Sentiment Analysis)
- NER (Named Entity Recognition)
- Text Classification
- Embedding Models

This service performs REAL training using HuggingFace Transformers.
"""

import os
import uuid
import json
import asyncio
import hashlib
import threading
import secrets
import shutil
import zipfile
from datetime import datetime
from pathlib import Path
from typing import Optional, AsyncGenerator
from enum import Enum
from dataclasses import dataclass, field, asdict
from contextlib import asynccontextmanager
from collections import deque

import structlog
from fastapi import FastAPI, HTTPException, BackgroundTasks, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field

# Configure structlog
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer(),
    ],
    wrapper_class=structlog.stdlib.BoundLogger,
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    cache_logger_on_first_use=True,
)

log = structlog.get_logger()

# Environment configuration
MODEL_DIR = Path(os.getenv("MODEL_DIR", "/app/models"))
DATASET_DIR = Path(os.getenv("DATASET_DIR", "/app/datasets"))
LOG_DIR = Path(os.getenv("LOG_DIR", "/app/logs"))
USE_GPU = os.getenv("USE_GPU", "true").lower() == "true"
MAX_CONCURRENT_JOBS = int(os.getenv("MAX_CONCURRENT_JOBS", "2"))

# Ensure directories exist
MODEL_DIR.mkdir(parents=True, exist_ok=True)
DATASET_DIR.mkdir(parents=True, exist_ok=True)
LOG_DIR.mkdir(parents=True, exist_ok=True)


# =============================================================================
# Enums and Data Classes
# =============================================================================


class JobState(str, Enum):
    PENDING = "PENDING"
    INITIALIZING = "INITIALIZING"
    RUNNING = "RUNNING"
    COMPLETED = "COMPLETED"
    FAILED = "FAILED"
    CANCELLED = "CANCELLED"


class ModelType(str, Enum):
    SENTIMENT = "sentiment"
    ABSA = "absa"
    NER = "ner"
    CLASSIFICATION = "classification"
    EMBEDDING = "embedding"
    TRANSFORMER = "transformer"


@dataclass
class TrainingMetrics:
    epoch: int = 0
    total_epochs: int = 0
    step: int = 0
    total_steps: int = 0
    loss: float = 0.0
    accuracy: float = 0.0
    validation_loss: float = 0.0
    validation_accuracy: float = 0.0
    learning_rate: float = 0.0
    samples_processed: int = 0
    total_samples: int = 0
    f1_score: float = 0.0
    precision: float = 0.0
    recall: float = 0.0


@dataclass
class TrainingJob:
    job_id: str
    model_name: str
    model_type: ModelType
    dataset_path: str
    dataset_format: str
    base_model: Optional[str]
    max_epochs: int
    validation_split: float
    hyperparameters: dict = field(default_factory=dict)
    callbacks: dict = field(default_factory=dict)
    metadata: dict = field(default_factory=dict)
    state: JobState = JobState.PENDING
    progress: float = 0.0
    metrics: TrainingMetrics = field(default_factory=TrainingMetrics)
    error_message: Optional[str] = None
    model_path: Optional[str] = None
    created_at: str = field(default_factory=lambda: datetime.utcnow().isoformat())
    started_at: Optional[str] = None
    completed_at: Optional[str] = None
    # For SSE streaming
    event_queue: deque = field(default_factory=lambda: deque(maxlen=100))
    # External training support (Colab/Jupyter)
    is_external: bool = False
    upload_token: Optional[str] = None
    external_worker_info: dict = field(default_factory=dict)


# In-memory job storage (backed by Redis via state_store)
# This dict is a cache, actual persistence is handled by StateStore
jobs: dict[str, TrainingJob] = {}
# Lock for thread-safe operations
jobs_lock = threading.Lock()

# State store instance (initialized in lifespan)
state_store = None


# =============================================================================
# Pydantic Models for API
# =============================================================================


class TrainingRequest(BaseModel):
    model_name: str = Field(..., description="Name of the model to train")
    model_type: str = Field(
        ..., description="Type of model (sentiment, absa, ner, etc.)"
    )
    dataset_path: str = Field(..., description="Path to training dataset")
    dataset_format: str = Field(
        default="csv", description="Format of dataset (csv, jsonl, parquet)"
    )
    base_model: Optional[str] = Field(
        default=None, description="Base model for fine-tuning"
    )
    max_epochs: int = Field(
        default=3, ge=1, le=100, description="Maximum training epochs"
    )
    validation_split: float = Field(
        default=0.1, ge=0.0, le=0.5, description="Validation data split ratio"
    )
    hyperparameters: dict = Field(
        default_factory=dict, description="Training hyperparameters"
    )
    callbacks: dict = Field(default_factory=dict, description="Callback configurations")
    metadata: dict = Field(default_factory=dict, description="Additional metadata")


class TrainingResponse(BaseModel):
    job_id: str
    model_name: str
    model_type: str
    state: str
    progress: float
    created_at: str
    message: str


class JobStatusResponse(BaseModel):
    job_id: str
    model_name: str
    model_type: str
    state: str
    progress: float
    metrics: dict
    error_message: Optional[str]
    model_path: Optional[str]
    created_at: str
    started_at: Optional[str]
    completed_at: Optional[str]
    current_epoch: int = 0
    total_epochs: int = 0


class ModelArtifactResponse(BaseModel):
    model_path: str
    model_name: str
    model_type: str
    framework: str
    version: str
    size_bytes: int
    checksum: str
    metrics: dict
    model_filename: str


class HealthResponse(BaseModel):
    status: str
    version: str
    gpu_available: bool
    active_jobs: int
    supported_model_types: list[str]
    max_concurrent_jobs: int
    redis_connected: bool = False
    persisted_jobs: int = 0


# =============================================================================
# External Training (Colab/Jupyter) Request/Response Models
# =============================================================================


class ExternalTrainingStartRequest(BaseModel):
    """Request to start an external training session from Colab/Jupyter."""

    model_name: str = Field(..., description="Name for the trained model")
    model_type: str = Field(
        default="sentiment", description="Type of model being trained"
    )
    base_model: Optional[str] = Field(
        default=None, description="Base model being fine-tuned (optional)"
    )
    max_epochs: int = Field(default=10, ge=1, le=1000, description="Expected epochs")
    metadata: dict = Field(
        default_factory=dict,
        description="Additional metadata (e.g., Colab notebook URL)",
    )


class ExternalTrainingStartResponse(BaseModel):
    """Response with job_id and upload_token for external training."""

    job_id: str
    upload_token: str
    model_name: str
    model_type: str
    state: str
    created_at: str
    message: str
    api_endpoints: dict = Field(
        default_factory=dict, description="API endpoints for progress/upload/complete"
    )


class ExternalProgressRequest(BaseModel):
    """Request to report training progress from external worker."""

    upload_token: str = Field(
        ..., description="Token received from /train/external/start"
    )
    progress: float = Field(
        default=0.0, ge=0.0, le=100.0, description="Progress percentage (0-100)"
    )
    epoch: int = Field(default=0, ge=0, description="Current epoch")
    total_epochs: int = Field(default=0, ge=0, description="Total epochs")
    step: int = Field(default=0, ge=0, description="Current step")
    total_steps: int = Field(default=0, ge=0, description="Total steps")
    loss: float = Field(default=0.0, description="Current loss value")
    accuracy: float = Field(default=0.0, ge=0.0, le=1.0, description="Current accuracy")
    validation_loss: float = Field(default=0.0, description="Validation loss")
    validation_accuracy: float = Field(
        default=0.0, ge=0.0, le=1.0, description="Validation accuracy"
    )
    f1_score: float = Field(default=0.0, ge=0.0, le=1.0, description="F1 score")
    learning_rate: float = Field(default=0.0, description="Current learning rate")
    message: Optional[str] = Field(default=None, description="Optional status message")


class ExternalCompleteRequest(BaseModel):
    """Request to mark external training as complete."""

    upload_token: str = Field(
        ..., description="Token received from /train/external/start"
    )
    final_metrics: dict = Field(
        default_factory=dict, description="Final training metrics"
    )
    model_path: Optional[str] = Field(
        default=None, description="Path to model if already uploaded"
    )


# =============================================================================
# Training Progress Callback (Real HuggingFace Integration)
# =============================================================================


class TrainingProgressCallback:
    """Custom callback to track training progress for HuggingFace Trainer."""

    def __init__(self, job: TrainingJob):
        self.job = job

    def on_train_begin(self, args, state, control, **kwargs):
        self.job.metrics.total_steps = state.max_steps if state.max_steps else 0
        self.job.metrics.total_epochs = args.num_train_epochs
        self._emit_event(
            "training_started", {"total_steps": self.job.metrics.total_steps}
        )

    def on_step_end(self, args, state, control, **kwargs):
        self.job.metrics.step = state.global_step
        if state.max_steps:
            self.job.progress = (state.global_step / state.max_steps) * 100

        if state.log_history:
            latest = state.log_history[-1]
            self.job.metrics.loss = latest.get("loss", self.job.metrics.loss)
            self.job.metrics.learning_rate = latest.get(
                "learning_rate", self.job.metrics.learning_rate
            )

        self._emit_event(
            "step_completed",
            {
                "step": state.global_step,
                "progress": self.job.progress,
                "loss": self.job.metrics.loss,
            },
        )

    def on_epoch_end(self, args, state, control, **kwargs):
        self.job.metrics.epoch = int(state.epoch) if state.epoch else 0
        self._emit_event(
            "epoch_completed",
            {"epoch": self.job.metrics.epoch, "progress": self.job.progress},
        )

    def on_evaluate(self, args, state, control, metrics=None, **kwargs):
        if metrics:
            self.job.metrics.validation_loss = metrics.get("eval_loss", 0.0)
            self.job.metrics.validation_accuracy = metrics.get("eval_accuracy", 0.0)
            self.job.metrics.f1_score = metrics.get("eval_f1", 0.0)
            self._emit_event(
                "evaluation_completed",
                {
                    "eval_loss": self.job.metrics.validation_loss,
                    "eval_accuracy": self.job.metrics.validation_accuracy,
                },
            )

    def on_train_end(self, args, state, control, **kwargs):
        self._emit_event("training_ended", {"final_step": state.global_step})

    def _emit_event(self, event_type: str, data: dict):
        """Emit event to job's event queue for SSE streaming."""
        event = {
            "type": event_type,
            "timestamp": datetime.utcnow().isoformat(),
            "job_id": self.job.job_id,
            "progress": self.job.progress,
            "state": self.job.state.value,
            "metrics": asdict(self.job.metrics),
            **data,
        }
        self.job.event_queue.append(event)


# =============================================================================
# Real Training Logic
# =============================================================================


def get_default_base_model(model_type: ModelType) -> str:
    """Returns the default base model for each model type."""
    defaults = {
        ModelType.SENTIMENT: "klue/bert-base",
        ModelType.ABSA: "monologg/koelectra-base-v3-discriminator",
        ModelType.NER: "klue/bert-base",
        ModelType.CLASSIFICATION: "klue/roberta-base",
        ModelType.EMBEDDING: "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        ModelType.TRANSFORMER: "klue/bert-base",
    }
    return defaults.get(model_type, "klue/bert-base")


def load_dataset_from_path(
    dataset_path: str, dataset_format: str, validation_split: float
):
    """Load dataset from file path with proper format handling."""
    from datasets import load_dataset, Dataset, DatasetDict
    import pandas as pd

    path = Path(dataset_path)
    if not path.exists():
        # Check in DATASET_DIR
        path = DATASET_DIR / dataset_path
        if not path.exists():
            raise FileNotFoundError(f"Dataset not found: {dataset_path}")

    log.info("Loading dataset", path=str(path), format=dataset_format)

    if dataset_format == "csv":
        df = pd.read_csv(path)
    elif dataset_format == "jsonl":
        df = pd.read_json(path, lines=True)
    elif dataset_format == "json":
        df = pd.read_json(path)
    elif dataset_format == "parquet":
        df = pd.read_parquet(path)
    else:
        raise ValueError(f"Unsupported dataset format: {dataset_format}")

    # Convert to HuggingFace dataset
    dataset = Dataset.from_pandas(df)

    # Split into train/validation
    if validation_split > 0:
        split = dataset.train_test_split(test_size=validation_split, seed=42)
        return DatasetDict({"train": split["train"], "validation": split["test"]})
    else:
        return DatasetDict({"train": dataset})


def compute_metrics(eval_pred):
    """Compute evaluation metrics."""
    import numpy as np
    from sklearn.metrics import accuracy_score, precision_recall_fscore_support

    predictions, labels = eval_pred
    if isinstance(predictions, tuple):
        predictions = predictions[0]
    predictions = np.argmax(predictions, axis=-1)

    accuracy = accuracy_score(labels, predictions)
    precision, recall, f1, _ = precision_recall_fscore_support(
        labels, predictions, average="weighted", zero_division=0
    )

    return {"accuracy": accuracy, "precision": precision, "recall": recall, "f1": f1}


async def run_training(job: TrainingJob):
    """
    Runs actual training using HuggingFace Transformers.
    This is the production implementation.
    """
    try:
        # Import ML libraries
        import torch
        from transformers import (
            AutoTokenizer,
            AutoModelForSequenceClassification,
            Trainer,
            TrainingArguments,
            TrainerCallback,
            EarlyStoppingCallback,
        )

        job.state = JobState.INITIALIZING
        job.started_at = datetime.utcnow().isoformat()
        log.info(
            "Initializing training", job_id=job.job_id, model_type=job.model_type.value
        )

        # Determine device
        device = "cuda" if torch.cuda.is_available() and USE_GPU else "cpu"
        log.info(
            "Using device", device=device, cuda_available=torch.cuda.is_available()
        )

        # Determine base model
        base_model = job.base_model or get_default_base_model(job.model_type)
        log.info("Loading base model", base_model=base_model)

        # Load tokenizer and model
        tokenizer = AutoTokenizer.from_pretrained(base_model)

        # Load dataset
        dataset = load_dataset_from_path(
            job.dataset_path, job.dataset_format, job.validation_split
        )

        # Determine number of labels from dataset
        train_dataset = dataset["train"]
        if "label" in train_dataset.column_names:
            num_labels = len(set(train_dataset["label"]))
        elif "labels" in train_dataset.column_names:
            num_labels = len(set(train_dataset["labels"]))
        else:
            num_labels = 2  # Default binary classification

        log.info(
            "Dataset loaded", train_samples=len(train_dataset), num_labels=num_labels
        )

        job.metrics.total_samples = len(train_dataset)

        # Load model
        model = AutoModelForSequenceClassification.from_pretrained(
            base_model, num_labels=num_labels
        )
        model.to(device)

        # Tokenize dataset
        def tokenize_function(examples):
            # Try different text column names
            text_column = None
            for col in ["text", "content", "sentence", "review", "document"]:
                if col in examples:
                    text_column = col
                    break

            if text_column is None:
                raise ValueError(
                    f"No text column found. Available: {list(examples.keys())}"
                )

            return tokenizer(
                examples[text_column],
                padding="max_length",
                truncation=True,
                max_length=job.hyperparameters.get("max_length", 512),
            )

        tokenized_dataset = dataset.map(tokenize_function, batched=True)

        # Prepare output directory
        output_dir = MODEL_DIR / job.job_id
        output_dir.mkdir(parents=True, exist_ok=True)

        # Extract hyperparameters
        batch_size = job.hyperparameters.get("batch_size", 16)
        learning_rate = job.hyperparameters.get("learning_rate", 2e-5)
        warmup_steps = job.hyperparameters.get("warmup_steps", 500)
        weight_decay = job.hyperparameters.get("weight_decay", 0.01)

        # Training arguments
        training_args = TrainingArguments(
            output_dir=str(output_dir),
            num_train_epochs=job.max_epochs,
            per_device_train_batch_size=batch_size,
            per_device_eval_batch_size=batch_size,
            warmup_steps=warmup_steps,
            weight_decay=weight_decay,
            learning_rate=learning_rate,
            logging_dir=str(LOG_DIR / job.job_id),
            logging_steps=10,
            eval_strategy="epoch" if "validation" in tokenized_dataset else "no",
            save_strategy="epoch",
            load_best_model_at_end=True if "validation" in tokenized_dataset else False,
            save_total_limit=2,
            report_to=[],  # Disable wandb, etc.
            disable_tqdm=True,  # We use our own progress tracking
            fp16=torch.cuda.is_available()
            and USE_GPU,  # Use mixed precision if available
        )

        # Create custom callback for progress tracking
        class ProgressCallback(TrainerCallback):
            def __init__(self, training_job: TrainingJob):
                self.job = training_job

            def on_train_begin(self, args, state, control, **kwargs):
                self.job.state = JobState.RUNNING
                self.job.metrics.total_steps = state.max_steps or 0
                self.job.metrics.total_epochs = int(args.num_train_epochs)
                self._emit("training_started")

            def on_step_end(self, args, state, control, **kwargs):
                self.job.metrics.step = state.global_step
                if state.max_steps:
                    self.job.progress = (state.global_step / state.max_steps) * 100

                if state.log_history:
                    latest = state.log_history[-1]
                    self.job.metrics.loss = latest.get("loss", self.job.metrics.loss)
                    self.job.metrics.learning_rate = latest.get("learning_rate", 0.0)

                # Emit every 10 steps
                if state.global_step % 10 == 0:
                    self._emit("step_update")

            def on_epoch_end(self, args, state, control, **kwargs):
                self.job.metrics.epoch = int(state.epoch) if state.epoch else 0
                self._emit("epoch_completed")

            def on_evaluate(self, args, state, control, metrics=None, **kwargs):
                if metrics:
                    self.job.metrics.validation_loss = metrics.get("eval_loss", 0.0)
                    self.job.metrics.validation_accuracy = metrics.get(
                        "eval_accuracy", 0.0
                    )
                    self.job.metrics.f1_score = metrics.get("eval_f1", 0.0)
                    self.job.metrics.precision = metrics.get("eval_precision", 0.0)
                    self.job.metrics.recall = metrics.get("eval_recall", 0.0)
                self._emit("evaluation_completed")

            def _emit(self, event_type: str):
                event = {
                    "type": event_type,
                    "timestamp": datetime.utcnow().isoformat(),
                    "job_id": self.job.job_id,
                    "progress": round(self.job.progress, 2),
                    "state": self.job.state.value,
                    "metrics": {
                        "epoch": self.job.metrics.epoch,
                        "step": self.job.metrics.step,
                        "loss": round(self.job.metrics.loss, 4)
                        if self.job.metrics.loss
                        else 0,
                        "accuracy": round(self.job.metrics.accuracy, 4)
                        if self.job.metrics.accuracy
                        else 0,
                        "validation_loss": round(self.job.metrics.validation_loss, 4)
                        if self.job.metrics.validation_loss
                        else 0,
                        "validation_accuracy": round(
                            self.job.metrics.validation_accuracy, 4
                        )
                        if self.job.metrics.validation_accuracy
                        else 0,
                        "f1_score": round(self.job.metrics.f1_score, 4)
                        if self.job.metrics.f1_score
                        else 0,
                        "learning_rate": self.job.metrics.learning_rate,
                    },
                }
                self.job.event_queue.append(event)

        # Create Trainer
        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=tokenized_dataset["train"],
            eval_dataset=tokenized_dataset.get("validation"),
            tokenizer=tokenizer,
            compute_metrics=compute_metrics
            if "validation" in tokenized_dataset
            else None,
            callbacks=[
                ProgressCallback(job),
                EarlyStoppingCallback(early_stopping_patience=3)
                if "validation" in tokenized_dataset
                else None,
            ],
        )

        # Filter None callbacks
        trainer.callback_handler.callbacks = [
            cb for cb in trainer.callback_handler.callbacks if cb is not None
        ]

        log.info("Starting training", job_id=job.job_id)

        # Train
        trainer.train()

        # Save final model
        final_model_path = output_dir / "final"
        trainer.save_model(str(final_model_path))
        tokenizer.save_pretrained(str(final_model_path))

        # Save training info
        training_info = {
            "job_id": job.job_id,
            "model_name": job.model_name,
            "model_type": job.model_type.value,
            "base_model": base_model,
            "final_metrics": asdict(job.metrics),
            "hyperparameters": job.hyperparameters,
            "completed_at": datetime.utcnow().isoformat(),
        }

        with open(final_model_path / "training_info.json", "w") as f:
            json.dump(training_info, f, indent=2)

        job.model_path = str(final_model_path)
        job.state = JobState.COMPLETED
        job.completed_at = datetime.utcnow().isoformat()
        job.progress = 100.0

        # Final metrics from evaluation
        if "validation" in tokenized_dataset:
            final_metrics = trainer.evaluate()
            job.metrics.accuracy = final_metrics.get("eval_accuracy", 0.0)
            job.metrics.f1_score = final_metrics.get("eval_f1", 0.0)

        log.info(
            "Training completed",
            job_id=job.job_id,
            model_path=job.model_path,
            final_accuracy=job.metrics.accuracy,
        )

        # Emit completion event
        job.event_queue.append(
            {
                "type": "training_completed",
                "timestamp": datetime.utcnow().isoformat(),
                "job_id": job.job_id,
                "progress": 100.0,
                "state": JobState.COMPLETED.value,
                "model_path": job.model_path,
                "metrics": asdict(job.metrics),
            }
        )

    except Exception as e:
        job.state = JobState.FAILED
        job.error_message = str(e)
        job.completed_at = datetime.utcnow().isoformat()
        log.error("Training failed", job_id=job.job_id, error=str(e), exc_info=True)

        # Emit failure event
        job.event_queue.append(
            {
                "type": "training_failed",
                "timestamp": datetime.utcnow().isoformat(),
                "job_id": job.job_id,
                "state": JobState.FAILED.value,
                "error": str(e),
            }
        )


async def run_training_with_persistence(job: TrainingJob):
    """
    Wrapper around run_training that persists state changes to Redis.
    """
    try:
        # Save initial state
        if state_store:
            await state_store.save_job(job.job_id, job)

        # Run the actual training
        await run_training(job)

    finally:
        # Always save final state (success or failure)
        if state_store:
            await state_store.save_job(job.job_id, job)
            log.info("Job state persisted", job_id=job.job_id, state=job.state.value)


# =============================================================================
# FastAPI Application
# =============================================================================


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan manager."""
    global state_store

    log.info(
        "ML Training Service starting",
        model_dir=str(MODEL_DIR),
        dataset_dir=str(DATASET_DIR),
        max_concurrent_jobs=MAX_CONCURRENT_JOBS,
    )

    # Initialize state store
    from state_store import get_state_store

    state_store = await get_state_store()

    # Load existing jobs from Redis into memory
    if state_store.is_redis_connected:
        log.info("Redis connected, loading persisted jobs")
        memory_store = state_store.get_memory_store()
        with jobs_lock:
            for job_id, job_data in memory_store.items():
                # Reconstruct TrainingJob from stored data
                try:
                    job = TrainingJob(
                        job_id=job_data.get("job_id", job_id),
                        model_name=job_data.get("model_name", "unknown"),
                        model_type=ModelType(job_data.get("model_type", "sentiment")),
                        dataset_path=job_data.get("dataset_path", ""),
                        dataset_format=job_data.get("dataset_format", "csv"),
                        base_model=job_data.get("base_model"),
                        max_epochs=job_data.get("max_epochs", 3),
                        validation_split=job_data.get("validation_split", 0.1),
                        hyperparameters=job_data.get("hyperparameters", {}),
                        callbacks=job_data.get("callbacks", {}),
                        metadata=job_data.get("metadata", {}),
                        state=JobState(job_data.get("state", "PENDING")),
                        progress=job_data.get("progress", 0.0),
                        error_message=job_data.get("error_message"),
                        model_path=job_data.get("model_path"),
                        created_at=job_data.get(
                            "created_at", datetime.utcnow().isoformat()
                        ),
                        started_at=job_data.get("started_at"),
                        completed_at=job_data.get("completed_at"),
                        # External training fields
                        is_external=job_data.get("is_external", False),
                        upload_token=job_data.get("upload_token"),
                        external_worker_info=job_data.get("external_worker_info", {}),
                    )
                    # Restore metrics
                    if "metrics" in job_data:
                        m = job_data["metrics"]
                        job.metrics = TrainingMetrics(
                            epoch=m.get("epoch", 0),
                            total_epochs=m.get("total_epochs", 0),
                            step=m.get("step", 0),
                            total_steps=m.get("total_steps", 0),
                            loss=m.get("loss", 0.0),
                            accuracy=m.get("accuracy", 0.0),
                            validation_loss=m.get("validation_loss", 0.0),
                            validation_accuracy=m.get("validation_accuracy", 0.0),
                            learning_rate=m.get("learning_rate", 0.0),
                            samples_processed=m.get("samples_processed", 0),
                            total_samples=m.get("total_samples", 0),
                            f1_score=m.get("f1_score", 0.0),
                            precision=m.get("precision", 0.0),
                            recall=m.get("recall", 0.0),
                        )
                    jobs[job_id] = job
                    log.info(
                        "Loaded persisted job", job_id=job_id, state=job.state.value
                    )
                except Exception as e:
                    log.warning("Failed to restore job", job_id=job_id, error=str(e))
    else:
        log.warning(
            "Redis not available, using in-memory storage only (data will be lost on restart)"
        )

    yield

    # Cleanup: save all jobs before shutdown
    if state_store:
        log.info("Saving jobs before shutdown")
        with jobs_lock:
            for job_id, job in jobs.items():
                await state_store.save_job(job_id, job)
        await state_store.disconnect()

    log.info("ML Training Service shutting down")


app = FastAPI(
    title="ML Training Service",
    description="Production ML model training service for sentiment analysis, ABSA, NER, and more",
    version="2.0.0",
    lifespan=lifespan,
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Health check endpoint for service discovery."""
    try:
        import torch

        gpu_available = torch.cuda.is_available()
    except ImportError:
        gpu_available = False

    with jobs_lock:
        active_jobs = sum(
            1
            for j in jobs.values()
            if j.state in [JobState.RUNNING, JobState.INITIALIZING]
        )

    return HealthResponse(
        status="healthy",
        version="2.0.0",
        gpu_available=gpu_available,
        active_jobs=active_jobs,
        supported_model_types=[t.value for t in ModelType],
        max_concurrent_jobs=MAX_CONCURRENT_JOBS,
        redis_connected=state_store.is_redis_connected if state_store else False,
        persisted_jobs=len(state_store.get_memory_store()) if state_store else 0,
    )


@app.post("/train", response_model=TrainingResponse)
async def submit_training_job(
    request: TrainingRequest, background_tasks: BackgroundTasks
):
    """Submit a new training job."""
    # Check concurrent job limit
    with jobs_lock:
        active_jobs = sum(
            1
            for j in jobs.values()
            if j.state in [JobState.RUNNING, JobState.INITIALIZING, JobState.PENDING]
        )
        if active_jobs >= MAX_CONCURRENT_JOBS:
            raise HTTPException(
                status_code=429,
                detail=f"Maximum concurrent jobs ({MAX_CONCURRENT_JOBS}) reached. Please wait.",
            )

    job_id = str(uuid.uuid4())

    try:
        model_type = ModelType(request.model_type.lower())
    except ValueError:
        raise HTTPException(
            status_code=400,
            detail=f"Invalid model type: {request.model_type}. "
            f"Supported types: {[t.value for t in ModelType]}",
        )

    job = TrainingJob(
        job_id=job_id,
        model_name=request.model_name,
        model_type=model_type,
        dataset_path=request.dataset_path,
        dataset_format=request.dataset_format,
        base_model=request.base_model,
        max_epochs=request.max_epochs,
        validation_split=request.validation_split,
        hyperparameters=request.hyperparameters,
        callbacks=request.callbacks,
        metadata=request.metadata,
    )

    with jobs_lock:
        jobs[job_id] = job

    # Persist job to Redis
    if state_store:
        await state_store.save_job(job_id, job)

    # Start training in background - ALWAYS use real training
    background_tasks.add_task(run_training_with_persistence, job)

    log.info("Training job submitted", job_id=job_id, model_name=request.model_name)

    return TrainingResponse(
        job_id=job_id,
        model_name=job.model_name,
        model_type=job.model_type.value,
        state=job.state.value,
        progress=job.progress,
        created_at=job.created_at,
        message="Training job submitted successfully",
    )


@app.get("/jobs/{job_id}/status", response_model=JobStatusResponse)
async def get_job_status(job_id: str):
    """Get the status of a training job."""
    with jobs_lock:
        if job_id not in jobs:
            raise HTTPException(status_code=404, detail=f"Job not found: {job_id}")
        job = jobs[job_id]

    return JobStatusResponse(
        job_id=job.job_id,
        model_name=job.model_name,
        model_type=job.model_type.value,
        state=job.state.value,
        progress=round(job.progress, 2),
        metrics=asdict(job.metrics),
        error_message=job.error_message,
        model_path=job.model_path,
        created_at=job.created_at,
        started_at=job.started_at,
        completed_at=job.completed_at,
        current_epoch=job.metrics.epoch,
        total_epochs=job.metrics.total_epochs,
    )


@app.get("/jobs/{job_id}/stream")
async def stream_job_status(job_id: str):
    """
    SSE endpoint for real-time training progress updates.
    """
    with jobs_lock:
        if job_id not in jobs:
            raise HTTPException(status_code=404, detail=f"Job not found: {job_id}")

    async def event_generator() -> AsyncGenerator[str, None]:
        last_sent_index = 0

        while True:
            with jobs_lock:
                if job_id not in jobs:
                    break
                job = jobs[job_id]

                # Send any new events
                events = list(job.event_queue)
                new_events = events[last_sent_index:]
                last_sent_index = len(events)

            for event in new_events:
                yield f"data: {json.dumps(event)}\n\n"

            # Check if job is done
            if job.state in [JobState.COMPLETED, JobState.FAILED, JobState.CANCELLED]:
                # Send final status
                final_event = {
                    "type": "job_finished",
                    "job_id": job_id,
                    "state": job.state.value,
                    "progress": job.progress,
                    "model_path": job.model_path,
                    "error_message": job.error_message,
                }
                yield f"data: {json.dumps(final_event)}\n\n"
                break

            await asyncio.sleep(1)  # Poll interval

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
        },
    )


@app.post("/jobs/{job_id}/cancel")
async def cancel_job(job_id: str):
    """Cancel a training job."""
    with jobs_lock:
        if job_id not in jobs:
            raise HTTPException(status_code=404, detail=f"Job not found: {job_id}")

        job = jobs[job_id]

        if job.state not in [JobState.PENDING, JobState.RUNNING, JobState.INITIALIZING]:
            raise HTTPException(
                status_code=400, detail=f"Cannot cancel job in state: {job.state.value}"
            )

        job.state = JobState.CANCELLED
        job.completed_at = datetime.utcnow().isoformat()

    log.info("Training job cancelled", job_id=job_id)

    return {"success": True, "message": "Job cancelled successfully"}


@app.get("/jobs/{job_id}/artifact", response_model=ModelArtifactResponse)
async def get_model_artifact(job_id: str):
    """Get the trained model artifact information."""
    with jobs_lock:
        if job_id not in jobs:
            raise HTTPException(status_code=404, detail=f"Job not found: {job_id}")
        job = jobs[job_id]

    if job.state != JobState.COMPLETED:
        raise HTTPException(
            status_code=400, detail=f"Model not available. Job state: {job.state.value}"
        )

    if not job.model_path or not Path(str(job.model_path)).exists():
        raise HTTPException(status_code=404, detail="Model artifact not found")

    # Calculate file size and checksum
    model_path = Path(job.model_path)

    # Get total size of all files in directory
    size_bytes = sum(f.stat().st_size for f in model_path.rglob("*") if f.is_file())

    # Checksum of the config file
    config_file = model_path / "config.json"
    if config_file.exists():
        with open(config_file, "rb") as f:
            checksum = hashlib.sha256(f.read()).hexdigest()
    else:
        checksum = "directory"

    return ModelArtifactResponse(
        model_path=str(job.model_path),
        model_name=job.model_name,
        model_type=job.model_type.value,
        framework="pytorch",
        version="1.0.0",
        size_bytes=size_bytes,
        checksum=checksum,
        metrics={
            "accuracy": job.metrics.accuracy,
            "f1_score": job.metrics.f1_score,
            "precision": job.metrics.precision,
            "recall": job.metrics.recall,
            "final_loss": job.metrics.loss,
        },
        model_filename=f"{job.model_name}_{job.job_id[:8]}",
    )


@app.get("/jobs/{job_id}/model/meta")
async def get_model_metadata(job_id: str):
    """Get model metadata for download."""
    with jobs_lock:
        if job_id not in jobs:
            raise HTTPException(status_code=404, detail=f"Job not found: {job_id}")
        job = jobs[job_id]

    if job.state != JobState.COMPLETED:
        raise HTTPException(status_code=400, detail="Model not ready")

    model_path = Path(job.model_path)
    size_bytes = sum(f.stat().st_size for f in model_path.rglob("*") if f.is_file())

    return {
        "model_name": job.model_name,
        "model_type": job.model_type.value,
        "model_filename": f"{job.model_name}_{job.job_id[:8]}",
        "format": "huggingface",
        "size_bytes": size_bytes,
        "metrics": asdict(job.metrics),
        "checksum": "directory",
        "version": "1.0.0",
    }


@app.get("/jobs")
async def list_jobs(
    state: Optional[str] = None, model_type: Optional[str] = None, limit: int = 50
):
    """List training jobs with optional filtering."""
    result = []

    with jobs_lock:
        for job in list(jobs.values())[-limit:]:
            if state and job.state.value.lower() != state.lower():
                continue
            if model_type and job.model_type.value.lower() != model_type.lower():
                continue

            result.append(
                {
                    "job_id": job.job_id,
                    "model_name": job.model_name,
                    "model_type": job.model_type.value,
                    "state": job.state.value,
                    "progress": round(job.progress, 2),
                    "created_at": job.created_at,
                    "completed_at": job.completed_at,
                }
            )

    return {"jobs": result, "total": len(result)}


@app.get("/models")
async def list_models():
    """List available trained models."""
    models = []

    with jobs_lock:
        for job in jobs.values():
            if job.state == JobState.COMPLETED and job.model_path:
                models.append(
                    {
                        "job_id": job.job_id,
                        "model_name": job.model_name,
                        "model_type": job.model_type.value,
                        "model_path": job.model_path,
                        "accuracy": job.metrics.accuracy,
                        "f1_score": job.metrics.f1_score,
                        "completed_at": job.completed_at,
                    }
                )

    return {"models": models, "total": len(models)}


@app.get("/supported-types")
async def get_supported_types():
    """Get list of supported model types with their default configurations."""
    return {
        "types": [
            {
                "type": t.value,
                "default_base_model": get_default_base_model(t),
                "description": get_model_type_description(t),
            }
            for t in ModelType
        ]
    }


def get_model_type_description(model_type: ModelType) -> str:
    """Returns description for each model type."""
    descriptions = {
        ModelType.SENTIMENT: "Binary or multi-class sentiment classification",
        ModelType.ABSA: "Aspect-Based Sentiment Analysis for fine-grained opinion mining",
        ModelType.NER: "Named Entity Recognition for extracting entities from text",
        ModelType.CLASSIFICATION: "General text classification for custom categories",
        ModelType.EMBEDDING: "Text embedding models for semantic similarity",
        ModelType.TRANSFORMER: "Custom transformer models for various NLP tasks",
    }
    return descriptions.get(model_type, "")


# =============================================================================
# External Training API (Colab/Jupyter Integration)
# =============================================================================


def _verify_upload_token(job_id: str, token: str) -> TrainingJob:
    """Verify upload token and return the job if valid."""
    with jobs_lock:
        if job_id not in jobs:
            raise HTTPException(status_code=404, detail=f"Job not found: {job_id}")
        job = jobs[job_id]
        if not job.is_external:
            raise HTTPException(
                status_code=400, detail="This job is not an external training job"
            )
        if job.upload_token != token:
            raise HTTPException(status_code=403, detail="Invalid upload token")
        return job


@app.post("/train/external/start", response_model=ExternalTrainingStartResponse)
async def start_external_training(request: ExternalTrainingStartRequest):
    """
    Start an external training session (Colab/Jupyter).

    Returns a job_id and upload_token that the external worker uses to:
    - Report training progress via POST /jobs/{job_id}/progress
    - Upload the trained model via POST /jobs/{job_id}/upload
    - Mark training as complete via POST /jobs/{job_id}/complete
    """
    job_id = str(uuid.uuid4())
    upload_token = secrets.token_urlsafe(32)

    try:
        model_type = ModelType(request.model_type.lower())
    except ValueError:
        raise HTTPException(
            status_code=400,
            detail=f"Invalid model type: {request.model_type}. "
            f"Supported types: {[t.value for t in ModelType]}",
        )

    job = TrainingJob(
        job_id=job_id,
        model_name=request.model_name,
        model_type=model_type,
        dataset_path="external",  # Not applicable for external training
        dataset_format="external",
        base_model=request.base_model,
        max_epochs=request.max_epochs,
        validation_split=0.0,
        metadata=request.metadata,
        state=JobState.PENDING,
        is_external=True,
        upload_token=upload_token,
        external_worker_info={
            "registered_at": datetime.utcnow().isoformat(),
            "source": request.metadata.get("source", "unknown"),
        },
    )

    with jobs_lock:
        jobs[job_id] = job

    # Persist job to Redis
    if state_store:
        await state_store.save_job(job_id, job)

    log.info(
        "External training session started",
        job_id=job_id,
        model_name=request.model_name,
        model_type=model_type.value,
    )

    return ExternalTrainingStartResponse(
        job_id=job_id,
        upload_token=upload_token,
        model_name=job.model_name,
        model_type=job.model_type.value,
        state=job.state.value,
        created_at=job.created_at,
        message="External training session created. Use the upload_token for progress updates and model upload.",
        api_endpoints={
            "progress": f"/jobs/{job_id}/progress",
            "upload": f"/jobs/{job_id}/upload",
            "complete": f"/jobs/{job_id}/complete",
            "status": f"/jobs/{job_id}/status",
            "stream": f"/jobs/{job_id}/stream",
        },
    )


@app.post("/jobs/{job_id}/progress")
async def report_external_progress(job_id: str, request: ExternalProgressRequest):
    """
    Report training progress from external worker (Colab/Jupyter).

    The external worker should call this endpoint periodically to update
    the dashboard with current training metrics.
    """
    job = _verify_upload_token(job_id, request.upload_token)

    # Update job state if still pending
    if job.state == JobState.PENDING:
        job.state = JobState.RUNNING
        job.started_at = datetime.utcnow().isoformat()

    # Update progress and metrics
    job.progress = request.progress
    job.metrics.epoch = request.epoch
    job.metrics.total_epochs = request.total_epochs
    job.metrics.step = request.step
    job.metrics.total_steps = request.total_steps
    job.metrics.loss = request.loss
    job.metrics.accuracy = request.accuracy
    job.metrics.validation_loss = request.validation_loss
    job.metrics.validation_accuracy = request.validation_accuracy
    job.metrics.f1_score = request.f1_score
    job.metrics.learning_rate = request.learning_rate

    # Emit SSE event
    event = {
        "type": "external_progress",
        "timestamp": datetime.utcnow().isoformat(),
        "job_id": job_id,
        "progress": round(job.progress, 2),
        "state": job.state.value,
        "metrics": {
            "epoch": job.metrics.epoch,
            "total_epochs": job.metrics.total_epochs,
            "step": job.metrics.step,
            "loss": round(job.metrics.loss, 4) if job.metrics.loss else 0,
            "accuracy": round(job.metrics.accuracy, 4) if job.metrics.accuracy else 0,
            "validation_loss": round(job.metrics.validation_loss, 4)
            if job.metrics.validation_loss
            else 0,
            "validation_accuracy": round(job.metrics.validation_accuracy, 4)
            if job.metrics.validation_accuracy
            else 0,
            "f1_score": round(job.metrics.f1_score, 4) if job.metrics.f1_score else 0,
        },
        "message": request.message,
    }
    job.event_queue.append(event)

    # Persist to Redis
    if state_store:
        await state_store.save_job(job_id, job)

    log.debug(
        "External progress reported",
        job_id=job_id,
        progress=job.progress,
        epoch=job.metrics.epoch,
    )

    return {
        "success": True,
        "job_id": job_id,
        "progress": job.progress,
        "state": job.state.value,
    }


@app.post("/jobs/{job_id}/upload")
async def upload_external_model(
    job_id: str,
    upload_token: str = Form(...),
    model_file: UploadFile = File(...),
):
    """
    Upload trained model artifact from external worker (Colab/Jupyter).

    Accepts .pt, .pth, .bin, .safetensors, .h5, .pkl, .joblib, .onnx files,
    or a .zip archive containing the model directory.
    """
    job = _verify_upload_token(job_id, upload_token)

    # Validate file extension
    allowed_extensions = {
        ".pt",
        ".pth",
        ".bin",
        ".safetensors",
        ".h5",
        ".pkl",
        ".joblib",
        ".onnx",
        ".zip",
    }
    file_ext = Path(model_file.filename or "").suffix.lower()
    if file_ext not in allowed_extensions:
        raise HTTPException(
            status_code=400,
            detail=f"Unsupported file type: {file_ext}. Allowed: {allowed_extensions}",
        )

    # Create model directory
    model_dir = MODEL_DIR / job_id / "external"
    model_dir.mkdir(parents=True, exist_ok=True)

    try:
        if file_ext == ".zip":
            # Save and extract zip file
            zip_path = model_dir / "model.zip"
            with open(zip_path, "wb") as f:
                content = await model_file.read()
                f.write(content)

            # Extract zip contents
            with zipfile.ZipFile(zip_path, "r") as zip_ref:
                zip_ref.extractall(model_dir)

            # Remove the zip file after extraction
            zip_path.unlink()
            log.info("Model zip extracted", job_id=job_id, path=str(model_dir))
        else:
            # Save single file
            file_path = model_dir / (model_file.filename or f"model{file_ext}")
            with open(file_path, "wb") as f:
                content = await model_file.read()
                f.write(content)
            log.info("Model file saved", job_id=job_id, path=str(file_path))

        # Update job with model path
        job.model_path = str(model_dir)
        job.external_worker_info["model_uploaded_at"] = datetime.utcnow().isoformat()
        job.external_worker_info["original_filename"] = model_file.filename

        # Persist to Redis
        if state_store:
            await state_store.save_job(job_id, job)

        # Emit SSE event
        event = {
            "type": "model_uploaded",
            "timestamp": datetime.utcnow().isoformat(),
            "job_id": job_id,
            "model_path": job.model_path,
        }
        job.event_queue.append(event)

        return {
            "success": True,
            "job_id": job_id,
            "model_path": job.model_path,
            "message": "Model uploaded successfully",
        }

    except Exception as e:
        log.error("Model upload failed", job_id=job_id, error=str(e))
        raise HTTPException(status_code=500, detail=f"Upload failed: {str(e)}")


@app.post("/jobs/{job_id}/complete")
async def complete_external_training(job_id: str, request: ExternalCompleteRequest):
    """
    Mark external training job as complete.

    Should be called after the model has been uploaded (or if using external storage).
    """
    job = _verify_upload_token(job_id, request.upload_token)

    if job.state == JobState.COMPLETED:
        return {
            "success": True,
            "job_id": job_id,
            "message": "Job already completed",
            "state": job.state.value,
        }

    # Update final metrics if provided
    if request.final_metrics:
        job.metrics.accuracy = request.final_metrics.get(
            "accuracy", job.metrics.accuracy
        )
        job.metrics.f1_score = request.final_metrics.get(
            "f1_score", job.metrics.f1_score
        )
        job.metrics.precision = request.final_metrics.get(
            "precision", job.metrics.precision
        )
        job.metrics.recall = request.final_metrics.get("recall", job.metrics.recall)
        job.metrics.loss = request.final_metrics.get("loss", job.metrics.loss)
        job.metrics.validation_loss = request.final_metrics.get(
            "validation_loss", job.metrics.validation_loss
        )
        job.metrics.validation_accuracy = request.final_metrics.get(
            "validation_accuracy", job.metrics.validation_accuracy
        )

    # Update model path if provided
    if request.model_path:
        job.model_path = request.model_path

    # Mark as complete
    job.state = JobState.COMPLETED
    job.progress = 100.0
    job.completed_at = datetime.utcnow().isoformat()

    # Create training info file
    if job.model_path:
        training_info_path = Path(job.model_path) / "training_info.json"
        if training_info_path.parent.exists():
            training_info = {
                "job_id": job.job_id,
                "model_name": job.model_name,
                "model_type": job.model_type.value,
                "base_model": job.base_model,
                "is_external": True,
                "source": job.external_worker_info.get("source", "external"),
                "final_metrics": asdict(job.metrics),
                "completed_at": job.completed_at,
            }
            try:
                with open(training_info_path, "w") as f:
                    json.dump(training_info, f, indent=2)
            except Exception as e:
                log.warning("Failed to save training info", error=str(e))

    # Persist to Redis
    if state_store:
        await state_store.save_job(job_id, job)

    # Emit SSE event
    event = {
        "type": "training_completed",
        "timestamp": datetime.utcnow().isoformat(),
        "job_id": job_id,
        "progress": 100.0,
        "state": JobState.COMPLETED.value,
        "model_path": job.model_path,
        "metrics": asdict(job.metrics),
    }
    job.event_queue.append(event)

    log.info(
        "External training completed",
        job_id=job_id,
        model_name=job.model_name,
        model_path=job.model_path,
        accuracy=job.metrics.accuracy,
    )

    return {
        "success": True,
        "job_id": job_id,
        "state": job.state.value,
        "model_path": job.model_path,
        "metrics": asdict(job.metrics),
        "message": "External training completed successfully",
    }


# =============================================================================
# Inference API
# =============================================================================


# Global model cache for inference
_model_cache: dict[str, tuple] = {}  # job_id -> (tokenizer, model)
_model_cache_lock = threading.Lock()


class InferenceRequest(BaseModel):
    """Request for model inference."""

    text: str = Field(
        ..., min_length=1, max_length=10000, description="Text to analyze"
    )
    texts: Optional[list[str]] = Field(
        None, description="Batch of texts (alternative to single text)"
    )
    aspects: Optional[list[str]] = Field(
        None, description="Aspects to analyze (for ABSA)"
    )
    max_length: int = Field(512, ge=32, le=2048, description="Maximum token length")
    return_probabilities: bool = Field(True, description="Return class probabilities")


class AspectSentiment(BaseModel):
    """Aspect sentiment result."""

    sentimentScore: float = Field(
        ..., ge=-1.0, le=1.0, description="Sentiment score -1 to 1"
    )
    sentimentLabel: str = Field(..., description="positive/negative/neutral")
    confidence: float = Field(..., ge=0.0, le=1.0, description="Confidence score")


class OverallSentiment(BaseModel):
    """Overall sentiment result."""

    score: float = Field(..., ge=-1.0, le=1.0)
    label: str


class InferenceResponse(BaseModel):
    """Response from model inference."""

    analysisId: str
    contentId: Optional[str] = None
    textPreview: str
    aspectsAnalyzed: list[str]
    aspectSentiments: dict[str, AspectSentiment]
    overallSentiment: OverallSentiment
    confidence: float
    analyzedAt: str
    modelUsed: str
    modelType: str
    responseTimeMs: int


def load_model_for_inference(job_id: str) -> tuple:
    """
    Load a trained model for inference with caching.
    Returns (tokenizer, model) tuple.
    """
    with _model_cache_lock:
        if job_id in _model_cache:
            return _model_cache[job_id]

    # Get job info
    with jobs_lock:
        if job_id not in jobs:
            raise HTTPException(status_code=404, detail=f"Job not found: {job_id}")
        job = jobs[job_id]

    if job.state != JobState.COMPLETED:
        raise HTTPException(
            status_code=400, detail=f"Model not available. Job state: {job.state.value}"
        )

    if not job.model_path or not Path(job.model_path).exists():
        raise HTTPException(status_code=404, detail="Model artifact not found")

    try:
        from transformers import AutoTokenizer, AutoModelForSequenceClassification
        import torch

        model_path = job.model_path
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model = AutoModelForSequenceClassification.from_pretrained(model_path)

        # Move to GPU if available
        device = "cuda" if USE_GPU and torch.cuda.is_available() else "cpu"
        model = model.to(device)
        model.eval()

        with _model_cache_lock:
            _model_cache[job_id] = (tokenizer, model, device)

        log.info("Model loaded for inference", job_id=job_id, device=device)
        return tokenizer, model, device

    except Exception as e:
        log.error("Failed to load model", job_id=job_id, error=str(e))
        raise HTTPException(status_code=500, detail=f"Failed to load model: {str(e)}")


def compute_sentiment_label(score: float) -> str:
    """Convert sentiment score to label."""
    if score > 0.1:
        return "positive"
    elif score < -0.1:
        return "negative"
    return "neutral"


@app.post("/inference/{job_id}", response_model=InferenceResponse)
async def run_inference(job_id: str, request: InferenceRequest):
    """
    Run inference using a trained model.

    For ABSA models, analyzes sentiment for each aspect.
    For sentiment/classification models, returns overall sentiment.
    """
    import time
    import torch

    start_time = time.time()

    # Load model
    tokenizer, model, device = load_model_for_inference(job_id)

    # Get job info for model type
    with jobs_lock:
        job = jobs[job_id]

    texts = request.texts or [request.text]
    aspects = request.aspects or []

    # For ABSA: if no aspects provided, analyze full text
    if not aspects:
        aspects = ["전체"]  # Default aspect

    aspect_sentiments: dict[str, AspectSentiment] = {}
    all_scores = []

    try:
        for aspect in aspects:
            # For ABSA, combine aspect with text
            if job.model_type == ModelType.ABSA and aspect != "전체":
                input_text = f"[{aspect}] {texts[0]}"
            else:
                input_text = texts[0]

            # Tokenize
            inputs = tokenizer(
                input_text,
                return_tensors="pt",
                truncation=True,
                max_length=request.max_length,
                padding=True,
            )
            inputs = {k: v.to(device) for k, v in inputs.items()}

            # Inference
            with torch.no_grad():
                outputs = model(**inputs)

            logits = outputs.logits
            probabilities = torch.softmax(logits, dim=-1).cpu().numpy()[0]

            # Determine sentiment (assuming binary or 3-class classification)
            num_classes = len(probabilities)

            if num_classes == 2:
                # Binary: [negative, positive]
                sentiment_score = float(probabilities[1] - probabilities[0])
                confidence = float(max(probabilities))
            elif num_classes == 3:
                # 3-class: [negative, neutral, positive]
                sentiment_score = float(probabilities[2] - probabilities[0])
                confidence = float(max(probabilities))
            else:
                # Multi-class: use argmax
                predicted_class = int(probabilities.argmax())
                sentiment_score = (
                    float(2 * (predicted_class / (num_classes - 1)) - 1)
                    if num_classes > 1
                    else 0.0
                )
                confidence = float(probabilities[predicted_class])

            all_scores.append(sentiment_score)

            aspect_sentiments[aspect] = AspectSentiment(
                sentimentScore=round(sentiment_score, 4),
                sentimentLabel=compute_sentiment_label(sentiment_score),
                confidence=round(confidence, 4),
            )

        # Compute overall sentiment (average of all aspects)
        overall_score = sum(all_scores) / len(all_scores) if all_scores else 0.0
        overall_confidence = (
            sum(a.confidence for a in aspect_sentiments.values())
            / len(aspect_sentiments)
            if aspect_sentiments
            else 0.0
        )

        response_time_ms = int((time.time() - start_time) * 1000)

        return InferenceResponse(
            analysisId=str(uuid.uuid4()),
            contentId=None,
            textPreview=texts[0][:200] + "..." if len(texts[0]) > 200 else texts[0],
            aspectsAnalyzed=list(aspect_sentiments.keys()),
            aspectSentiments=aspect_sentiments,
            overallSentiment=OverallSentiment(
                score=round(overall_score, 4),
                label=compute_sentiment_label(overall_score),
            ),
            confidence=round(overall_confidence, 4),
            analyzedAt=datetime.utcnow().isoformat(),
            modelUsed=job.model_name,
            modelType=job.model_type.value,
            responseTimeMs=response_time_ms,
        )

    except Exception as e:
        log.error("Inference failed", job_id=job_id, error=str(e), exc_info=True)
        raise HTTPException(status_code=500, detail=f"Inference failed: {str(e)}")


@app.post("/inference/by-name/{model_name}", response_model=InferenceResponse)
async def run_inference_by_name(model_name: str, request: InferenceRequest):
    """
    Run inference using a model by name (uses latest completed model with that name).
    """
    # Find the latest completed job with this model name
    job_id = None
    latest_completed_at = None

    with jobs_lock:
        for job in jobs.values():
            if (
                job.model_name == model_name
                and job.state == JobState.COMPLETED
                and job.model_path
            ):
                if latest_completed_at is None or (
                    job.completed_at and job.completed_at > latest_completed_at
                ):
                    job_id = job.job_id
                    latest_completed_at = job.completed_at

    if not job_id:
        raise HTTPException(
            status_code=404, detail=f"No completed model found with name: {model_name}"
        )

    return await run_inference(job_id, request)


@app.delete("/inference/cache/{job_id}")
async def clear_model_cache(job_id: str):
    """Clear a model from the inference cache to free memory."""
    with _model_cache_lock:
        if job_id in _model_cache:
            del _model_cache[job_id]
            return {"success": True, "message": f"Model {job_id} removed from cache"}
    return {"success": False, "message": "Model not in cache"}


@app.get("/inference/cache/status")
async def get_cache_status():
    """Get inference cache status."""
    with _model_cache_lock:
        cached_models = list(_model_cache.keys())
    return {
        "cached_models": cached_models,
        "total_cached": len(cached_models),
    }


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8090)

```

---

## backend/ml-addons/ml-trainer/notebooks/main_ref.py

```py
"""
ML Training Service - Production Version

FastAPI-based ML training service that supports multiple model types:
- Sentiment Analysis (BERT-based)
- ABSA (Aspect-Based Sentiment Analysis)
- NER (Named Entity Recognition)
- Text Classification
- Embedding Models

This service performs REAL training using HuggingFace Transformers.
"""

import os
import uuid
import json
import asyncio
import hashlib
import threading
from datetime import datetime
from pathlib import Path
from typing import Optional, AsyncGenerator
from enum import Enum
from dataclasses import dataclass, field, asdict
from contextlib import asynccontextmanager
from collections import deque

import structlog
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field

# Configure structlog
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer(),
    ],
    wrapper_class=structlog.stdlib.BoundLogger,
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    cache_logger_on_first_use=True,
)

log = structlog.get_logger()

# Environment configuration
MODEL_DIR = Path(os.getenv("MODEL_DIR", "/app/models"))
DATASET_DIR = Path(os.getenv("DATASET_DIR", "/app/datasets"))
LOG_DIR = Path(os.getenv("LOG_DIR", "/app/logs"))
USE_GPU = os.getenv("USE_GPU", "true").lower() == "true"
MAX_CONCURRENT_JOBS = int(os.getenv("MAX_CONCURRENT_JOBS", "2"))

# Ensure directories exist
MODEL_DIR.mkdir(parents=True, exist_ok=True)
DATASET_DIR.mkdir(parents=True, exist_ok=True)
LOG_DIR.mkdir(parents=True, exist_ok=True)


# =============================================================================
# Enums and Data Classes
# =============================================================================


class JobState(str, Enum):
    PENDING = "PENDING"
    INITIALIZING = "INITIALIZING"
    RUNNING = "RUNNING"
    COMPLETED = "COMPLETED"
    FAILED = "FAILED"
    CANCELLED = "CANCELLED"


class ModelType(str, Enum):
    SENTIMENT = "sentiment"
    ABSA = "absa"
    NER = "ner"
    CLASSIFICATION = "classification"
    EMBEDDING = "embedding"
    TRANSFORMER = "transformer"


@dataclass
class TrainingMetrics:
    epoch: int = 0
    total_epochs: int = 0
    step: int = 0
    total_steps: int = 0
    loss: float = 0.0
    accuracy: float = 0.0
    validation_loss: float = 0.0
    validation_accuracy: float = 0.0
    learning_rate: float = 0.0
    samples_processed: int = 0
    total_samples: int = 0
    f1_score: float = 0.0
    precision: float = 0.0
    recall: float = 0.0


@dataclass
class TrainingJob:
    job_id: str
    model_name: str
    model_type: ModelType
    dataset_path: str
    dataset_format: str
    base_model: Optional[str]
    max_epochs: int
    validation_split: float
    hyperparameters: dict = field(default_factory=dict)
    callbacks: dict = field(default_factory=dict)
    metadata: dict = field(default_factory=dict)
    state: JobState = JobState.PENDING
    progress: float = 0.0
    metrics: TrainingMetrics = field(default_factory=TrainingMetrics)
    error_message: Optional[str] = None
    model_path: Optional[str] = None
    created_at: str = field(default_factory=lambda: datetime.utcnow().isoformat())
    started_at: Optional[str] = None
    completed_at: Optional[str] = None
    # For SSE streaming
    event_queue: deque = field(default_factory=lambda: deque(maxlen=100))


# In-memory job storage (backed by Redis via state_store)
# This dict is a cache, actual persistence is handled by StateStore
jobs: dict[str, TrainingJob] = {}
# Lock for thread-safe operations
jobs_lock = threading.Lock()

# State store instance (initialized in lifespan)
state_store = None


# =============================================================================
# Pydantic Models for API
# =============================================================================


class TrainingRequest(BaseModel):
    model_name: str = Field(..., description="Name of the model to train")
    model_type: str = Field(
        ..., description="Type of model (sentiment, absa, ner, etc.)"
    )
    dataset_path: str = Field(..., description="Path to training dataset")
    dataset_format: str = Field(
        default="csv", description="Format of dataset (csv, jsonl, parquet)"
    )
    base_model: Optional[str] = Field(
        default=None, description="Base model for fine-tuning"
    )
    max_epochs: int = Field(
        default=3, ge=1, le=100, description="Maximum training epochs"
    )
    validation_split: float = Field(
        default=0.1, ge=0.0, le=0.5, description="Validation data split ratio"
    )
    hyperparameters: dict = Field(
        default_factory=dict, description="Training hyperparameters"
    )
    callbacks: dict = Field(default_factory=dict, description="Callback configurations")
    metadata: dict = Field(default_factory=dict, description="Additional metadata")


class TrainingResponse(BaseModel):
    job_id: str
    model_name: str
    model_type: str
    state: str
    progress: float
    created_at: str
    message: str


class JobStatusResponse(BaseModel):
    job_id: str
    model_name: str
    model_type: str
    state: str
    progress: float
    metrics: dict
    error_message: Optional[str]
    model_path: Optional[str]
    created_at: str
    started_at: Optional[str]
    completed_at: Optional[str]
    current_epoch: int = 0
    total_epochs: int = 0


class ModelArtifactResponse(BaseModel):
    model_path: str
    model_name: str
    model_type: str
    framework: str
    version: str
    size_bytes: int
    checksum: str
    metrics: dict
    model_filename: str


class HealthResponse(BaseModel):
    status: str
    version: str
    gpu_available: bool
    active_jobs: int
    supported_model_types: list[str]
    max_concurrent_jobs: int
    redis_connected: bool = False
    persisted_jobs: int = 0


# =============================================================================
# Training Progress Callback (Real HuggingFace Integration)
# =============================================================================


class TrainingProgressCallback:
    """Custom callback to track training progress for HuggingFace Trainer."""

    def __init__(self, job: TrainingJob):
        self.job = job

    def on_train_begin(self, args, state, control, **kwargs):
        self.job.metrics.total_steps = state.max_steps if state.max_steps else 0
        self.job.metrics.total_epochs = args.num_train_epochs
        self._emit_event(
            "training_started", {"total_steps": self.job.metrics.total_steps}
        )

    def on_step_end(self, args, state, control, **kwargs):
        self.job.metrics.step = state.global_step
        if state.max_steps:
            self.job.progress = (state.global_step / state.max_steps) * 100

        if state.log_history:
            latest = state.log_history[-1]
            self.job.metrics.loss = latest.get("loss", self.job.metrics.loss)
            self.job.metrics.learning_rate = latest.get(
                "learning_rate", self.job.metrics.learning_rate
            )

        self._emit_event(
            "step_completed",
            {
                "step": state.global_step,
                "progress": self.job.progress,
                "loss": self.job.metrics.loss,
            },
        )

    def on_epoch_end(self, args, state, control, **kwargs):
        self.job.metrics.epoch = int(state.epoch) if state.epoch else 0
        self._emit_event(
            "epoch_completed",
            {"epoch": self.job.metrics.epoch, "progress": self.job.progress},
        )

    def on_evaluate(self, args, state, control, metrics=None, **kwargs):
        if metrics:
            self.job.metrics.validation_loss = metrics.get("eval_loss", 0.0)
            self.job.metrics.validation_accuracy = metrics.get("eval_accuracy", 0.0)
            self.job.metrics.f1_score = metrics.get("eval_f1", 0.0)
            self._emit_event(
                "evaluation_completed",
                {
                    "eval_loss": self.job.metrics.validation_loss,
                    "eval_accuracy": self.job.metrics.validation_accuracy,
                },
            )

    def on_train_end(self, args, state, control, **kwargs):
        self._emit_event("training_ended", {"final_step": state.global_step})

    def _emit_event(self, event_type: str, data: dict):
        """Emit event to job's event queue for SSE streaming."""
        event = {
            "type": event_type,
            "timestamp": datetime.utcnow().isoformat(),
            "job_id": self.job.job_id,
            "progress": self.job.progress,
            "state": self.job.state.value,
            "metrics": asdict(self.job.metrics),
            **data,
        }
        self.job.event_queue.append(event)


# =============================================================================
# Real Training Logic
# =============================================================================


def get_default_base_model(model_type: ModelType) -> str:
    """Returns the default base model for each model type."""
    defaults = {
        ModelType.SENTIMENT: "klue/bert-base",
        ModelType.ABSA: "monologg/koelectra-base-v3-discriminator",
        ModelType.NER: "klue/bert-base",
        ModelType.CLASSIFICATION: "klue/roberta-base",
        ModelType.EMBEDDING: "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        ModelType.TRANSFORMER: "klue/bert-base",
    }
    return defaults.get(model_type, "klue/bert-base")


def load_dataset_from_path(
    dataset_path: str, dataset_format: str, validation_split: float
):
    """Load dataset from file path with proper format handling."""
    from datasets import load_dataset, Dataset, DatasetDict
    import pandas as pd

    path = Path(dataset_path)
    if not path.exists():
        # Check in DATASET_DIR
        path = DATASET_DIR / dataset_path
        if not path.exists():
            raise FileNotFoundError(f"Dataset not found: {dataset_path}")

    log.info("Loading dataset", path=str(path), format=dataset_format)

    if dataset_format == "csv":
        df = pd.read_csv(path)
    elif dataset_format == "jsonl":
        df = pd.read_json(path, lines=True)
    elif dataset_format == "json":
        df = pd.read_json(path)
    elif dataset_format == "parquet":
        df = pd.read_parquet(path)
    else:
        raise ValueError(f"Unsupported dataset format: {dataset_format}")

    # Convert to HuggingFace dataset
    dataset = Dataset.from_pandas(df)

    # Split into train/validation
    if validation_split > 0:
        split = dataset.train_test_split(test_size=validation_split, seed=42)
        return DatasetDict({"train": split["train"], "validation": split["test"]})
    else:
        return DatasetDict({"train": dataset})


def compute_metrics(eval_pred):
    """Compute evaluation metrics."""
    import numpy as np
    from sklearn.metrics import accuracy_score, precision_recall_fscore_support

    predictions, labels = eval_pred
    if isinstance(predictions, tuple):
        predictions = predictions[0]
    predictions = np.argmax(predictions, axis=-1)

    accuracy = accuracy_score(labels, predictions)
    precision, recall, f1, _ = precision_recall_fscore_support(
        labels, predictions, average="weighted", zero_division=0
    )

    return {"accuracy": accuracy, "precision": precision, "recall": recall, "f1": f1}


async def run_training(job: TrainingJob):
    """
    Runs actual training using HuggingFace Transformers.
    This is the production implementation.
    """
    try:
        # Import ML libraries
        import torch
        from transformers import (
            AutoTokenizer,
            AutoModelForSequenceClassification,
            Trainer,
            TrainingArguments,
            TrainerCallback,
            EarlyStoppingCallback,
        )

        job.state = JobState.INITIALIZING
        job.started_at = datetime.utcnow().isoformat()
        log.info(
            "Initializing training", job_id=job.job_id, model_type=job.model_type.value
        )

        # Determine device
        device = "cuda" if torch.cuda.is_available() and USE_GPU else "cpu"
        log.info(
            "Using device", device=device, cuda_available=torch.cuda.is_available()
        )

        # Determine base model
        base_model = job.base_model or get_default_base_model(job.model_type)
        log.info("Loading base model", base_model=base_model)

        # Load tokenizer and model
        tokenizer = AutoTokenizer.from_pretrained(base_model)

        # Load dataset
        dataset = load_dataset_from_path(
            job.dataset_path, job.dataset_format, job.validation_split
        )

        # Determine number of labels from dataset
        train_dataset = dataset["train"]
        if "label" in train_dataset.column_names:
            num_labels = len(set(train_dataset["label"]))
        elif "labels" in train_dataset.column_names:
            num_labels = len(set(train_dataset["labels"]))
        else:
            num_labels = 2  # Default binary classification

        log.info(
            "Dataset loaded", train_samples=len(train_dataset), num_labels=num_labels
        )

        job.metrics.total_samples = len(train_dataset)

        # Load model
        model = AutoModelForSequenceClassification.from_pretrained(
            base_model, num_labels=num_labels
        )
        model.to(device)

        # Tokenize dataset
        def tokenize_function(examples):
            # Try different text column names
            text_column = None
            for col in ["text", "content", "sentence", "review", "document"]:
                if col in examples:
                    text_column = col
                    break

            if text_column is None:
                raise ValueError(
                    f"No text column found. Available: {list(examples.keys())}"
                )

            return tokenizer(
                examples[text_column],
                padding="max_length",
                truncation=True,
                max_length=job.hyperparameters.get("max_length", 512),
            )

        tokenized_dataset = dataset.map(tokenize_function, batched=True)

        # Prepare output directory
        output_dir = MODEL_DIR / job.job_id
        output_dir.mkdir(parents=True, exist_ok=True)

        # Extract hyperparameters
        batch_size = job.hyperparameters.get("batch_size", 16)
        learning_rate = job.hyperparameters.get("learning_rate", 2e-5)
        warmup_steps = job.hyperparameters.get("warmup_steps", 500)
        weight_decay = job.hyperparameters.get("weight_decay", 0.01)

        # Training arguments
        training_args = TrainingArguments(
            output_dir=str(output_dir),
            num_train_epochs=job.max_epochs,
            per_device_train_batch_size=batch_size,
            per_device_eval_batch_size=batch_size,
            warmup_steps=warmup_steps,
            weight_decay=weight_decay,
            learning_rate=learning_rate,
            logging_dir=str(LOG_DIR / job.job_id),
            logging_steps=10,
            eval_strategy="epoch" if "validation" in tokenized_dataset else "no",
            save_strategy="epoch",
            load_best_model_at_end=True if "validation" in tokenized_dataset else False,
            save_total_limit=2,
            report_to=[],  # Disable wandb, etc.
            disable_tqdm=True,  # We use our own progress tracking
            fp16=torch.cuda.is_available()
            and USE_GPU,  # Use mixed precision if available
        )

        # Create custom callback for progress tracking
        class ProgressCallback(TrainerCallback):
            def __init__(self, training_job: TrainingJob):
                self.job = training_job

            def on_train_begin(self, args, state, control, **kwargs):
                self.job.state = JobState.RUNNING
                self.job.metrics.total_steps = state.max_steps or 0
                self.job.metrics.total_epochs = int(args.num_train_epochs)
                self._emit("training_started")

            def on_step_end(self, args, state, control, **kwargs):
                self.job.metrics.step = state.global_step
                if state.max_steps:
                    self.job.progress = (state.global_step / state.max_steps) * 100

                if state.log_history:
                    latest = state.log_history[-1]
                    self.job.metrics.loss = latest.get("loss", self.job.metrics.loss)
                    self.job.metrics.learning_rate = latest.get("learning_rate", 0.0)

                # Emit every 10 steps
                if state.global_step % 10 == 0:
                    self._emit("step_update")

            def on_epoch_end(self, args, state, control, **kwargs):
                self.job.metrics.epoch = int(state.epoch) if state.epoch else 0
                self._emit("epoch_completed")

            def on_evaluate(self, args, state, control, metrics=None, **kwargs):
                if metrics:
                    self.job.metrics.validation_loss = metrics.get("eval_loss", 0.0)
                    self.job.metrics.validation_accuracy = metrics.get(
                        "eval_accuracy", 0.0
                    )
                    self.job.metrics.f1_score = metrics.get("eval_f1", 0.0)
                    self.job.metrics.precision = metrics.get("eval_precision", 0.0)
                    self.job.metrics.recall = metrics.get("eval_recall", 0.0)
                self._emit("evaluation_completed")

            def _emit(self, event_type: str):
                event = {
                    "type": event_type,
                    "timestamp": datetime.utcnow().isoformat(),
                    "job_id": self.job.job_id,
                    "progress": round(self.job.progress, 2),
                    "state": self.job.state.value,
                    "metrics": {
                        "epoch": self.job.metrics.epoch,
                        "step": self.job.metrics.step,
                        "loss": round(self.job.metrics.loss, 4)
                        if self.job.metrics.loss
                        else 0,
                        "accuracy": round(self.job.metrics.accuracy, 4)
                        if self.job.metrics.accuracy
                        else 0,
                        "validation_loss": round(self.job.metrics.validation_loss, 4)
                        if self.job.metrics.validation_loss
                        else 0,
                        "validation_accuracy": round(
                            self.job.metrics.validation_accuracy, 4
                        )
                        if self.job.metrics.validation_accuracy
                        else 0,
                        "f1_score": round(self.job.metrics.f1_score, 4)
                        if self.job.metrics.f1_score
                        else 0,
                        "learning_rate": self.job.metrics.learning_rate,
                    },
                }
                self.job.event_queue.append(event)

        # Create Trainer
        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=tokenized_dataset["train"],
            eval_dataset=tokenized_dataset.get("validation"),
            tokenizer=tokenizer,
            compute_metrics=compute_metrics
            if "validation" in tokenized_dataset
            else None,
            callbacks=[
                ProgressCallback(job),
                EarlyStoppingCallback(early_stopping_patience=3)
                if "validation" in tokenized_dataset
                else None,
            ],
        )

        # Filter None callbacks
        trainer.callback_handler.callbacks = [
            cb for cb in trainer.callback_handler.callbacks if cb is not None
        ]

        log.info("Starting training", job_id=job.job_id)

        # Train
        trainer.train()

        # Save final model
        final_model_path = output_dir / "final"
        trainer.save_model(str(final_model_path))
        tokenizer.save_pretrained(str(final_model_path))

        # Save training info
        training_info = {
            "job_id": job.job_id,
            "model_name": job.model_name,
            "model_type": job.model_type.value,
            "base_model": base_model,
            "final_metrics": asdict(job.metrics),
            "hyperparameters": job.hyperparameters,
            "completed_at": datetime.utcnow().isoformat(),
        }

        with open(final_model_path / "training_info.json", "w") as f:
            json.dump(training_info, f, indent=2)

        job.model_path = str(final_model_path)
        job.state = JobState.COMPLETED
        job.completed_at = datetime.utcnow().isoformat()
        job.progress = 100.0

        # Final metrics from evaluation
        if "validation" in tokenized_dataset:
            final_metrics = trainer.evaluate()
            job.metrics.accuracy = final_metrics.get("eval_accuracy", 0.0)
            job.metrics.f1_score = final_metrics.get("eval_f1", 0.0)

        log.info(
            "Training completed",
            job_id=job.job_id,
            model_path=job.model_path,
            final_accuracy=job.metrics.accuracy,
        )

        # Emit completion event
        job.event_queue.append(
            {
                "type": "training_completed",
                "timestamp": datetime.utcnow().isoformat(),
                "job_id": job.job_id,
                "progress": 100.0,
                "state": JobState.COMPLETED.value,
                "model_path": job.model_path,
                "metrics": asdict(job.metrics),
            }
        )

    except Exception as e:
        job.state = JobState.FAILED
        job.error_message = str(e)
        job.completed_at = datetime.utcnow().isoformat()
        log.error("Training failed", job_id=job.job_id, error=str(e), exc_info=True)

        # Emit failure event
        job.event_queue.append(
            {
                "type": "training_failed",
                "timestamp": datetime.utcnow().isoformat(),
                "job_id": job.job_id,
                "state": JobState.FAILED.value,
                "error": str(e),
            }
        )


async def run_training_with_persistence(job: TrainingJob):
    """
    Wrapper around run_training that persists state changes to Redis.
    """
    try:
        # Save initial state
        if state_store:
            await state_store.save_job(job.job_id, job)

        # Run the actual training
        await run_training(job)

    finally:
        # Always save final state (success or failure)
        if state_store:
            await state_store.save_job(job.job_id, job)
            log.info("Job state persisted", job_id=job.job_id, state=job.state.value)


# =============================================================================
# FastAPI Application
# =============================================================================


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan manager."""
    global state_store

    log.info(
        "ML Training Service starting",
        model_dir=str(MODEL_DIR),
        dataset_dir=str(DATASET_DIR),
        max_concurrent_jobs=MAX_CONCURRENT_JOBS,
    )

    # Initialize state store
    from state_store import get_state_store

    state_store = await get_state_store()

    # Load existing jobs from Redis into memory
    if state_store.is_redis_connected:
        log.info("Redis connected, loading persisted jobs")
        memory_store = state_store.get_memory_store()
        with jobs_lock:
            for job_id, job_data in memory_store.items():
                # Reconstruct TrainingJob from stored data
                try:
                    job = TrainingJob(
                        job_id=job_data.get("job_id", job_id),
                        model_name=job_data.get("model_name", "unknown"),
                        model_type=ModelType(job_data.get("model_type", "sentiment")),
                        dataset_path=job_data.get("dataset_path", ""),
                        dataset_format=job_data.get("dataset_format", "csv"),
                        base_model=job_data.get("base_model"),
                        max_epochs=job_data.get("max_epochs", 3),
                        validation_split=job_data.get("validation_split", 0.1),
                        hyperparameters=job_data.get("hyperparameters", {}),
                        callbacks=job_data.get("callbacks", {}),
                        metadata=job_data.get("metadata", {}),
                        state=JobState(job_data.get("state", "PENDING")),
                        progress=job_data.get("progress", 0.0),
                        error_message=job_data.get("error_message"),
                        model_path=job_data.get("model_path"),
                        created_at=job_data.get(
                            "created_at", datetime.utcnow().isoformat()
                        ),
                        started_at=job_data.get("started_at"),
                        completed_at=job_data.get("completed_at"),
                    )
                    # Restore metrics
                    if "metrics" in job_data:
                        m = job_data["metrics"]
                        job.metrics = TrainingMetrics(
                            epoch=m.get("epoch", 0),
                            total_epochs=m.get("total_epochs", 0),
                            step=m.get("step", 0),
                            total_steps=m.get("total_steps", 0),
                            loss=m.get("loss", 0.0),
                            accuracy=m.get("accuracy", 0.0),
                            validation_loss=m.get("validation_loss", 0.0),
                            validation_accuracy=m.get("validation_accuracy", 0.0),
                            learning_rate=m.get("learning_rate", 0.0),
                            samples_processed=m.get("samples_processed", 0),
                            total_samples=m.get("total_samples", 0),
                            f1_score=m.get("f1_score", 0.0),
                            precision=m.get("precision", 0.0),
                            recall=m.get("recall", 0.0),
                        )
                    jobs[job_id] = job
                    log.info(
                        "Loaded persisted job", job_id=job_id, state=job.state.value
                    )
                except Exception as e:
                    log.warning("Failed to restore job", job_id=job_id, error=str(e))
    else:
        log.warning(
            "Redis not available, using in-memory storage only (data will be lost on restart)"
        )

    yield

    # Cleanup: save all jobs before shutdown
    if state_store:
        log.info("Saving jobs before shutdown")
        with jobs_lock:
            for job_id, job in jobs.items():
                await state_store.save_job(job_id, job)
        await state_store.disconnect()

    log.info("ML Training Service shutting down")


app = FastAPI(
    title="ML Training Service",
    description="Production ML model training service for sentiment analysis, ABSA, NER, and more",
    version="2.0.0",
    lifespan=lifespan,
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Health check endpoint for service discovery."""
    try:
        import torch

        gpu_available = torch.cuda.is_available()
    except ImportError:
        gpu_available = False

    with jobs_lock:
        active_jobs = sum(
            1
            for j in jobs.values()
            if j.state in [JobState.RUNNING, JobState.INITIALIZING]
        )

    return HealthResponse(
        status="healthy",
        version="2.0.0",
        gpu_available=gpu_available,
        active_jobs=active_jobs,
        supported_model_types=[t.value for t in ModelType],
        max_concurrent_jobs=MAX_CONCURRENT_JOBS,
        redis_connected=state_store.is_redis_connected if state_store else False,
        persisted_jobs=len(state_store.get_memory_store()) if state_store else 0,
    )


@app.post("/train", response_model=TrainingResponse)
async def submit_training_job(
    request: TrainingRequest, background_tasks: BackgroundTasks
):
    """Submit a new training job."""
    # Check concurrent job limit
    with jobs_lock:
        active_jobs = sum(
            1
            for j in jobs.values()
            if j.state in [JobState.RUNNING, JobState.INITIALIZING, JobState.PENDING]
        )
        if active_jobs >= MAX_CONCURRENT_JOBS:
            raise HTTPException(
                status_code=429,
                detail=f"Maximum concurrent jobs ({MAX_CONCURRENT_JOBS}) reached. Please wait.",
            )

    job_id = str(uuid.uuid4())

    try:
        model_type = ModelType(request.model_type.lower())
    except ValueError:
        raise HTTPException(
            status_code=400,
            detail=f"Invalid model type: {request.model_type}. "
            f"Supported types: {[t.value for t in ModelType]}",
        )

    job = TrainingJob(
        job_id=job_id,
        model_name=request.model_name,
        model_type=model_type,
        dataset_path=request.dataset_path,
        dataset_format=request.dataset_format,
        base_model=request.base_model,
        max_epochs=request.max_epochs,
        validation_split=request.validation_split,
        hyperparameters=request.hyperparameters,
        callbacks=request.callbacks,
        metadata=request.metadata,
    )

    with jobs_lock:
        jobs[job_id] = job

    # Persist job to Redis
    if state_store:
        await state_store.save_job(job_id, job)

    # Start training in background - ALWAYS use real training
    background_tasks.add_task(run_training_with_persistence, job)

    log.info("Training job submitted", job_id=job_id, model_name=request.model_name)

    return TrainingResponse(
        job_id=job_id,
        model_name=job.model_name,
        model_type=job.model_type.value,
        state=job.state.value,
        progress=job.progress,
        created_at=job.created_at,
        message="Training job submitted successfully",
    )


@app.get("/jobs/{job_id}/status", response_model=JobStatusResponse)
async def get_job_status(job_id: str):
    """Get the status of a training job."""
    with jobs_lock:
        if job_id not in jobs:
            raise HTTPException(status_code=404, detail=f"Job not found: {job_id}")
        job = jobs[job_id]

    return JobStatusResponse(
        job_id=job.job_id,
        model_name=job.model_name,
        model_type=job.model_type.value,
        state=job.state.value,
        progress=round(job.progress, 2),
        metrics=asdict(job.metrics),
        error_message=job.error_message,
        model_path=job.model_path,
        created_at=job.created_at,
        started_at=job.started_at,
        completed_at=job.completed_at,
        current_epoch=job.metrics.epoch,
        total_epochs=job.metrics.total_epochs,
    )


@app.get("/jobs/{job_id}/stream")
async def stream_job_status(job_id: str):
    """
    SSE endpoint for real-time training progress updates.
    """
    with jobs_lock:
        if job_id not in jobs:
            raise HTTPException(status_code=404, detail=f"Job not found: {job_id}")

    async def event_generator() -> AsyncGenerator[str, None]:
        last_sent_index = 0

        while True:
            with jobs_lock:
                if job_id not in jobs:
                    break
                job = jobs[job_id]

                # Send any new events
                events = list(job.event_queue)
                new_events = events[last_sent_index:]
                last_sent_index = len(events)

            for event in new_events:
                yield f"data: {json.dumps(event)}\n\n"

            # Check if job is done
            if job.state in [JobState.COMPLETED, JobState.FAILED, JobState.CANCELLED]:
                # Send final status
                final_event = {
                    "type": "job_finished",
                    "job_id": job_id,
                    "state": job.state.value,
                    "progress": job.progress,
                    "model_path": job.model_path,
                    "error_message": job.error_message,
                }
                yield f"data: {json.dumps(final_event)}\n\n"
                break

            await asyncio.sleep(1)  # Poll interval

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
        },
    )


@app.post("/jobs/{job_id}/cancel")
async def cancel_job(job_id: str):
    """Cancel a training job."""
    with jobs_lock:
        if job_id not in jobs:
            raise HTTPException(status_code=404, detail=f"Job not found: {job_id}")

        job = jobs[job_id]

        if job.state not in [JobState.PENDING, JobState.RUNNING, JobState.INITIALIZING]:
            raise HTTPException(
                status_code=400, detail=f"Cannot cancel job in state: {job.state.value}"
            )

        job.state = JobState.CANCELLED
        job.completed_at = datetime.utcnow().isoformat()

    log.info("Training job cancelled", job_id=job_id)

    return {"success": True, "message": "Job cancelled successfully"}


@app.get("/jobs/{job_id}/artifact", response_model=ModelArtifactResponse)
async def get_model_artifact(job_id: str):
    """Get the trained model artifact information."""
    with jobs_lock:
        if job_id not in jobs:
            raise HTTPException(status_code=404, detail=f"Job not found: {job_id}")
        job = jobs[job_id]

    if job.state != JobState.COMPLETED:
        raise HTTPException(
            status_code=400, detail=f"Model not available. Job state: {job.state.value}"
        )

    if not job.model_path or not Path(str(job.model_path)).exists():
        raise HTTPException(status_code=404, detail="Model artifact not found")

    # Calculate file size and checksum
    model_path = Path(job.model_path)

    # Get total size of all files in directory
    size_bytes = sum(f.stat().st_size for f in model_path.rglob("*") if f.is_file())

    # Checksum of the config file
    config_file = model_path / "config.json"
    if config_file.exists():
        with open(config_file, "rb") as f:
            checksum = hashlib.sha256(f.read()).hexdigest()
    else:
        checksum = "directory"

    return ModelArtifactResponse(
        model_path=str(job.model_path),
        model_name=job.model_name,
        model_type=job.model_type.value,
        framework="pytorch",
        version="1.0.0",
        size_bytes=size_bytes,
        checksum=checksum,
        metrics={
            "accuracy": job.metrics.accuracy,
            "f1_score": job.metrics.f1_score,
            "precision": job.metrics.precision,
            "recall": job.metrics.recall,
            "final_loss": job.metrics.loss,
        },
        model_filename=f"{job.model_name}_{job.job_id[:8]}",
    )


@app.get("/jobs/{job_id}/model/meta")
async def get_model_metadata(job_id: str):
    """Get model metadata for download."""
    with jobs_lock:
        if job_id not in jobs:
            raise HTTPException(status_code=404, detail=f"Job not found: {job_id}")
        job = jobs[job_id]

    if job.state != JobState.COMPLETED:
        raise HTTPException(status_code=400, detail="Model not ready")

    model_path = Path(job.model_path)
    size_bytes = sum(f.stat().st_size for f in model_path.rglob("*") if f.is_file())

    return {
        "model_name": job.model_name,
        "model_type": job.model_type.value,
        "model_filename": f"{job.model_name}_{job.job_id[:8]}",
        "format": "huggingface",
        "size_bytes": size_bytes,
        "metrics": asdict(job.metrics),
        "checksum": "directory",
        "version": "1.0.0",
    }


@app.get("/jobs")
async def list_jobs(
    state: Optional[str] = None, model_type: Optional[str] = None, limit: int = 50
):
    """List training jobs with optional filtering."""
    result = []

    with jobs_lock:
        for job in list(jobs.values())[-limit:]:
            if state and job.state.value.lower() != state.lower():
                continue
            if model_type and job.model_type.value.lower() != model_type.lower():
                continue

            result.append(
                {
                    "job_id": job.job_id,
                    "model_name": job.model_name,
                    "model_type": job.model_type.value,
                    "state": job.state.value,
                    "progress": round(job.progress, 2),
                    "created_at": job.created_at,
                    "completed_at": job.completed_at,
                }
            )

    return {"jobs": result, "total": len(result)}


@app.get("/models")
async def list_models():
    """List available trained models."""
    models = []

    with jobs_lock:
        for job in jobs.values():
            if job.state == JobState.COMPLETED and job.model_path:
                models.append(
                    {
                        "job_id": job.job_id,
                        "model_name": job.model_name,
                        "model_type": job.model_type.value,
                        "model_path": job.model_path,
                        "accuracy": job.metrics.accuracy,
                        "f1_score": job.metrics.f1_score,
                        "completed_at": job.completed_at,
                    }
                )

    return {"models": models, "total": len(models)}


@app.get("/supported-types")
async def get_supported_types():
    """Get list of supported model types with their default configurations."""
    return {
        "types": [
            {
                "type": t.value,
                "default_base_model": get_default_base_model(t),
                "description": get_model_type_description(t),
            }
            for t in ModelType
        ]
    }


def get_model_type_description(model_type: ModelType) -> str:
    """Returns description for each model type."""
    descriptions = {
        ModelType.SENTIMENT: "Binary or multi-class sentiment classification",
        ModelType.ABSA: "Aspect-Based Sentiment Analysis for fine-grained opinion mining",
        ModelType.NER: "Named Entity Recognition for extracting entities from text",
        ModelType.CLASSIFICATION: "General text classification for custom categories",
        ModelType.EMBEDDING: "Text embedding models for semantic similarity",
        ModelType.TRANSFORMER: "Custom transformer models for various NLP tasks",
    }
    return descriptions.get(model_type, "")


# =============================================================================
# Inference API
# =============================================================================


# Global model cache for inference
_model_cache: dict[str, tuple] = {}  # job_id -> (tokenizer, model)
_model_cache_lock = threading.Lock()


class InferenceRequest(BaseModel):
    """Request for model inference."""

    text: str = Field(
        ..., min_length=1, max_length=10000, description="Text to analyze"
    )
    texts: Optional[list[str]] = Field(
        None, description="Batch of texts (alternative to single text)"
    )
    aspects: Optional[list[str]] = Field(
        None, description="Aspects to analyze (for ABSA)"
    )
    max_length: int = Field(512, ge=32, le=2048, description="Maximum token length")
    return_probabilities: bool = Field(True, description="Return class probabilities")


class AspectSentiment(BaseModel):
    """Aspect sentiment result."""

    sentimentScore: float = Field(
        ..., ge=-1.0, le=1.0, description="Sentiment score -1 to 1"
    )
    sentimentLabel: str = Field(..., description="positive/negative/neutral")
    confidence: float = Field(..., ge=0.0, le=1.0, description="Confidence score")


class OverallSentiment(BaseModel):
    """Overall sentiment result."""

    score: float = Field(..., ge=-1.0, le=1.0)
    label: str


class InferenceResponse(BaseModel):
    """Response from model inference."""

    analysisId: str
    contentId: Optional[str] = None
    textPreview: str
    aspectsAnalyzed: list[str]
    aspectSentiments: dict[str, AspectSentiment]
    overallSentiment: OverallSentiment
    confidence: float
    analyzedAt: str
    modelUsed: str
    modelType: str
    responseTimeMs: int


def load_model_for_inference(job_id: str) -> tuple:
    """
    Load a trained model for inference with caching.
    Returns (tokenizer, model) tuple.
    """
    with _model_cache_lock:
        if job_id in _model_cache:
            return _model_cache[job_id]

    # Get job info
    with jobs_lock:
        if job_id not in jobs:
            raise HTTPException(status_code=404, detail=f"Job not found: {job_id}")
        job = jobs[job_id]

    if job.state != JobState.COMPLETED:
        raise HTTPException(
            status_code=400, detail=f"Model not available. Job state: {job.state.value}"
        )

    if not job.model_path or not Path(job.model_path).exists():
        raise HTTPException(status_code=404, detail="Model artifact not found")

    try:
        from transformers import AutoTokenizer, AutoModelForSequenceClassification
        import torch

        model_path = job.model_path
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model = AutoModelForSequenceClassification.from_pretrained(model_path)

        # Move to GPU if available
        device = "cuda" if USE_GPU and torch.cuda.is_available() else "cpu"
        model = model.to(device)
        model.eval()

        with _model_cache_lock:
            _model_cache[job_id] = (tokenizer, model, device)

        log.info("Model loaded for inference", job_id=job_id, device=device)
        return tokenizer, model, device

    except Exception as e:
        log.error("Failed to load model", job_id=job_id, error=str(e))
        raise HTTPException(status_code=500, detail=f"Failed to load model: {str(e)}")


def compute_sentiment_label(score: float) -> str:
    """Convert sentiment score to label."""
    if score > 0.1:
        return "positive"
    elif score < -0.1:
        return "negative"
    return "neutral"


@app.post("/inference/{job_id}", response_model=InferenceResponse)
async def run_inference(job_id: str, request: InferenceRequest):
    """
    Run inference using a trained model.

    For ABSA models, analyzes sentiment for each aspect.
    For sentiment/classification models, returns overall sentiment.
    """
    import time
    import torch

    start_time = time.time()

    # Load model
    tokenizer, model, device = load_model_for_inference(job_id)

    # Get job info for model type
    with jobs_lock:
        job = jobs[job_id]

    texts = request.texts or [request.text]
    aspects = request.aspects or []

    # For ABSA: if no aspects provided, analyze full text
    if not aspects:
        aspects = ["전체"]  # Default aspect

    aspect_sentiments: dict[str, AspectSentiment] = {}
    all_scores = []

    try:
        for aspect in aspects:
            # For ABSA, combine aspect with text
            if job.model_type == ModelType.ABSA and aspect != "전체":
                input_text = f"[{aspect}] {texts[0]}"
            else:
                input_text = texts[0]

            # Tokenize
            inputs = tokenizer(
                input_text,
                return_tensors="pt",
                truncation=True,
                max_length=request.max_length,
                padding=True,
            )
            inputs = {k: v.to(device) for k, v in inputs.items()}

            # Inference
            with torch.no_grad():
                outputs = model(**inputs)

            logits = outputs.logits
            probabilities = torch.softmax(logits, dim=-1).cpu().numpy()[0]

            # Determine sentiment (assuming binary or 3-class classification)
            num_classes = len(probabilities)

            if num_classes == 2:
                # Binary: [negative, positive]
                sentiment_score = float(probabilities[1] - probabilities[0])
                confidence = float(max(probabilities))
            elif num_classes == 3:
                # 3-class: [negative, neutral, positive]
                sentiment_score = float(probabilities[2] - probabilities[0])
                confidence = float(max(probabilities))
            else:
                # Multi-class: use argmax
                predicted_class = int(probabilities.argmax())
                sentiment_score = (
                    float(2 * (predicted_class / (num_classes - 1)) - 1)
                    if num_classes > 1
                    else 0.0
                )
                confidence = float(probabilities[predicted_class])

            all_scores.append(sentiment_score)

            aspect_sentiments[aspect] = AspectSentiment(
                sentimentScore=round(sentiment_score, 4),
                sentimentLabel=compute_sentiment_label(sentiment_score),
                confidence=round(confidence, 4),
            )

        # Compute overall sentiment (average of all aspects)
        overall_score = sum(all_scores) / len(all_scores) if all_scores else 0.0
        overall_confidence = (
            sum(a.confidence for a in aspect_sentiments.values())
            / len(aspect_sentiments)
            if aspect_sentiments
            else 0.0
        )

        response_time_ms = int((time.time() - start_time) * 1000)

        return InferenceResponse(
            analysisId=str(uuid.uuid4()),
            contentId=None,
            textPreview=texts[0][:200] + "..." if len(texts[0]) > 200 else texts[0],
            aspectsAnalyzed=list(aspect_sentiments.keys()),
            aspectSentiments=aspect_sentiments,
            overallSentiment=OverallSentiment(
                score=round(overall_score, 4),
                label=compute_sentiment_label(overall_score),
            ),
            confidence=round(overall_confidence, 4),
            analyzedAt=datetime.utcnow().isoformat(),
            modelUsed=job.model_name,
            modelType=job.model_type.value,
            responseTimeMs=response_time_ms,
        )

    except Exception as e:
        log.error("Inference failed", job_id=job_id, error=str(e), exc_info=True)
        raise HTTPException(status_code=500, detail=f"Inference failed: {str(e)}")


@app.post("/inference/by-name/{model_name}", response_model=InferenceResponse)
async def run_inference_by_name(model_name: str, request: InferenceRequest):
    """
    Run inference using a model by name (uses latest completed model with that name).
    """
    # Find the latest completed job with this model name
    job_id = None
    latest_completed_at = None

    with jobs_lock:
        for job in jobs.values():
            if (
                job.model_name == model_name
                and job.state == JobState.COMPLETED
                and job.model_path
            ):
                if latest_completed_at is None or (
                    job.completed_at and job.completed_at > latest_completed_at
                ):
                    job_id = job.job_id
                    latest_completed_at = job.completed_at

    if not job_id:
        raise HTTPException(
            status_code=404, detail=f"No completed model found with name: {model_name}"
        )

    return await run_inference(job_id, request)


@app.delete("/inference/cache/{job_id}")
async def clear_model_cache(job_id: str):
    """Clear a model from the inference cache to free memory."""
    with _model_cache_lock:
        if job_id in _model_cache:
            del _model_cache[job_id]
            return {"success": True, "message": f"Model {job_id} removed from cache"}
    return {"success": False, "message": "Model not in cache"}


@app.get("/inference/cache/status")
async def get_cache_status():
    """Get inference cache status."""
    with _model_cache_lock:
        cached_models = list(_model_cache.keys())
    return {
        "cached_models": cached_models,
        "total_cached": len(cached_models),
    }


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8090)

```

---

## backend/ml-addons/ml-trainer/state_store.py

```py
"""
State Storage Module for ML Trainer Service

Provides persistent storage for training jobs using Redis.
Falls back to in-memory storage if Redis is unavailable.

Usage:
    store = StateStore()
    await store.connect()
    await store.save_job(job_id, job_data)
    job = await store.load_job(job_id)
"""

import os
import json
import asyncio
from datetime import datetime, timedelta
from typing import Optional, Dict, Any, List
from dataclasses import asdict
from enum import Enum

import structlog

log = structlog.get_logger()

# Redis configuration from environment
REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")
REDIS_PREFIX = os.getenv("REDIS_PREFIX", "ml_trainer")
JOB_TTL_DAYS = int(os.getenv("JOB_TTL_DAYS", "30"))  # Jobs expire after 30 days


class EnhancedJSONEncoder(json.JSONEncoder):
    """JSON encoder that handles dataclasses, enums, and datetime."""
    
    def default(self, o: Any) -> Any:
        if hasattr(o, '__dataclass_fields__'):
            return asdict(o)
        if isinstance(o, Enum):
            return o.value
        if isinstance(o, datetime):
            return o.isoformat()
        if hasattr(o, 'maxlen'):  # deque
            return list(o)
        return super().default(o)


class StateStore:
    """
    Persistent state storage with Redis backend.
    Falls back to in-memory storage if Redis is unavailable.
    """
    
    def __init__(self):
        self._redis = None
        self._memory_store: Dict[str, Any] = {}
        self._using_redis = False
        self._lock = asyncio.Lock()
    
    async def connect(self) -> bool:
        """
        Connect to Redis. Returns True if connected, False if falling back to memory.
        """
        try:
            import redis.asyncio as redis
            
            self._redis = redis.from_url(
                REDIS_URL,
                encoding="utf-8",
                decode_responses=True,
                socket_connect_timeout=5,
                socket_timeout=5,
            )
            
            # Test connection
            await self._redis.ping()
            self._using_redis = True
            log.info("Connected to Redis", url=REDIS_URL, prefix=REDIS_PREFIX)
            
            # Load existing jobs from Redis into memory cache
            await self._load_existing_jobs()
            
            return True
            
        except ImportError:
            log.warning("redis package not installed, using in-memory storage")
            self._using_redis = False
            return False
            
        except Exception as e:
            log.warning("Failed to connect to Redis, using in-memory storage", error=str(e))
            self._using_redis = False
            return False
    
    async def disconnect(self):
        """Close Redis connection."""
        if self._redis:
            await self._redis.close()
            self._redis = None
            self._using_redis = False
            log.info("Disconnected from Redis")
    
    async def _load_existing_jobs(self):
        """Load existing jobs from Redis into memory on startup."""
        if not self._using_redis:
            return
        
        try:
            pattern = f"{REDIS_PREFIX}:job:*"
            cursor = 0
            count = 0
            
            while True:
                if self._redis is None:
                    break
                cursor, keys = await self._redis.scan(cursor, match=pattern, count=100)
                for key in keys:
                    job_id = key.split(":")[-1]
                    job_data = await self._redis.get(key)
                    if job_data:
                        self._memory_store[job_id] = json.loads(job_data)
                        count += 1
                
                if cursor == 0:
                    break
            
            log.info("Loaded existing jobs from Redis", count=count)
            
        except Exception as e:
            log.error("Failed to load existing jobs from Redis", error=str(e))
    
    def _key(self, job_id: str) -> str:
        """Generate Redis key for a job."""
        return f"{REDIS_PREFIX}:job:{job_id}"
    
    async def save_job(self, job_id: str, job: Any) -> bool:
        """
        Save a training job to storage.
        
        Args:
            job_id: Unique job identifier
            job: TrainingJob dataclass or dict
            
        Returns:
            True if saved successfully
        """
        async with self._lock:
            try:
                # Convert to dict if needed
                if hasattr(job, '__dataclass_fields__'):
                    job_data = asdict(job)
                    # Handle non-serializable fields
                    job_data.pop('event_queue', None)  # Remove deque
                elif isinstance(job, dict):
                    job_data = job.copy()
                    job_data.pop('event_queue', None)
                else:
                    job_data = job
                
                job_json = json.dumps(job_data, cls=EnhancedJSONEncoder)
                
                # Save to memory (always)
                self._memory_store[job_id] = json.loads(job_json)
                
                # Save to Redis if available
                if self._using_redis and self._redis:
                    ttl_seconds = JOB_TTL_DAYS * 24 * 60 * 60
                    await self._redis.set(self._key(job_id), job_json, ex=ttl_seconds)
                
                return True
                
            except Exception as e:
                log.error("Failed to save job", job_id=job_id, error=str(e))
                return False
    
    async def load_job(self, job_id: str) -> Optional[Dict[str, Any]]:
        """
        Load a training job from storage.
        
        Args:
            job_id: Unique job identifier
            
        Returns:
            Job data as dict, or None if not found
        """
        # Check memory first
        if job_id in self._memory_store:
            return self._memory_store[job_id]
        
        # Try Redis
        if self._using_redis and self._redis:
            try:
                job_json = await self._redis.get(self._key(job_id))
                if job_json:
                    job_data = json.loads(job_json)
                    self._memory_store[job_id] = job_data
                    return job_data
            except Exception as e:
                log.error("Failed to load job from Redis", job_id=job_id, error=str(e))
        
        return None
    
    async def delete_job(self, job_id: str) -> bool:
        """
        Delete a training job from storage.
        
        Args:
            job_id: Unique job identifier
            
        Returns:
            True if deleted successfully
        """
        async with self._lock:
            try:
                # Remove from memory
                self._memory_store.pop(job_id, None)
                
                # Remove from Redis
                if self._using_redis and self._redis:
                    await self._redis.delete(self._key(job_id))
                
                return True
                
            except Exception as e:
                log.error("Failed to delete job", job_id=job_id, error=str(e))
                return False
    
    async def list_jobs(
        self,
        state: Optional[str] = None,
        model_type: Optional[str] = None,
        limit: int = 50
    ) -> List[Dict[str, Any]]:
        """
        List jobs with optional filtering.
        
        Args:
            state: Filter by job state
            model_type: Filter by model type
            limit: Maximum number of jobs to return
            
        Returns:
            List of job data dicts
        """
        jobs = []
        
        for job_id, job_data in list(self._memory_store.items())[-limit:]:
            if state and job_data.get('state', '').lower() != state.lower():
                continue
            if model_type and job_data.get('model_type', '').lower() != model_type.lower():
                continue
            jobs.append(job_data)
        
        return jobs
    
    async def update_job_status(
        self,
        job_id: str,
        state: str,
        progress: Optional[float] = None,
        error_message: Optional[str] = None,
        completed_at: Optional[str] = None,
        **kwargs: Any
    ) -> bool:
        """
        Update specific fields of a job.
        
        Args:
            job_id: Unique job identifier
            state: New job state
            progress: Current progress percentage
            error_message: Error message if failed
            completed_at: Completion timestamp
            **kwargs: Additional fields to update
            
        Returns:
            True if updated successfully
        """
        job_data = await self.load_job(job_id)
        if not job_data:
            return False
        
        job_data['state'] = state
        if progress is not None:
            job_data['progress'] = progress
        if error_message is not None:
            job_data['error_message'] = error_message
        if completed_at is not None:
            job_data['completed_at'] = completed_at
        
        # Update additional fields
        for key, value in kwargs.items():
            if value is not None:
                job_data[key] = value
        
        return await self.save_job(job_id, job_data)
    
    async def get_active_job_count(self) -> int:
        """Get count of active (pending, running, initializing) jobs."""
        count = 0
        active_states = {'PENDING', 'RUNNING', 'INITIALIZING'}
        
        for job_data in self._memory_store.values():
            if job_data.get('state', '').upper() in active_states:
                count += 1
        
        return count
    
    async def get_completed_models(self) -> List[Dict[str, Any]]:
        """Get list of completed jobs with model paths."""
        models = []
        
        for job_data in self._memory_store.values():
            if job_data.get('state') == 'COMPLETED' and job_data.get('model_path'):
                models.append({
                    'job_id': job_data.get('job_id'),
                    'model_name': job_data.get('model_name'),
                    'model_type': job_data.get('model_type'),
                    'model_path': job_data.get('model_path'),
                    'metrics': job_data.get('metrics', {}),
                    'completed_at': job_data.get('completed_at'),
                })
        
        return models
    
    @property
    def is_redis_connected(self) -> bool:
        """Check if Redis is connected."""
        return self._using_redis
    
    def get_memory_store(self) -> Dict[str, Any]:
        """Get reference to memory store for direct access (e.g., for event_queue)."""
        return self._memory_store


# Singleton instance
_store: Optional[StateStore] = None


async def get_state_store() -> StateStore:
    """Get or create the singleton StateStore instance."""
    global _store
    if _store is None:
        _store = StateStore()
        await _store.connect()
    return _store

```

---

## backend/ml-addons/sentiment-addon/addon_server.py

```py
"""
ML Add-on Server: Korean Sentiment Analysis with ML Models

NewsInsight ML Add-on 시스템의 감정 분석 구현.
KoELECTRA/KoBERT 기반 ML 모델을 사용하여 한국어 뉴스 기사의
감정(긍정/부정/중립)을 정확하게 분석합니다.

Features:
- KoELECTRA 기반 3-class 감정 분류
- 세부 감정(기쁨, 분노, 슬픔, 두려움 등) 분석
- 키워드 기반 폴백 모드 지원
- 배치 처리 지원
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import Response
from pydantic import BaseModel, Field
from typing import Optional, Dict, List, Any
import time
import os
import logging
import asyncio
from contextlib import asynccontextmanager
from functools import lru_cache

# Prometheus metrics
try:
    from prometheus_client import (
        Counter,
        Histogram,
        Gauge,
        CONTENT_TYPE_LATEST,
        generate_latest,
    )

    PROMETHEUS_AVAILABLE = True
except ImportError:
    PROMETHEUS_AVAILABLE = False

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ML Model cache (lazy loading)
_ml_models = {}
_model_loading = False


def get_ml_models():
    """Lazy load ML models on first use"""
    global _ml_models, _model_loading

    if _ml_models.get("loaded") or _model_loading:
        return _ml_models

    _model_loading = True

    try:
        import torch
        from transformers import (
            AutoTokenizer,
            AutoModelForSequenceClassification,
            pipeline,
        )

        logger.info("Loading sentiment ML models...")

        # Device selection
        device = "cuda" if torch.cuda.is_available() else "cpu"
        logger.info(f"Using device: {device}")

        # 1. Primary Sentiment Model (KoELECTRA fine-tuned for sentiment)
        # Use Korean sentiment models
        sentiment_model_name = os.getenv(
            "SENTIMENT_MODEL",
            "snunlp/KR-FinBert-SC",  # Korean sentiment classifier
        )

        try:
            _ml_models["sentiment_pipeline"] = pipeline(
                "sentiment-analysis",
                model=sentiment_model_name,
                tokenizer=sentiment_model_name,
                device=0 if device == "cuda" else -1,
                max_length=512,
                truncation=True,
            )
            logger.info(f"Loaded primary sentiment model: {sentiment_model_name}")
        except Exception as e:
            logger.warning(f"Failed to load primary sentiment model: {e}")
            # Fallback to base KoELECTRA
            try:
                fallback_model = "monologg/koelectra-base-v3-discriminator"
                _ml_models["sentiment_tokenizer"] = AutoTokenizer.from_pretrained(
                    fallback_model
                )
                _ml_models["sentiment_model"] = (
                    AutoModelForSequenceClassification.from_pretrained(
                        fallback_model,
                        num_labels=3,  # positive, negative, neutral
                    ).to(device)
                )
                _ml_models["sentiment_model"].eval()
                logger.info(f"Loaded fallback sentiment model: {fallback_model}")
            except Exception as e2:
                logger.warning(f"Failed to load fallback model: {e2}")

        # 2. Emotion Classification Model (optional, for detailed emotions)
        emotion_model_name = os.getenv(
            "EMOTION_MODEL",
            "j-hartmann/emotion-english-distilroberta-base",  # Will work for general emotions
        )
        try:
            _ml_models["emotion_pipeline"] = pipeline(
                "text-classification",
                model=emotion_model_name,
                tokenizer=emotion_model_name,
                device=0 if device == "cuda" else -1,
                top_k=None,  # Return all emotion scores
                max_length=512,
                truncation=True,
            )
            logger.info(f"Loaded emotion model: {emotion_model_name}")
        except Exception as e:
            logger.warning(f"Failed to load emotion model (optional): {e}")

        _ml_models["device"] = device
        _ml_models["loaded"] = True
        logger.info("All sentiment ML models loaded successfully")

    except ImportError as e:
        logger.warning(f"ML libraries not available, using heuristic mode: {e}")
        _ml_models["loaded"] = False
    except Exception as e:
        logger.error(f"Error loading ML models: {e}")
        _ml_models["loaded"] = False

    _model_loading = False
    return _ml_models


# Model loading status for health checks
_model_warmup_complete = False
_model_warmup_error = None


async def _warmup_models():
    """Warm up models and track completion status"""
    global _model_warmup_complete, _model_warmup_error
    try:
        logger.info("Starting sentiment model warm-up...")
        start_time = time.time()

        # Load models synchronously in thread
        models = await asyncio.to_thread(get_ml_models)

        if models.get("loaded"):
            # Run a dummy inference to fully warm up the model
            if "sentiment_pipeline" in models:
                try:
                    dummy_text = "테스트 문장입니다."
                    _ = models["sentiment_pipeline"](dummy_text)
                    logger.info("Sentiment pipeline warm-up inference complete")
                except Exception as e:
                    logger.warning(f"Sentiment pipeline warm-up failed: {e}")

            elapsed = time.time() - start_time
            logger.info(f"Sentiment model warm-up completed in {elapsed:.2f}s")
            _model_warmup_complete = True
        else:
            logger.warning("Models not loaded, running in heuristic mode")
            _model_warmup_complete = True

    except Exception as e:
        logger.error(f"Sentiment model warm-up failed: {e}")
        _model_warmup_error = str(e)
        _model_warmup_complete = True


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan handler"""
    # Startup
    logger.info("Sentiment addon starting...")

    # Preload models in background if ML is enabled
    if os.getenv("ENABLE_ML_MODELS", "true").lower() == "true":
        asyncio.create_task(_warmup_models())

    yield

    # Shutdown
    logger.info("Sentiment addon shutting down...")


app = FastAPI(
    title="Sentiment Analysis Add-on (ML Enhanced)",
    description="Korean news article sentiment analysis with ML models for NewsInsight",
    version="2.0.0",
    lifespan=lifespan,
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ========== Prometheus Metrics ==========

if PROMETHEUS_AVAILABLE:
    # Request metrics
    REQUEST_COUNT = Counter(
        "sentiment_requests_total",
        "Total number of sentiment analysis requests",
        ["endpoint", "status"],
    )
    REQUEST_LATENCY = Histogram(
        "sentiment_request_latency_seconds",
        "Request latency in seconds",
        ["endpoint"],
        buckets=(0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0),
    )

    # Analysis metrics
    ANALYSIS_COUNT = Counter(
        "sentiment_analysis_total",
        "Total number of sentiment analyses performed",
        ["label", "mode"],
    )

    # Model metrics
    MODEL_LOADED = Gauge(
        "sentiment_model_loaded", "Whether ML models are loaded (1=yes, 0=no)"
    )
    MODEL_WARMUP_COMPLETE = Gauge(
        "sentiment_model_warmup_complete",
        "Whether model warm-up is complete (1=yes, 0=no)",
    )

    # Error metrics
    ERROR_COUNT = Counter(
        "sentiment_errors_total", "Total number of errors", ["error_type"]
    )

    @app.get("/metrics")
    async def metrics():
        """Prometheus metrics endpoint"""
        models = get_ml_models() if not _model_loading else {}
        MODEL_LOADED.set(1 if models.get("loaded") else 0)
        MODEL_WARMUP_COMPLETE.set(1 if _model_warmup_complete else 0)

        return Response(content=generate_latest(), media_type=CONTENT_TYPE_LATEST)


# ========== Request/Response Models ==========


class ArticleInput(BaseModel):
    id: Optional[int] = None
    title: Optional[str] = None
    content: Optional[str] = None
    url: Optional[str] = None
    source: Optional[str] = None
    published_at: Optional[str] = None


class AnalysisContext(BaseModel):
    language: Optional[str] = "ko"
    country: Optional[str] = "KR"
    previous_results: Optional[Dict[str, Any]] = None


class ExecutionOptions(BaseModel):
    importance: Optional[str] = "batch"
    debug: Optional[bool] = False
    timeout_ms: Optional[int] = None
    use_ml: Optional[bool] = True
    include_emotions: Optional[bool] = True


class AddonRequest(BaseModel):
    request_id: str
    addon_id: str
    task: str = "article_analysis"
    input_schema_version: str = "1.0"
    article: Optional[ArticleInput] = None
    context: Optional[AnalysisContext] = None
    options: Optional[ExecutionOptions] = None


class EmotionScore(BaseModel):
    joy: float = 0.0
    anger: float = 0.0
    sadness: float = 0.0
    fear: float = 0.0
    surprise: float = 0.0
    disgust: float = 0.0


class SentimentResult(BaseModel):
    score: float = Field(
        ...,
        ge=-1.0,
        le=1.0,
        description="Sentiment score from -1 (negative) to 1 (positive)",
    )
    label: str = Field(
        ..., description="Sentiment label: positive, negative, or neutral"
    )
    confidence: float = Field(..., ge=0.0, le=1.0, description="Model confidence score")
    distribution: Dict[str, float] = Field(
        ..., description="Score distribution across sentiment classes"
    )
    emotions: Optional[EmotionScore] = None
    explanations: List[str] = []
    analysis_method: str = "ml"  # ml, heuristic, hybrid


class AnalysisResults(BaseModel):
    sentiment: Optional[SentimentResult] = None
    raw: Optional[Dict[str, Any]] = None


class ResponseMeta(BaseModel):
    model_version: str
    model_name: str
    latency_ms: int
    processed_at: str
    device: str = "cpu"


class ErrorInfo(BaseModel):
    code: str
    message: str
    details: Optional[str] = None


class AddonResponse(BaseModel):
    request_id: str
    addon_id: str
    status: str  # success, error, partial
    output_schema_version: str = "1.0"
    results: Optional[AnalysisResults] = None
    error: Optional[ErrorInfo] = None
    meta: Optional[ResponseMeta] = None


# ========== Keyword-based Fallback (Heuristic) ==========

# Korean positive keywords
POSITIVE_KEYWORDS = [
    "성공",
    "발전",
    "향상",
    "긍정",
    "좋은",
    "훌륭",
    "최고",
    "행복",
    "성장",
    "협력",
    "지원",
    "개선",
    "희망",
    "기대",
    "축하",
    "승리",
    "호황",
    "상승",
    "증가",
    "활성화",
    "혁신",
    "돌파",
    "기록",
    "최대",
    "회복",
    "안정",
    "확대",
    "강화",
    "달성",
    "우수",
    "선도",
    "획기적",
    "감사",
    "축복",
    "영광",
    "존경",
    "사랑",
    "평화",
    "화합",
    "번영",
]

# Korean negative keywords
NEGATIVE_KEYWORDS = [
    "실패",
    "문제",
    "위기",
    "부정",
    "나쁜",
    "최악",
    "우려",
    "불안",
    "감소",
    "하락",
    "갈등",
    "비판",
    "논란",
    "피해",
    "사고",
    "범죄",
    "폭락",
    "붕괴",
    "파산",
    "침체",
    "악화",
    "충격",
    "위험",
    "경고",
    "분쟁",
    "반발",
    "혼란",
    "지연",
    "중단",
    "취소",
    "실망",
    "좌절",
    "공포",
    "분노",
    "슬픔",
    "죽음",
    "재난",
    "폭력",
    "테러",
    "전쟁",
]


def analyze_sentiment_heuristic(text: str) -> SentimentResult:
    """
    Fallback keyword-based sentiment analysis.
    Used when ML models are not available.
    """
    if not text:
        return SentimentResult(
            score=0.0,
            label="neutral",
            confidence=0.5,
            distribution={"positive": 0.33, "negative": 0.33, "neutral": 0.34},
            explanations=["텍스트 없음"],
            analysis_method="heuristic",
        )

    text_lower = text.lower()

    # Count keywords
    positive_count = sum(1 for kw in POSITIVE_KEYWORDS if kw in text_lower)
    negative_count = sum(1 for kw in NEGATIVE_KEYWORDS if kw in text_lower)
    total_keywords = positive_count + negative_count + 1

    # Calculate score (-1 ~ 1)
    raw_score = (positive_count - negative_count) / total_keywords
    score = max(-1.0, min(1.0, raw_score * 2))  # Scale up for more sensitivity

    # Calculate distribution
    positive_ratio = positive_count / total_keywords
    negative_ratio = negative_count / total_keywords
    neutral_ratio = max(0.0, 1.0 - positive_ratio - negative_ratio)

    # Normalize distribution
    total_ratio = positive_ratio + negative_ratio + neutral_ratio
    positive_ratio /= total_ratio
    negative_ratio /= total_ratio
    neutral_ratio /= total_ratio

    # Determine label
    if score > 0.15:
        label = "positive"
    elif score < -0.15:
        label = "negative"
    else:
        label = "neutral"

    # Calculate confidence based on keyword density
    confidence = min(0.9, 0.5 + (positive_count + negative_count) * 0.05)

    # Generate explanations
    explanations = []
    if positive_count > 0:
        explanations.append(f"긍정 키워드 {positive_count}개 발견")
    if negative_count > 0:
        explanations.append(f"부정 키워드 {negative_count}개 발견")
    if not explanations:
        explanations.append("특별한 감정 신호 없음 (중립)")

    # Simple emotion estimation from keywords
    emotions = EmotionScore(
        joy=positive_ratio * 0.8,
        anger=negative_ratio * 0.4,
        sadness=negative_ratio * 0.3,
        fear=negative_ratio * 0.2,
        surprise=0.1,
        disgust=negative_ratio * 0.1,
    )

    return SentimentResult(
        score=round(score, 4),
        label=label,
        confidence=round(confidence, 4),
        distribution={
            "positive": round(positive_ratio, 4),
            "negative": round(negative_ratio, 4),
            "neutral": round(neutral_ratio, 4),
        },
        emotions=emotions,
        explanations=explanations,
        analysis_method="heuristic",
    )


# ========== ML-based Sentiment Analysis ==========


def analyze_sentiment_ml(text: str, include_emotions: bool = True) -> SentimentResult:
    """
    ML-based sentiment analysis using KoELECTRA/KoBERT models.
    """
    models = get_ml_models()

    if not models.get("loaded"):
        logger.warning("ML models not loaded, falling back to heuristic")
        return analyze_sentiment_heuristic(text)

    try:
        import torch

        device = models.get("device", "cpu")
        explanations = []

        # Primary sentiment analysis
        sentiment_result = None

        if "sentiment_pipeline" in models:
            # Use pipeline-based inference
            pipeline_result = models["sentiment_pipeline"](text[:512])

            if isinstance(pipeline_result, list):
                pipeline_result = pipeline_result[0]

            label_map = {
                "POSITIVE": "positive",
                "NEGATIVE": "negative",
                "NEUTRAL": "neutral",
                "LABEL_0": "negative",  # Common mapping for 3-class
                "LABEL_1": "neutral",
                "LABEL_2": "positive",
                "긍정": "positive",
                "부정": "negative",
                "중립": "neutral",
            }

            raw_label = pipeline_result.get("label", "NEUTRAL").upper()
            label = label_map.get(raw_label, "neutral")
            confidence = pipeline_result.get("score", 0.5)

            # Convert label to score
            score_map = {"positive": 1.0, "negative": -1.0, "neutral": 0.0}
            score = score_map.get(label, 0.0) * confidence

            # Estimate distribution
            if label == "positive":
                distribution = {
                    "positive": confidence,
                    "negative": (1 - confidence) * 0.3,
                    "neutral": (1 - confidence) * 0.7,
                }
            elif label == "negative":
                distribution = {
                    "positive": (1 - confidence) * 0.3,
                    "negative": confidence,
                    "neutral": (1 - confidence) * 0.7,
                }
            else:
                distribution = {
                    "positive": (1 - confidence) * 0.5,
                    "negative": (1 - confidence) * 0.5,
                    "neutral": confidence,
                }

            explanations.append(f"KoELECTRA 모델 분석 (신뢰도: {confidence:.1%})")

        elif "sentiment_model" in models and "sentiment_tokenizer" in models:
            # Use manual inference with tokenizer + model
            tokenizer = models["sentiment_tokenizer"]
            model = models["sentiment_model"]

            inputs = tokenizer(
                text[:512],
                return_tensors="pt",
                truncation=True,
                max_length=512,
                padding=True,
            )
            inputs = {k: v.to(device) for k, v in inputs.items()}

            with torch.no_grad():
                outputs = model(**inputs)
                probs = torch.softmax(outputs.logits, dim=-1)[0]

            # Map to sentiment (assuming 3-class: negative, neutral, positive)
            neg_prob = probs[0].item()
            neu_prob = probs[1].item() if len(probs) > 2 else 0.33
            pos_prob = probs[2].item() if len(probs) > 2 else probs[1].item()

            distribution = {
                "negative": neg_prob,
                "neutral": neu_prob,
                "positive": pos_prob,
            }

            # Get dominant label
            max_idx = torch.argmax(probs).item()
            labels = ["negative", "neutral", "positive"]
            label = labels[min(max_idx, 2)]
            confidence = probs[max_idx].item()

            # Calculate score
            score = pos_prob - neg_prob

            explanations.append(
                f"KoELECTRA 베이스 모델 분석 (신뢰도: {confidence:.1%})"
            )

        else:
            logger.warning("No sentiment model available, using heuristic")
            return analyze_sentiment_heuristic(text)

        # Emotion analysis (optional)
        emotions = None
        if include_emotions and "emotion_pipeline" in models:
            try:
                emotion_result = models["emotion_pipeline"](text[:512])

                if isinstance(emotion_result, list) and len(emotion_result) > 0:
                    if isinstance(emotion_result[0], list):
                        emotion_result = emotion_result[0]

                    emotion_scores = {
                        e["label"].lower(): e["score"] for e in emotion_result
                    }

                    emotions = EmotionScore(
                        joy=emotion_scores.get("joy", 0.0),
                        anger=emotion_scores.get("anger", 0.0),
                        sadness=emotion_scores.get("sadness", 0.0),
                        fear=emotion_scores.get("fear", 0.0),
                        surprise=emotion_scores.get("surprise", 0.0),
                        disgust=emotion_scores.get("disgust", 0.0),
                    )
                    explanations.append("감정 세부 분석 완료")
            except Exception as e:
                logger.warning(f"Emotion analysis failed: {e}")
                # Estimate emotions from sentiment
                emotions = EmotionScore(
                    joy=distribution["positive"] * 0.8,
                    anger=distribution["negative"] * 0.4,
                    sadness=distribution["negative"] * 0.3,
                    fear=distribution["negative"] * 0.2,
                    surprise=0.1,
                    disgust=distribution["negative"] * 0.1,
                )
        else:
            # Estimate emotions from sentiment distribution
            emotions = EmotionScore(
                joy=distribution["positive"] * 0.8,
                anger=distribution["negative"] * 0.4,
                sadness=distribution["negative"] * 0.3,
                fear=distribution["negative"] * 0.2,
                surprise=0.1,
                disgust=distribution["negative"] * 0.1,
            )

        return SentimentResult(
            score=round(score, 4),
            label=label,
            confidence=round(confidence, 4),
            distribution={k: round(v, 4) for k, v in distribution.items()},
            emotions=emotions,
            explanations=explanations,
            analysis_method="ml",
        )

    except Exception as e:
        logger.error(f"ML sentiment analysis failed: {e}", exc_info=True)
        result = analyze_sentiment_heuristic(text)
        result.explanations.append(f"ML 분석 실패, 휴리스틱 폴백: {str(e)[:50]}")
        return result


def analyze_sentiment(
    text: str, use_ml: bool = True, include_emotions: bool = True
) -> SentimentResult:
    """
    Main sentiment analysis function.
    Automatically selects ML or heuristic based on availability.
    """
    if not text or not text.strip():
        return SentimentResult(
            score=0.0,
            label="neutral",
            confidence=0.5,
            distribution={"positive": 0.33, "negative": 0.33, "neutral": 0.34},
            explanations=["분석할 텍스트 없음"],
            analysis_method="none",
        )

    if use_ml:
        return analyze_sentiment_ml(text, include_emotions)
    else:
        return analyze_sentiment_heuristic(text)


# ========== API Endpoints ==========


@app.get("/health")
async def health_check():
    """Health check endpoint"""
    models = get_ml_models()
    ml_status = "loaded" if models.get("loaded") else "heuristic_mode"

    return {
        "status": "healthy",
        "service": "sentiment-addon",
        "version": "2.0.0",
        "ml_status": ml_status,
        "warmup_complete": _model_warmup_complete,
        "warmup_error": _model_warmup_error,
        "device": models.get("device", "cpu"),
        "models": {
            "sentiment_pipeline": "sentiment_pipeline" in models,
            "sentiment_model": "sentiment_model" in models,
            "emotion_pipeline": "emotion_pipeline" in models,
        },
    }


@app.get("/ready")
async def readiness_check():
    """Readiness check - only returns healthy when models are warmed up"""
    if not _model_warmup_complete:
        return {"status": "warming_up", "ready": False}

    models = get_ml_models()
    return {
        "status": "ready",
        "ready": True,
        "ml_enabled": models.get("loaded", False),
        "warmup_error": _model_warmup_error,
    }


@app.get("/models")
async def get_model_info():
    """Get information about loaded models"""
    models = get_ml_models()

    return {
        "loaded": models.get("loaded", False),
        "device": models.get("device", "cpu"),
        "available_models": [k for k in models.keys() if k not in ["loaded", "device"]],
        "sentiment_model": os.getenv("SENTIMENT_MODEL", "snunlp/KR-FinBert-SC"),
        "emotion_model": os.getenv(
            "EMOTION_MODEL", "j-hartmann/emotion-english-distilroberta-base"
        ),
    }


@app.post("/analyze", response_model=AddonResponse)
async def analyze(request: AddonRequest):
    """
    Article sentiment analysis endpoint.
    Called by NewsInsight Orchestrator.
    """
    start_time = time.time()
    models = get_ml_models()

    try:
        # Validate input
        if not request.article:
            raise ValueError("article is required")

        # Prepare text for analysis
        text = ""
        if request.article.title:
            text += request.article.title + " "
        if request.article.content:
            text += request.article.content

        # Get options
        options = request.options or ExecutionOptions()
        use_ml = options.use_ml if options.use_ml is not None else True
        include_emotions = (
            options.include_emotions if options.include_emotions is not None else True
        )

        # Run sentiment analysis
        sentiment_result = analyze_sentiment(
            text, use_ml=use_ml, include_emotions=include_emotions
        )

        # Build response
        latency_ms = int((time.time() - start_time) * 1000)

        model_name = (
            "koelectra-sentiment-v2" if models.get("loaded") else "keyword-heuristic-v1"
        )

        # Track Prometheus metrics
        if PROMETHEUS_AVAILABLE:
            REQUEST_COUNT.labels(endpoint="analyze", status="success").inc()
            REQUEST_LATENCY.labels(endpoint="analyze").observe(time.time() - start_time)
            ANALYSIS_COUNT.labels(
                label=sentiment_result.label,
                mode="ml" if models.get("loaded") and use_ml else "heuristic",
            ).inc()

        return AddonResponse(
            request_id=request.request_id,
            addon_id=request.addon_id,
            status="success",
            results=AnalysisResults(
                sentiment=sentiment_result,
                raw={
                    "text_length": len(text),
                    "ml_available": models.get("loaded", False),
                    "analysis_method": sentiment_result.analysis_method,
                },
            ),
            meta=ResponseMeta(
                model_version="2.0.0",
                model_name=model_name,
                latency_ms=latency_ms,
                processed_at=time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
                device=models.get("device", "cpu"),
            ),
        )

    except ValueError as e:
        latency_ms = int((time.time() - start_time) * 1000)

        # Track error metrics
        if PROMETHEUS_AVAILABLE:
            REQUEST_COUNT.labels(endpoint="analyze", status="error").inc()
            REQUEST_LATENCY.labels(endpoint="analyze").observe(time.time() - start_time)
            ERROR_COUNT.labels(error_type="ValidationError").inc()

        return AddonResponse(
            request_id=request.request_id,
            addon_id=request.addon_id,
            status="error",
            error=ErrorInfo(code="VALIDATION_ERROR", message=str(e)),
            meta=ResponseMeta(
                model_version="2.0.0",
                model_name="sentiment-addon",
                latency_ms=latency_ms,
                processed_at=time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
                device=models.get("device", "cpu"),
            ),
        )
    except Exception as e:
        logger.error(f"Analysis error: {e}", exc_info=True)
        latency_ms = int((time.time() - start_time) * 1000)

        # Track error metrics
        if PROMETHEUS_AVAILABLE:
            REQUEST_COUNT.labels(endpoint="analyze", status="error").inc()
            REQUEST_LATENCY.labels(endpoint="analyze").observe(time.time() - start_time)
            ERROR_COUNT.labels(error_type=type(e).__name__).inc()

        return AddonResponse(
            request_id=request.request_id,
            addon_id=request.addon_id,
            status="error",
            error=ErrorInfo(
                code="ANALYSIS_ERROR",
                message=str(e),
                details=f"Error occurred during sentiment analysis",
            ),
            meta=ResponseMeta(
                model_version="2.0.0",
                model_name="sentiment-addon",
                latency_ms=latency_ms,
                processed_at=time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
                device=models.get("device", "cpu"),
            ),
        )


@app.post("/batch", response_model=List[AddonResponse])
async def analyze_batch(requests: List[AddonRequest]):
    """Batch analyze multiple articles"""
    results = []
    for req in requests:
        result = await analyze(req)
        results.append(result)
    return results


@app.post("/analyze/simple")
async def analyze_simple(text: str):
    """
    Simple text sentiment analysis endpoint.
    For quick testing without full request structure.
    """
    start_time = time.time()

    result = analyze_sentiment(text)
    latency_ms = int((time.time() - start_time) * 1000)

    return {
        "text": text[:100] + "..." if len(text) > 100 else text,
        "sentiment": result.model_dump(),
        "latency_ms": latency_ms,
    }


# ========== Topic Classification (Bonus Feature) ==========

TOPIC_KEYWORDS = {
    "정치": [
        "국회",
        "대통령",
        "정당",
        "선거",
        "투표",
        "정부",
        "장관",
        "의원",
        "청와대",
        "여당",
        "야당",
    ],
    "경제": [
        "주식",
        "코스피",
        "환율",
        "금리",
        "투자",
        "부동산",
        "GDP",
        "물가",
        "인플레이션",
        "기업",
    ],
    "사회": [
        "교육",
        "학교",
        "범죄",
        "사건",
        "복지",
        "의료",
        "병원",
        "사고",
        "재난",
        "환경",
    ],
    "문화": [
        "영화",
        "드라마",
        "음악",
        "공연",
        "전시",
        "예술",
        "문학",
        "K팝",
        "연예",
        "방송",
    ],
    "IT/과학": [
        "AI",
        "인공지능",
        "반도체",
        "스마트폰",
        "로봇",
        "우주",
        "연구",
        "개발",
        "기술",
        "디지털",
    ],
    "스포츠": [
        "축구",
        "야구",
        "농구",
        "올림픽",
        "월드컵",
        "선수",
        "경기",
        "대회",
        "승리",
        "우승",
    ],
    "국제": [
        "미국",
        "중국",
        "일본",
        "북한",
        "유럽",
        "UN",
        "외교",
        "무역",
        "전쟁",
        "분쟁",
    ],
}


@app.post("/analyze/topic")
async def analyze_topic(request: AddonRequest):
    """
    Article topic classification endpoint.
    Simple keyword-based topic detection.
    """
    start_time = time.time()

    if not request.article:
        raise HTTPException(status_code=400, detail="article is required")

    text = ""
    if request.article.title:
        text += request.article.title + " "
    if request.article.content:
        text += request.article.content

    text_lower = text.lower()

    # Count topic keywords
    topic_scores = {}
    for topic, keywords in TOPIC_KEYWORDS.items():
        count = sum(1 for kw in keywords if kw in text_lower)
        if count > 0:
            topic_scores[topic] = count

    # Normalize scores
    total = sum(topic_scores.values()) or 1
    topic_distribution = {k: v / total for k, v in topic_scores.items()}

    # Get primary topic
    primary_topic = (
        max(topic_scores.keys(), key=lambda k: topic_scores[k])
        if topic_scores
        else "기타"
    )

    latency_ms = int((time.time() - start_time) * 1000)

    return {
        "request_id": request.request_id,
        "status": "success",
        "topic": {
            "primary": primary_topic,
            "confidence": topic_distribution.get(primary_topic, 0.0),
            "distribution": topic_distribution,
            "all_topics": list(topic_scores.keys()),
        },
        "meta": {
            "model_version": "topic-keyword-v1",
            "latency_ms": latency_ms,
            "processed_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        },
    }


# ========== Entry Point ==========

if __name__ == "__main__":
    import uvicorn

    port = int(os.getenv("PORT", "8100"))
    host = os.getenv("HOST", "0.0.0.0")

    uvicorn.run(app, host=host, port=port)

```

---

## backend/news-scraper/main.py

```py
"""
Newspaper4k News Article Scraper Service

A FastAPI microservice that extracts clean article content from news URLs
using the newspaper4k library. Designed to be called from Java services
with fallback support.
"""

import asyncio
import hashlib
import logging
import os
import uuid
from datetime import datetime
from typing import Optional, List, Dict, Any
from contextlib import asynccontextmanager
from enum import Enum

from fastapi import FastAPI, HTTPException, Request, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
import newspaper
from newspaper import Article, Config

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


# --- Configuration ---
class AppConfig:
    """Application configuration from environment variables."""

    DEFAULT_LANGUAGE = os.getenv("NEWS_SCRAPER_DEFAULT_LANGUAGE", "ko")
    DEFAULT_TIMEOUT = int(os.getenv("NEWS_SCRAPER_DEFAULT_TIMEOUT", "10"))
    MAX_TIMEOUT = int(os.getenv("NEWS_SCRAPER_MAX_TIMEOUT", "30"))
    USER_AGENT = os.getenv(
        "NEWS_SCRAPER_USER_AGENT",
        "Mozilla/5.0 (compatible; NewsInsight-Scraper/1.0; +https://newsinsight.ai)",
    )
    ALLOWED_SCHEMES = {"http", "https"}
    # Batch processing settings
    BATCH_MAX_URLS = int(os.getenv("NEWS_SCRAPER_BATCH_MAX_URLS", "100"))
    BATCH_CONCURRENCY = int(os.getenv("NEWS_SCRAPER_BATCH_CONCURRENCY", "5"))
    BATCH_JOB_TTL_HOURS = int(os.getenv("NEWS_SCRAPER_BATCH_JOB_TTL_HOURS", "24"))


config = AppConfig()


# --- Request/Response Models ---
class ScrapeRequest(BaseModel):
    """Request model for article scraping."""

    url: str = Field(..., description="The URL of the news article to scrape")
    language: Optional[str] = Field(
        default=None,
        description="Language code (e.g., 'ko', 'en'). Auto-detected if not specified.",
    )
    timeout_sec: Optional[int] = Field(
        default=None, ge=1, le=30, description="Request timeout in seconds (1-30)"
    )
    extract_html: Optional[bool] = Field(
        default=False, description="Whether to include raw HTML in response"
    )


class ScrapeResponse(BaseModel):
    """Response model for successful article extraction."""

    status: str = Field(default="ok", description="Response status")
    url: str = Field(..., description="Original URL")
    title: Optional[str] = Field(default=None, description="Article title")
    text: str = Field(..., description="Extracted article text content")
    html: Optional[str] = Field(default=None, description="Raw article HTML")
    top_image: Optional[str] = Field(default=None, description="Main article image URL")
    authors: List[str] = Field(default_factory=list, description="List of authors")
    publish_date: Optional[str] = Field(
        default=None, description="Publication date in ISO8601 format"
    )
    keywords: List[str] = Field(default_factory=list, description="Extracted keywords")
    summary: Optional[str] = Field(
        default=None, description="Article summary/description"
    )
    content_hash: Optional[str] = Field(
        default=None, description="SHA-256 hash of extracted text for deduplication"
    )
    extraction_time_ms: Optional[int] = Field(
        default=None, description="Time taken for extraction in milliseconds"
    )


class ErrorResponse(BaseModel):
    """Response model for errors."""

    status: str = Field(default="error")
    url: str
    error_code: str
    error_message: str


class HealthResponse(BaseModel):
    """Health check response."""

    status: str
    version: str
    library_version: str


# --- Batch Processing Enums and Models ---
class JobStatus(str, Enum):
    """Batch job status enum."""

    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


class UrlStatus(str, Enum):
    """Individual URL processing status."""

    PENDING = "pending"
    PROCESSING = "processing"
    SUCCESS = "success"
    FAILED = "failed"


class BatchUrlItem(BaseModel):
    """Individual URL item in batch request."""

    url: str = Field(..., description="URL to scrape")
    language: Optional[str] = Field(
        default=None, description="Language override for this URL"
    )


class BatchScrapeRequest(BaseModel):
    """Request model for batch scraping."""

    urls: List[str] = Field(
        ...,
        min_length=1,
        max_length=100,
        description="List of URLs to scrape (max 100)",
    )
    language: Optional[str] = Field(
        default=None, description="Default language for all URLs"
    )
    timeout_sec: Optional[int] = Field(
        default=10, ge=1, le=30, description="Timeout per URL in seconds"
    )
    concurrency: Optional[int] = Field(
        default=5, ge=1, le=10, description="Number of concurrent scraping tasks"
    )
    callback_url: Optional[str] = Field(
        default=None, description="Webhook URL to notify when job completes"
    )


class UrlResult(BaseModel):
    """Result for a single URL in batch processing."""

    url: str
    status: UrlStatus
    title: Optional[str] = None
    text: Optional[str] = None
    top_image: Optional[str] = None
    authors: List[str] = Field(default_factory=list)
    publish_date: Optional[str] = None
    keywords: List[str] = Field(default_factory=list)
    summary: Optional[str] = None
    content_hash: Optional[str] = None
    extraction_time_ms: Optional[int] = None
    error_code: Optional[str] = None
    error_message: Optional[str] = None


class BatchJobResponse(BaseModel):
    """Response for batch job submission."""

    job_id: str = Field(..., description="Unique job identifier")
    status: JobStatus
    total_urls: int
    message: str


class BatchJobStatusResponse(BaseModel):
    """Response for batch job status query."""

    job_id: str
    status: JobStatus
    total_urls: int
    completed: int
    failed: int
    pending: int
    progress_percent: float
    created_at: str
    updated_at: str
    completed_at: Optional[str] = None
    results: Optional[List[UrlResult]] = None


class BatchJob:
    """Internal batch job tracking class."""

    def __init__(
        self,
        job_id: str,
        urls: List[str],
        language: Optional[str],
        timeout_sec: int,
        concurrency: int,
        callback_url: Optional[str] = None,
    ):
        self.job_id = job_id
        self.urls = urls
        self.language = language
        self.timeout_sec = timeout_sec
        self.concurrency = concurrency
        self.callback_url = callback_url
        self.status = JobStatus.PENDING
        self.results: Dict[str, UrlResult] = {}
        self.created_at = datetime.utcnow()
        self.updated_at = datetime.utcnow()
        self.completed_at: Optional[datetime] = None

        # Initialize all URLs as pending
        for url in urls:
            self.results[url] = UrlResult(url=url, status=UrlStatus.PENDING)

    @property
    def total_urls(self) -> int:
        return len(self.urls)

    @property
    def completed_count(self) -> int:
        return sum(1 for r in self.results.values() if r.status == UrlStatus.SUCCESS)

    @property
    def failed_count(self) -> int:
        return sum(1 for r in self.results.values() if r.status == UrlStatus.FAILED)

    @property
    def pending_count(self) -> int:
        return sum(
            1
            for r in self.results.values()
            if r.status in (UrlStatus.PENDING, UrlStatus.PROCESSING)
        )

    @property
    def progress_percent(self) -> float:
        processed = self.completed_count + self.failed_count
        return (
            round((processed / self.total_urls) * 100, 2)
            if self.total_urls > 0
            else 0.0
        )

    def to_status_response(
        self, include_results: bool = True
    ) -> BatchJobStatusResponse:
        return BatchJobStatusResponse(
            job_id=self.job_id,
            status=self.status,
            total_urls=self.total_urls,
            completed=self.completed_count,
            failed=self.failed_count,
            pending=self.pending_count,
            progress_percent=self.progress_percent,
            created_at=self.created_at.isoformat(),
            updated_at=self.updated_at.isoformat(),
            completed_at=self.completed_at.isoformat() if self.completed_at else None,
            results=list(self.results.values()) if include_results else None,
        )


# --- In-Memory Job Store ---
class JobStore:
    """Simple in-memory job store with TTL-based cleanup."""

    def __init__(self, ttl_hours: int = 24):
        self._jobs: Dict[str, BatchJob] = {}
        self._ttl_hours = ttl_hours
        self._lock = asyncio.Lock()

    async def create_job(
        self,
        urls: List[str],
        language: Optional[str],
        timeout_sec: int,
        concurrency: int,
        callback_url: Optional[str] = None,
    ) -> BatchJob:
        """Create a new batch job."""
        job_id = str(uuid.uuid4())
        job = BatchJob(
            job_id=job_id,
            urls=urls,
            language=language,
            timeout_sec=timeout_sec,
            concurrency=concurrency,
            callback_url=callback_url,
        )
        async with self._lock:
            self._jobs[job_id] = job
        return job

    async def get_job(self, job_id: str) -> Optional[BatchJob]:
        """Get job by ID."""
        async with self._lock:
            return self._jobs.get(job_id)

    async def update_job(self, job: BatchJob) -> None:
        """Update job in store."""
        job.updated_at = datetime.utcnow()
        async with self._lock:
            self._jobs[job.job_id] = job

    async def cleanup_old_jobs(self) -> int:
        """Remove jobs older than TTL."""
        cutoff = datetime.utcnow()
        removed = 0
        async with self._lock:
            to_remove = []
            for job_id, job in self._jobs.items():
                age_hours = (cutoff - job.created_at).total_seconds() / 3600
                if age_hours > self._ttl_hours:
                    to_remove.append(job_id)
            for job_id in to_remove:
                del self._jobs[job_id]
                removed += 1
        return removed

    async def list_jobs(self, limit: int = 50) -> List[BatchJob]:
        """List recent jobs."""
        async with self._lock:
            jobs = sorted(self._jobs.values(), key=lambda j: j.created_at, reverse=True)
            return jobs[:limit]


# Global job store
job_store = JobStore(ttl_hours=config.BATCH_JOB_TTL_HOURS)


# --- Lifespan Management ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan handler for startup/shutdown."""
    logger.info("News Scraper service starting up...")
    logger.info(f"Default language: {config.DEFAULT_LANGUAGE}")
    logger.info(f"Default timeout: {config.DEFAULT_TIMEOUT}s")
    yield
    logger.info("News Scraper service shutting down...")


# --- FastAPI App ---
app = FastAPI(
    title="Newspaper4k News Scraper",
    description="Extracts clean article content from news URLs using newspaper4k",
    version="1.0.0",
    lifespan=lifespan,
)

# CORS middleware for development
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# --- Helper Functions ---
def validate_url(url: str) -> None:
    """Validate URL scheme and format."""
    from urllib.parse import urlparse

    try:
        parsed = urlparse(url)
        if parsed.scheme not in config.ALLOWED_SCHEMES:
            raise ValueError(f"Unsupported URL scheme: {parsed.scheme}")
        if not parsed.netloc:
            raise ValueError("Invalid URL: missing domain")
    except Exception as e:
        raise ValueError(f"Invalid URL format: {str(e)}")


def compute_content_hash(text: str) -> str:
    """Compute SHA-256 hash of content for deduplication."""
    return hashlib.sha256(text.encode("utf-8")).hexdigest()


def create_newspaper_config(
    language: Optional[str] = None, timeout: int = 10
) -> Config:
    """Create newspaper4k configuration."""
    cfg = Config()
    cfg.browser_user_agent = config.USER_AGENT
    cfg.request_timeout = timeout
    cfg.fetch_images = True
    cfg.memoize_articles = False
    cfg.language = language or config.DEFAULT_LANGUAGE
    cfg.keep_article_html = True
    return cfg


async def extract_article(
    url: str,
    language: Optional[str] = None,
    timeout: int = 10,
    extract_html: bool = False,
) -> dict:
    """
    Extract article content from URL using newspaper4k.

    Runs in thread pool to avoid blocking the event loop.
    """

    def _extract():
        start_time = datetime.now()

        cfg = create_newspaper_config(language, timeout)
        article = Article(url, config=cfg)

        # Download and parse
        article.download()
        article.parse()

        # NLP processing for keywords/summary (optional, may fail)
        try:
            article.nlp()
        except Exception as nlp_error:
            logger.warning(f"NLP processing failed for {url}: {nlp_error}")

        # Calculate extraction time
        extraction_time_ms = int((datetime.now() - start_time).total_seconds() * 1000)

        # Format publish date
        publish_date = None
        if article.publish_date:
            try:
                publish_date = article.publish_date.isoformat()
            except Exception:
                publish_date = str(article.publish_date)

        # Get text content
        text = article.text or ""

        return {
            "title": article.title,
            "text": text,
            "html": article.article_html if extract_html else None,
            "top_image": article.top_image,
            "authors": list(article.authors) if article.authors else [],
            "publish_date": publish_date,
            "keywords": list(article.keywords) if article.keywords else [],
            "summary": article.summary if hasattr(article, "summary") else None,
            "content_hash": compute_content_hash(text) if text else None,
            "extraction_time_ms": extraction_time_ms,
        }

    # Run in thread pool to avoid blocking
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, _extract)


# --- Batch Processing Functions ---
async def process_single_url(
    job: BatchJob, url: str, semaphore: asyncio.Semaphore
) -> UrlResult:
    """Process a single URL within a batch job with semaphore-controlled concurrency."""
    async with semaphore:
        # Mark as processing
        job.results[url].status = UrlStatus.PROCESSING

        try:
            # Validate URL first
            validate_url(url)

            # Extract article
            result = await asyncio.wait_for(
                extract_article(
                    url=url,
                    language=job.language,
                    timeout=job.timeout_sec,
                    extract_html=False,
                ),
                timeout=job.timeout_sec + 2,
            )

            # Check content quality
            if not result["text"] or len(result["text"].strip()) < 50:
                job.results[url] = UrlResult(
                    url=url,
                    status=UrlStatus.FAILED,
                    error_code="CONTENT_TOO_SHORT",
                    error_message="Extracted content is too short or empty",
                )
            else:
                job.results[url] = UrlResult(
                    url=url,
                    status=UrlStatus.SUCCESS,
                    title=result.get("title"),
                    text=result.get("text"),
                    top_image=result.get("top_image"),
                    authors=result.get("authors", []),
                    publish_date=result.get("publish_date"),
                    keywords=result.get("keywords", []),
                    summary=result.get("summary"),
                    content_hash=result.get("content_hash"),
                    extraction_time_ms=result.get("extraction_time_ms"),
                )
                logger.info(f"[Batch:{job.job_id}] Successfully scraped: {url}")

        except asyncio.TimeoutError:
            job.results[url] = UrlResult(
                url=url,
                status=UrlStatus.FAILED,
                error_code="TIMEOUT",
                error_message=f"Extraction timed out after {job.timeout_sec}s",
            )
            logger.warning(f"[Batch:{job.job_id}] Timeout: {url}")
        except ValueError as e:
            job.results[url] = UrlResult(
                url=url,
                status=UrlStatus.FAILED,
                error_code="INVALID_URL",
                error_message=str(e),
            )
            logger.warning(f"[Batch:{job.job_id}] Invalid URL: {url} - {e}")
        except Exception as e:
            job.results[url] = UrlResult(
                url=url,
                status=UrlStatus.FAILED,
                error_code="EXTRACTION_FAILED",
                error_message=str(e),
            )
            logger.error(f"[Batch:{job.job_id}] Error scraping {url}: {e}")

        return job.results[url]


async def process_batch_job(job: BatchJob) -> None:
    """Process all URLs in a batch job with controlled concurrency."""
    logger.info(
        f"[Batch:{job.job_id}] Starting batch processing of {len(job.urls)} URLs "
        f"with concurrency={job.concurrency}"
    )

    job.status = JobStatus.PROCESSING
    await job_store.update_job(job)

    # Create semaphore for concurrency control
    semaphore = asyncio.Semaphore(job.concurrency)

    # Process all URLs concurrently (limited by semaphore)
    tasks = [process_single_url(job, url, semaphore) for url in job.urls]

    try:
        await asyncio.gather(*tasks, return_exceptions=True)

        # Determine final job status
        if job.failed_count == job.total_urls:
            job.status = JobStatus.FAILED
        else:
            job.status = JobStatus.COMPLETED

    except Exception as e:
        logger.exception(f"[Batch:{job.job_id}] Batch processing error: {e}")
        job.status = JobStatus.FAILED

    job.completed_at = datetime.utcnow()
    await job_store.update_job(job)

    logger.info(
        f"[Batch:{job.job_id}] Batch completed: "
        f"{job.completed_count}/{job.total_urls} success, "
        f"{job.failed_count} failed"
    )

    # Optional: Send webhook callback
    if job.callback_url:
        await send_webhook_callback(job)


async def send_webhook_callback(job: BatchJob) -> None:
    """Send webhook notification when job completes."""
    try:
        import aiohttp

        async with aiohttp.ClientSession() as session:
            payload = {
                "job_id": job.job_id,
                "status": job.status.value,
                "total_urls": job.total_urls,
                "completed": job.completed_count,
                "failed": job.failed_count,
            }
            async with session.post(
                job.callback_url, json=payload, timeout=aiohttp.ClientTimeout(total=10)
            ) as response:
                logger.info(
                    f"[Batch:{job.job_id}] Webhook callback sent to {job.callback_url}: "
                    f"status={response.status}"
                )
    except Exception as e:
        logger.warning(f"[Batch:{job.job_id}] Webhook callback failed: {e}")


# --- API Endpoints ---
@app.get("/health", response_model=HealthResponse)
@app.head("/health")
async def health_check():
    """Health check endpoint."""
    return HealthResponse(
        status="ok",
        version="1.0.0",
        library_version=newspaper.__version__
        if hasattr(newspaper, "__version__")
        else "unknown",
    )


@app.post(
    "/v1/scrape/article",
    response_model=ScrapeResponse,
    responses={
        400: {"model": ErrorResponse, "description": "Invalid request"},
        500: {"model": ErrorResponse, "description": "Extraction failed"},
    },
)
async def scrape_article(request: ScrapeRequest, req: Request):
    """
    Extract article content from a news URL.

    Uses newspaper4k to extract:
    - Title
    - Main text content (cleaned)
    - Authors
    - Publication date
    - Top image
    - Keywords (via NLP)
    - Summary

    Returns content hash for deduplication support.
    """
    # Get trace ID from header if available
    trace_id = req.headers.get("X-Trace-Id", req.headers.get("X-Request-Id", "unknown"))

    logger.info(f"[{trace_id}] Scraping article: {request.url}")

    # Validate URL
    try:
        validate_url(request.url)
    except ValueError as e:
        logger.warning(f"[{trace_id}] Invalid URL: {request.url} - {e}")
        raise HTTPException(
            status_code=400,
            detail=ErrorResponse(
                url=request.url, error_code="INVALID_URL", error_message=str(e)
            ).model_dump(),
        )

    # Determine timeout
    timeout = request.timeout_sec or config.DEFAULT_TIMEOUT
    timeout = min(timeout, config.MAX_TIMEOUT)

    try:
        # Extract article with asyncio timeout
        result = await asyncio.wait_for(
            extract_article(
                url=request.url,
                language=request.language,
                timeout=timeout,
                extract_html=request.extract_html or False,
            ),
            timeout=timeout + 2,  # Add buffer for processing
        )

        # Check if we got meaningful content
        if not result["text"] or len(result["text"].strip()) < 50:
            logger.warning(
                f"[{trace_id}] Extracted content too short for {request.url}: "
                f"{len(result['text'] or '')} chars"
            )
            raise HTTPException(
                status_code=400,
                detail=ErrorResponse(
                    url=request.url,
                    error_code="CONTENT_TOO_SHORT",
                    error_message="Extracted article content is too short or empty",
                ).model_dump(),
            )

        logger.info(
            f"[{trace_id}] Successfully extracted {len(result['text'])} chars "
            f"from {request.url} in {result['extraction_time_ms']}ms"
        )

        return ScrapeResponse(status="ok", url=request.url, **result)

    except asyncio.TimeoutError:
        logger.error(f"[{trace_id}] Timeout extracting article: {request.url}")
        raise HTTPException(
            status_code=500,
            detail=ErrorResponse(
                url=request.url,
                error_code="TIMEOUT",
                error_message=f"Article extraction timed out after {timeout}s",
            ).model_dump(),
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"[{trace_id}] Error extracting article: {request.url}")
        raise HTTPException(
            status_code=500,
            detail=ErrorResponse(
                url=request.url, error_code="EXTRACTION_FAILED", error_message=str(e)
            ).model_dump(),
        )


# --- Batch Processing Endpoints ---
@app.post(
    "/v1/scrape/batch",
    response_model=BatchJobResponse,
    responses={
        400: {"description": "Invalid request"},
        503: {"description": "Service overloaded"},
    },
)
async def submit_batch_job(
    request: BatchScrapeRequest, background_tasks: BackgroundTasks, req: Request
):
    """
    Submit a batch scraping job for multiple URLs.

    The job runs asynchronously in the background. Use the returned job_id
    to poll for status and results via GET /v1/scrape/batch/{job_id}.

    Features:
    - Processes up to 100 URLs per batch
    - Configurable concurrency (1-10 parallel requests)
    - Per-URL timeout with graceful error handling
    - Optional webhook callback on completion
    """
    trace_id = req.headers.get("X-Trace-Id", req.headers.get("X-Request-Id", "unknown"))

    # Validate URL count
    if len(request.urls) > config.BATCH_MAX_URLS:
        raise HTTPException(
            status_code=400,
            detail=f"Maximum {config.BATCH_MAX_URLS} URLs allowed per batch",
        )

    # Remove duplicates while preserving order
    unique_urls = list(dict.fromkeys(request.urls))

    logger.info(
        f"[{trace_id}] Batch job submitted: {len(unique_urls)} URLs "
        f"(concurrency={request.concurrency})"
    )

    # Create job
    job = await job_store.create_job(
        urls=unique_urls,
        language=request.language,
        timeout_sec=request.timeout_sec or config.DEFAULT_TIMEOUT,
        concurrency=min(request.concurrency or config.BATCH_CONCURRENCY, 10),
        callback_url=request.callback_url,
    )

    # Start background processing
    background_tasks.add_task(process_batch_job, job)

    return BatchJobResponse(
        job_id=job.job_id,
        status=job.status,
        total_urls=job.total_urls,
        message=f"Batch job created. Poll GET /v1/scrape/batch/{job.job_id} for status.",
    )


@app.get(
    "/v1/scrape/batch/{job_id}",
    response_model=BatchJobStatusResponse,
    responses={404: {"description": "Job not found"}},
)
async def get_batch_job_status(job_id: str, include_results: bool = True):
    """
    Get the status and results of a batch scraping job.

    Parameters:
    - job_id: The unique job identifier from the POST response
    - include_results: Whether to include individual URL results (default: true)

    Returns progress information and, when complete, the results for each URL.
    """
    job = await job_store.get_job(job_id)

    if not job:
        raise HTTPException(
            status_code=404, detail=f"Job {job_id} not found or has expired"
        )

    return job.to_status_response(include_results=include_results)


@app.delete(
    "/v1/scrape/batch/{job_id}",
    responses={
        404: {"description": "Job not found"},
        409: {"description": "Job cannot be cancelled"},
    },
)
async def cancel_batch_job(job_id: str):
    """
    Cancel a pending or processing batch job.

    Note: URLs that are already being processed may still complete.
    """
    job = await job_store.get_job(job_id)

    if not job:
        raise HTTPException(status_code=404, detail=f"Job {job_id} not found")

    if job.status in (JobStatus.COMPLETED, JobStatus.FAILED, JobStatus.CANCELLED):
        raise HTTPException(
            status_code=409,
            detail=f"Job {job_id} is already {job.status.value} and cannot be cancelled",
        )

    job.status = JobStatus.CANCELLED
    job.completed_at = datetime.utcnow()
    await job_store.update_job(job)

    logger.info(f"[Batch:{job_id}] Job cancelled by user")

    return {"status": "cancelled", "job_id": job_id}


@app.get("/v1/scrape/batch")
async def list_batch_jobs(limit: int = 20):
    """
    List recent batch jobs.

    Returns summary information for up to `limit` most recent jobs.
    """
    jobs = await job_store.list_jobs(limit=min(limit, 50))

    return {
        "jobs": [
            {
                "job_id": job.job_id,
                "status": job.status.value,
                "total_urls": job.total_urls,
                "completed": job.completed_count,
                "failed": job.failed_count,
                "progress_percent": job.progress_percent,
                "created_at": job.created_at.isoformat(),
            }
            for job in jobs
        ],
        "count": len(jobs),
    }


@app.get("/v1/scrape/batch/status")
async def batch_service_status():
    """Get batch processing service status and configuration."""
    jobs = await job_store.list_jobs(limit=100)
    active_jobs = [
        j for j in jobs if j.status in (JobStatus.PENDING, JobStatus.PROCESSING)
    ]

    return {
        "status": "ok",
        "config": {
            "max_urls_per_batch": config.BATCH_MAX_URLS,
            "default_concurrency": config.BATCH_CONCURRENCY,
            "job_ttl_hours": config.BATCH_JOB_TTL_HOURS,
        },
        "stats": {"active_jobs": len(active_jobs), "total_jobs_in_memory": len(jobs)},
    }


# --- Main Entry Point ---
if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=int(os.getenv("PORT", "8000")),
        reload=os.getenv("ENV", "production") == "development",
    )

```

---

## backend/shared/__init__.py

```py
__all__ = []

```

---

## backend/shared/prometheus_metrics.py

```py
from __future__ import annotations

import time
from contextlib import contextmanager
from typing import Any, Callable, Iterable, Optional

from fastapi import FastAPI
from fastapi.responses import Response
from prometheus_client import CONTENT_TYPE_LATEST, Counter, Gauge, Histogram, generate_latest


def setup_metrics(app: FastAPI, service_name: str, version: str = "") -> None:
    def metrics_endpoint() -> Response:
        payload = generate_latest()
        return Response(content=payload, media_type=CONTENT_TYPE_LATEST)

    app.add_api_route("/metrics", metrics_endpoint, methods=["GET"])


class ServiceMetrics:
    def __init__(self, service_name: str) -> None:
        self._service_name = service_name.replace("-", "_")

    def _full_name(self, metric_name: str) -> str:
        metric = metric_name.strip()
        if metric.startswith(f"{self._service_name}_"):
            return metric
        return f"{self._service_name}_{metric}"

    def create_counter(self, name: str, documentation: str, labelnames: Optional[Iterable[str]] = None) -> Counter:
        return Counter(self._full_name(name), documentation, labelnames=list(labelnames or []))

    def create_histogram(
        self,
        name: str,
        documentation: str,
        labelnames: Optional[Iterable[str]] = None,
        buckets: Optional[tuple[float, ...]] = None,
    ) -> Histogram:
        return Histogram(
            self._full_name(name),
            documentation,
            labelnames=list(labelnames or []),
            buckets=buckets,
        )

    def create_gauge(self, name: str, documentation: str, labelnames: Optional[Iterable[str]] = None) -> Gauge:
        return Gauge(self._full_name(name), documentation, labelnames=list(labelnames or []))


@contextmanager
def track_request_time(metric: Any, *label_values: Any, **label_kwargs: Any):
    start = time.time()
    try:
        yield
    finally:
        duration = time.time() - start
        try:
            if hasattr(metric, "labels"):
                metric.labels(*label_values, **label_kwargs).observe(duration)
            else:
                metric.observe(duration)
        except Exception:
            pass


def track_operation(counter: Any, *label_values: Any, **label_kwargs: Any) -> None:
    try:
        if hasattr(counter, "labels"):
            counter.labels(*label_values, **label_kwargs).inc()
        else:
            counter.inc()
    except Exception:
        pass


def track_error(counter: Any, *label_values: Any, **label_kwargs: Any) -> None:
    track_operation(counter, *label_values, **label_kwargs)


def track_item_processed(counter: Any, count: int = 1, *label_values: Any, **label_kwargs: Any) -> None:
    try:
        if hasattr(counter, "labels"):
            counter.labels(*label_values, **label_kwargs).inc(count)
        else:
            counter.inc(count)
    except Exception:
        pass

```

---

## backend/shared/proxy_client.py

```py
from __future__ import annotations

import asyncio
from dataclasses import dataclass
from typing import Any, Optional

import httpx


@dataclass
class ProxyInfo:
    id: str
    address: str
    protocol: str = "http"
    username: Optional[str] = None
    password: Optional[str] = None
    country: Optional[str] = None
    health_status: Optional[str] = None

    def get_proxy_url(self) -> str:
        if self.username and self.password and "://" in self.address:
            scheme, rest = self.address.split("://", 1)
            return f"{scheme}://{self.username}:{self.password}@{rest}"
        return self.address


class ProxyRotationClient:
    def __init__(
        self,
        base_url: str,
        timeout: float = 5.0,
        enabled: bool = True,
    ) -> None:
        self._base_url = base_url.rstrip("/")
        self._timeout = timeout
        self._enabled = enabled
        self._client: Optional[httpx.AsyncClient] = None
        self._lock = asyncio.Lock()

    async def _get_client(self) -> httpx.AsyncClient:
        async with self._lock:
            if self._client is None:
                self._client = httpx.AsyncClient(timeout=self._timeout)
            return self._client

    async def close(self) -> None:
        async with self._lock:
            if self._client is not None:
                await self._client.aclose()
                self._client = None

    async def health_check(self) -> bool:
        if not self._enabled:
            return False
        client = await self._get_client()
        try:
            resp = await client.get(f"{self._base_url}/health")
            return resp.status_code == 200
        except Exception:
            return False

    async def get_next_proxy(self) -> Optional[ProxyInfo]:
        if not self._enabled:
            return None
        client = await self._get_client()
        try:
            resp = await client.get(f"{self._base_url}/proxy/next")
            if resp.status_code != 200:
                return None
            data: Any = resp.json()
            if not isinstance(data, dict):
                return None

            proxy_id = data.get("proxyId") or data.get("proxy_id") or data.get("id")
            address = data.get("address")
            if not proxy_id or not address:
                return None

            return ProxyInfo(
                id=str(proxy_id),
                address=str(address),
                protocol=str(data.get("protocol") or "http"),
                username=data.get("username"),
                password=data.get("password"),
                country=data.get("country"),
                health_status=data.get("healthStatus") or data.get("health_status"),
            )
        except Exception:
            return None

    async def record_success(self, proxy_id: str, latency_ms: int = 0) -> bool:
        return await self._record(proxy_id=proxy_id, success=True, latency_ms=latency_ms)

    async def record_failure(self, proxy_id: str, reason: str = "") -> bool:
        return await self._record(proxy_id=proxy_id, success=False, reason=reason)

    async def record_captcha(self, proxy_id: str, captcha_type: str = "") -> bool:
        if not self._enabled:
            return False
        client = await self._get_client()
        payload = {
            "proxyId": proxy_id,
            "type": captcha_type,
        }
        try:
            resp = await client.post(f"{self._base_url}/proxy/captcha", json=payload)
            return resp.status_code == 200
        except Exception:
            return False

    async def _record(
        self,
        proxy_id: str,
        success: bool,
        latency_ms: int = 0,
        reason: str = "",
    ) -> bool:
        if not self._enabled:
            return False
        client = await self._get_client()
        payload = {
            "proxyId": proxy_id,
            "success": bool(success),
            "latencyMs": int(latency_ms),
            "reason": reason,
        }
        try:
            resp = await client.post(f"{self._base_url}/proxy/record", json=payload)
            return resp.status_code == 200
        except Exception:
            return False

    async def get_pool_stats(self) -> Optional[dict[str, Any]]:
        if not self._enabled:
            return None
        client = await self._get_client()
        try:
            resp = await client.get(f"{self._base_url}/health")
            if resp.status_code != 200:
                return None
            data: Any = resp.json()
            if isinstance(data, dict):
                stats = data.get("stats")
                return stats if isinstance(stats, dict) else data
            return None
        except Exception:
            return None

```

---

## backend/shared-libs/build.gradle.kts

```kts
// 공통 라이브러리 모듈 빌드 설정 (선택 사항)

plugins {
    `java-library`
}

// 공통 라이브러리는 실행 가능한 JAR가 아니므로 일반 JAR로 패키징
tasks.named<Jar>("jar") {
    enabled = true
}

dependencies {
    // 공통으로 사용할 유틸리티 클래스, 예외, DTO 등
    
    // Consul Config (공통 설정 로더)
    api("org.springframework.cloud:spring-cloud-starter-consul-config")
    
    // Validation
    api("org.springframework.boot:spring-boot-starter-validation")
    
    // JSON Processing
    api("com.fasterxml.jackson.core:jackson-databind")
    api("com.fasterxml.jackson.datatype:jackson-datatype-jsr310")
}

```

---

## backend/shared-libs/src/main/java/com/newsinsight/shared/package-info.java

```java
/**
 * NewsInsight 공통 라이브러리 패키지.
 * 
 * 이 모듈은 모든 서비스에서 공유하는 공통 유틸리티, DTO, 예외 클래스 등을 포함합니다.
 */
package com.newsinsight.shared;

```

---

## build.gradle.kts

```kts
// NewsInsight 루트 빌드 설정

plugins {
    java
    id("org.springframework.boot") version "3.2.1" apply false
    id("io.spring.dependency-management") version "1.1.4" apply false
    kotlin("jvm") version "1.9.21" apply false
    kotlin("plugin.spring") version "1.9.21" apply false
}

allprojects {
    group = "com.newsinsight"
    version = "1.0.0"
    
    repositories {
        mavenCentral()
    }
}

subprojects {
    // backend 디렉터리 자체는 모듈이 아니므로 스킵
    if (path == ":backend") {
        return@subprojects
    }
    
    apply(plugin = "java")
    
    java {
        sourceCompatibility = JavaVersion.VERSION_21
        targetCompatibility = JavaVersion.VERSION_21
    }
    
    // 실행 가능한 모듈에만 Spring Boot 플러그인 적용
    if (name !in listOf("shared-libs")) {
        apply(plugin = "org.springframework.boot")
        apply(plugin = "io.spring.dependency-management")
        
        dependencies {
            // 모든 서비스 공통 의존성
            implementation("org.springframework.boot:spring-boot-starter-actuator")
            implementation("org.springframework.cloud:spring-cloud-starter-consul-config")
            implementation("org.springframework.cloud:spring-cloud-starter-consul-discovery")
            
            // Lombok (선택 사항)
            compileOnly("org.projectlombok:lombok")
            annotationProcessor("org.projectlombok:lombok")
            
            // Logging
            implementation("net.logstash.logback:logstash-logback-encoder:7.4")
            
            // Validation
            implementation("org.springframework.boot:spring-boot-starter-validation")
            
            // Test
            testImplementation("org.springframework.boot:spring-boot-starter-test")
            testRuntimeOnly("org.junit.platform:junit-platform-launcher")
        }
    } else {
        // shared-libs needs dependency management for Spring Boot dependencies
        apply(plugin = "io.spring.dependency-management")
    }
    
    // Spring Cloud 버전 관리
    extra["springCloudVersion"] = "2023.0.0"
    extra["springBootVersion"] = "3.2.1"
    
    configure<io.spring.gradle.dependencymanagement.dsl.DependencyManagementExtension> {
        imports {
            mavenBom("org.springframework.boot:spring-boot-dependencies:${project.extra["springBootVersion"]}")
            mavenBom("org.springframework.cloud:spring-cloud-dependencies:${project.extra["springCloudVersion"]}")
        }
    }
    
    tasks.withType<Test> {
        useJUnitPlatform()
    }
    
    tasks.withType<JavaCompile> {
        options.encoding = "UTF-8"
        options.compilerArgs.add("-parameters")
    }
}

```

---

## collect-code-to-md.js

```js
const fs = require('fs').promises;
const path = require('path');
const { spawn } = require('child_process');

const config = {
  rootDir: process.cwd(),
  // 기본 출력 파일 이름(여러 개로 나눌 경우 접미사가 붙습니다)
  outputFile: 'project-code-collection.md',
  // 포함할 확장자
  includeExtensions: [
    '.js',
    '.jsx',
    '.ts',
    '.tsx',
    '.java',
    '.kt',
    '.kts',
    '.py',
    '.go',
    '.rs',
    '.c',
    '.cpp',
    '.h',
    '.hpp',
    '.html',
    '.css',
    '.scss',
    '.json',
    '.yml',
    '.yaml'
  ],
  // 완전히 제외할 디렉터리명
  excludeDirs: [
    '.git',
    'node_modules',
    '.next',
    'dist',
    'build',
    'out',
    'coverage',
    'target',
    '.idea',
    '.vscode',
    '.gradle',
    '.turbo',
    '.github',
    'docs',
    'builds'
  ],
  // 제외할 파일 확장자 (includeExtensions에 있어도 우선 제외)
  excludeExtensions: [
    '.sh',
    '.jar',
    '.class',
    '.jpg'
  ],
  // 한 파일 최대 크기 (바이너리/초대형 파일 방지)
  maxFileSizeBytes: 2 * 1024 * 1024,
  // 출력할 Markdown 파일 개수 (1이면 단일 파일)
  maxOutputFiles: 5,
  // 첫 번째 출력 파일을 Kwrite로 열지 여부
  openInKwrite: false,
  // 출력 파일들이 있는 디렉터리를 Dolphin으로 열지 여부
  openInDolphin: true,
};

function shouldExcludeDir(name) {
  if (config.excludeDirs.includes(name)) return true;
  // 숨김 디렉터리는 기본 제외(.github 등 예외는 위에서 명시)
  if (name.startsWith('.') && !config.excludeDirs.includes(name)) return true;
  return false;
}

function shouldIncludeFile(name, fullPath, relPath) {
  if (relPath === config.outputFile || name === config.outputFile) return false;
  const ext = path.extname(name).toLowerCase();
  if (config.excludeExtensions.includes(ext)) return false;
  if (!config.includeExtensions.includes(ext)) return false;
  return true;
}

async function walk(dir, result) {
  const entries = await fs.readdir(dir, { withFileTypes: true });
  for (const entry of entries) {
    const fullPath = path.join(dir, entry.name);
    const relPath = path.relative(config.rootDir, fullPath);
    if (entry.isDirectory()) {
      if (shouldExcludeDir(entry.name)) continue;
      await walk(fullPath, result);
    } else if (entry.isFile()) {
      if (!shouldIncludeFile(entry.name, fullPath, relPath)) continue;
      result.push({ fullPath, relPath });
    }
  }
}

async function buildMarkdown(files) {
  const parts = [];
  parts.push('# Project Code Snapshot\n\n');
  parts.push(`Generated at ${new Date().toISOString()}\n`);
  for (const file of files) {
    const stat = await fs.stat(file.fullPath);
    if (stat.size > config.maxFileSizeBytes) continue;
    const content = await fs.readFile(file.fullPath, 'utf8');
    const ext = path.extname(file.fullPath).slice(1);
    const lang = ext || '';
    parts.push('\n---\n\n');
    parts.push(`## ${file.relPath}\n\n`);
    const safeContent = content.replace(/``\`/g, '``\\`');
    parts.push('``\`' + lang + '\n' + safeContent + '\n``\`\n');
  }
  return parts.join('');
}

async function openInKwrite(outPath) {
  if (!config.openInKwrite) return;
  try {
    const kwrite = spawn('kwrite', [outPath], {
      detached: true,
      stdio: 'ignore',
    });
    kwrite.on('error', (err) => {
      console.error('Failed to open Kwrite:', err && err.message ? err.message : err);
    });
    kwrite.unref();
  } catch (err) {
    console.error('Failed to spawn Kwrite:', err && err.message ? err.message : err);
  }
}

async function openInDolphin(dirPath) {
  if (!config.openInDolphin) return;
  try {
    const dolphin = spawn('dolphin', [dirPath], {
      detached: true,
      stdio: 'ignore',
    });
    dolphin.on('error', (err) => {
      console.error('Failed to open Dolphin:', err && err.message ? err.message : err);
    });
    dolphin.unref();
  } catch (err) {
    console.error('Failed to spawn Dolphin:', err && err.message ? err.message : err);
  }
}

function getOutputFileName(baseName, index, total) {
  if (total === 1) return baseName;
  const ext = path.extname(baseName); // .md
  const name = path.basename(baseName, ext); // project-code-collection
  return `${name}-${index + 1}${ext}`;
}

async function writeOutputMarkdowns(allFiles) {
  const totalFiles = allFiles.length;
  if (totalFiles === 0) {
    console.log('No files matched filters. Nothing to write.');
    return [];
  }

  const outputCount = Math.max(1, Math.min(config.maxOutputFiles || 1, totalFiles));
  const filesPerOutput = Math.ceil(totalFiles / outputCount);

  const outputPaths = [];

  for (let i = 0; i < outputCount; i++) {
    const start = i * filesPerOutput;
    if (start >= totalFiles) break;
    const end = Math.min(start + filesPerOutput, totalFiles);
    const slice = allFiles.slice(start, end);
    const markdown = await buildMarkdown(slice);
    const fileName = getOutputFileName(config.outputFile, i, outputCount);
    const outPath = path.join(config.rootDir, fileName);
    await fs.writeFile(outPath, markdown, 'utf8');
    outputPaths.push(outPath);
  }

  return outputPaths;
}

async function main() {
  try {
    const files = [];
    await walk(config.rootDir, files);

    const outputPaths = await writeOutputMarkdowns(files);
    if (outputPaths.length === 0) {
      return;
    }

    console.log(`Collected ${files.length} source files into ${outputPaths.length} markdown file(s):`);
    for (const p of outputPaths) {
      console.log('  - ' + path.relative(config.rootDir, p));
    }

    // 첫 번째 출력 파일을 Kwrite로 열기
    await openInKwrite(outputPaths[0]);
    // 출력 파일들이 있는 디렉터리를 Dolphin으로 열기 (모든 출력 파일이 같은 디렉터리에 있으므로 한 번만 호출)
    await openInDolphin(path.dirname(outputPaths[0]));
  } catch (err) {
    console.error('Failed to collect code to markdown:', err);
    process.exitCode = 1;
  }
}

main();

```

---

## etc/configs/services.json

```json
{
  "$schema": "./services.schema.json",
  "version": "1.1.0",
  "description": "NewsInsight service configuration profiles with Consul service discovery",
  
  "services": {
    "api-gateway": {
      "name": "API Gateway",
      "description": "Spring Boot API Gateway service",
      "port": 8000,
      "healthcheck": "/actuator/health",
      "hostname": "api-gateway",
      "dependencies": ["postgres", "mongo", "redis", "consul", "redpanda"],
      "consul": {
        "register": true,
        "service_name": "api-gateway",
        "tags": ["gateway", "api", "spring-boot"]
      },
      "profiles": {
        "development": {
          "replicas": 1,
          "resources": {
            "memory": "512Mi",
            "cpu": "250m"
          },
          "env": {
            "SPRING_PROFILES_ACTIVE": "development",
            "LOG_LEVEL": "DEBUG",
            "JAVA_OPTS": "-Xms128m -Xmx256m"
          }
        },
        "staging": {
          "replicas": 1,
          "resources": {
            "memory": "1Gi",
            "cpu": "500m"
          },
          "env": {
            "SPRING_PROFILES_ACTIVE": "staging",
            "LOG_LEVEL": "DEBUG",
            "JAVA_OPTS": "-Xms256m -Xmx512m"
          }
        },
        "production": {
          "replicas": 3,
          "resources": {
            "memory": "2Gi",
            "cpu": "1000m"
          },
          "env": {
            "SPRING_PROFILES_ACTIVE": "production",
            "LOG_LEVEL": "INFO",
            "JAVA_OPTS": "-Xms256m -Xmx512m"
          }
        }
      }
    },
    
    "collector-service": {
      "name": "Data Collector Service",
      "description": "News data collection and processing service",
      "port": 8081,
      "healthcheck": "/actuator/health",
      "hostname": "collector-service",
      "dependencies": ["postgres", "mongo", "redis", "consul", "redpanda"],
      "consul": {
        "register": true,
        "service_name": "collector-service",
        "tags": ["collector", "data", "spring-boot"]
      },
      "profiles": {
        "development": {
          "replicas": 1,
          "resources": {
            "memory": "512Mi",
            "cpu": "250m"
          },
          "env": {
            "SPRING_PROFILES_ACTIVE": "development",
            "LOG_LEVEL": "DEBUG",
            "JAVA_OPTS": "-Xms128m -Xmx256m"
          }
        },
        "staging": {
          "replicas": 1,
          "resources": {
            "memory": "1Gi",
            "cpu": "500m"
          },
          "env": {
            "SPRING_PROFILES_ACTIVE": "staging",
            "LOG_LEVEL": "DEBUG",
            "JAVA_OPTS": "-Xms256m -Xmx512m"
          }
        },
        "production": {
          "replicas": 2,
          "resources": {
            "memory": "2Gi",
            "cpu": "1000m"
          },
          "env": {
            "SPRING_PROFILES_ACTIVE": "production",
            "LOG_LEVEL": "INFO",
            "JAVA_OPTS": "-Xms256m -Xmx512m"
          }
        }
      }
    },
    
    "browser-use-api": {
      "name": "Browser-Use API",
      "description": "AI-powered browser automation service",
      "port": 8500,
      "healthcheck": "/health",
      "hostname": "browser-use-api",
      "dependencies": [],
      "consul": {
        "register": true,
        "service_name": "browser-use-api",
        "tags": ["browser", "automation", "python"]
      },
      "profiles": {
        "development": {
          "replicas": 1,
          "resources": {
            "memory": "1Gi",
            "cpu": "500m"
          },
          "env": {
            "PYTHONUNBUFFERED": "1",
            "LOG_LEVEL": "DEBUG"
          }
        },
        "staging": {
          "replicas": 1,
          "resources": {
            "memory": "2Gi",
            "cpu": "1000m"
          },
          "env": {
            "PYTHONUNBUFFERED": "1",
            "LOG_LEVEL": "DEBUG"
          }
        },
        "production": {
          "replicas": 2,
          "resources": {
            "memory": "4Gi",
            "cpu": "2000m"
          },
          "env": {
            "PYTHONUNBUFFERED": "1",
            "LOG_LEVEL": "INFO"
          }
        }
      }
    },
    
    "autonomous-crawler": {
      "name": "Autonomous Crawler",
      "description": "Autonomous web crawling and data extraction service",
      "port": 9090,
      "api_port": 8030,
      "healthcheck": "/health",
      "hostname": "autonomous-crawler",
      "dependencies": ["postgres", "mongo", "redis", "browser-use-api", "web-crawler"],
      "consul": {
        "register": true,
        "service_name": "autonomous-crawler",
        "tags": ["crawler", "autonomous", "python"]
      },
      "profiles": {
        "development": {
          "replicas": 1,
          "resources": {
            "memory": "512Mi",
            "cpu": "250m"
          },
          "env": {
            "LOG_LEVEL": "DEBUG",
            "LLM_PROVIDER": "openrouter",
            "LLM_OPENAI_MODEL": "gpt-4o",
            "LLM_ANTHROPIC_MODEL": "claude-3-5-sonnet-20241022",
            "LLM_OPENROUTER_MODEL": "anthropic/claude-3.5-sonnet",
            "LLM_OPENROUTER_BASE_URL": "https://openrouter.ai/api/v1",
            "LLM_OLLAMA_MODEL": "llama3.1",
            "LLM_OLLAMA_BASE_URL": "http://localhost:11434",
            "LLM_AZURE_API_VERSION": "2024-02-15-preview",
            "LLM_CUSTOM_RESPONSE_PATH": "reply"
          }
        },
        "staging": {
          "replicas": 1,
          "resources": {
            "memory": "1Gi",
            "cpu": "500m"
          },
          "env": {
            "LOG_LEVEL": "DEBUG",
            "LLM_PROVIDER": "openrouter",
            "LLM_OPENAI_MODEL": "gpt-4o",
            "LLM_ANTHROPIC_MODEL": "claude-3-5-sonnet-20241022",
            "LLM_OPENROUTER_MODEL": "anthropic/claude-3.5-sonnet",
            "LLM_OPENROUTER_BASE_URL": "https://openrouter.ai/api/v1",
            "LLM_OLLAMA_MODEL": "llama3.1",
            "LLM_OLLAMA_BASE_URL": "http://localhost:11434",
            "LLM_AZURE_API_VERSION": "2024-02-15-preview",
            "LLM_CUSTOM_RESPONSE_PATH": "reply"
          }
        },
        "production": {
          "replicas": 2,
          "resources": {
            "memory": "2Gi",
            "cpu": "1000m"
          },
          "env": {
            "LOG_LEVEL": "INFO",
            "LLM_PROVIDER": "openrouter",
            "LLM_OPENAI_MODEL": "gpt-4o",
            "LLM_ANTHROPIC_MODEL": "claude-3-5-sonnet-20241022",
            "LLM_OPENROUTER_MODEL": "anthropic/claude-3.5-sonnet",
            "LLM_OPENROUTER_BASE_URL": "https://openrouter.ai/api/v1",
            "LLM_OLLAMA_MODEL": "llama3.1",
            "LLM_OLLAMA_BASE_URL": "http://localhost:11434",
            "LLM_AZURE_API_VERSION": "2024-02-15-preview",
            "LLM_CUSTOM_RESPONSE_PATH": "reply"
          }
        }
      }
    },
    
    "web-crawler": {
      "name": "Web Crawler",
      "description": "Crawl4AI web crawling service",
      "port": 11235,
      "healthcheck": "/health",
      "hostname": "web-crawler",
      "dependencies": [],
      "consul": {
        "register": true,
        "service_name": "web-crawler",
        "tags": ["crawler", "crawl4ai"]
      },
      "profiles": {
        "development": {
          "replicas": 1,
          "resources": {
            "memory": "1Gi",
            "cpu": "500m"
          },
          "env": {}
        },
        "staging": {
          "replicas": 1,
          "resources": {
            "memory": "2Gi",
            "cpu": "1000m"
          },
          "env": {}
        },
        "production": {
          "replicas": 1,
          "resources": {
            "memory": "2Gi",
            "cpu": "1000m"
          },
          "env": {}
        }
      }
    },
    
    "admin-dashboard": {
      "name": "Admin Dashboard",
      "description": "Administration dashboard API",
      "port": 8888,
      "healthcheck": "/health",
      "hostname": "admin-dashboard",
      "dependencies": ["postgres", "mongo"],
      "consul": {
        "register": true,
        "service_name": "admin-dashboard",
        "tags": ["admin", "dashboard", "python"]
      },
      "profiles": {
        "development": {
          "replicas": 1,
          "resources": {
            "memory": "256Mi",
            "cpu": "100m"
          },
          "env": {}
        },
        "staging": {
          "replicas": 1,
          "resources": {
            "memory": "512Mi",
            "cpu": "250m"
          },
          "env": {}
        },
        "production": {
          "replicas": 1,
          "resources": {
            "memory": "512Mi",
            "cpu": "250m"
          },
          "env": {}
        }
      }
    },
    
    "frontend": {
      "name": "Frontend",
      "description": "React/Vite frontend application",
      "port": 8080,
      "healthcheck": "/health",
      "hostname": "frontend",
      "dependencies": ["api-gateway"],
      "consul": {
        "register": false,
        "service_name": "frontend",
        "tags": ["frontend", "react", "nginx"]
      },
      "profiles": {
        "development": {
          "replicas": 1,
          "resources": {
            "memory": "128Mi",
            "cpu": "100m"
          },
          "env": {}
        },
        "staging": {
          "replicas": 1,
          "resources": {
            "memory": "256Mi",
            "cpu": "200m"
          },
          "env": {}
        },
        "production": {
          "replicas": 3,
          "resources": {
            "memory": "512Mi",
            "cpu": "500m"
          },
          "env": {}
        }
      }
    }
  },
  
  "service_urls": {
    "_comment": "Direct service URLs for API Gateway routing (used when Consul service discovery is unavailable)",
    "collector-service": "http://collector-service:8081",
    "browser-use-api": "http://browser-use-api:8500",
    "autonomous-crawler": "http://autonomous-crawler:8030",
    "web-crawler": "http://web-crawler:11235",
    "admin-dashboard": "http://admin-dashboard:8888",
    "sentiment-addon": "http://sentiment-addon:8100",
    "factcheck-addon": "http://factcheck-addon:8101",
    "bias-addon": "http://bias-addon:8102",
    "bot-detector": "http://bot-detector:8041",
    "ml-trainer": "http://ml-trainer:8090",
    "newsinsight-mcp": "http://newsinsight-mcp:5000",
    "bias-mcp": "http://bias-mcp:5001",
    "factcheck-mcp": "http://factcheck-mcp:5002",
    "topic-mcp": "http://topic-mcp:5003",
    "aiagent-mcp": "http://aiagent-mcp:5004",
    "huggingface-mcp": "http://huggingface-mcp:5011",
    "kaggle-mcp": "http://kaggle-mcp:5012",
    "mltraining-mcp": "http://mltraining-mcp:5013",
    "roboflow-mcp": "http://roboflow-mcp:5014",
    "ip-rotation": "http://ip-rotation:8050",
    "crawl-worker": "http://crawl-worker:8040",
    "maigret-worker": "http://maigret-worker:8020"
  },
  
  "ml-addons": {
    "sentiment-addon": {
      "name": "Sentiment Analysis Addon",
      "port": 8100,
      "healthcheck": "/health",
      "enabled": {
        "development": false,
        "staging": false,
        "production": true
      }
    },
    "factcheck-addon": {
      "name": "Fact Check Addon",
      "port": 8101,
      "healthcheck": "/health",
      "enabled": {
        "development": false,
        "staging": false,
        "production": true
      }
    },
    "bias-addon": {
      "name": "Bias Detection Addon",
      "port": 8102,
      "healthcheck": "/health",
      "enabled": {
        "development": false,
        "staging": false,
        "production": true
      }
    }
  },
  
  "infrastructure": {
    "postgres": {
      "image": "postgres:15-alpine",
      "port": 5432,
      "healthcheck": "pg_isready"
    },
    "mongo": {
      "image": "mongo:7",
      "port": 27017,
      "healthcheck": "mongosh --eval db.adminCommand('ping')"
    },
    "redis": {
      "image": "redis:7-alpine",
      "port": 6379,
      "healthcheck": "redis-cli ping"
    },
    "consul": {
      "image": "hashicorp/consul:1.18",
      "port": 8500,
      "healthcheck": "consul members"
    },
    "redpanda": {
      "image": "docker.redpanda.com/redpandadata/redpanda:latest",
      "port": 9092,
      "healthcheck": "rpk cluster health"
    }
  }
}

```

---

## etc/configs/services.schema.json

```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://newsinsight.nodove.com/schemas/services.json",
  "title": "NewsInsight Services Configuration",
  "description": "Schema for validating NewsInsight service configuration profiles",
  "type": "object",
  "required": ["version", "services"],
  "properties": {
    "$schema": {
      "type": "string",
      "description": "Reference to the JSON schema file"
    },
    "version": {
      "type": "string",
      "pattern": "^\\d+\\.\\d+\\.\\d+$",
      "description": "Semantic version of the configuration"
    },
    "description": {
      "type": "string",
      "description": "Human-readable description of this configuration"
    },
    "services": {
      "type": "object",
      "description": "Service definitions",
      "additionalProperties": {
        "$ref": "#/$defs/serviceDefinition"
      }
    },
    "ml-addons": {
      "type": "object",
      "description": "ML addon service definitions",
      "additionalProperties": {
        "$ref": "#/$defs/mlAddonDefinition"
      }
    },
    "infrastructure": {
      "type": "object",
      "description": "Infrastructure service definitions",
      "additionalProperties": {
        "$ref": "#/$defs/infrastructureDefinition"
      }
    }
  },
  "$defs": {
    "port": {
      "type": "integer",
      "minimum": 1,
      "maximum": 65535,
      "description": "Network port number"
    },
    "resourceValue": {
      "type": "string",
      "pattern": "^\\d+(Mi|Gi|m)?$",
      "description": "Kubernetes resource value (e.g., 256Mi, 1Gi, 500m)"
    },
    "environmentName": {
      "type": "string",
      "enum": ["development", "staging", "production"],
      "description": "Environment name"
    },
    "resources": {
      "type": "object",
      "properties": {
        "memory": {
          "$ref": "#/$defs/resourceValue",
          "description": "Memory allocation (e.g., 512Mi, 2Gi)"
        },
        "cpu": {
          "$ref": "#/$defs/resourceValue",
          "description": "CPU allocation (e.g., 250m, 1000m)"
        }
      },
      "additionalProperties": false
    },
    "environmentProfile": {
      "type": "object",
      "required": ["replicas", "resources"],
      "properties": {
        "replicas": {
          "type": "integer",
          "minimum": 1,
          "maximum": 100,
          "description": "Number of replicas for this environment"
        },
        "resources": {
          "$ref": "#/$defs/resources"
        },
        "env": {
          "type": "object",
          "description": "Environment-specific variables",
          "additionalProperties": {
            "type": "string"
          }
        }
      },
      "additionalProperties": false
    },
    "serviceDefinition": {
      "type": "object",
      "required": ["name", "port", "healthcheck", "profiles"],
      "properties": {
        "name": {
          "type": "string",
          "description": "Human-readable service name"
        },
        "description": {
          "type": "string",
          "description": "Service description"
        },
        "port": {
          "$ref": "#/$defs/port"
        },
        "healthcheck": {
          "type": "string",
          "description": "Health check endpoint path"
        },
        "dependencies": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "description": "List of service dependencies"
        },
        "profiles": {
          "type": "object",
          "required": ["development", "staging", "production"],
          "properties": {
            "development": {
              "$ref": "#/$defs/environmentProfile"
            },
            "staging": {
              "$ref": "#/$defs/environmentProfile"
            },
            "production": {
              "$ref": "#/$defs/environmentProfile"
            }
          },
          "additionalProperties": false
        }
      },
      "additionalProperties": false
    },
    "mlAddonDefinition": {
      "type": "object",
      "required": ["name", "port", "healthcheck", "enabled"],
      "properties": {
        "name": {
          "type": "string",
          "description": "Human-readable addon name"
        },
        "port": {
          "$ref": "#/$defs/port"
        },
        "healthcheck": {
          "type": "string",
          "description": "Health check endpoint path"
        },
        "enabled": {
          "type": "object",
          "required": ["development", "staging", "production"],
          "properties": {
            "development": {
              "type": "boolean"
            },
            "staging": {
              "type": "boolean"
            },
            "production": {
              "type": "boolean"
            }
          },
          "additionalProperties": false
        }
      },
      "additionalProperties": false
    },
    "infrastructureDefinition": {
      "type": "object",
      "required": ["image", "port"],
      "properties": {
        "image": {
          "type": "string",
          "description": "Docker image reference"
        },
        "port": {
          "$ref": "#/$defs/port"
        },
        "healthcheck": {
          "type": "string",
          "description": "Health check command"
        }
      },
      "additionalProperties": false
    }
  }
}

```

---

## etc/docker/cloudflared-config.yml

```yml
tunnel: ed317942-3e87-4b0e-a3c2-3df106d4c0f4
ingress:
  - hostname: news.nodove.com
    path: "/api/.*"
    service: http://172.18.0.10:8000
    originRequest:
      connectTimeout: 30s
      noTLSVerify: true
  - hostname: news.nodove.com
    service: http://172.18.0.12:8080
    originRequest:
      connectTimeout: 30s
      noTLSVerify: true
  - service: http_status:404

```

---

## etc/docker/docker-compose.consul.yml

```yml
# Unified stack with Consul KV and all present services
services:
  consul:
    image: hashicorp/consul:1.18
    command: ["agent", "-dev", "-client", "0.0.0.0", "-ui"]
    ports:
      - "8505:8500"  # Consul UI/API
    environment:
      # Optional: advertise container hostname in logs
      - CONSUL_BIND_INTERFACE=eth0
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8500/v1/status/leader"]
      interval: 5s
      timeout: 3s
      retries: 20

  # Init container to seed Consul KV with configuration and register services
  consul-seed:
    image: alpine:3.18
    depends_on:
      consul:
        condition: service_healthy
    volumes:
      - ../../etc/scripts:/scripts:ro
      - ../../etc/configs:/configs:ro
    environment:
      - CONSUL_HTTP_ADDR=http://consul:8500
      - CONSUL_HTTP_TOKEN=${CONSUL_HTTP_TOKEN:-}
    command: >
      sh -c "
        apk add --no-cache curl bash jq &&
        /scripts/consul_seed.sh ${ENVIRONMENT:-development} --json
      "
    restart: "no"

  # Admin Dashboard API - 관리자 인증/환경 관리
  admin-dashboard:
    build:
      context: ../../backend/admin-dashboard
      dockerfile: Dockerfile
    image: newsinsight/admin-dashboard:local
    restart: unless-stopped
    environment:
      - PORT=8888
      - PROJECT_ROOT=/workspace
      - ADMIN_CONFIG_DIR=/app/config
      - CORS_ORIGINS=http://localhost:3000,http://localhost:5173,http://localhost:8080,http://localhost:8810,http://frontend:8080
    volumes:
      # Docker socket for environment management (docker-compose operations)
      - /var/run/docker.sock:/var/run/docker.sock:ro
      # Project root for accessing docker-compose files
      - ../../:/workspace:ro
      # Persist admin config (users, etc.)
      - admin-config:/app/config
    expose:
      - "8888"
    ports:
      - "8888:8888"  # Direct access for debugging
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8888/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - default

  api-gateway:
    build:
      context: ../../
      dockerfile: backend/api-gateway-service/Dockerfile
    image: newsinsight/api-gateway:local
    depends_on:
      consul:
        condition: service_healthy
      consul-seed:
        condition: service_completed_successfully
      collector-service:
        condition: service_started
      browser-use-api:
        condition: service_started
      sentiment-addon:
        condition: service_started
      factcheck-addon:
        condition: service_started
      bias-addon:
        condition: service_started
      bot-detector:
        condition: service_started
      admin-dashboard:
        condition: service_started
      ml-trainer:
        condition: service_started
      autonomous-crawler:
        condition: service_started
    environment:
      # Consul access for config loading in the app
      - CONSUL_HOST=${CONSUL_HOST:-consul}
      - CONSUL_PORT=${CONSUL_PORT:-8500}
      - CONSUL_HTTP_TOKEN=${CONSUL_HTTP_TOKEN:-}
      # Redis for rate limiting
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      # Service port
      - PORT=${API_GATEWAY_PORT:-8000}
      # Admin Dashboard URL (for routing)
      - ADMIN_DASHBOARD_URL=http://admin-dashboard:8888
      # Browser-Use API URLs (for routing)
      - BROWSER_USE_URL=http://browser-use-api:8500
      - BROWSER_USE_WS_URL=ws://browser-use-api:8500
      # ML Add-ons URLs (for routing)
      - ML_ADDON_SENTIMENT_URL=http://sentiment-addon:8100
      - ML_ADDON_FACTCHECK_URL=http://factcheck-addon:8101
      - ML_ADDON_BIAS_URL=http://bias-addon:8102
      - ML_ADDON_BOT_DETECTOR_URL=http://bot-detector:8041
      - ML_TRAINER_URL=http://ml-trainer:8090
    ports:
      - "8112:8000"  # keep gateway reachable from host
    networks:
      - default

  bot-detector:
    build:
      context: ../../
      dockerfile: backend/browser-use/bot-detector/Dockerfile
    image: newsinsight/bot-detector:local
    restart: unless-stopped
    environment:
      - BOT_DETECTOR_MODEL_NAME=${BOT_DETECTOR_MODEL_NAME:-roberta-base-openai-detector}
      - PORT=8041
    expose:
      - "8041"
    ports:
      - "8041:8041"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8041/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - default
      - newsinsight-shared-net

  frontend:
    image: node:20-alpine
    working_dir: /app
    volumes:
      - ../../frontend:/app
      - frontend-node-modules:/app/node_modules
    environment:
      # Docker 내부 네트워크: API Gateway 서비스 이름 사용
      - VITE_API_BASE_URL=http://api-gateway:8000
      - VITE_BROWSER_USE_URL=http://api-gateway:8000
    extra_hosts:
      - "host.docker.internal:host-gateway"
    command: >
      sh -c "(npm ci --legacy-peer-deps || npm install --legacy-peer-deps) \
      && npm run dev -- --host 0.0.0.0 --port 8080"
    ports:
      - "8810:8080"
    depends_on:
      api-gateway:
        condition: service_started
    networks:
      - default

  collector-service:
    build:
      context: ../../
      dockerfile: backend/data-collection-service/Dockerfile
    image: newsinsight/collector-service:local
    depends_on:
      consul:
        condition: service_healthy
      consul-seed:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
      mongo:
        condition: service_healthy
      web-crawler:
        condition: service_started
      redpanda-dev:
        condition: service_started
      # Use service_started to avoid blocking on autonomous-crawler healthcheck
      # collector-service will retry connections internally
      autonomous-crawler:
        condition: service_started
    environment:
      # Consul configuration
      - CONSUL_HOST=${CONSUL_HOST:-consul}
      - CONSUL_PORT=${CONSUL_PORT:-8500}
      - CONSUL_ENABLED=${CONSUL_ENABLED:-true}
      - "SPRING_CONFIG_IMPORT=consul:"
      - SPRING_PROFILES_ACTIVE=local-consul
      - SPRING_CLOUD_CONSUL_CONFIG_ENABLED=true
      - SPRING_CLOUD_CONSUL_CONFIG_PREFIX=config
      - SPRING_CLOUD_CONSUL_CONFIG_DEFAULT_CONTEXT=collector-service
      - SPRING_CLOUD_CONSUL_CONFIG_FORMAT=YAML
      - SPRING_CLOUD_CONSUL_CONFIG_FAIL_FAST=true
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - SPRING_DATA_REDIS_HOST=${REDIS_HOST:-redis}
      - SPRING_DATA_REDIS_PORT=${REDIS_PORT:-6379}
      - SPRING_JPA_HIBERNATE_DDL_AUTO=update
      - PERPLEXITY_API_KEY=${PERPLEXITY_API_KEY:-}
      - PERPLEXITY_MODEL=${PERPLEXITY_MODEL:-sonar}
      - PERPLEXITY_BASE_URL=${PERPLEXITY_BASE_URL:-https://api.perplexity.ai}
      # AI Service URLs (can be overridden via Consul KV)
      - COLLECTOR_AIDOVE_BASE_URL=${COLLECTOR_SERVICE_AIDOVE_BASE_URL:-https://workflow.nodove.com/webhook/aidove}
      - COLLECTOR_CALLBACK_BASE_URL=${COLLECTOR_SERVICE_CALLBACK_BASE_URL:-http://collector-service:8081}
      # DeepSearch - uses IntegratedCrawlerService (n8n deprecated)
      - COLLECTOR_DEEP_SEARCH_ENABLED=false
      - COLLECTOR_DEEP_SEARCH_FALLBACK_TO_WEBHOOK=false
      # Auto-Crawl Configuration (실시간 확장형 크롤링)
      - AUTOCRAWL_ENABLED=true
      - AUTOCRAWL_BATCH_SIZE=10
      - AUTOCRAWL_MAX_CONCURRENT_PER_DOMAIN=3
      - AUTOCRAWL_DISCOVER_FROM_SEARCH=true
      - AUTOCRAWL_DISCOVER_FROM_ARTICLES=true
      - AUTOCRAWL_DISCOVER_FROM_DEEP_SEARCH=true
      # Auto-Crawl Seed 초기화 (시작 시 자동 크롤링)
      # Note: Spring reads autocrawl.seed.enabled from application.yml, which defaults to false
      # We override it via environment variable naming convention: AUTOCRAWL_SEED_ENABLED -> autocrawl.seed.enabled
      - AUTOCRAWL_SEED_ENABLED=true
      - AUTOCRAWL_SEED_URLS=${AUTOCRAWL_SEED_URLS:-}
      - AUTOCRAWL_SEED_KEYWORDS=${AUTOCRAWL_SEED_KEYWORDS:-뉴스,정치,경제,사회,IT,기술}
      - AUTOCRAWL_SEED_PRIORITY=${AUTOCRAWL_SEED_PRIORITY:-70}
      # Database configuration
      - DB_HOST=${DB_HOST:-postgres}
      - DB_PORT=${DB_PORT:-5432}
      - DB_NAME=${DB_NAME:-newsinsight}
      - DB_USER=${DB_USER:-postgres}
      - DB_PASSWORD=${DB_PASSWORD:-postgres}
      - MONGODB_URI=${MONGODB_URI:-mongodb://mongo:27017/newsinsight}
      # Kafka configuration - connecting to redpanda-dev on newsinsight-shared-net
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS:-redpanda-dev:9092}
      # Service port
      - SERVER_PORT=${COLLECTOR_PORT:-8081}
      # Force Consul to register with newsinsight-net IP (not newsinsight-shared-net IP)
      - SPRING_CLOUD_INETUTILS_PREFERRED_NETWORKS=172.20
    expose:
      - "8081"
    networks:
      - default
      - newsinsight-shared-net

  # Crawl4AI web-crawler service
  web-crawler:
    image: unclecode/crawl4ai:latest
    shm_size: 1g
    environment:
      - LOG_LEVEL=${WEB_CRAWLER_LOG_LEVEL:-INFO}
    ports:
      - "11235:11235"  # playground and API
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:11235/health"]
      interval: 10s
      timeout: 5s
      retries: 10

  # PostgreSQL database
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=${DB_NAME:-newsinsight}
      - POSTGRES_USER=${DB_USER:-postgres}
      - POSTGRES_PASSWORD=${DB_PASSWORD:-postgres}
    expose:
      - "5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./db-init:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 3s
      retries: 5

  # MongoDB for AI response storage
  mongo:
    image: mongo:7
    restart: unless-stopped
    environment:
      - MONGO_INITDB_DATABASE=${DB_NAME:-newsinsight}
    expose:
      - "27017"
    volumes:
      - mongo-data:/data/db
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5

  redpanda-dev:
    image: docker.redpanda.com/redpandadata/redpanda:latest
    command:
      - redpanda
      - start
      - --overprovisioned
      - --smp
      - "1"
      - --memory
      - 1G
      - --reserve-memory
      - 0M
      - --node-id
      - "0"
      - --check=false
      - --kafka-addr
      - PLAINTEXT://0.0.0.0:9092
      - --advertise-kafka-addr
      - PLAINTEXT://redpanda-dev:9092
    ports:
      - "19093:9092"
      - "19644:9644"
    networks:
      - default
      - newsinsight-shared-net

  # Redis for API Gateway rate limiting
  redis:
    image: redis:7-alpine
    expose:
      - "6379"
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  # Autonomous Crawler Service (browser-use + AI)
  autonomous-crawler:
    build:
      context: ../../
      dockerfile: backend/autonomous-crawler-service/Dockerfile
    image: newsinsight/autonomous-crawler:local
    restart: unless-stopped
    depends_on:
      consul:
        condition: service_healthy
      consul-seed:
        condition: service_completed_successfully
      redpanda-dev:
        condition: service_started
      redis:
        condition: service_healthy
      # MCP servers - use service_started to avoid long dependency chains
      # MCP healthchecks will retry internally if services aren't ready
      newsinsight-mcp:
        condition: service_started
      bias-mcp:
        condition: service_started
      factcheck-mcp:
        condition: service_started
      topic-mcp:
        condition: service_started
      aiagent-mcp:
        condition: service_started
      huggingface-mcp:
        condition: service_started
      kaggle-mcp:
        condition: service_started
      mltraining-mcp:
        condition: service_started
      roboflow-mcp:
        condition: service_started
    environment:
      # Consul configuration
      - CONSUL_HOST=${CONSUL_HOST:-consul}
      - CONSUL_PORT=${CONSUL_PORT:-8500}
      - CONSUL_HTTP_TOKEN=${CONSUL_HTTP_TOKEN:-}
      - CONSUL_ENABLED=${CONSUL_ENABLED:-true}
      - CONSUL_SERVICE_NAME=autonomous-crawler
      # Service mode: kafka, api, or hybrid (both Kafka + REST API)
      - SERVICE_MODE=${SERVICE_MODE:-hybrid}
      - API_PORT=${CRAWLER_API_PORT:-8030}
      # Kafka configuration - MUST match collector-service topic names
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS:-redpanda-dev:9092}
      - KAFKA_CONSUMER_GROUP_ID=${CRAWLER_CONSUMER_GROUP:-autonomous-crawler-group}
      - KAFKA_BROWSER_TASK_TOPIC=newsinsight.crawl.browser.tasks
      - KAFKA_CRAWL_RESULT_TOPIC=newsinsight.crawl.results
      # Browser settings
      - BROWSER_HEADLESS=${CRAWLER_HEADLESS:-true}
      - BROWSER_MAX_CONCURRENT_SESSIONS=${CRAWLER_MAX_SESSIONS:-2}
      - BROWSER_DEFAULT_TIMEOUT_SECONDS=${CRAWLER_TIMEOUT:-300}
      - BROWSER_IS_DOCKER_ENV=true
      # LLM configuration
      # Supported providers: openai, anthropic, openrouter, ollama, custom
      - LLM_PROVIDER=${CRAWLER_LLM_PROVIDER:-openai}
      # OpenAI settings
      - LLM_OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - LLM_OPENAI_MODEL=${CRAWLER_OPENAI_MODEL:-gpt-4o}
      - LLM_OPENAI_BASE_URL=${OPENAI_BASE_URL:-}
      # Anthropic settings
      - LLM_ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - LLM_ANTHROPIC_MODEL=${CRAWLER_ANTHROPIC_MODEL:-claude-3-5-sonnet-20241022}
      # OpenRouter settings (https://openrouter.ai - access multiple models)
      - LLM_OPENROUTER_API_KEY=${OPENROUTER_API_KEY:-}
      - LLM_OPENROUTER_MODEL=${OPENROUTER_MODEL:-anthropic/claude-3.5-sonnet}
      - LLM_OPENROUTER_BASE_URL=${OPENROUTER_BASE_URL:-https://openrouter.ai/api/v1}
      # Ollama settings (local LLM)
      - LLM_OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - LLM_OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.2}
      # Custom OpenAI-compatible API settings
      - LLM_CUSTOM_API_KEY=${CUSTOM_LLM_API_KEY:-}
      - LLM_CUSTOM_BASE_URL=${CUSTOM_LLM_BASE_URL:-}
      - LLM_CUSTOM_MODEL=${CUSTOM_LLM_MODEL:-}
      # Search API keys (loaded from Consul KV)
      - SEARCH_BRAVE_API_KEY=${SEARCH_BRAVE_API_KEY:-}
      - SEARCH_TAVILY_API_KEY=${SEARCH_TAVILY_API_KEY:-}
      - SEARCH_PERPLEXITY_API_KEY=${SEARCH_PERPLEXITY_API_KEY:-}
      # Stealth/CAPTCHA settings
      - STEALTH_ENABLED=${STEALTH_ENABLED:-true}
      - CAPTCHA_ENABLED=${CAPTCHA_ENABLED:-true}
      # Paid CAPTCHA solver API keys (for reliable search portal bypass)
      # Get CapSolver key at: https://capsolver.com (recommended for Turnstile)
      - CAPTCHA_CAPSOLVER_API_KEY=${CAPTCHA_CAPSOLVER_API_KEY:-}
      # Get 2Captcha key at: https://2captcha.com
      - CAPTCHA_TWOCAPTCHA_API_KEY=${CAPTCHA_TWOCAPTCHA_API_KEY:-}
      - CAPTCHA_PREFER_PAID_SOLVER=${CAPTCHA_PREFER_PAID_SOLVER:-true}
      - CAPTCHA_PAID_SOLVER_TIMEOUT=${CAPTCHA_PAID_SOLVER_TIMEOUT:-120}
      # Redis for task state persistence
      - REDIS_ENABLED=true
      - REDIS_URL=redis://redis:6379/4
      # Metrics and logging
      - METRICS_ENABLED=${CRAWLER_METRICS_ENABLED:-true}
      - METRICS_PORT=${CRAWLER_METRICS_PORT:-9090}
      - LOG_LEVEL=${CRAWLER_LOG_LEVEL:-INFO}
      - LOG_FORMAT=${CRAWLER_LOG_FORMAT:-json}
      # MCP Server URLs for integrated analysis
      - BIAS_MCP_URL=http://bias-mcp:5001
      - FACTCHECK_MCP_URL=http://factcheck-mcp:5002
      - TOPIC_MCP_URL=http://topic-mcp:5003
      - NEWSINSIGHT_MCP_URL=http://newsinsight-mcp:5000
      - HUGGINGFACE_MCP_URL=http://huggingface-mcp:5011
      - KAGGLE_MCP_URL=http://kaggle-mcp:5012
      - MLTRAINING_MCP_URL=http://mltraining-mcp:5013
      - ROBOFLOW_MCP_URL=http://roboflow-mcp:5014
      - AIAGENT_MCP_URL=http://aiagent-mcp:5004
    expose:
      - "9090"
    ports:
      - "9190:9090"  # Prometheus metrics
      - "8030:8030"  # REST API
    shm_size: 2g  # Shared memory for browser
    healthcheck:
      # Use python socket check instead of curl (curl not installed in container)
      test: ["CMD", "python", "-c", "import socket; s=socket.socket(); s.connect(('localhost', 9090)); s.close()"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - default
      - newsinsight-shared-net

  # Browser-Use API Server with AI Dove Integration
  browser-use-api:
    build:
      context: ../../backend/browser-use
      dockerfile: Dockerfile.api
    image: newsinsight/browser-use-api:local
    restart: unless-stopped
    environment:
      # AI Dove webhook configuration
      - AIDOVE_WEBHOOK_URL=${AIDOVE_WEBHOOK_URL:-https://workflow.nodove.com/webhook/aidove}
      # Browser settings
      - BROWSER_HEADLESS=${BROWSER_USE_HEADLESS:-true}
      # Server settings
      - SERVER_PORT=8500
      - LOG_LEVEL=${BROWSER_USE_LOG_LEVEL:-INFO}
    ports:
      - "8501:8500"  # Browser-Use API (avoid conflict with Consul)
    shm_size: 2g  # Shared memory for browser
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8500/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - default
      - newsinsight-shared-net

  # ML Add-ons - 감정 분석 (Sentiment Analysis)
  sentiment-addon:
    build:
      context: ../../backend/ml-addons/sentiment-addon
      dockerfile: Dockerfile
    image: newsinsight/sentiment-addon:local
    restart: unless-stopped
    expose:
      - "8100"
    ports:
      - "8100:8100"  # Direct access for debugging
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8100/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - default

  # ML Add-ons - 팩트체크 (Fact Check)
  factcheck-addon:
    build:
      context: ../../backend/ml-addons/factcheck-addon
      dockerfile: Dockerfile
    image: newsinsight/factcheck-addon:local
    restart: unless-stopped
    expose:
      - "8101"
    ports:
      - "8101:8101"  # Direct access for debugging
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8101/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - default

  # ML Add-ons - 편향도 분석 (Bias Analysis)
  bias-addon:
    build:
      context: ../../backend/ml-addons/bias-addon
      dockerfile: Dockerfile
    image: newsinsight/bias-addon:local
    restart: unless-stopped
    expose:
      - "8102"
    ports:
      - "8102:8102"  # Direct access for debugging
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8102/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - default

  # ============================================================================
  # IP Rotation Service - Proxy Pool Management for Crawlers
  # ============================================================================
  ip-rotation:
    build:
      context: ../../backend/browser-use/ip-rotation
      dockerfile: Dockerfile
    image: newsinsight/ip-rotation:local
    restart: unless-stopped
    environment:
      # Rotation strategy: round_robin, random, least_used, weighted, geographic
      - STRATEGY=${IP_ROTATION_STRATEGY:-weighted}
      # Max failures before proxy is disabled
      - MAX_FAILURES=${IP_ROTATION_MAX_FAILURES:-5}
      # Cooldown in minutes before re-enabling failed proxy
      - COOLDOWN_MINUTES=${IP_ROTATION_COOLDOWN:-30}
      # Health check interval in seconds
      - HEALTH_CHECK_INTERVAL=${IP_ROTATION_HEALTH_CHECK:-300}
      # Persistence file path
      - PERSISTENCE_PATH=/data/ip_pool_state.json
      - PORT=8050
    volumes:
      - ip-rotation-data:/data
    ports:
      - "8050:8050"
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8050/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - default

  # ============================================================================
  # Crawl Worker - Web Crawling Service with Proxy Rotation
  # ============================================================================
  crawl-worker:
    build:
      context: ../../
      dockerfile: backend/autonomous-crawler-service/crawl-worker/Dockerfile
    image: newsinsight/crawl-worker:local
    restart: unless-stopped
    environment:
      - PORT=8040
      - MAX_CONCURRENT_CRAWLS=${CRAWL_WORKER_MAX_CONCURRENT:-5}
      # Proxy rotation configuration
      - USE_PROXY_ROTATION=${USE_PROXY_ROTATION:-true}
      - PROXY_ROTATION_URL=http://ip-rotation:8050
    ports:
      - "8040:8040"
    depends_on:
      ip-rotation:
        condition: service_healthy
    healthcheck:
      # Use wget instead of curl (wget available in slim images via playwright deps)
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8040/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - default

  # ============================================================================
  # Maigret Worker - Username OSINT Scanner with Proxy Rotation
  # ============================================================================
  maigret-worker:
    build:
      context: ../../
      dockerfile: backend/data-collection-service/maigret-worker/Dockerfile
    image: newsinsight/maigret-worker:local
    restart: unless-stopped
    environment:
      - PORT=8020
      - MAX_CONCURRENT_SCANS=${MAIGRET_MAX_CONCURRENT:-3}
      - SCAN_TIMEOUT_SEC=${MAIGRET_TIMEOUT:-300}
      - REPORTS_DIR=/app/reports
      # Proxy rotation configuration
      - USE_PROXY_ROTATION=${USE_PROXY_ROTATION:-true}
      - PROXY_ROTATION_URL=http://ip-rotation:8050
    volumes:
      - maigret-reports:/app/reports
    ports:
      - "8020:8020"
    depends_on:
      ip-rotation:
        condition: service_healthy
    healthcheck:
      # Use python urllib instead of curl (curl may not be available)
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8020/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - default

  # ============================================================================
  # MCP Servers - Analysis Tool Servers (Local Development)
  # ============================================================================
  newsinsight-mcp:
    build:
      context: ../../mcp/newsinsight_mcp
      dockerfile: Dockerfile
    image: newsinsight/newsinsight-mcp:local
    restart: unless-stopped
    environment:
      - DB_BACKEND=postgres
      - DATABASE_URL=postgresql://${DB_USER:-postgres}:${DB_PASSWORD:-postgres}@postgres:5432/${DB_NAME:-newsinsight}
      - MONGODB_URI=${MONGODB_URI:-mongodb://mongo:27017/newsinsight}
      - PORT=5000
    expose:
      - "5000"
    ports:
      - "5000:5000"
    depends_on:
      postgres:
        condition: service_healthy
      mongo:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - default

  bias-mcp:
    build:
      context: ../../mcp/bias_mcp
      dockerfile: Dockerfile
    image: newsinsight/bias-mcp:local
    restart: unless-stopped
    environment:
      - DB_BACKEND=postgres
      - DATABASE_URL=postgresql://${DB_USER:-postgres}:${DB_PASSWORD:-postgres}@postgres:5432/${DB_NAME:-newsinsight}
      - MONGODB_URI=${MONGODB_URI:-mongodb://mongo:27017/newsinsight}
      - PORT=5001
    expose:
      - "5001"
    ports:
      - "5001:5001"
    depends_on:
      postgres:
        condition: service_healthy
      mongo:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - default

  factcheck-mcp:
    build:
      context: ../../mcp/factcheck_mcp
      dockerfile: Dockerfile
    image: newsinsight/factcheck-mcp:local
    restart: unless-stopped
    environment:
      - DB_BACKEND=postgres
      - DATABASE_URL=postgresql://${DB_USER:-postgres}:${DB_PASSWORD:-postgres}@postgres:5432/${DB_NAME:-newsinsight}
      - MONGODB_URI=${MONGODB_URI:-mongodb://mongo:27017/newsinsight}
      - PORT=5002
    expose:
      - "5002"
    ports:
      - "5002:5002"
    depends_on:
      postgres:
        condition: service_healthy
      mongo:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - default

  topic-mcp:
    build:
      context: ../../mcp/topic_mcp
      dockerfile: Dockerfile
    image: newsinsight/topic-mcp:local
    restart: unless-stopped
    environment:
      - DB_BACKEND=postgres
      - DATABASE_URL=postgresql://${DB_USER:-postgres}:${DB_PASSWORD:-postgres}@postgres:5432/${DB_NAME:-newsinsight}
      - MONGODB_URI=${MONGODB_URI:-mongodb://mongo:27017/newsinsight}
      - PORT=5003
    expose:
      - "5003"
    ports:
      - "5003:5003"
    depends_on:
      postgres:
        condition: service_healthy
      mongo:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - default

  aiagent-mcp:
    build:
      context: ../../mcp/aiagent_mcp
      dockerfile: Dockerfile
    image: newsinsight/aiagent-mcp:local
    restart: unless-stopped
    environment:
      - DATABASE_URL=postgresql://${DB_USER:-postgres}:${DB_PASSWORD:-postgres}@postgres:5432/${DB_NAME:-newsinsight}
      - ENCRYPTION_KEY=${AI_PROVIDER_ENCRYPTION_KEY:-}
      - PORT=5004
    expose:
      - "5004"
    ports:
      - "5004:5004"
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5004/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - default

  huggingface-mcp:
    build:
      context: ../../mcp/huggingface_mcp
      dockerfile: Dockerfile
    image: newsinsight/huggingface-mcp:local
    restart: unless-stopped
    environment:
      - HF_TOKEN=${HF_TOKEN:-}
      - PORT=5011
      - DATA_DIR=/app/data
      - JOB_TIMEOUT=600
    expose:
      - "5011"
    ports:
      - "5011:5011"
    volumes:
      - huggingface-data:/app/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5011/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - default

  kaggle-mcp:
    build:
      context: ../../mcp/kaggle_mcp
      dockerfile: Dockerfile
    image: newsinsight/kaggle-mcp:local
    restart: unless-stopped
    environment:
      - KAGGLE_USERNAME=${KAGGLE_USERNAME:-}
      - KAGGLE_KEY=${KAGGLE_KEY:-}
      - PORT=5012
      - DATA_DIR=/app/data
    expose:
      - "5012"
    ports:
      - "5012:5012"
    volumes:
      - kaggle-data:/app/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5012/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - default

  mltraining-mcp:
    build:
      context: ../../mcp/mltraining_mcp
      dockerfile: Dockerfile
    image: newsinsight/mltraining-mcp:local
    restart: unless-stopped
    environment:
      - DATABASE_URL=postgresql://${DB_USER:-postgres}:${DB_PASSWORD:-postgres}@postgres:5432/${DB_NAME:-newsinsight}
      - PORT=5013
      - DATA_DIR=/app/data
    expose:
      - "5013"
    ports:
      - "5013:5013"
    volumes:
      - mltraining-data:/app/data
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5013/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - default

  roboflow-mcp:
    build:
      context: ../../mcp/roboflow_mcp
      dockerfile: Dockerfile
    image: newsinsight/roboflow-mcp:local
    restart: unless-stopped
    environment:
      - ROBOFLOW_API_KEY=${ROBOFLOW_API_KEY:-}
      - PORT=5014
      - DATA_DIR=/app/data
    expose:
      - "5014"
    ports:
      - "5014:5014"
    volumes:
      - roboflow-data:/app/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5014/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - default

  # ============================================================================
  # ML Trainer Service - Model Training and Management
  # ============================================================================
  ml-trainer:
    build:
      context: ../../backend/ml-addons/ml-trainer
      dockerfile: Dockerfile
    image: newsinsight/ml-trainer:local
    restart: unless-stopped
    environment:
      - PORT=8090
      - DATABASE_URL=postgresql://${DB_USER:-postgres}:${DB_PASSWORD:-postgres}@postgres:5432/${DB_NAME:-newsinsight}
      - MONGODB_URI=${MONGODB_URI:-mongodb://mongo:27017/newsinsight}
      - REDIS_URL=redis://redis:6379/5
      - HF_TOKEN=${HF_TOKEN:-}
      - KAGGLE_USERNAME=${KAGGLE_USERNAME:-}
      - KAGGLE_KEY=${KAGGLE_KEY:-}
      - ROBOFLOW_API_KEY=${ROBOFLOW_API_KEY:-}
      - MODEL_STORAGE_PATH=/app/models
      - TRAINING_DATA_PATH=/app/data
    expose:
      - "8090"
    ports:
      - "8090:8090"
    volumes:
      - ml-trainer-models:/app/models
      - ml-trainer-data:/app/data
    depends_on:
      postgres:
        condition: service_healthy
      mongo:
        condition: service_healthy
      redis:
        condition: service_healthy
      kaggle-mcp:
        condition: service_started
      mltraining-mcp:
        condition: service_started
      roboflow-mcp:
        condition: service_started
      huggingface-mcp:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8090/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - default

volumes:
  postgres-data:
  redis-data:
  frontend-node-modules:
  mongo-data:
  ip-rotation-data:
  maigret-reports:
  huggingface-data:
  admin-config:
  kaggle-data:
  mltraining-data:
  roboflow-data:
  ml-trainer-models:
  ml-trainer-data:

networks:
  default:
    name: newsinsight-net
  newsinsight-shared-net:
    name: newsinsight-shared-net
    driver: bridge

```

---

## etc/docker/docker-compose.production.yml

```yml
# ============================================================================
# NewsInsight Production Docker Compose
# Target: pmx-102-2 remote server
# Domain: newsinsight.nodove.com
# ============================================================================

networks:
  newsinsight-prod:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  postgres_prod_data:
  mongo_prod_data:
  redis_prod_data:
  consul_prod_data:
  ai_agent_data:
  ml_shared_data:
  embedding_model_cache:
  ip_rotation_data:
  maigret_reports:
  workspace_data:

services:
  # ============================================================================
  # Cloudflare Tunnel - newsinsight.nodove.com
  # 단일 엔드포인트 (Frontend)로 모든 트래픽 전달
  # Frontend nginx가 /api/* → api-gateway로 내부 라우팅
  # ============================================================================
  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: newsinsight-prod-cloudflared
    restart: unless-stopped
    command: tunnel --protocol http2 run
    environment:
      - TUNNEL_TOKEN=${CLOUDFLARE_TUNNEL_TOKEN_PROD}
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.2
    depends_on:
      frontend:
        condition: service_healthy
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================================
  # Infrastructure Services
  # ============================================================================
  postgres:
    image: pgvector/pgvector:pg15
    container_name: newsinsight-prod-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-newsinsight}
      POSTGRES_USER: ${POSTGRES_USER:-newsinsight}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_prod_data:/var/lib/postgresql/data
      - ./db-init:/docker-entrypoint-initdb.d:ro
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.10
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-newsinsight}"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  mongo:
    image: mongo:7
    container_name: newsinsight-prod-mongo
    restart: unless-stopped
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_USER:-newsinsight}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD}
      MONGO_INITDB_DATABASE: newsinsight
    volumes:
      - mongo_prod_data:/data/db
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.11
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  redis:
    image: redis:7-alpine
    container_name: newsinsight-prod-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_prod_data:/data
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.12
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  consul:
    image: hashicorp/consul:1.18
    container_name: newsinsight-prod-consul
    restart: unless-stopped
    command: agent -server -ui -node=server-1 -bootstrap-expect=1 -client=0.0.0.0 -bind=0.0.0.0
    volumes:
      - consul_prod_data:/consul/data
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.13
    healthcheck:
      test: ["CMD", "consul", "members"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================================
  # Consul Seed - Initialize Consul KV and register services
  # ============================================================================
  consul-seed:
    image: alpine:3.18
    container_name: newsinsight-prod-consul-seed
    depends_on:
      consul:
        condition: service_healthy
    volumes:
      - ../scripts:/scripts:ro
      - ../configs:/configs:ro
    environment:
      CONSUL_HTTP_ADDR: http://consul:8500
      CONSUL_HTTP_TOKEN: ${CONSUL_HTTP_TOKEN:-}
    command: >
      sh -c "
        apk add --no-cache curl bash jq &&
        /scripts/consul_seed.sh production --json
      "
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.15
    restart: "no"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  redpanda:
    image: docker.redpanda.com/redpandadata/redpanda:latest
    container_name: newsinsight-prod-redpanda
    restart: unless-stopped
    command:
      - redpanda
      - start
      - --kafka-addr internal://0.0.0.0:9092,external://0.0.0.0:19092
      - --advertise-kafka-addr internal://redpanda:9092,external://localhost:19092
      - --pandaproxy-addr internal://0.0.0.0:8082,external://0.0.0.0:18082
      - --advertise-pandaproxy-addr internal://redpanda:8082,external://localhost:18082
      - --schema-registry-addr internal://0.0.0.0:8081,external://0.0.0.0:18081
      - --rpc-addr redpanda:33145
      - --advertise-rpc-addr redpanda:33145
      - --mode dev-container
      - --smp 1
      - --memory 512M
      - --default-log-level=warn
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.14
    healthcheck:
      test: ["CMD", "rpk", "cluster", "health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================================
  # Application Services
  # ============================================================================
  api-gateway:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/api-gateway:${TAG:-latest}
    container_name: newsinsight-prod-api-gateway
    restart: unless-stopped
    environment:
      SPRING_PROFILES_ACTIVE: production
      # Database connections
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/${POSTGRES_DB:-newsinsight}
      SPRING_DATASOURCE_USERNAME: ${POSTGRES_USER:-newsinsight}
      SPRING_DATASOURCE_PASSWORD: ${POSTGRES_PASSWORD}
      SPRING_DATA_MONGODB_URI: mongodb://${MONGO_USER:-newsinsight}:${MONGO_PASSWORD}@mongo:27017/newsinsight?authSource=admin
      SPRING_DATA_REDIS_HOST: redis
      SPRING_DATA_REDIS_PASSWORD: ${REDIS_PASSWORD}
      # Consul settings
      SPRING_CLOUD_CONSUL_HOST: consul
      SPRING_CLOUD_CONSUL_PORT: 8500
      CONSUL_ENABLED: "true"
      CONSUL_DISCOVERY_ENABLED: "true"
      # Direct service URL (fallback when Consul is unavailable)
      # Consul 사용 시: lb://collector-service, 직접 연결 시: http://collector-service:8081
      COLLECTOR_SERVICE_URL: ${COLLECTOR_SERVICE_URL:-http://collector-service:8081}
      # Kafka
      SPRING_KAFKA_BOOTSTRAP_SERVERS: redpanda:9092
      # External services
      BROWSER_USE_API_URL: http://browser-use-api:8500
      BROWSER_USE_URL: http://browser-use-api:8500
      BROWSER_USE_WS_URL: ws://browser-use-api:8500
      WEB_CRAWLER_URL: http://web-crawler:11235
      AUTONOMOUS_CRAWLER_URL: http://autonomous-crawler:9090
      AUTONOMOUS_CRAWLER_API_URL: http://autonomous-crawler:8030
      ADMIN_DASHBOARD_URL: http://admin-dashboard:8888
      ML_ADDON_BOT_DETECTOR_URL: http://bot-detector:8041
      # Frontend config
      FRONTEND_API_BASE_URL: https://newsinsight.nodove.com
      # JVM settings
      JAVA_OPTS: "-Xms256m -Xmx512m"
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.20
    depends_on:
      postgres:
        condition: service_healthy
      mongo:
        condition: service_healthy
      redis:
        condition: service_healthy
      consul:
        condition: service_healthy
      consul-seed:
        condition: service_completed_successfully
      redpanda:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://127.0.0.1:8000/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  collector-service:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/collector-service:${TAG:-latest}
    container_name: newsinsight-prod-collector
    restart: unless-stopped
    environment:
      SPRING_PROFILES_ACTIVE: production
      # Database connections
      DB_HOST: postgres
      DB_PORT: "5432"
      DB_NAME: ${POSTGRES_DB:-newsinsight}
      DB_USER: ${POSTGRES_USER:-newsinsight}
      DB_PASSWORD: ${POSTGRES_PASSWORD}
      MONGODB_URI: mongodb://${MONGO_USER:-newsinsight}:${MONGO_PASSWORD}@mongo:27017/newsinsight?authSource=admin
      SPRING_DATA_REDIS_HOST: redis
      SPRING_DATA_REDIS_PASSWORD: ${REDIS_PASSWORD}
      # Consul settings
      CONSUL_HOST: consul
      CONSUL_PORT: "8500"
      CONSUL_ENABLED: "true"
      CONSUL_DISCOVERY_ENABLED: "true"
      CONSUL_DISCOVERY_HOSTNAME: collector-service
      # Kafka
      KAFKA_BOOTSTRAP_SERVERS: redpanda:9092
      # External services
      COLLECTOR_BROWSER_USE_BASE_URL: http://browser-use-api:8500
      COLLECTOR_SERVICE_CRAWLER_BASE_URL: http://web-crawler:11235
      COLLECTOR_CALLBACK_BASE_URL: http://collector-service:8081
      # Embedding server for hybrid search (enabled by default)
      EMBEDDING_BASE_URL: ${EMBEDDING_BASE_URL:-http://embedding-server:8011}
      EMBEDDING_ENABLED: ${EMBEDDING_ENABLED:-true}
      VECTOR_SEARCH_ENABLED: ${VECTOR_SEARCH_ENABLED:-true}
      HYBRID_SEARCH_ENABLED: ${HYBRID_SEARCH_ENABLED:-true}
      # Auto-Crawl Configuration (실시간 확장형 크롤링)
      AUTOCRAWL_ENABLED: ${AUTOCRAWL_ENABLED:-true}
      AUTOCRAWL_BATCH_SIZE: ${AUTOCRAWL_BATCH_SIZE:-10}
      AUTOCRAWL_MAX_CONCURRENT_PER_DOMAIN: ${AUTOCRAWL_MAX_CONCURRENT_PER_DOMAIN:-3}
      AUTOCRAWL_DISCOVER_FROM_SEARCH: ${AUTOCRAWL_DISCOVER_FROM_SEARCH:-true}
      AUTOCRAWL_DISCOVER_FROM_ARTICLES: ${AUTOCRAWL_DISCOVER_FROM_ARTICLES:-true}
      AUTOCRAWL_DISCOVER_FROM_DEEP_SEARCH: ${AUTOCRAWL_DISCOVER_FROM_DEEP_SEARCH:-true}
      # Workspace file storage
      WORKSPACE_STORAGE_PATH: /data/workspace
      WORKSPACE_MAX_FILE_SIZE: ${WORKSPACE_MAX_FILE_SIZE:-104857600}
      WORKSPACE_MAX_FILES_PER_SESSION: ${WORKSPACE_MAX_FILES_PER_SESSION:-100}
      WORKSPACE_SESSION_FILE_TTL_HOURS: ${WORKSPACE_SESSION_FILE_TTL_HOURS:-24}
      # JVM settings
      JAVA_OPTS: "-Xms256m -Xmx512m"
    volumes:
      - workspace_data:/data/workspace
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.21
    depends_on:
      postgres:
        condition: service_healthy
      mongo:
        condition: service_healthy
      consul:
        condition: service_healthy
      consul-seed:
        condition: service_completed_successfully
      redpanda:
        condition: service_healthy
      embedding-server:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://127.0.0.1:8081/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  browser-use-api:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/browser-use-api:${TAG:-latest}
    container_name: newsinsight-prod-browser-use
    restart: unless-stopped
    environment:
      AIDOVE_WEBHOOK_URL: ${AIDOVE_WEBHOOK_URL:-https://workflow.nodove.com/webhook/aidove}
      PYTHONUNBUFFERED: "1"
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.22
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:8500/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================================
  # Admin Dashboard - 관리자 대시보드 API
  # ============================================================================
  admin-dashboard:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/admin-dashboard:${TAG:-latest}
    container_name: newsinsight-prod-admin-dashboard
    restart: unless-stopped
    environment:
      PORT: "8888"
      PYTHONUNBUFFERED: "1"
      PROJECT_ROOT: /workspace
      ADMIN_CONFIG_DIR: /app/config
      # Database connections
      DATABASE_URL: postgresql://${POSTGRES_USER:-newsinsight}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-newsinsight}
      MONGODB_URI: mongodb://${MONGO_USER:-newsinsight}:${MONGO_PASSWORD}@mongo:27017/newsinsight?authSource=admin
      # JWT Authentication
      JWT_SECRET: ${JWT_SECRET_KEY:-change-me-in-production}
      # CORS (allow frontend origin)
      CORS_ORIGINS: ${CORS_ORIGINS:-https://newsinsight.nodove.com,http://localhost:8080}
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.26
    depends_on:
      postgres:
        condition: service_healthy
      mongo:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:8888/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  web-crawler:
    image: unclecode/crawl4ai:latest
    container_name: newsinsight-prod-web-crawler
    restart: unless-stopped
    environment:
      CRAWL4AI_API_TOKEN: ${CRAWL4AI_API_TOKEN:-newsinsight-crawler}
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.23
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:11235/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  autonomous-crawler:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/autonomous-crawler:${TAG:-latest}
    container_name: newsinsight-prod-autonomous-crawler
    restart: unless-stopped
    environment:
      # Service mode: kafka, api, or hybrid
      SERVICE_MODE: ${AUTONOMOUS_CRAWLER_MODE:-hybrid}
      API_PORT: "8030"
      # Database connections
      DATABASE_URL: postgresql://${POSTGRES_USER:-newsinsight}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-newsinsight}
      MONGODB_URI: mongodb://${MONGO_USER:-newsinsight}:${MONGO_PASSWORD}@mongo:27017/newsinsight?authSource=admin
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      # Kafka settings
      KAFKA_BOOTSTRAP_SERVERS: redpanda:9092
      KAFKA_CONSUMER_GROUP_ID: autonomous-crawler-group
      KAFKA_BROWSER_TASK_TOPIC: newsinsight.crawl.browser.tasks
      KAFKA_CRAWL_RESULT_TOPIC: newsinsight.crawl.results
      # External services
      BROWSER_USE_API_URL: http://browser-use-api:8500
      WEB_CRAWLER_URL: http://web-crawler:11235
      COLLECTOR_SERVICE_URL: http://collector-service:8081
      # LLM settings
      LLM_PROVIDER: ${LLM_PROVIDER:-openai}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY:-}
      GOOGLE_API_KEY: ${GOOGLE_API_KEY:-}
      USE_DB_PROVIDERS: "true"
      # AIdove/custom LLM
      AIDOVE_API_KEY: ${AIDOVE_API_KEY}
      AIDOVE_API_BASE_URL: ${AIDOVE_API_BASE_URL:-https://ai.nodove.com}
      # MCP Server URLs for integrated analysis
      BIAS_MCP_URL: http://bias-mcp:5001
      FACTCHECK_MCP_URL: http://factcheck-mcp:5002
      TOPIC_MCP_URL: http://topic-mcp:5003
      NEWSINSIGHT_MCP_URL: http://newsinsight-mcp:5000
      HUGGINGFACE_MCP_URL: http://huggingface-mcp:5011
      # Observability
      LOG_LEVEL: INFO
      LOG_FORMAT: json
      METRICS_ENABLED: "true"
      METRICS_PORT: "9090"
    ports:
      - "8030:8030"  # REST API
      - "9090:9090"  # Prometheus metrics
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.24
    depends_on:
      postgres:
        condition: service_healthy
      mongo:
        condition: service_healthy
      redis:
        condition: service_healthy
      redpanda:
        condition: service_healthy
      browser-use-api:
        condition: service_healthy
      web-crawler:
        condition: service_healthy
      # MCP servers for analysis
      newsinsight-mcp:
        condition: service_healthy
      bias-mcp:
        condition: service_healthy
      factcheck-mcp:
        condition: service_healthy
      topic-mcp:
        condition: service_healthy
    healthcheck:
      # Check both metrics (9090) and API (8030) endpoints
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://127.0.0.1:9090/ || wget --no-verbose --tries=1 --spider http://127.0.0.1:8030/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================================
  # AI Agent Worker - Kafka Consumer for AI Processing
  # Consumes newsinsight.ai.requests, produces to newsinsight.ai.responses
  # ============================================================================
  ai-agent-worker:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/ai-agent-worker:${TAG:-latest}
    container_name: newsinsight-prod-ai-agent-worker
    restart: unless-stopped
    environment:
      # Admin Server
      ADMIN_PORT: "7080"
      ADMIN_JWT_SECRET: ${JWT_SECRET_KEY:-change-me}
      ADMIN_DB_PATH: /data/proxy-admin.db
      ADMIN_EMAIL: ${AI_AGENT_ADMIN_EMAIL:-admin@newsinsight.nodove.com}
      ADMIN_PASSWORD: ${AI_AGENT_ADMIN_PASSWORD:-}
      # Kafka
      KAFKA_BROKERS: redpanda:9092
      KAFKA_GROUP_ID: ai-agent-worker
      KAFKA_REQUEST_TOPIC: newsinsight.ai.requests
      KAFKA_RESPONSE_TOPIC: newsinsight.ai.responses
      # Upstream LLM (OpenCode or external)
      OPENCODE_BASE: ${OPENCODE_BASE:-http://opencode:7012}
    volumes:
      - ai_agent_data:/data
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.25
    depends_on:
      redpanda:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://127.0.0.1:7080/admin/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================================
  # Frontend - 단일 진입점, nginx가 내부 라우팅 담당
  # ============================================================================
  frontend:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/frontend:${TAG:-latest}
    container_name: newsinsight-prod-frontend
    restart: unless-stopped
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.30
    depends_on:
      api-gateway:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://127.0.0.1:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================================
  # ML Addons - 뉴스 분석을 위한 ML 서비스
  # ============================================================================
  sentiment-addon:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/sentiment-addon:${TAG:-latest}
    container_name: newsinsight-prod-sentiment
    restart: unless-stopped
    environment:
      MODEL_NAME: ${SENTIMENT_MODEL:-cardiffnlp/twitter-roberta-base-sentiment-latest}
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.40
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:8100/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  factcheck-addon:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/factcheck-addon:${TAG:-latest}
    container_name: newsinsight-prod-factcheck
    restart: unless-stopped
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.41
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:8101/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  bias-addon:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/bias-addon:${TAG:-latest}
    container_name: newsinsight-prod-bias
    restart: unless-stopped
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.42
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:8102/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================================
  # MCP Servers - AI Agent용 도구 서버
  # ============================================================================
  newsinsight-mcp:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/newsinsight-mcp:${TAG:-latest}
    build:
      context: ../../mcp/newsinsight_mcp
      dockerfile: Dockerfile
    container_name: newsinsight-prod-mcp
    restart: unless-stopped
    environment:
      DB_BACKEND: postgres
      DATABASE_URL: postgresql://${POSTGRES_USER:-newsinsight}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-newsinsight}
      MONGODB_URI: mongodb://${MONGO_USER:-newsinsight}:${MONGO_PASSWORD}@mongo:27017/newsinsight?authSource=admin
      AIDOVE_WEBHOOK_URL: ${AIDOVE_WEBHOOK_URL:-https://workflow.nodove.com/webhook/aidove}
      PORT: "5000"
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.50
    depends_on:
      postgres:
        condition: service_healthy
      mongo:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  bias-mcp:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/bias-mcp:${TAG:-latest}
    build:
      context: ../../mcp/bias_mcp
      dockerfile: Dockerfile
    container_name: newsinsight-prod-bias-mcp
    restart: unless-stopped
    environment:
      DB_BACKEND: postgres
      DATABASE_URL: postgresql://${POSTGRES_USER:-newsinsight}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-newsinsight}
      MONGODB_URI: mongodb://${MONGO_USER:-newsinsight}:${MONGO_PASSWORD}@mongo:27017/newsinsight?authSource=admin
      AIDOVE_WEBHOOK_URL: ${AIDOVE_WEBHOOK_URL:-https://workflow.nodove.com/webhook/aidove}
      PORT: "5001"
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.51
    depends_on:
      postgres:
        condition: service_healthy
      mongo:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:5001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  factcheck-mcp:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/factcheck-mcp:${TAG:-latest}
    build:
      context: ../../mcp/factcheck_mcp
      dockerfile: Dockerfile
    container_name: newsinsight-prod-factcheck-mcp
    restart: unless-stopped
    environment:
      DB_BACKEND: postgres
      DATABASE_URL: postgresql://${POSTGRES_USER:-newsinsight}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-newsinsight}
      MONGODB_URI: mongodb://${MONGO_USER:-newsinsight}:${MONGO_PASSWORD}@mongo:27017/newsinsight?authSource=admin
      AIDOVE_WEBHOOK_URL: ${AIDOVE_WEBHOOK_URL:-https://workflow.nodove.com/webhook/aidove}
      PORT: "5002"
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.52
    depends_on:
      postgres:
        condition: service_healthy
      mongo:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:5002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  topic-mcp:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/topic-mcp:${TAG:-latest}
    build:
      context: ../../mcp/topic_mcp
      dockerfile: Dockerfile
    container_name: newsinsight-prod-topic-mcp
    restart: unless-stopped
    environment:
      DB_BACKEND: postgres
      DATABASE_URL: postgresql://${POSTGRES_USER:-newsinsight}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-newsinsight}
      MONGODB_URI: mongodb://${MONGO_USER:-newsinsight}:${MONGO_PASSWORD}@mongo:27017/newsinsight?authSource=admin
      AIDOVE_WEBHOOK_URL: ${AIDOVE_WEBHOOK_URL:-https://workflow.nodove.com/webhook/aidove}
      PORT: "5003"
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.53
    depends_on:
      postgres:
        condition: service_healthy
      mongo:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:5003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  aiagent-mcp:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/aiagent-mcp:${TAG:-latest}
    build:
      context: ../../mcp/aiagent_mcp
      dockerfile: Dockerfile
    container_name: newsinsight-prod-aiagent-mcp
    restart: unless-stopped
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER:-newsinsight}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-newsinsight}
      ENCRYPTION_KEY: ${AI_PROVIDER_ENCRYPTION_KEY:-}
      AIDOVE_WEBHOOK_URL: ${AIDOVE_WEBHOOK_URL:-https://workflow.nodove.com/webhook/aidove}
      PORT: "5004"
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.54
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:5004/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================================
  # ML Training MCP Servers - Computer Vision & NLP
  # ============================================================================

  # ============================================================================
  # Text Embedding Server (for Hybrid Search)
  # HuggingFace Text Embeddings Inference with multilingual-e5-large
  # ============================================================================
  embedding-server:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.5
    container_name: newsinsight-prod-embedding
    restart: unless-stopped
    command:
      - --model-id
      - intfloat/multilingual-e5-large
      - --port
      - "8011"
      - --max-concurrent-requests
      - "128"
    volumes:
      - embedding_model_cache:/data
    environment:
      HF_HOME: /data
      HUGGING_FACE_HUB_TOKEN: ${HF_TOKEN:-}
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.70
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:8011/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================================
  # IP Rotation Service - Proxy Pool Management for Crawlers
  # Provides rotating proxies with health checks and adaptive load balancing
  # ============================================================================
  ip-rotation:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/ip-rotation:${TAG:-latest}
    build:
      context: ../../backend/browser-use/ip-rotation
      dockerfile: Dockerfile
    container_name: newsinsight-prod-ip-rotation
    restart: unless-stopped
    environment:
      # Rotation strategy: round_robin, random, least_used, weighted, geographic
      STRATEGY: ${IP_ROTATION_STRATEGY:-weighted}
      # Max failures before proxy is disabled
      MAX_FAILURES: ${IP_ROTATION_MAX_FAILURES:-5}
      # Cooldown in minutes before re-enabling failed proxy
      COOLDOWN_MINUTES: ${IP_ROTATION_COOLDOWN:-30}
      # Health check interval in seconds
      HEALTH_CHECK_INTERVAL: ${IP_ROTATION_HEALTH_CHECK:-300}
      # Persistence file path
      PERSISTENCE_PATH: /data/ip_pool_state.json
      # Server port
      PORT: "8050"
    volumes:
      - ip_rotation_data:/data
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.71
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://127.0.0.1:8050/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================================
  # Crawl Worker - Web Crawling Service with Proxy Rotation
  # ============================================================================
  crawl-worker:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/crawl-worker:${TAG:-latest}
    build:
      context: ../../
      dockerfile: backend/autonomous-crawler-service/crawl-worker/Dockerfile
    container_name: newsinsight-prod-crawl-worker
    restart: unless-stopped
    environment:
      PORT: "8040"
      MAX_CONCURRENT_CRAWLS: ${CRAWL_WORKER_MAX_CONCURRENT:-5}
      # Proxy rotation configuration
      USE_PROXY_ROTATION: ${USE_PROXY_ROTATION:-true}
      PROXY_ROTATION_URL: http://ip-rotation:8050
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.72
    depends_on:
      ip-rotation:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:8040/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================================
  # Maigret Worker - Username OSINT Scanner with Proxy Rotation
  # ============================================================================
  maigret-worker:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/maigret-worker:${TAG:-latest}
    build:
      context: ../../
      dockerfile: backend/data-collection-service/maigret-worker/Dockerfile
    container_name: newsinsight-prod-maigret-worker
    restart: unless-stopped
    environment:
      PORT: "8020"
      MAX_CONCURRENT_SCANS: ${MAIGRET_MAX_CONCURRENT:-3}
      SCAN_TIMEOUT_SEC: ${MAIGRET_TIMEOUT:-300}
      REPORTS_DIR: /app/reports
      # Proxy rotation configuration
      USE_PROXY_ROTATION: ${USE_PROXY_ROTATION:-true}
      PROXY_ROTATION_URL: http://ip-rotation:8050
    volumes:
      - maigret_reports:/app/reports
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.73
    depends_on:
      ip-rotation:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:8020/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  bot-detector:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/bot-detector:${TAG:-latest}
    build:
      context: ../../
      dockerfile: backend/browser-use/bot-detector/Dockerfile
    container_name: newsinsight-prod-bot-detector
    restart: unless-stopped
    environment:
      BOT_DETECTOR_MODEL_NAME: ${BOT_DETECTOR_MODEL_NAME:-roberta-base-openai-detector}
      PORT: "8041"
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.74
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:8041/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  roboflow-mcp:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/roboflow-mcp:${TAG:-latest}
    build:
      context: ../../mcp/roboflow_mcp
      dockerfile: Dockerfile
    container_name: newsinsight-prod-roboflow-mcp
    restart: unless-stopped
    profiles: ["ml-mcp"]
    environment:
      ROBOFLOW_API_KEY: ${ROBOFLOW_API_KEY:-}
      DATA_DIR: /app/data
      PORT: "5010"
    volumes:
      - ml_shared_data:/app/data
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.60
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:5010/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  huggingface-mcp:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/huggingface-mcp:${TAG:-latest}
    build:
      context: ../../mcp/huggingface_mcp
      dockerfile: Dockerfile
    container_name: newsinsight-prod-huggingface-mcp
    restart: unless-stopped
    profiles: ["ml-mcp"]
    environment:
      HF_TOKEN: ${HF_TOKEN:-}
      DATA_DIR: /app/data
      PORT: "5011"
    volumes:
      - ml_shared_data:/app/data
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.61
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:5011/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  kaggle-mcp:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/kaggle-mcp:${TAG:-latest}
    build:
      context: ../../mcp/kaggle_mcp
      dockerfile: Dockerfile
    container_name: newsinsight-prod-kaggle-mcp
    restart: unless-stopped
    profiles: ["ml-mcp"]
    environment:
      KAGGLE_USERNAME: ${KAGGLE_USERNAME:-}
      KAGGLE_KEY: ${KAGGLE_KEY:-}
      DATA_DIR: /app/data
      PORT: "5012"
    volumes:
      - ml_shared_data:/app/data
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.62
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:5012/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  mltraining-mcp:
    image: ${REGISTRY:-ghcr.io/nodove}/newsinsight/mltraining-mcp:${TAG:-latest}
    build:
      context: ../../mcp/mltraining_mcp
      dockerfile: Dockerfile
    container_name: newsinsight-prod-mltraining-mcp
    restart: unless-stopped
    profiles: ["ml-mcp"]
    environment:
      ROBOFLOW_MCP_URL: http://roboflow-mcp:5010
      HUGGINGFACE_MCP_URL: http://huggingface-mcp:5011
      KAGGLE_MCP_URL: http://kaggle-mcp:5012
      DATA_DIR: /app/data
      PORT: "5020"
    volumes:
      - ml_shared_data:/app/data
    networks:
      newsinsight-prod:
        ipv4_address: 172.20.0.63
    depends_on:
      - roboflow-mcp
      - huggingface-mcp
      - kaggle-mcp
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:5020/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
```

---

## etc/docker/docker-compose.zerotrust-news.yml

```yml
# Cloudflare Zero Trust Tunnel 기반 NewsInsight Stack
# news.nodove.com 전용 구성 (Preview 환경)
#
# 사전 준비:
# 1. Cloudflare Dashboard에서 Zero Trust > Access > Tunnels 메뉴 진입
# 2. Create a tunnel 클릭 후 tunnel 이름 지정 (예: news-tunnel)
# 3. 생성된 tunnel token 복사
# 4. .env 파일에 CLOUDFLARE_TUNNEL_TOKEN_NEWS=<your-token> 추가
# 5. Public hostname 설정:
#    - news.nodove.com -> http://frontend:8080
#    - news.nodove.com/api/* -> http://api-gateway:8000
#
# 실행: docker compose -f docker-compose.zerotrust-news.yml up -d

services:
  # Cloudflare Tunnel - 외부 트래픽을 내부 서비스로 라우팅
  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: news-cloudflared
    restart: unless-stopped
    command: tunnel run
    environment:
      - TUNNEL_TOKEN=${CLOUDFLARE_TUNNEL_TOKEN_NEWS}
    depends_on:
      frontend:
        condition: service_started
      api-gateway:
        condition: service_started
    networks:
      - default
    # 외부 포트 노출 없음 - Cloudflare Tunnel을 통해서만 접근

  consul:
    image: hashicorp/consul:1.18
    container_name: news-consul
    command: ["agent", "-dev", "-client", "0.0.0.0", "-ui"]
    # 외부 포트 노출 제거 - 내부 네트워크에서만 접근 가능
    expose:
      - "8500"
    environment:
      - CONSUL_BIND_INTERFACE=eth0
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8500/v1/status/leader"]
      interval: 5s
      timeout: 3s
      retries: 20

  consul-seed:
    image: alpine:3.18
    container_name: news-consul-seed
    depends_on:
      consul:
        condition: service_healthy
    volumes:
      - ../../etc/scripts:/scripts:ro
      - ../../etc/configs:/configs:ro
    environment:
      - CONSUL_HTTP_ADDR=http://consul:8500
      - CONSUL_HTTP_TOKEN=${CONSUL_HTTP_TOKEN:-}
    command: >
      sh -c "
        apk add --no-cache curl bash jq &&
        /scripts/consul_seed.sh ${ENVIRONMENT:-staging}
      "
    restart: "no"

  api-gateway:
    build:
      context: ../../
      dockerfile: backend/api-gateway-service/Dockerfile
    image: news/api-gateway:local
    container_name: news-api-gateway
    depends_on:
      consul:
        condition: service_healthy
      consul-seed:
        condition: service_completed_successfully
      collector-service:
        condition: service_started
      browser-use-api:
        condition: service_started
    environment:
      - CONSUL_HOST=${CONSUL_HOST:-consul}
      - CONSUL_PORT=${CONSUL_PORT:-8500}
      - CONSUL_HTTP_TOKEN=${CONSUL_HTTP_TOKEN:-}
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - PORT=${API_GATEWAY_PORT:-8000}
      - BROWSER_USE_URL=http://browser-use-api:8500
      - BROWSER_USE_WS_URL=ws://browser-use-api:8500
    # 외부 포트 노출 제거 - Cloudflare Tunnel을 통해서만 접근
    expose:
      - "8000"
    networks:
      - default

  frontend:
    build:
      context: ../../frontend
      dockerfile: Dockerfile
      args:
        # API URL은 브라우저에서 접근 가능한 경로로 설정 (nginx가 프록시함)
        - VITE_API_BASE_URL=
        - VITE_BROWSER_USE_URL=
    image: news/frontend:local
    container_name: news-frontend
    # 외부 포트 노출 제거 - Cloudflare Tunnel을 통해서만 접근
    expose:
      - "8080"
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8080/health"]
      interval: 30s
      timeout: 3s
      retries: 3
    depends_on:
      api-gateway:
        condition: service_started
    networks:
      - default

  collector-service:
    build:
      context: ../../
      dockerfile: backend/data-collection-service/Dockerfile
    image: news/collector-service:local
    container_name: news-collector-service
    depends_on:
      consul:
        condition: service_healthy
      consul-seed:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
      mongo:
        condition: service_healthy
      web-crawler:
        condition: service_started
      redpanda-dev:
        condition: service_started
    environment:
      - CONSUL_HOST=${CONSUL_HOST:-consul}
      - CONSUL_PORT=${CONSUL_PORT:-8500}
      - CONSUL_ENABLED=${CONSUL_ENABLED:-true}
      - "SPRING_CONFIG_IMPORT=consul:"
      - SPRING_CLOUD_CONSUL_CONFIG_ENABLED=true
      - SPRING_CLOUD_CONSUL_CONFIG_PREFIX=config
      - SPRING_CLOUD_CONSUL_CONFIG_DEFAULT_CONTEXT=collector-service
      - SPRING_CLOUD_CONSUL_CONFIG_FORMAT=YAML
      - SPRING_CLOUD_CONSUL_CONFIG_FAIL_FAST=true
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - SPRING_DATA_REDIS_HOST=${REDIS_HOST:-redis}
      - SPRING_DATA_REDIS_PORT=${REDIS_PORT:-6379}
      - SPRING_JPA_HIBERNATE_DDL_AUTO=validate
      - PERPLEXITY_API_KEY=${PERPLEXITY_API_KEY:-}
      - PERPLEXITY_MODEL=${PERPLEXITY_MODEL:-sonar}
      - PERPLEXITY_BASE_URL=${PERPLEXITY_BASE_URL:-https://api.perplexity.ai}
      # AI Service URLs (can be overridden via Consul KV)
      - COLLECTOR_AIDOVE_BASE_URL=${COLLECTOR_SERVICE_AIDOVE_BASE_URL:-https://workflow.nodove.com/webhook/aidove}
      - COLLECTOR_CALLBACK_BASE_URL=${COLLECTOR_SERVICE_CALLBACK_BASE_URL:-http://collector-service:8081}
      # DeepSearch - uses IntegratedCrawlerService (n8n deprecated)
      - COLLECTOR_DEEP_SEARCH_ENABLED=false
      - COLLECTOR_DEEP_SEARCH_FALLBACK_TO_WEBHOOK=false
      - DB_HOST=${DB_HOST:-postgres}
      - DB_PORT=${DB_PORT:-5432}
      - DB_NAME=${DB_NAME:-news}
      - DB_USER=${DB_USER:-postgres}
      - DB_PASSWORD=${DB_PASSWORD:-postgres}
      - MONGODB_URI=${MONGODB_URI:-mongodb://mongo:27017/news}
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS:-redpanda-dev:9092}
      - SERVER_PORT=${COLLECTOR_PORT:-8081}
      - SPRING_CLOUD_INETUTILS_PREFERRED_NETWORKS=172.21
    expose:
      - "8081"
    networks:
      - default

  web-crawler:
    image: unclecode/crawl4ai:latest
    container_name: news-web-crawler
    shm_size: 1g
    environment:
      - LOG_LEVEL=${WEB_CRAWLER_LOG_LEVEL:-INFO}
    # 외부 포트 노출 제거
    expose:
      - "11235"
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:11235/health"]
      interval: 10s
      timeout: 5s
      retries: 10

  postgres:
    image: postgres:15-alpine
    container_name: news-postgres
    environment:
      - POSTGRES_DB=${DB_NAME:-news}
      - POSTGRES_USER=${DB_USER:-postgres}
      - POSTGRES_PASSWORD=${DB_PASSWORD:-postgres}
    expose:
      - "5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./db-init:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 3s
      retries: 5

  mongo:
    image: mongo:7
    container_name: news-mongo
    restart: unless-stopped
    environment:
      - MONGO_INITDB_DATABASE=${DB_NAME:-news}
    expose:
      - "27017"
    volumes:
      - mongo-data:/data/db
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5

  redpanda-dev:
    image: docker.redpanda.com/redpandadata/redpanda:latest
    container_name: news-redpanda
    command:
      - redpanda
      - start
      - --overprovisioned
      - --smp
      - "1"
      - --memory
      - 1G
      - --reserve-memory
      - 0M
      - --node-id
      - "0"
      - --check=false
      - --kafka-addr
      - PLAINTEXT://0.0.0.0:9092
      - --advertise-kafka-addr
      - PLAINTEXT://redpanda-dev:9092
    # 외부 포트 노출 제거
    expose:
      - "9092"
      - "9644"
    networks:
      - default

  redis:
    image: redis:7-alpine
    container_name: news-redis
    expose:
      - "6379"
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  autonomous-crawler:
    build:
      context: ../../
      dockerfile: backend/autonomous-crawler-service/Dockerfile
    image: news/autonomous-crawler:local
    container_name: news-autonomous-crawler
    restart: unless-stopped
    depends_on:
      consul:
        condition: service_healthy
      consul-seed:
        condition: service_completed_successfully
      redpanda-dev:
        condition: service_started
    environment:
      - CONSUL_HOST=${CONSUL_HOST:-consul}
      - CONSUL_PORT=${CONSUL_PORT:-8500}
      - CONSUL_HTTP_TOKEN=${CONSUL_HTTP_TOKEN:-}
      - CONSUL_ENABLED=${CONSUL_ENABLED:-true}
      - CONSUL_SERVICE_NAME=autonomous-crawler
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS:-redpanda-dev:9092}
      - KAFKA_CONSUMER_GROUP_ID=${CRAWLER_CONSUMER_GROUP:-autonomous-crawler-group}
      - KAFKA_BROWSER_TASK_TOPIC=${CRAWLER_TASK_TOPIC:-news.crawl.browser.tasks}
      - KAFKA_CRAWL_RESULT_TOPIC=${CRAWLER_RESULT_TOPIC:-news.crawl.results}
      - BROWSER_HEADLESS=${CRAWLER_HEADLESS:-true}
      - BROWSER_MAX_CONCURRENT_SESSIONS=${CRAWLER_MAX_SESSIONS:-2}
      - BROWSER_DEFAULT_TIMEOUT_SECONDS=${CRAWLER_TIMEOUT:-300}
      - LLM_PROVIDER=${CRAWLER_LLM_PROVIDER:-openai}
      - LLM_OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - LLM_OPENAI_MODEL=${CRAWLER_OPENAI_MODEL:-gpt-4o}
      - LLM_ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - LLM_ANTHROPIC_MODEL=${CRAWLER_ANTHROPIC_MODEL:-claude-3-5-sonnet-20241022}
      - SEARCH_BRAVE_API_KEY=${SEARCH_BRAVE_API_KEY:-}
      - SEARCH_TAVILY_API_KEY=${SEARCH_TAVILY_API_KEY:-}
      - SEARCH_PERPLEXITY_API_KEY=${SEARCH_PERPLEXITY_API_KEY:-}
      - STEALTH_ENABLED=${STEALTH_ENABLED:-true}
      - CAPTCHA_ENABLED=${CAPTCHA_ENABLED:-true}
      - METRICS_ENABLED=${CRAWLER_METRICS_ENABLED:-true}
      - METRICS_PORT=${CRAWLER_METRICS_PORT:-9090}
      - LOG_LEVEL=${CRAWLER_LOG_LEVEL:-INFO}
      - LOG_FORMAT=${CRAWLER_LOG_FORMAT:-json}
    # 외부 포트 노출 제거
    expose:
      - "9090"
    shm_size: 2g
    networks:
      - default

  browser-use-api:
    build:
      context: ../../backend/browser-use
      dockerfile: Dockerfile.api
    image: news/browser-use-api:local
    container_name: news-browser-use-api
    restart: unless-stopped
    environment:
      - AIDOVE_WEBHOOK_URL=${AIDOVE_WEBHOOK_URL:-https://workflow.nodove.com/webhook/aidove}
      - BROWSER_HEADLESS=${BROWSER_USE_HEADLESS:-true}
      - SERVER_PORT=8500
      - LOG_LEVEL=${BROWSER_USE_LOG_LEVEL:-INFO}
    # 외부 포트 노출 제거
    expose:
      - "8500"
    shm_size: 2g
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8500/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - default

volumes:
  postgres-data:
    name: news-postgres-data
  redis-data:
    name: news-redis-data
  mongo-data:
    name: news-mongo-data

networks:
  default:
    name: news-zerotrust-net

```

---

## etc/docker/docker-compose.zerotrust-newsinsight.yml

```yml
# Cloudflare Zero Trust Tunnel 기반 NewsInsight Stack
# newsinsight.nodove.com 전용 구성
#
# 사전 준비:
# 1. Cloudflare Dashboard에서 Zero Trust > Access > Tunnels 메뉴 진입
# 2. Create a tunnel 클릭 후 tunnel 이름 지정 (예: newsinsight-tunnel)
# 3. 생성된 tunnel token 복사
# 4. .env 파일에 CLOUDFLARE_TUNNEL_TOKEN_NEWSINSIGHT=<your-token> 추가
# 5. Public hostname 설정:
#    - newsinsight.nodove.com -> http://frontend:8080
#    - newsinsight.nodove.com/api/* -> http://api-gateway:8000
#
# 실행: docker compose -p newsinsight -f docker-compose.zerotrust-newsinsight.yml up -d

services:
  # ============================================================================
  # Infrastructure Services
  # ============================================================================
  
  consul:
    image: hashicorp/consul:1.18
    container_name: newsinsight-consul
    command: ["agent", "-dev", "-client", "0.0.0.0", "-ui"]
    expose:
      - "8500"
    environment:
      - CONSUL_BIND_INTERFACE=eth0
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8500/v1/status/leader"]
      interval: 5s
      timeout: 3s
      retries: 20
    volumes:
      - consul-data:/consul/data

  consul-seed:
    image: alpine:3.18
    container_name: newsinsight-consul-seed
    depends_on:
      consul:
        condition: service_healthy
    volumes:
      - ../../etc/scripts:/scripts:ro
      - ../../etc/configs:/configs:ro
    environment:
      - CONSUL_HTTP_ADDR=http://consul:8500
      - CONSUL_HTTP_TOKEN=${CONSUL_HTTP_TOKEN:-}
    command: >
      sh -c "
        apk add --no-cache curl bash jq &&
        /scripts/consul_seed.sh ${ENVIRONMENT:-production}
      "
    restart: "no"

  postgres:
    image: postgres:15-alpine
    container_name: newsinsight-postgres
    environment:
      - POSTGRES_DB=${DB_NAME:-newsinsight}
      - POSTGRES_USER=${DB_USER:-postgres}
      - POSTGRES_PASSWORD=${DB_PASSWORD:-postgres}
    expose:
      - "5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./db-init:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 3s
      retries: 5

  mongo:
    image: mongo:7
    container_name: newsinsight-mongo
    restart: unless-stopped
    environment:
      - MONGO_INITDB_DATABASE=${DB_NAME:-newsinsight}
    expose:
      - "27017"
    volumes:
      - mongo-data:/data/db
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: newsinsight-redis
    expose:
      - "6379"
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  redpanda-dev:
    image: docker.redpanda.com/redpandadata/redpanda:latest
    container_name: newsinsight-redpanda
    command:
      - redpanda
      - start
      - --overprovisioned
      - --smp
      - "1"
      - --memory
      - 1G
      - --reserve-memory
      - 0M
      - --node-id
      - "0"
      - --check=false
      - --kafka-addr
      - PLAINTEXT://0.0.0.0:9092
      - --advertise-kafka-addr
      - PLAINTEXT://redpanda-dev:9092
    expose:
      - "9092"
      - "9644"

  # ============================================================================
  # Crawling Infrastructure
  # ============================================================================

  web-crawler:
    image: unclecode/crawl4ai:latest
    container_name: newsinsight-web-crawler
    shm_size: 1g
    environment:
      - LOG_LEVEL=${WEB_CRAWLER_LOG_LEVEL:-INFO}
    expose:
      - "11235"
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:11235/health"]
      interval: 10s
      timeout: 5s
      retries: 10

  ip-rotation:
    build:
      context: ../../backend/browser-use/ip-rotation
      dockerfile: Dockerfile
    image: newsinsight/ip-rotation:local
    container_name: newsinsight-ip-rotation
    restart: unless-stopped
    environment:
      - STRATEGY=${IP_ROTATION_STRATEGY:-weighted}
      - MAX_FAILURES=${IP_ROTATION_MAX_FAILURES:-5}
      - COOLDOWN_MINUTES=${IP_ROTATION_COOLDOWN:-30}
      - HEALTH_CHECK_INTERVAL=${IP_ROTATION_HEALTH_CHECK:-300}
      - PERSISTENCE_PATH=/data/ip_pool_state.json
      - PORT=8050
    volumes:
      - ip-rotation-data:/data
    expose:
      - "8050"
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8050/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  crawl-worker:
    build:
      context: ../../
      dockerfile: backend/autonomous-crawler-service/crawl-worker/Dockerfile
    image: newsinsight/crawl-worker:local
    container_name: newsinsight-crawl-worker
    restart: unless-stopped
    environment:
      - PORT=8040
      - MAX_CONCURRENT_CRAWLS=${CRAWL_WORKER_MAX_CONCURRENT:-5}
      - USE_PROXY_ROTATION=${USE_PROXY_ROTATION:-true}
      - PROXY_ROTATION_URL=http://ip-rotation:8050
    expose:
      - "8040"
    depends_on:
      ip-rotation:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8040/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  maigret-worker:
    build:
      context: ../../
      dockerfile: backend/data-collection-service/maigret-worker/Dockerfile
    image: newsinsight/maigret-worker:local
    container_name: newsinsight-maigret-worker
    restart: unless-stopped
    environment:
      - PORT=8020
      - MAX_CONCURRENT_SCANS=${MAIGRET_MAX_CONCURRENT:-3}
      - SCAN_TIMEOUT_SEC=${MAIGRET_TIMEOUT:-300}
      - REPORTS_DIR=/app/reports
      - USE_PROXY_ROTATION=${USE_PROXY_ROTATION:-true}
      - PROXY_ROTATION_URL=http://ip-rotation:8050
    volumes:
      - maigret-reports:/app/reports
    expose:
      - "8020"
    depends_on:
      ip-rotation:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8020/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  browser-use-api:
    build:
      context: ../../backend/browser-use
      dockerfile: Dockerfile.api
    image: newsinsight/browser-use-api:local
    container_name: newsinsight-browser-use-api
    restart: unless-stopped
    environment:
      - AIDOVE_WEBHOOK_URL=${AIDOVE_WEBHOOK_URL:-https://workflow.nodove.com/webhook/aidove}
      - BROWSER_HEADLESS=${BROWSER_USE_HEADLESS:-true}
      - SERVER_PORT=8500
      - LOG_LEVEL=${BROWSER_USE_LOG_LEVEL:-INFO}
    expose:
      - "8500"
    shm_size: 2g
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8500/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ============================================================================
  # ML Add-ons
  # ============================================================================

  sentiment-addon:
    build:
      context: ../../backend/ml-addons/sentiment-addon
      dockerfile: Dockerfile
    image: newsinsight/sentiment-addon:local
    container_name: newsinsight-sentiment-addon
    restart: unless-stopped
    expose:
      - "8100"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8100/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  factcheck-addon:
    build:
      context: ../../backend/ml-addons/factcheck-addon
      dockerfile: Dockerfile
    image: newsinsight/factcheck-addon:local
    container_name: newsinsight-factcheck-addon
    restart: unless-stopped
    expose:
      - "8101"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8101/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  bias-addon:
    build:
      context: ../../backend/ml-addons/bias-addon
      dockerfile: Dockerfile
    image: newsinsight/bias-addon:local
    container_name: newsinsight-bias-addon
    restart: unless-stopped
    expose:
      - "8102"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8102/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  bot-detector:
    build:
      context: ../../
      dockerfile: backend/browser-use/bot-detector/Dockerfile
    image: newsinsight/bot-detector:local
    container_name: newsinsight-bot-detector
    restart: unless-stopped
    environment:
      - BOT_DETECTOR_MODEL_NAME=${BOT_DETECTOR_MODEL_NAME:-roberta-base-openai-detector}
    expose:
      - "8040"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8040/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # ============================================================================
  # Application Services
  # ============================================================================

  collector-service:
    build:
      context: ../../
      dockerfile: backend/data-collection-service/Dockerfile
    image: newsinsight/collector-service:local
    container_name: newsinsight-collector-service
    depends_on:
      consul:
        condition: service_healthy
      consul-seed:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
      mongo:
        condition: service_healthy
      redis:
        condition: service_healthy
      web-crawler:
        condition: service_started
      redpanda-dev:
        condition: service_started
    environment:
      - CONSUL_HOST=${CONSUL_HOST:-consul}
      - CONSUL_PORT=${CONSUL_PORT:-8500}
      - CONSUL_ENABLED=${CONSUL_ENABLED:-true}
      - "SPRING_CONFIG_IMPORT=consul:"
      - SPRING_PROFILES_ACTIVE=local-consul
      - SPRING_CLOUD_CONSUL_CONFIG_ENABLED=true
      - SPRING_CLOUD_CONSUL_CONFIG_PREFIX=config
      - SPRING_CLOUD_CONSUL_CONFIG_DEFAULT_CONTEXT=collector-service
      - SPRING_CLOUD_CONSUL_CONFIG_FORMAT=YAML
      - SPRING_CLOUD_CONSUL_CONFIG_FAIL_FAST=true
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - SPRING_DATA_REDIS_HOST=${REDIS_HOST:-redis}
      - SPRING_DATA_REDIS_PORT=${REDIS_PORT:-6379}
      - SPRING_JPA_HIBERNATE_DDL_AUTO=validate
      - PERPLEXITY_API_KEY=${PERPLEXITY_API_KEY:-}
      - PERPLEXITY_MODEL=${PERPLEXITY_MODEL:-sonar}
      - PERPLEXITY_BASE_URL=${PERPLEXITY_BASE_URL:-https://api.perplexity.ai}
      - COLLECTOR_AIDOVE_BASE_URL=${COLLECTOR_SERVICE_AIDOVE_BASE_URL:-https://workflow.nodove.com/webhook/aidove}
      - COLLECTOR_CALLBACK_BASE_URL=${COLLECTOR_SERVICE_CALLBACK_BASE_URL:-http://collector-service:8081}
      - COLLECTOR_DEEP_SEARCH_ENABLED=false
      - COLLECTOR_DEEP_SEARCH_FALLBACK_TO_WEBHOOK=false
      # Auto-Crawl Configuration (실시간 확장형 크롤링)
      - AUTOCRAWL_ENABLED=true
      - AUTOCRAWL_BATCH_SIZE=10
      - AUTOCRAWL_DISCOVER_FROM_SEARCH=true
      - AUTOCRAWL_DISCOVER_FROM_ARTICLES=true
      - AUTOCRAWL_DISCOVER_FROM_DEEP_SEARCH=true
      - DB_HOST=${DB_HOST:-postgres}
      - DB_PORT=${DB_PORT:-5432}
      - DB_NAME=${DB_NAME:-newsinsight}
      - DB_USER=${DB_USER:-postgres}
      - DB_PASSWORD=${DB_PASSWORD:-postgres}
      - MONGODB_URI=${MONGODB_URI:-mongodb://mongo:27017/newsinsight}
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS:-redpanda-dev:9092}
      - SERVER_PORT=${COLLECTOR_PORT:-8081}
    expose:
      - "8081"

  autonomous-crawler:
    build:
      context: ../../
      dockerfile: backend/autonomous-crawler-service/Dockerfile
    image: newsinsight/autonomous-crawler:local
    container_name: newsinsight-autonomous-crawler
    restart: unless-stopped
    depends_on:
      consul:
        condition: service_healthy
      consul-seed:
        condition: service_completed_successfully
      redpanda-dev:
        condition: service_started
      browser-use-api:
        condition: service_healthy
    environment:
      - CONSUL_HOST=${CONSUL_HOST:-consul}
      - CONSUL_PORT=${CONSUL_PORT:-8500}
      - CONSUL_HTTP_TOKEN=${CONSUL_HTTP_TOKEN:-}
      - CONSUL_ENABLED=${CONSUL_ENABLED:-true}
      - CONSUL_SERVICE_NAME=autonomous-crawler
      - SERVICE_MODE=${CRAWLER_SERVICE_MODE:-hybrid}
      - API_PORT=${CRAWLER_API_PORT:-8030}
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS:-redpanda-dev:9092}
      - KAFKA_CONSUMER_GROUP_ID=${CRAWLER_CONSUMER_GROUP:-autonomous-crawler-group}
      - KAFKA_BROWSER_TASK_TOPIC=${CRAWLER_TASK_TOPIC:-newsinsight.crawl.browser.tasks}
      - KAFKA_CRAWL_RESULT_TOPIC=${CRAWLER_RESULT_TOPIC:-newsinsight.crawl.results}
      - BROWSER_HEADLESS=${CRAWLER_HEADLESS:-true}
      - BROWSER_MAX_CONCURRENT_SESSIONS=${CRAWLER_MAX_SESSIONS:-2}
      - BROWSER_DEFAULT_TIMEOUT_SECONDS=${CRAWLER_TIMEOUT:-300}
      - LLM_PROVIDER=${CRAWLER_LLM_PROVIDER:-openai}
      - LLM_OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - LLM_OPENAI_MODEL=${CRAWLER_OPENAI_MODEL:-gpt-4o}
      - LLM_ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - LLM_ANTHROPIC_MODEL=${CRAWLER_ANTHROPIC_MODEL:-claude-3-5-sonnet-20241022}
      - SEARCH_BRAVE_API_KEY=${SEARCH_BRAVE_API_KEY:-}
      - SEARCH_TAVILY_API_KEY=${SEARCH_TAVILY_API_KEY:-}
      - SEARCH_PERPLEXITY_API_KEY=${SEARCH_PERPLEXITY_API_KEY:-}
      - STEALTH_ENABLED=${STEALTH_ENABLED:-true}
      - CAPTCHA_ENABLED=${CAPTCHA_ENABLED:-true}
      - METRICS_ENABLED=${CRAWLER_METRICS_ENABLED:-true}
      - METRICS_PORT=${CRAWLER_METRICS_PORT:-9090}
      - LOG_LEVEL=${CRAWLER_LOG_LEVEL:-INFO}
      - LOG_FORMAT=${CRAWLER_LOG_FORMAT:-json}
    expose:
      - "9090"
      - "8030"
    shm_size: 2g
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8030/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  api-gateway:
    build:
      context: ../../
      dockerfile: backend/api-gateway-service/Dockerfile
    image: newsinsight/api-gateway:local
    container_name: newsinsight-api-gateway
    depends_on:
      consul:
        condition: service_healthy
      consul-seed:
        condition: service_completed_successfully
      collector-service:
        condition: service_started
      browser-use-api:
        condition: service_started
      sentiment-addon:
        condition: service_started
      factcheck-addon:
        condition: service_started
      bias-addon:
        condition: service_started
      bot-detector:
        condition: service_started
    environment:
      - CONSUL_HOST=${CONSUL_HOST:-consul}
      - CONSUL_PORT=${CONSUL_PORT:-8500}
      - CONSUL_HTTP_TOKEN=${CONSUL_HTTP_TOKEN:-}
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - PORT=${API_GATEWAY_PORT:-8000}
      - BROWSER_USE_URL=http://browser-use-api:8500
      - BROWSER_USE_WS_URL=ws://browser-use-api:8500
      - ML_ADDON_SENTIMENT_URL=http://sentiment-addon:8100
      - ML_ADDON_FACTCHECK_URL=http://factcheck-addon:8101
      - ML_ADDON_BIAS_URL=http://bias-addon:8102
      - ML_ADDON_BOT_DETECTOR_URL=http://bot-detector:8040
    expose:
      - "8000"

  frontend:
    image: node:20-alpine
    container_name: newsinsight-frontend
    working_dir: /app
    volumes:
      - ../../frontend:/app
      - frontend-node-modules:/app/node_modules
    environment:
      - VITE_API_BASE_URL=http://api-gateway:8000
      - VITE_BROWSER_USE_URL=http://api-gateway:8000
    command: >
      sh -c "(npm ci --legacy-peer-deps || npm install --legacy-peer-deps) \
      && npm run dev -- --host 0.0.0.0 --port 8080"
    expose:
      - "8080"
    depends_on:
      api-gateway:
        condition: service_started

  # ============================================================================
  # Cloudflare Tunnel - 외부 트래픽을 내부 서비스로 라우팅
  # ============================================================================
  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: newsinsight-cloudflared
    restart: unless-stopped
    command: tunnel run
    environment:
      - TUNNEL_TOKEN=${CLOUDFLARE_TUNNEL_TOKEN_NEWSINSIGHT}
    depends_on:
      frontend:
        condition: service_started
      api-gateway:
        condition: service_started

volumes:
  consul-data:
    name: newsinsight-consul-data
  postgres-data:
    name: newsinsight-postgres-data
  mongo-data:
    name: newsinsight-mongo-data
  redis-data:
    name: newsinsight-redis-data
  frontend-node-modules:
    name: newsinsight-frontend-node-modules
  ip-rotation-data:
    name: newsinsight-ip-rotation-data
  maigret-reports:
    name: newsinsight-maigret-reports

networks:
  default:
    name: newsinsight-zerotrust-dedicated-net

```

---

## etc/docker/docker-compose.zerotrust-preview.yml

```yml
# Cloudflare Zero Trust Tunnel 기반 NewsInsight Stack (Preview)
# news.nodove.com (프리뷰 프로덕션) 으로만 접근 가능하도록 구성
#
# 사전 준비:
# 1. Cloudflare Dashboard에서 Zero Trust > Access > Tunnels 메뉴 진입
# 2. Create a tunnel 클릭 후 tunnel 이름 지정 (예: news-preview-tunnel)
# 3. 생성된 preview tunnel token 복사
# 4. etc/docker/.env 파일에 CLOUDFLARE_TUNNEL_TOKEN_PREVIEW=<your-preview-token> 추가
# 5. Public hostname 설정:
#    - news.nodove.com -> http://frontend:8080
#    - news.nodove.com/api/* -> http://api-gateway:8000
#
# 실행: docker compose -f docker-compose.zerotrust-preview.yml up -d

services:
  # Cloudflare Tunnel - 외부 트래픽을 내부 서비스로 라우팅 (Preview)
  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: newsinsight-preview-cloudflared
    restart: unless-stopped
    command: tunnel run
    environment:
      - TUNNEL_TOKEN=${CLOUDFLARE_TUNNEL_TOKEN_PREVIEW}
    depends_on:
      frontend:
        condition: service_started
      api-gateway:
        condition: service_started
    networks:
      - default
    # 외부 포트 노출 없음 - Cloudflare Tunnel을 통해서만 접근

  consul:
    image: hashicorp/consul:1.18
    command: ["agent", "-dev", "-client", "0.0.0.0", "-ui"]
    # 외부 포트 노출 제거 - 내부 네트워크에서만 접근 가능
    expose:
      - "8500"
    environment:
      - CONSUL_BIND_INTERFACE=eth0
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8500/v1/status/leader"]
      interval: 5s
      timeout: 3s
      retries: 20

  consul-seed:
    image: alpine:3.18
    depends_on:
      consul:
        condition: service_healthy
    volumes:
      - ../../etc/scripts:/scripts:ro
      - ../../etc/configs:/configs:ro
    environment:
      - CONSUL_HTTP_ADDR=http://consul:8500
      - CONSUL_HTTP_TOKEN=${CONSUL_HTTP_TOKEN:-}
    command: >
      sh -c "
        apk add --no-cache curl bash jq &&
        /scripts/consul_seed.sh ${ENVIRONMENT:-production}
      "
    restart: "no"

  api-gateway:
    build:
      context: ../../
      dockerfile: backend/api-gateway-service/Dockerfile
    image: newsinsight/api-gateway:local-preview
    depends_on:
      consul:
        condition: service_healthy
      consul-seed:
        condition: service_completed_successfully
      collector-service:
        condition: service_started
      browser-use-api:
        condition: service_started
      sentiment-addon:
        condition: service_started
      factcheck-addon:
        condition: service_started
      bias-addon:
        condition: service_started
    environment:
      - CONSUL_HOST=${CONSUL_HOST:-consul}
      - CONSUL_PORT=${CONSUL_PORT:-8500}
      - CONSUL_HTTP_TOKEN=${CONSUL_HTTP_TOKEN:-}
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - PORT=${API_GATEWAY_PORT:-8000}
      - BROWSER_USE_URL=http://browser-use-api:8500
      - BROWSER_USE_WS_URL=ws://browser-use-api:8500
      - ML_ADDON_SENTIMENT_URL=http://sentiment-addon:8100
      - ML_ADDON_FACTCHECK_URL=http://factcheck-addon:8101
      - ML_ADDON_BIAS_URL=http://bias-addon:8102
    # 외부 포트 노출 제거 - Cloudflare Tunnel을 통해서만 접근
    expose:
      - "8000"
    networks:
      - default

  frontend:
    image: node:20-alpine
    working_dir: /app
    volumes:
      - ../../frontend:/app
      - frontend-node-modules:/app/node_modules
    environment:
      # Zero Trust Preview 환경: Vite 프록시를 통해 내부 api-gateway로 라우팅
      - VITE_API_BASE_URL=http://api-gateway:8000
      - VITE_BROWSER_USE_URL=http://api-gateway:8000
    command: >
      sh -c "(npm ci --legacy-peer-deps || npm install --legacy-peer-deps) \
      && npm run dev -- --host 0.0.0.0 --port 8080"
    # 외부 포트 노출 제거 - Cloudflare Tunnel을 통해서만 접근
    expose:
      - "8080"
    depends_on:
      api-gateway:
        condition: service_started
    networks:
      - default

  collector-service:
    build:
      context: ../../
      dockerfile: backend/data-collection-service/Dockerfile
    image: newsinsight/collector-service:local-preview
    depends_on:
      consul:
        condition: service_healthy
      consul-seed:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
      mongo:
        condition: service_healthy
      web-crawler:
        condition: service_started
      redpanda-dev:
        condition: service_started
    environment:
      - CONSUL_HOST=${CONSUL_HOST:-consul}
      - CONSUL_PORT=${CONSUL_PORT:-8500}
      - CONSUL_ENABLED=${CONSUL_ENABLED:-true}
      - "SPRING_CONFIG_IMPORT=consul:"
      - SPRING_CLOUD_CONSUL_CONFIG_ENABLED=true
      - SPRING_CLOUD_CONSUL_CONFIG_PREFIX=config
      - SPRING_CLOUD_CONSUL_CONFIG_DEFAULT_CONTEXT=collector-service
      - SPRING_CLOUD_CONSUL_CONFIG_FORMAT=YAML
      - SPRING_CLOUD_CONSUL_CONFIG_FAIL_FAST=true
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - SPRING_DATA_REDIS_HOST=${REDIS_HOST:-redis}
      - SPRING_DATA_REDIS_PORT=${REDIS_PORT:-6379}
      - SPRING_JPA_HIBERNATE_DDL_AUTO=validate
      - PERPLEXITY_API_KEY=${PERPLEXITY_API_KEY:-}
      - PERPLEXITY_MODEL=${PERPLEXITY_MODEL:-sonar}
      - PERPLEXITY_BASE_URL=${PERPLEXITY_BASE_URL:-https://api.perplexity.ai}
      # AI Service URLs (can be overridden via Consul KV)
      - COLLECTOR_AIDOVE_BASE_URL=${COLLECTOR_SERVICE_AIDOVE_BASE_URL:-https://workflow.nodove.com/webhook/aidove}
      - COLLECTOR_CALLBACK_BASE_URL=${COLLECTOR_SERVICE_CALLBACK_BASE_URL:-http://collector-service:8081}
      # DeepSearch - uses IntegratedCrawlerService (n8n deprecated)
      - COLLECTOR_DEEP_SEARCH_ENABLED=false
      - COLLECTOR_DEEP_SEARCH_FALLBACK_TO_WEBHOOK=false
      - DB_HOST=${DB_HOST:-postgres}
      - DB_PORT=${DB_PORT:-5432}
      - DB_NAME=${DB_NAME:-newsinsight}
      - DB_USER=${DB_USER:-postgres}
      - DB_PASSWORD=${DB_PASSWORD:-postgres}
      - MONGODB_URI=${MONGODB_URI:-mongodb://mongo:27017/newsinsight}
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS:-redpanda-dev:9092}
      - SERVER_PORT=${COLLECTOR_PORT:-8081}
      - SPRING_CLOUD_INETUTILS_PREFERRED_NETWORKS=172.20
    expose:
      - "8081"
    networks:
      - default

  web-crawler:
    image: unclecode/crawl4ai:latest
    shm_size: 1g
    environment:
      - LOG_LEVEL=${WEB_CRAWLER_LOG_LEVEL:-INFO}
    # 외부 포트 노출 제거
    expose:
      - "11235"
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:11235/health"]
      interval: 10s
      timeout: 5s
      retries: 10

  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=${DB_NAME:-newsinsight}
      - POSTGRES_USER=${DB_USER:-postgres}
      - POSTGRES_PASSWORD=${DB_PASSWORD:-postgres}
    expose:
      - "5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./db-init:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 3s
      retries: 5

  mongo:
    image: mongo:7
    restart: unless-stopped
    environment:
      - MONGO_INITDB_DATABASE=${DB_NAME:-newsinsight}
    expose:
      - "27017"
    volumes:
      - mongo-data:/data/db
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5

  redpanda-dev:
    image: docker.redpanda.com/redpandadata/redpanda:latest
    command:
      - redpanda
      - start
      - --overprovisioned
      - --smp
      - "1"
      - --memory
      - 1G
      - --reserve-memory
      - 0M
      - --node-id
      - "0"
      - --check=false
      - --kafka-addr
      - PLAINTEXT://0.0.0.0:9092
      - --advertise-kafka-addr
      - PLAINTEXT://redpanda-dev:9092
    # 외부 포트 노출 제거
    expose:
      - "9092"
      - "9644"
    networks:
      - default

  redis:
    image: redis:7-alpine
    expose:
      - "6379"
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  autonomous-crawler:
    build:
      context: ../../
      dockerfile: backend/autonomous-crawler-service/Dockerfile
    image: newsinsight/autonomous-crawler:local-preview
    restart: unless-stopped
    depends_on:
      consul:
        condition: service_healthy
      consul-seed:
        condition: service_completed_successfully
      redpanda-dev:
        condition: service_started
    environment:
      - CONSUL_HOST=${CONSUL_HOST:-consul}
      - CONSUL_PORT=${CONSUL_PORT:-8500}
      - CONSUL_HTTP_TOKEN=${CONSUL_HTTP_TOKEN:-}
      - CONSUL_ENABLED=${CONSUL_ENABLED:-true}
      - CONSUL_SERVICE_NAME=autonomous-crawler
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS:-redpanda-dev:9092}
      - KAFKA_CONSUMER_GROUP_ID=${CRAWLER_CONSUMER_GROUP:-autonomous-crawler-group}
      - KAFKA_BROWSER_TASK_TOPIC=${CRAWLER_TASK_TOPIC:-newsinsight.crawl.browser.tasks}
      - KAFKA_CRAWL_RESULT_TOPIC=${CRAWLER_RESULT_TOPIC:-newsinsight.crawl.results}
      - BROWSER_HEADLESS=${CRAWLER_HEADLESS:-true}
      - BROWSER_MAX_CONCURRENT_SESSIONS=${CRAWLER_MAX_SESSIONS:-2}
      - BROWSER_DEFAULT_TIMEOUT_SECONDS=${CRAWLER_TIMEOUT:-300}
      - LLM_PROVIDER=${CRAWLER_LLM_PROVIDER:-openai}
      - LLM_OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - LLM_OPENAI_MODEL=${CRAWLER_OPENAI_MODEL:-gpt-4o}
      - LLM_ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - LLM_ANTHROPIC_MODEL=${CRAWLER_ANTHROPIC_MODEL:-claude-3-5-sonnet-20241022}
      - SEARCH_BRAVE_API_KEY=${SEARCH_BRAVE_API_KEY:-}
      - SEARCH_TAVILY_API_KEY=${SEARCH_TAVILY_API_KEY:-}
      - SEARCH_PERPLEXITY_API_KEY=${SEARCH_PERPLEXITY_API_KEY:-}
      - STEALTH_ENABLED=${STEALTH_ENABLED:-true}
      - CAPTCHA_ENABLED=${CAPTCHA_ENABLED:-true}
      - METRICS_ENABLED=${CRAWLER_METRICS_ENABLED:-true}
      - METRICS_PORT=${CRAWLER_METRICS_PORT:-9090}
      - LOG_LEVEL=${CRAWLER_LOG_LEVEL:-INFO}
      - LOG_FORMAT=${CRAWLER_LOG_FORMAT:-json}
    # 외부 포트 노출 제거
    expose:
      - "9090"
    shm_size: 2g
    networks:
      - default

  browser-use-api:
    build:
      context: ../../backend/browser-use
      dockerfile: Dockerfile.api
    image: newsinsight/browser-use-api:local-preview
    restart: unless-stopped
    environment:
      - AIDOVE_WEBHOOK_URL=${AIDOVE_WEBHOOK_URL:-https://workflow.nodove.com/webhook/aidove}
      - BROWSER_HEADLESS=${BROWSER_USE_HEADLESS:-true}
      - SERVER_PORT=8500
      - LOG_LEVEL=${BROWSER_USE_LOG_LEVEL:-INFO}
    # 외부 포트 노출 제거
    expose:
      - "8500"
    shm_size: 2g
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8500/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - default

  # ML Add-ons - 감정 분석 (Sentiment Analysis)
  sentiment-addon:
    build:
      context: ../../backend/ml-addons/sentiment-addon
      dockerfile: Dockerfile
    image: newsinsight/sentiment-addon:local-preview
    restart: unless-stopped
    expose:
      - "8100"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8100/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - default

  # ML Add-ons - 팩트체크 (Fact Check)
  factcheck-addon:
    build:
      context: ../../backend/ml-addons/factcheck-addon
      dockerfile: Dockerfile
    image: newsinsight/factcheck-addon:local-preview
    restart: unless-stopped
    expose:
      - "8101"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8101/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - default

  # ML Add-ons - 편향도 분석 (Bias Analysis)
  bias-addon:
    build:
      context: ../../backend/ml-addons/bias-addon
      dockerfile: Dockerfile
    image: newsinsight/bias-addon:local-preview
    restart: unless-stopped
    expose:
      - "8102"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8102/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - default

volumes:
  postgres-data:
  redis-data:
  frontend-node-modules:
  mongo-data:

networks:
  default:
    name: newsinsight-zerotrust-preview-net

```

---

## etc/docker/docker-compose.zerotrust.yml

```yml
# Cloudflare Zero Trust Tunnel 기반 NewsInsight Stack
# newsinsight.nodove.com 으로만 접근 가능하도록 구성
#
# 사전 준비:
# 1. Cloudflare Dashboard에서 Zero Trust > Access > Tunnels 메뉴 진입
# 2. Create a tunnel 클릭 후 tunnel 이름 지정 (예: newsinsight-tunnel)
# 3. 생성된 tunnel token 복사
# 4. .env 파일에 CLOUDFLARE_TUNNEL_TOKEN=<your-token> 추가
# 5. Public hostname 설정:
#    - newsinsight.nodove.com -> http://frontend:8080
#    - newsinsight.nodove.com/api/* -> http://api-gateway:8000
#
# 실행: docker compose -f docker-compose.zerotrust.yml up -d

services:
  # Cloudflare Tunnel - 외부 트래픽을 내부 서비스로 라우팅
  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: newsinsight-cloudflared
    restart: unless-stopped
    command: tunnel run
    environment:
      - TUNNEL_TOKEN=${CLOUDFLARE_TUNNEL_TOKEN}
    depends_on:
      frontend:
        condition: service_started
      api-gateway:
        condition: service_started
    networks:
      - default
    # 외부 포트 노출 없음 - Cloudflare Tunnel을 통해서만 접근

  consul:
    image: hashicorp/consul:1.18
    command: ["agent", "-dev", "-client", "0.0.0.0", "-ui"]
    # 외부 포트 노출 제거 - 내부 네트워크에서만 접근 가능
    expose:
      - "8500"
    environment:
      - CONSUL_BIND_INTERFACE=eth0
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8500/v1/status/leader"]
      interval: 5s
      timeout: 3s
      retries: 20

  consul-seed:
    image: alpine:3.18
    depends_on:
      consul:
        condition: service_healthy
    volumes:
      - ../../etc/scripts:/scripts:ro
      - ../../etc/configs:/configs:ro
    environment:
      - CONSUL_HTTP_ADDR=http://consul:8500
      - CONSUL_HTTP_TOKEN=${CONSUL_HTTP_TOKEN:-}
    command: >
      sh -c "
        apk add --no-cache curl bash jq &&
        /scripts/consul_seed.sh ${ENVIRONMENT:-production}
      "
    restart: "no"

  api-gateway:
    build:
      context: ../../
      dockerfile: backend/api-gateway-service/Dockerfile
    image: newsinsight/api-gateway:local
    depends_on:
      consul:
        condition: service_healthy
      consul-seed:
        condition: service_completed_successfully
      collector-service:
        condition: service_started
      browser-use-api:
        condition: service_started
    environment:
      - CONSUL_HOST=${CONSUL_HOST:-consul}
      - CONSUL_PORT=${CONSUL_PORT:-8500}
      - CONSUL_HTTP_TOKEN=${CONSUL_HTTP_TOKEN:-}
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - PORT=${API_GATEWAY_PORT:-8000}
      - BROWSER_USE_URL=http://browser-use-api:8500
      - BROWSER_USE_WS_URL=ws://browser-use-api:8500
    # 외부 포트 노출 제거 - Cloudflare Tunnel을 통해서만 접근
    expose:
      - "8000"
    networks:
      - default

  frontend:
    image: node:20-alpine
    working_dir: /app
    volumes:
      - ../../frontend:/app
      - frontend-node-modules:/app/node_modules
    environment:
      # Zero Trust 환경: Vite 프록시를 통해 내부 api-gateway로 라우팅
      - VITE_API_BASE_URL=http://api-gateway:8000
      - VITE_BROWSER_USE_URL=http://api-gateway:8000
    command: >
      sh -c "(npm ci --legacy-peer-deps || npm install --legacy-peer-deps) \
      && npm run dev -- --host 0.0.0.0 --port 8080"
    # 외부 포트 노출 제거 - Cloudflare Tunnel을 통해서만 접근
    expose:
      - "8080"
    depends_on:
      api-gateway:
        condition: service_started
    networks:
      - default

  collector-service:
    build:
      context: ../../
      dockerfile: backend/data-collection-service/Dockerfile
    image: newsinsight/collector-service:local
    depends_on:
      consul:
        condition: service_healthy
      consul-seed:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
      mongo:
        condition: service_healthy
      web-crawler:
        condition: service_started
      redpanda-dev:
        condition: service_started
    environment:
      - CONSUL_HOST=${CONSUL_HOST:-consul}
      - CONSUL_PORT=${CONSUL_PORT:-8500}
      - CONSUL_ENABLED=${CONSUL_ENABLED:-true}
      - "SPRING_CONFIG_IMPORT=consul:"
      - SPRING_CLOUD_CONSUL_CONFIG_ENABLED=true
      - SPRING_CLOUD_CONSUL_CONFIG_PREFIX=config
      - SPRING_CLOUD_CONSUL_CONFIG_DEFAULT_CONTEXT=collector-service
      - SPRING_CLOUD_CONSUL_CONFIG_FORMAT=YAML
      - SPRING_CLOUD_CONSUL_CONFIG_FAIL_FAST=true
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - SPRING_DATA_REDIS_HOST=${REDIS_HOST:-redis}
      - SPRING_DATA_REDIS_PORT=${REDIS_PORT:-6379}
      - SPRING_JPA_HIBERNATE_DDL_AUTO=validate
      - PERPLEXITY_API_KEY=${PERPLEXITY_API_KEY:-}
      - PERPLEXITY_MODEL=${PERPLEXITY_MODEL:-sonar}
      - PERPLEXITY_BASE_URL=${PERPLEXITY_BASE_URL:-https://api.perplexity.ai}
      # AI Service URLs (can be overridden via Consul KV)
      - COLLECTOR_AIDOVE_BASE_URL=${COLLECTOR_SERVICE_AIDOVE_BASE_URL:-https://workflow.nodove.com/webhook/aidove}
      - COLLECTOR_CALLBACK_BASE_URL=${COLLECTOR_SERVICE_CALLBACK_BASE_URL:-http://collector-service:8081}
      # DeepSearch - uses IntegratedCrawlerService (n8n deprecated)
      - COLLECTOR_DEEP_SEARCH_ENABLED=false
      - COLLECTOR_DEEP_SEARCH_FALLBACK_TO_WEBHOOK=false
      - DB_HOST=${DB_HOST:-postgres}
      - DB_PORT=${DB_PORT:-5432}
      - DB_NAME=${DB_NAME:-newsinsight}
      - DB_USER=${DB_USER:-postgres}
      - DB_PASSWORD=${DB_PASSWORD:-postgres}
      - MONGODB_URI=${MONGODB_URI:-mongodb://mongo:27017/newsinsight}
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS:-redpanda-dev:9092}
      - SERVER_PORT=${COLLECTOR_PORT:-8081}
      - SPRING_CLOUD_INETUTILS_PREFERRED_NETWORKS=172.20
    expose:
      - "8081"
    networks:
      - default

  web-crawler:
    image: unclecode/crawl4ai:latest
    shm_size: 1g
    environment:
      - LOG_LEVEL=${WEB_CRAWLER_LOG_LEVEL:-INFO}
    # 외부 포트 노출 제거
    expose:
      - "11235"
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:11235/health"]
      interval: 10s
      timeout: 5s
      retries: 10

  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=${DB_NAME:-newsinsight}
      - POSTGRES_USER=${DB_USER:-postgres}
      - POSTGRES_PASSWORD=${DB_PASSWORD:-postgres}
    expose:
      - "5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./db-init:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 3s
      retries: 5

  mongo:
    image: mongo:7
    restart: unless-stopped
    environment:
      - MONGO_INITDB_DATABASE=${DB_NAME:-newsinsight}
    expose:
      - "27017"
    volumes:
      - mongo-data:/data/db
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5

  redpanda-dev:
    image: docker.redpanda.com/redpandadata/redpanda:latest
    command:
      - redpanda
      - start
      - --overprovisioned
      - --smp
      - "1"
      - --memory
      - 1G
      - --reserve-memory
      - 0M
      - --node-id
      - "0"
      - --check=false
      - --kafka-addr
      - PLAINTEXT://0.0.0.0:9092
      - --advertise-kafka-addr
      - PLAINTEXT://redpanda-dev:9092
    # 외부 포트 노출 제거
    expose:
      - "9092"
      - "9644"
    networks:
      - default

  redis:
    image: redis:7-alpine
    expose:
      - "6379"
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  autonomous-crawler:
    build:
      context: ../../
      dockerfile: backend/autonomous-crawler-service/Dockerfile
    image: newsinsight/autonomous-crawler:local
    restart: unless-stopped
    depends_on:
      consul:
        condition: service_healthy
      consul-seed:
        condition: service_completed_successfully
      redpanda-dev:
        condition: service_started
    environment:
      - CONSUL_HOST=${CONSUL_HOST:-consul}
      - CONSUL_PORT=${CONSUL_PORT:-8500}
      - CONSUL_HTTP_TOKEN=${CONSUL_HTTP_TOKEN:-}
      - CONSUL_ENABLED=${CONSUL_ENABLED:-true}
      - CONSUL_SERVICE_NAME=autonomous-crawler
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS:-redpanda-dev:9092}
      - KAFKA_CONSUMER_GROUP_ID=${CRAWLER_CONSUMER_GROUP:-autonomous-crawler-group}
      - KAFKA_BROWSER_TASK_TOPIC=${CRAWLER_TASK_TOPIC:-newsinsight.crawl.browser.tasks}
      - KAFKA_CRAWL_RESULT_TOPIC=${CRAWLER_RESULT_TOPIC:-newsinsight.crawl.results}
      - BROWSER_HEADLESS=${CRAWLER_HEADLESS:-true}
      - BROWSER_MAX_CONCURRENT_SESSIONS=${CRAWLER_MAX_SESSIONS:-2}
      - BROWSER_DEFAULT_TIMEOUT_SECONDS=${CRAWLER_TIMEOUT:-300}
      - LLM_PROVIDER=${CRAWLER_LLM_PROVIDER:-openai}
      - LLM_OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - LLM_OPENAI_MODEL=${CRAWLER_OPENAI_MODEL:-gpt-4o}
      - LLM_ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - LLM_ANTHROPIC_MODEL=${CRAWLER_ANTHROPIC_MODEL:-claude-3-5-sonnet-20241022}
      - SEARCH_BRAVE_API_KEY=${SEARCH_BRAVE_API_KEY:-}
      - SEARCH_TAVILY_API_KEY=${SEARCH_TAVILY_API_KEY:-}
      - SEARCH_PERPLEXITY_API_KEY=${SEARCH_PERPLEXITY_API_KEY:-}
      - STEALTH_ENABLED=${STEALTH_ENABLED:-true}
      - CAPTCHA_ENABLED=${CAPTCHA_ENABLED:-true}
      - METRICS_ENABLED=${CRAWLER_METRICS_ENABLED:-true}
      - METRICS_PORT=${CRAWLER_METRICS_PORT:-9090}
      - LOG_LEVEL=${CRAWLER_LOG_LEVEL:-INFO}
      - LOG_FORMAT=${CRAWLER_LOG_FORMAT:-json}
    # 외부 포트 노출 제거
    expose:
      - "9090"
    shm_size: 2g
    networks:
      - default

  browser-use-api:
    build:
      context: ../../backend/browser-use
      dockerfile: Dockerfile.api
    image: newsinsight/browser-use-api:local
    restart: unless-stopped
    environment:
      - AIDOVE_WEBHOOK_URL=${AIDOVE_WEBHOOK_URL:-https://workflow.nodove.com/webhook/aidove}
      - BROWSER_HEADLESS=${BROWSER_USE_HEADLESS:-true}
      - SERVER_PORT=8500
      - LOG_LEVEL=${BROWSER_USE_LOG_LEVEL:-INFO}
    # 외부 포트 노출 제거
    expose:
      - "8500"
    shm_size: 2g
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8500/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - default

volumes:
  postgres-data:
  redis-data:
  frontend-node-modules:
  mongo-data:

networks:
  default:
    name: newsinsight-zerotrust-net

```

---

## etc/k8s/keda/ai-agent-worker-scaledobject.yaml

```yaml
# ============================================================================
# KEDA ScaledObject - AI Agent Worker Service
# ============================================================================
# 
# Kafka 토픽의 메시지 lag을 기반으로 ai-agent-worker 파드를 자동 스케일링합니다.
# 
# 동작 방식:
#   - newsinsight.ai.requests 토픽의 consumer lag을 모니터링
#   - lag이 lagThreshold(5)를 초과하면 파드 수를 증가
#   - AI 처리는 비용이 높으므로 보수적으로 스케일링
#
# 적용:
#   kubectl apply -f ai-agent-worker-scaledobject.yaml
# ============================================================================

apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: ai-agent-worker-scaler
  namespace: newsinsight
  labels:
    app: ai-agent-worker
    component: scaler
spec:
  # 스케일 대상 Deployment
  scaleTargetRef:
    name: ai-agent-worker
    kind: Deployment
  
  # 스케일링 범위 (AI 비용 고려해서 보수적으로)
  minReplicaCount: 1    # 최소 1개 파드 유지
  maxReplicaCount: 3    # 최대 3개 파드 (비용 제한)
  
  # 스케일 다운 안정화
  advanced:
    horizontalPodAutoscalerConfig:
      behavior:
        scaleDown:
          stabilizationWindowSeconds: 600  # 10분간 안정화 후 스케일 다운
          policies:
            - type: Pods
              value: 1
              periodSeconds: 120  # 2분에 1개씩만 감소
        scaleUp:
          stabilizationWindowSeconds: 30   # 30초 후 스케일 업
          policies:
            - type: Pods
              value: 1
              periodSeconds: 60  # 1분에 1개씩 증가
  
  # 쿨다운 기간
  cooldownPeriod: 120
  
  # 폴링 간격
  pollingInterval: 30
  
  # 트리거 정의
  triggers:
    # Kafka Consumer Lag 기반 트리거
    - type: kafka
      metadata:
        bootstrapServers: redpanda.newsinsight.svc.cluster.local:9092
        consumerGroup: ai-agent-worker
        topic: newsinsight.ai.requests
        # AI 처리는 느리므로 낮은 임계값
        lagThreshold: "5"
        offsetResetPolicy: earliest

```

---

## etc/k8s/keda/autonomous-crawler-scaledobject.yaml

```yaml
# ============================================================================
# KEDA ScaledObject - Autonomous Crawler Service
# ============================================================================
# 
# Kafka 토픽의 메시지 lag을 기반으로 autonomous-crawler 파드를 자동 스케일링합니다.
# 
# 동작 방식:
#   - newsinsight.crawl.browser.tasks 토픽의 consumer lag을 모니터링
#   - lag이 lagThreshold(10)를 초과하면 파드 수를 증가
#   - lag이 0이면 minReplicaCount(1)로 스케일 다운
#   - 최대 maxReplicaCount(5)까지 스케일 업
#
# 적용:
#   kubectl apply -f autonomous-crawler-scaledobject.yaml
#
# 확인:
#   kubectl get scaledobject autonomous-crawler-scaler -n newsinsight
#   kubectl describe scaledobject autonomous-crawler-scaler -n newsinsight
#   kubectl get hpa -n newsinsight
# ============================================================================

apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: autonomous-crawler-scaler
  namespace: newsinsight
  labels:
    app: autonomous-crawler
    component: scaler
spec:
  # 스케일 대상 Deployment
  scaleTargetRef:
    name: autonomous-crawler
    kind: Deployment
  
  # 스케일링 범위
  minReplicaCount: 1    # 최소 1개 파드 유지 (0으로 설정하면 scale-to-zero 가능)
  maxReplicaCount: 5    # 최대 5개 파드
  
  # 스케일 다운 안정화 (급격한 스케일 다운 방지)
  advanced:
    horizontalPodAutoscalerConfig:
      behavior:
        scaleDown:
          stabilizationWindowSeconds: 300  # 5분간 안정화 후 스케일 다운
          policies:
            - type: Pods
              value: 1
              periodSeconds: 60  # 1분에 1개씩만 감소
        scaleUp:
          stabilizationWindowSeconds: 0    # 즉시 스케일 업
          policies:
            - type: Pods
              value: 2
              periodSeconds: 60  # 1분에 2개씩 증가 가능
  
  # 쿨다운 기간 (deprecated, behavior 사용 권장)
  cooldownPeriod: 60
  
  # 폴링 간격 (Kafka lag 확인 주기)
  pollingInterval: 15
  
  # 트리거 정의
  triggers:
    # Kafka Consumer Lag 기반 트리거
    - type: kafka
      metadata:
        # Kafka/Redpanda 부트스트랩 서버
        bootstrapServers: redpanda.newsinsight.svc.cluster.local:9092
        # Consumer Group ID (autonomous-crawler-service에서 사용하는 그룹)
        consumerGroup: autonomous-crawler-group
        # 모니터링할 토픽
        topic: newsinsight.crawl.browser.tasks
        # 스케일링 임계값 (파드당 처리해야 할 메시지 수)
        lagThreshold: "10"
        # offset reset policy
        offsetResetPolicy: earliest
        # 인증 (필요시)
        # sasl: plaintext
        # username: 
        # passwordFromEnv: KAFKA_PASSWORD
        
---
# TriggerAuthentication - Kafka 인증이 필요한 경우 사용
# apiVersion: keda.sh/v1alpha1
# kind: TriggerAuthentication
# metadata:
#   name: kafka-auth
#   namespace: newsinsight
# spec:
#   secretTargetRef:
#     - parameter: password
#       name: kafka-credentials
#       key: password

```

---

## etc/k8s/namespace.yaml

```yaml
# ============================================================================
# NewsInsight Kubernetes Namespace
# ============================================================================

apiVersion: v1
kind: Namespace
metadata:
  name: newsinsight
  labels:
    app.kubernetes.io/name: newsinsight
    app.kubernetes.io/part-of: newsinsight
  annotations:
    description: "NewsInsight AI 기반 뉴스 분석 플랫폼"

```

---

## frontend/components.json

```json
{
  "$schema": "https://ui.shadcn.com/schema.json",
  "style": "default",
  "rsc": false,
  "tsx": true,
  "tailwind": {
    "config": "tailwind.config.ts",
    "css": "src/index.css",
    "baseColor": "slate",
    "cssVariables": true,
    "prefix": ""
  },
  "aliases": {
    "components": "@/components",
    "utils": "@/lib/utils",
    "ui": "@/components/ui",
    "lib": "@/lib",
    "hooks": "@/hooks"
  }
}

```

---

## frontend/eslint.config.js

```js
import js from "@eslint/js";
import globals from "globals";
import reactHooks from "eslint-plugin-react-hooks";
import reactRefresh from "eslint-plugin-react-refresh";
import tseslint from "typescript-eslint";

export default tseslint.config(
  { ignores: ["dist"] },
  {
    extends: [js.configs.recommended, ...tseslint.configs.recommended],
    files: ["**/*.{ts,tsx}"],
    languageOptions: {
      ecmaVersion: 2020,
      globals: globals.browser,
    },
    plugins: {
      "react-hooks": reactHooks,
      "react-refresh": reactRefresh,
    },
    rules: {
      ...reactHooks.configs.recommended.rules,
      "react-refresh/only-export-components": ["warn", { allowConstantExport: true }],
      "@typescript-eslint/no-unused-vars": "off",
    },
  },
);

```

---

## frontend/index.html

```html
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>NewInsight - News Sentiment Analysis</title>
    <meta name="description" content="키워드 기반 NewInsight 및 인사이트 제공 플랫폼. 실시간 뉴스 데이터를 분석하여 긍정/부정 감성과 핵심 키워드를 시각화합니다." />
    <meta name="author" content="News Sentiment Analyzer" />

    <meta property="og:title" content="NewInsight - News Sentiment Analysis" />
    <meta property="og:description" content="키워드 기반 NewInsight 및 인사이트 제공 플랫폼" />
    <meta property="og:type" content="website" />

    <meta name="twitter:card" content="summary_large_image" />
  </head>

  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.tsx"></script>
  </body>
</html>

```

---

## frontend/package-lock.json

```json
{
  "name": "vite_react_shadcn_ts",
  "version": "0.0.0",
  "lockfileVersion": 3,
  "requires": true,
  "packages": {
    "": {
      "name": "vite_react_shadcn_ts",
      "version": "0.0.0",
      "dependencies": {
        "@hookform/resolvers": "^3.10.0",
        "@radix-ui/react-accordion": "^1.2.11",
        "@radix-ui/react-alert-dialog": "^1.1.14",
        "@radix-ui/react-aspect-ratio": "^1.1.7",
        "@radix-ui/react-avatar": "^1.1.10",
        "@radix-ui/react-checkbox": "^1.3.2",
        "@radix-ui/react-collapsible": "^1.1.11",
        "@radix-ui/react-context-menu": "^2.2.15",
        "@radix-ui/react-dialog": "^1.1.14",
        "@radix-ui/react-dropdown-menu": "^2.1.15",
        "@radix-ui/react-hover-card": "^1.1.14",
        "@radix-ui/react-label": "^2.1.7",
        "@radix-ui/react-menubar": "^1.1.15",
        "@radix-ui/react-navigation-menu": "^1.2.13",
        "@radix-ui/react-popover": "^1.1.14",
        "@radix-ui/react-progress": "^1.1.7",
        "@radix-ui/react-radio-group": "^1.3.7",
        "@radix-ui/react-scroll-area": "^1.2.9",
        "@radix-ui/react-select": "^2.2.5",
        "@radix-ui/react-separator": "^1.1.7",
        "@radix-ui/react-slider": "^1.3.5",
        "@radix-ui/react-slot": "^1.2.3",
        "@radix-ui/react-switch": "^1.2.5",
        "@radix-ui/react-tabs": "^1.1.12",
        "@radix-ui/react-toast": "^1.2.14",
        "@radix-ui/react-toggle": "^1.1.9",
        "@radix-ui/react-toggle-group": "^1.1.10",
        "@radix-ui/react-tooltip": "^1.2.7",
        "@tanstack/react-query": "^5.83.0",
        "axios": "^1.13.2",
        "chart.js": "^4.5.1",
        "class-variance-authority": "^0.7.1",
        "clsx": "^2.1.1",
        "cmdk": "^1.1.1",
        "d3-cloud": "^1.2.7",
        "date-fns": "^3.6.0",
        "embla-carousel-react": "^8.6.0",
        "input-otp": "^1.4.2",
        "lucide-react": "^0.462.0",
        "next-themes": "^0.3.0",
        "react": "^18.3.1",
        "react-chartjs-2": "^5.3.1",
        "react-day-picker": "^8.10.1",
        "react-dom": "^18.3.1",
        "react-hook-form": "^7.61.1",
        "react-markdown": "^9.0.1",
        "react-resizable-panels": "^2.1.9",
        "react-router-dom": "^6.30.1",
        "react-wordcloud": "^1.2.7",
        "recharts": "^2.15.4",
        "remark-gfm": "^4.0.0",
        "sonner": "^1.7.4",
        "tailwind-merge": "^2.6.0",
        "tailwindcss-animate": "^1.0.7",
        "vaul": "^0.9.9",
        "zod": "^3.25.76"
      },
      "devDependencies": {
        "@eslint/js": "^9.32.0",
        "@playwright/test": "^1.40.0",
        "@tailwindcss/typography": "^0.5.16",
        "@types/node": "^22.16.5",
        "@types/react": "^18.3.23",
        "@types/react-dom": "^18.3.7",
        "@vitejs/plugin-react-swc": "^3.11.0",
        "autoprefixer": "^10.4.21",
        "eslint": "^9.32.0",
        "eslint-plugin-react-hooks": "^5.2.0",
        "eslint-plugin-react-refresh": "^0.4.20",
        "globals": "^15.15.0",
        "postcss": "^8.5.6",
        "tailwindcss": "^3.4.17",
        "typescript": "^5.8.3",
        "typescript-eslint": "^8.38.0",
        "vite": "^5.4.19"
      }
    },
    "node_modules/@alloc/quick-lru": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/@alloc/quick-lru/-/quick-lru-5.2.0.tgz",
      "integrity": "sha512-UrcABB+4bUrFABwbluTIBErXwvbsU/V7TZWfmbgJfbkwiBuziS9gxdODUyuiecfdGQ85jglMW6juS3+z5TsKLw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/@babel/runtime": {
      "version": "7.28.2",
      "resolved": "https://registry.npmjs.org/@babel/runtime/-/runtime-7.28.2.tgz",
      "integrity": "sha512-KHp2IflsnGywDjBWDkR9iEqiWSpc8GIi0lgTT3mOElT0PP1tG26P4tmFI2YvAdzgq9RGyoHZQEIEdZy6Ec5xCA==",
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@esbuild/aix-ppc64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/aix-ppc64/-/aix-ppc64-0.21.5.tgz",
      "integrity": "sha512-1SDgH6ZSPTlggy1yI6+Dbkiz8xzpHJEVAlF/AM1tHPLsf5STom9rwtjE4hKAF20FfXXNTFqEYXyJNWh1GiZedQ==",
      "cpu": [
        "ppc64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "aix"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/android-arm": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/android-arm/-/android-arm-0.21.5.tgz",
      "integrity": "sha512-vCPvzSjpPHEi1siZdlvAlsPxXl7WbOVUBBAowWug4rJHb68Ox8KualB+1ocNvT5fjv6wpkX6o/iEpbDrf68zcg==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/android-arm64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/android-arm64/-/android-arm64-0.21.5.tgz",
      "integrity": "sha512-c0uX9VAUBQ7dTDCjq+wdyGLowMdtR/GoC2U5IYk/7D1H1JYC0qseD7+11iMP2mRLN9RcCMRcjC4YMclCzGwS/A==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/android-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/android-x64/-/android-x64-0.21.5.tgz",
      "integrity": "sha512-D7aPRUUNHRBwHxzxRvp856rjUHRFW1SdQATKXH2hqA0kAZb1hKmi02OpYRacl0TxIGz/ZmXWlbZgjwWYaCakTA==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/darwin-arm64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/darwin-arm64/-/darwin-arm64-0.21.5.tgz",
      "integrity": "sha512-DwqXqZyuk5AiWWf3UfLiRDJ5EDd49zg6O9wclZ7kUMv2WRFr4HKjXp/5t8JZ11QbQfUS6/cRCKGwYhtNAY88kQ==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/darwin-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/darwin-x64/-/darwin-x64-0.21.5.tgz",
      "integrity": "sha512-se/JjF8NlmKVG4kNIuyWMV/22ZaerB+qaSi5MdrXtd6R08kvs2qCN4C09miupktDitvh8jRFflwGFBQcxZRjbw==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/freebsd-arm64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/freebsd-arm64/-/freebsd-arm64-0.21.5.tgz",
      "integrity": "sha512-5JcRxxRDUJLX8JXp/wcBCy3pENnCgBR9bN6JsY4OmhfUtIHe3ZW0mawA7+RDAcMLrMIZaf03NlQiX9DGyB8h4g==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/freebsd-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/freebsd-x64/-/freebsd-x64-0.21.5.tgz",
      "integrity": "sha512-J95kNBj1zkbMXtHVH29bBriQygMXqoVQOQYA+ISs0/2l3T9/kj42ow2mpqerRBxDJnmkUDCaQT/dfNXWX/ZZCQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-arm": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-arm/-/linux-arm-0.21.5.tgz",
      "integrity": "sha512-bPb5AHZtbeNGjCKVZ9UGqGwo8EUu4cLq68E95A53KlxAPRmUyYv2D6F0uUI65XisGOL1hBP5mTronbgo+0bFcA==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-arm64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-arm64/-/linux-arm64-0.21.5.tgz",
      "integrity": "sha512-ibKvmyYzKsBeX8d8I7MH/TMfWDXBF3db4qM6sy+7re0YXya+K1cem3on9XgdT2EQGMu4hQyZhan7TeQ8XkGp4Q==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-ia32": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-ia32/-/linux-ia32-0.21.5.tgz",
      "integrity": "sha512-YvjXDqLRqPDl2dvRODYmmhz4rPeVKYvppfGYKSNGdyZkA01046pLWyRKKI3ax8fbJoK5QbxblURkwK/MWY18Tg==",
      "cpu": [
        "ia32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-loong64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-loong64/-/linux-loong64-0.21.5.tgz",
      "integrity": "sha512-uHf1BmMG8qEvzdrzAqg2SIG/02+4/DHB6a9Kbya0XDvwDEKCoC8ZRWI5JJvNdUjtciBGFQ5PuBlpEOXQj+JQSg==",
      "cpu": [
        "loong64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-mips64el": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-mips64el/-/linux-mips64el-0.21.5.tgz",
      "integrity": "sha512-IajOmO+KJK23bj52dFSNCMsz1QP1DqM6cwLUv3W1QwyxkyIWecfafnI555fvSGqEKwjMXVLokcV5ygHW5b3Jbg==",
      "cpu": [
        "mips64el"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-ppc64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-ppc64/-/linux-ppc64-0.21.5.tgz",
      "integrity": "sha512-1hHV/Z4OEfMwpLO8rp7CvlhBDnjsC3CttJXIhBi+5Aj5r+MBvy4egg7wCbe//hSsT+RvDAG7s81tAvpL2XAE4w==",
      "cpu": [
        "ppc64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-riscv64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-riscv64/-/linux-riscv64-0.21.5.tgz",
      "integrity": "sha512-2HdXDMd9GMgTGrPWnJzP2ALSokE/0O5HhTUvWIbD3YdjME8JwvSCnNGBnTThKGEB91OZhzrJ4qIIxk/SBmyDDA==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-s390x": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-s390x/-/linux-s390x-0.21.5.tgz",
      "integrity": "sha512-zus5sxzqBJD3eXxwvjN1yQkRepANgxE9lgOW2qLnmr8ikMTphkjgXu1HR01K4FJg8h1kEEDAqDcZQtbrRnB41A==",
      "cpu": [
        "s390x"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-x64/-/linux-x64-0.21.5.tgz",
      "integrity": "sha512-1rYdTpyv03iycF1+BhzrzQJCdOuAOtaqHTWJZCWvijKD2N5Xu0TtVC8/+1faWqcP9iBCWOmjmhoH94dH82BxPQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/netbsd-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/netbsd-x64/-/netbsd-x64-0.21.5.tgz",
      "integrity": "sha512-Woi2MXzXjMULccIwMnLciyZH4nCIMpWQAs049KEeMvOcNADVxo0UBIQPfSmxB3CWKedngg7sWZdLvLczpe0tLg==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "netbsd"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/openbsd-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/openbsd-x64/-/openbsd-x64-0.21.5.tgz",
      "integrity": "sha512-HLNNw99xsvx12lFBUwoT8EVCsSvRNDVxNpjZ7bPn947b8gJPzeHWyNVhFsaerc0n3TsbOINvRP2byTZ5LKezow==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "openbsd"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/sunos-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/sunos-x64/-/sunos-x64-0.21.5.tgz",
      "integrity": "sha512-6+gjmFpfy0BHU5Tpptkuh8+uw3mnrvgs+dSPQXQOv3ekbordwnzTVEb4qnIvQcYXq6gzkyTnoZ9dZG+D4garKg==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "sunos"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/win32-arm64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/win32-arm64/-/win32-arm64-0.21.5.tgz",
      "integrity": "sha512-Z0gOTd75VvXqyq7nsl93zwahcTROgqvuAcYDUr+vOv8uHhNSKROyU961kgtCD1e95IqPKSQKH7tBTslnS3tA8A==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/win32-ia32": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/win32-ia32/-/win32-ia32-0.21.5.tgz",
      "integrity": "sha512-SWXFF1CL2RVNMaVs+BBClwtfZSvDgtL//G/smwAc5oVK/UPu2Gu9tIaRgFmYFFKrmg3SyAjSrElf0TiJ1v8fYA==",
      "cpu": [
        "ia32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/win32-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/win32-x64/-/win32-x64-0.21.5.tgz",
      "integrity": "sha512-tQd/1efJuzPC6rCFwEvLtci/xNFcTZknmXs98FYDfGE4wP9ClFV98nyKrzJKVPMhdDnjzLhdUyMX4PsQAPjwIw==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@eslint-community/eslint-utils": {
      "version": "4.7.0",
      "resolved": "https://registry.npmjs.org/@eslint-community/eslint-utils/-/eslint-utils-4.7.0.tgz",
      "integrity": "sha512-dyybb3AcajC7uha6CvhdVRJqaKyn7w2YKqKyAN37NKYgZT36w+iRb0Dymmc5qEJ549c/S31cMMSFd75bteCpCw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "eslint-visitor-keys": "^3.4.3"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      },
      "peerDependencies": {
        "eslint": "^6.0.0 || ^7.0.0 || >=8.0.0"
      }
    },
    "node_modules/@eslint-community/eslint-utils/node_modules/eslint-visitor-keys": {
      "version": "3.4.3",
      "resolved": "https://registry.npmjs.org/eslint-visitor-keys/-/eslint-visitor-keys-3.4.3.tgz",
      "integrity": "sha512-wpc+LXeiyiisxPlEkUzU6svyS1frIO3Mgxj1fdy7Pm8Ygzguax2N3Fa/D/ag1WqbOprdI+uY6wMUl8/a2G+iag==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/@eslint-community/regexpp": {
      "version": "4.12.1",
      "resolved": "https://registry.npmjs.org/@eslint-community/regexpp/-/regexpp-4.12.1.tgz",
      "integrity": "sha512-CCZCDJuduB9OUkFkY2IgppNZMi2lBQgD2qzwXkEia16cge2pijY/aXi96CJMquDMn3nJdlPV1A5KrJEXwfLNzQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^12.0.0 || ^14.0.0 || >=16.0.0"
      }
    },
    "node_modules/@eslint/config-array": {
      "version": "0.21.0",
      "resolved": "https://registry.npmjs.org/@eslint/config-array/-/config-array-0.21.0.tgz",
      "integrity": "sha512-ENIdc4iLu0d93HeYirvKmrzshzofPw6VkZRKQGe9Nv46ZnWUzcF1xV01dcvEg/1wXUR61OmmlSfyeyO7EvjLxQ==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "@eslint/object-schema": "^2.1.6",
        "debug": "^4.3.1",
        "minimatch": "^3.1.2"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      }
    },
    "node_modules/@eslint/config-helpers": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/@eslint/config-helpers/-/config-helpers-0.3.0.tgz",
      "integrity": "sha512-ViuymvFmcJi04qdZeDc2whTHryouGcDlaxPqarTD0ZE10ISpxGUVZGZDx4w01upyIynL3iu6IXH2bS1NhclQMw==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      }
    },
    "node_modules/@eslint/core": {
      "version": "0.15.1",
      "resolved": "https://registry.npmjs.org/@eslint/core/-/core-0.15.1.tgz",
      "integrity": "sha512-bkOp+iumZCCbt1K1CmWf0R9pM5yKpDv+ZXtvSyQpudrI9kuFLp+bM2WOPXImuD/ceQuaa8f5pj93Y7zyECIGNA==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "@types/json-schema": "^7.0.15"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      }
    },
    "node_modules/@eslint/eslintrc": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/@eslint/eslintrc/-/eslintrc-3.3.1.tgz",
      "integrity": "sha512-gtF186CXhIl1p4pJNGZw8Yc6RlshoePRvE0X91oPGb3vZ8pM3qOS9W9NGPat9LziaBV7XrJWGylNQXkGcnM3IQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ajv": "^6.12.4",
        "debug": "^4.3.2",
        "espree": "^10.0.1",
        "globals": "^14.0.0",
        "ignore": "^5.2.0",
        "import-fresh": "^3.2.1",
        "js-yaml": "^4.1.0",
        "minimatch": "^3.1.2",
        "strip-json-comments": "^3.1.1"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/@eslint/eslintrc/node_modules/globals": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/globals/-/globals-14.0.0.tgz",
      "integrity": "sha512-oahGvuMGQlPw/ivIYBjVSrWAfWLBeku5tpPE2fOPLi+WHffIWbuh2tCjhyQhTBPMf5E9jDEH4FOmTYgYwbKwtQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=18"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/@eslint/js": {
      "version": "9.32.0",
      "resolved": "https://registry.npmjs.org/@eslint/js/-/js-9.32.0.tgz",
      "integrity": "sha512-BBpRFZK3eX6uMLKz8WxFOBIFFcGFJ/g8XuwjTHCqHROSIsopI+ddn/d5Cfh36+7+e5edVS8dbSHnBNhrLEX0zg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "url": "https://eslint.org/donate"
      }
    },
    "node_modules/@eslint/object-schema": {
      "version": "2.1.6",
      "resolved": "https://registry.npmjs.org/@eslint/object-schema/-/object-schema-2.1.6.tgz",
      "integrity": "sha512-RBMg5FRL0I0gs51M/guSAj5/e14VQ4tpZnQNWwuDT66P14I43ItmPfIZRhO9fUVIPOAQXU47atlywZ/czoqFPA==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      }
    },
    "node_modules/@eslint/plugin-kit": {
      "version": "0.3.4",
      "resolved": "https://registry.npmjs.org/@eslint/plugin-kit/-/plugin-kit-0.3.4.tgz",
      "integrity": "sha512-Ul5l+lHEcw3L5+k8POx6r74mxEYKG5kOb6Xpy2gCRW6zweT6TEhAf8vhxGgjhqrd/VO/Dirhsb+1hNpD1ue9hw==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "@eslint/core": "^0.15.1",
        "levn": "^0.4.1"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      }
    },
    "node_modules/@floating-ui/core": {
      "version": "1.7.2",
      "resolved": "https://registry.npmjs.org/@floating-ui/core/-/core-1.7.2.tgz",
      "integrity": "sha512-wNB5ooIKHQc+Kui96jE/n69rHFWAVoxn5CAzL1Xdd8FG03cgY3MLO+GF9U3W737fYDSgPWA6MReKhBQBop6Pcw==",
      "license": "MIT",
      "dependencies": {
        "@floating-ui/utils": "^0.2.10"
      }
    },
    "node_modules/@floating-ui/dom": {
      "version": "1.7.2",
      "resolved": "https://registry.npmjs.org/@floating-ui/dom/-/dom-1.7.2.tgz",
      "integrity": "sha512-7cfaOQuCS27HD7DX+6ib2OrnW+b4ZBwDNnCcT0uTyidcmyWb03FnQqJybDBoCnpdxwBSfA94UAYlRCt7mV+TbA==",
      "license": "MIT",
      "dependencies": {
        "@floating-ui/core": "^1.7.2",
        "@floating-ui/utils": "^0.2.10"
      }
    },
    "node_modules/@floating-ui/react-dom": {
      "version": "2.1.4",
      "resolved": "https://registry.npmjs.org/@floating-ui/react-dom/-/react-dom-2.1.4.tgz",
      "integrity": "sha512-JbbpPhp38UmXDDAu60RJmbeme37Jbgsm7NrHGgzYYFKmblzRUh6Pa641dII6LsjwF4XlScDrde2UAzDo/b9KPw==",
      "license": "MIT",
      "dependencies": {
        "@floating-ui/dom": "^1.7.2"
      },
      "peerDependencies": {
        "react": ">=16.8.0",
        "react-dom": ">=16.8.0"
      }
    },
    "node_modules/@floating-ui/utils": {
      "version": "0.2.10",
      "resolved": "https://registry.npmjs.org/@floating-ui/utils/-/utils-0.2.10.tgz",
      "integrity": "sha512-aGTxbpbg8/b5JfU1HXSrbH3wXZuLPJcNEcZQFMxLs3oSzgtVu6nFPkbbGGUvBcUjKV2YyB9Wxxabo+HEH9tcRQ==",
      "license": "MIT"
    },
    "node_modules/@hookform/resolvers": {
      "version": "3.10.0",
      "resolved": "https://registry.npmjs.org/@hookform/resolvers/-/resolvers-3.10.0.tgz",
      "integrity": "sha512-79Dv+3mDF7i+2ajj7SkypSKHhl1cbln1OGavqrsF7p6mbUv11xpqpacPsGDCTRvCSjEEIez2ef1NveSVL3b0Ag==",
      "license": "MIT",
      "peerDependencies": {
        "react-hook-form": "^7.0.0"
      }
    },
    "node_modules/@humanfs/core": {
      "version": "0.19.1",
      "resolved": "https://registry.npmjs.org/@humanfs/core/-/core-0.19.1.tgz",
      "integrity": "sha512-5DyQ4+1JEUzejeK1JGICcideyfUbGixgS9jNgex5nqkW+cY7WZhxBigmieN5Qnw9ZosSNVC9KQKyb+GUaGyKUA==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">=18.18.0"
      }
    },
    "node_modules/@humanfs/node": {
      "version": "0.16.6",
      "resolved": "https://registry.npmjs.org/@humanfs/node/-/node-0.16.6.tgz",
      "integrity": "sha512-YuI2ZHQL78Q5HbhDiBA1X4LmYdXCKCMQIfw0pw7piHJwyREFebJUvrQN4cMssyES6x+vfUbx1CIpaQUKYdQZOw==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "@humanfs/core": "^0.19.1",
        "@humanwhocodes/retry": "^0.3.0"
      },
      "engines": {
        "node": ">=18.18.0"
      }
    },
    "node_modules/@humanfs/node/node_modules/@humanwhocodes/retry": {
      "version": "0.3.1",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/retry/-/retry-0.3.1.tgz",
      "integrity": "sha512-JBxkERygn7Bv/GbN5Rv8Ul6LVknS+5Bp6RgDC/O8gEBU/yeH5Ui5C/OlWrTb6qct7LjjfT6Re2NxB0ln0yYybA==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">=18.18"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/nzakas"
      }
    },
    "node_modules/@humanwhocodes/module-importer": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/module-importer/-/module-importer-1.0.1.tgz",
      "integrity": "sha512-bxveV4V8v5Yb4ncFTT3rPSgZBOpCkjfK0y4oVVVJwIuDVBRMDXrPyXRL988i5ap9m9bnyEEjWfm5WkBmtffLfA==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">=12.22"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/nzakas"
      }
    },
    "node_modules/@humanwhocodes/retry": {
      "version": "0.4.3",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/retry/-/retry-0.4.3.tgz",
      "integrity": "sha512-bV0Tgo9K4hfPCek+aMAn81RppFKv2ySDQeMoSZuvTASywNTnVJCArCZE2FWqpvIatKu7VMRLWlR1EazvVhDyhQ==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">=18.18"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/nzakas"
      }
    },
    "node_modules/@isaacs/cliui": {
      "version": "8.0.2",
      "resolved": "https://registry.npmjs.org/@isaacs/cliui/-/cliui-8.0.2.tgz",
      "integrity": "sha512-O8jcjabXaleOG9DQ0+ARXWZBTfnP4WNAqzuiJK7ll44AmxGKv/J2M4TPjxjY3znBCfvBXFzucm1twdyFybFqEA==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "string-width": "^5.1.2",
        "string-width-cjs": "npm:string-width@^4.2.0",
        "strip-ansi": "^7.0.1",
        "strip-ansi-cjs": "npm:strip-ansi@^6.0.1",
        "wrap-ansi": "^8.1.0",
        "wrap-ansi-cjs": "npm:wrap-ansi@^7.0.0"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@jridgewell/gen-mapping": {
      "version": "0.3.5",
      "resolved": "https://registry.npmjs.org/@jridgewell/gen-mapping/-/gen-mapping-0.3.5.tgz",
      "integrity": "sha512-IzL8ZoEDIBRWEzlCcRhOaCupYyN5gdIK+Q6fbFdPDg6HqX6jpkItn7DFIpW9LQzXG6Df9sA7+OKnq0qlz/GaQg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/set-array": "^1.2.1",
        "@jridgewell/sourcemap-codec": "^1.4.10",
        "@jridgewell/trace-mapping": "^0.3.24"
      },
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@jridgewell/resolve-uri": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/@jridgewell/resolve-uri/-/resolve-uri-3.1.2.tgz",
      "integrity": "sha512-bRISgCIjP20/tbWSPWMEi54QVPRZExkuD9lJL+UIxUKtwVJA8wW1Trb1jMs1RFXo1CBTNZ/5hpC9QvmKWdopKw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@jridgewell/set-array": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/@jridgewell/set-array/-/set-array-1.2.1.tgz",
      "integrity": "sha512-R8gLRTZeyp03ymzP/6Lil/28tGeGEzhx1q2k703KGWRAI1VdvPIXdG70VJc2pAMw3NA6JKL5hhFu1sJX0Mnn/A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@jridgewell/sourcemap-codec": {
      "version": "1.5.0",
      "resolved": "https://registry.npmjs.org/@jridgewell/sourcemap-codec/-/sourcemap-codec-1.5.0.tgz",
      "integrity": "sha512-gv3ZRaISU3fjPAgNsriBRqGWQL6quFx04YMPW/zD8XMLsU32mhCCbfbO6KZFLjvYpCZ8zyDEgqsgf+PwPaM7GQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@jridgewell/trace-mapping": {
      "version": "0.3.25",
      "resolved": "https://registry.npmjs.org/@jridgewell/trace-mapping/-/trace-mapping-0.3.25.tgz",
      "integrity": "sha512-vNk6aEwybGtawWmy/PzwnGDOjCkLWSD2wqvjGGAgOAwCGWySYXfYoxt00IJkTF+8Lb57DwOb3Aa0o9CApepiYQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/resolve-uri": "^3.1.0",
        "@jridgewell/sourcemap-codec": "^1.4.14"
      }
    },
    "node_modules/@kurkle/color": {
      "version": "0.3.4",
      "resolved": "https://registry.npmjs.org/@kurkle/color/-/color-0.3.4.tgz",
      "integrity": "sha512-M5UknZPHRu3DEDWoipU6sE8PdkZ6Z/S+v4dD+Ke8IaNlpdSQah50lz1KtcFBa2vsdOnwbbnxJwVM4wty6udA5w==",
      "license": "MIT"
    },
    "node_modules/@nodelib/fs.scandir": {
      "version": "2.1.5",
      "resolved": "https://registry.npmjs.org/@nodelib/fs.scandir/-/fs.scandir-2.1.5.tgz",
      "integrity": "sha512-vq24Bq3ym5HEQm2NKCr3yXDwjc7vTsEThRDnkp2DK9p1uqLR+DHurm/NOTo0KG7HYHU7eppKZj3MyqYuMBf62g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@nodelib/fs.stat": "2.0.5",
        "run-parallel": "^1.1.9"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/@nodelib/fs.stat": {
      "version": "2.0.5",
      "resolved": "https://registry.npmjs.org/@nodelib/fs.stat/-/fs.stat-2.0.5.tgz",
      "integrity": "sha512-RkhPPp2zrqDAQA/2jNhnztcPAlv64XdhIp7a7454A5ovI7Bukxgt7MX7udwAu3zg1DcpPU0rz3VV1SeaqvY4+A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/@nodelib/fs.walk": {
      "version": "1.2.8",
      "resolved": "https://registry.npmjs.org/@nodelib/fs.walk/-/fs.walk-1.2.8.tgz",
      "integrity": "sha512-oGB+UxlgWcgQkgwo8GcEGwemoTFt3FIO9ababBmaGwXIoBKZ+GTy0pP185beGg7Llih/NSHSV2XAs1lnznocSg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@nodelib/fs.scandir": "2.1.5",
        "fastq": "^1.6.0"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/@pkgjs/parseargs": {
      "version": "0.11.0",
      "resolved": "https://registry.npmjs.org/@pkgjs/parseargs/-/parseargs-0.11.0.tgz",
      "integrity": "sha512-+1VkjdD0QBLPodGrJUeqarH8VAIvQODIbwh9XpP5Syisf7YoQgsJKPNFoqqLQlu+VQ/tVSshMR6loPMn8U+dPg==",
      "dev": true,
      "license": "MIT",
      "optional": true,
      "engines": {
        "node": ">=14"
      }
    },
    "node_modules/@playwright/test": {
      "version": "1.57.0",
      "resolved": "https://registry.npmjs.org/@playwright/test/-/test-1.57.0.tgz",
      "integrity": "sha512-6TyEnHgd6SArQO8UO2OMTxshln3QMWBtPGrOCgs3wVEmQmwyuNtB10IZMfmYDE0riwNR1cu4q+pPcxMVtaG3TA==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "playwright": "1.57.0"
      },
      "bin": {
        "playwright": "cli.js"
      },
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@popperjs/core": {
      "version": "2.11.8",
      "resolved": "https://registry.npmjs.org/@popperjs/core/-/core-2.11.8.tgz",
      "integrity": "sha512-P1st0aksCrn9sGZhp8GMYwBnQsbvAWsZAX44oXNNvLHGqAOcoVxmjZiohstwQ7SqKnbR47akdNi+uleWD8+g6A==",
      "license": "MIT",
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/popperjs"
      }
    },
    "node_modules/@radix-ui/number": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/@radix-ui/number/-/number-1.1.1.tgz",
      "integrity": "sha512-MkKCwxlXTgz6CFoJx3pCwn07GKp36+aZyu/u2Ln2VrA5DcdyCZkASEDBTd8x5whTQQL5CiYf4prXKLcgQdv29g==",
      "license": "MIT"
    },
    "node_modules/@radix-ui/primitive": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/@radix-ui/primitive/-/primitive-1.1.2.tgz",
      "integrity": "sha512-XnbHrrprsNqZKQhStrSwgRUQzoCI1glLzdw79xiZPoofhGICeZRSQ3dIxAKH1gb3OHfNf4d6f+vAv3kil2eggA==",
      "license": "MIT"
    },
    "node_modules/@radix-ui/react-accordion": {
      "version": "1.2.11",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-accordion/-/react-accordion-1.2.11.tgz",
      "integrity": "sha512-l3W5D54emV2ues7jjeG1xcyN7S3jnK3zE2zHqgn0CmMsy9lNJwmgcrmaxS+7ipw15FAivzKNzH3d5EcGoFKw0A==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-collapsible": "1.1.11",
        "@radix-ui/react-collection": "1.1.7",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-direction": "1.1.1",
        "@radix-ui/react-id": "1.1.1",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-use-controllable-state": "1.2.2"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-alert-dialog": {
      "version": "1.1.14",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-alert-dialog/-/react-alert-dialog-1.1.14.tgz",
      "integrity": "sha512-IOZfZ3nPvN6lXpJTBCunFQPRSvK8MDgSc1FB85xnIpUKOw9en0dJj8JmCAxV7BiZdtYlUpmrQjoTFkVYtdoWzQ==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-dialog": "1.1.14",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-slot": "1.2.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-arrow": {
      "version": "1.1.7",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-arrow/-/react-arrow-1.1.7.tgz",
      "integrity": "sha512-F+M1tLhO+mlQaOWspE8Wstg+z6PwxwRd8oQ8IXceWz92kfAmalTRf0EjrouQeo7QssEPfCn05B4Ihs1K9WQ/7w==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-primitive": "2.1.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-aspect-ratio": {
      "version": "1.1.7",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-aspect-ratio/-/react-aspect-ratio-1.1.7.tgz",
      "integrity": "sha512-Yq6lvO9HQyPwev1onK1daHCHqXVLzPhSVjmsNjCa2Zcxy2f7uJD2itDtxknv6FzAKCwD1qQkeVDmX/cev13n/g==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-primitive": "2.1.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-avatar": {
      "version": "1.1.10",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-avatar/-/react-avatar-1.1.10.tgz",
      "integrity": "sha512-V8piFfWapM5OmNCXTzVQY+E1rDa53zY+MQ4Y7356v4fFz6vqCyUtIz2rUD44ZEdwg78/jKmMJHj07+C/Z/rcog==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-use-callback-ref": "1.1.1",
        "@radix-ui/react-use-is-hydrated": "0.1.0",
        "@radix-ui/react-use-layout-effect": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-checkbox": {
      "version": "1.3.2",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-checkbox/-/react-checkbox-1.3.2.tgz",
      "integrity": "sha512-yd+dI56KZqawxKZrJ31eENUwqc1QSqg4OZ15rybGjF2ZNwMO+wCyHzAVLRp9qoYJf7kYy0YpZ2b0JCzJ42HZpA==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-presence": "1.1.4",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-use-controllable-state": "1.2.2",
        "@radix-ui/react-use-previous": "1.1.1",
        "@radix-ui/react-use-size": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-collapsible": {
      "version": "1.1.11",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-collapsible/-/react-collapsible-1.1.11.tgz",
      "integrity": "sha512-2qrRsVGSCYasSz1RFOorXwl0H7g7J1frQtgpQgYrt+MOidtPAINHn9CPovQXb83r8ahapdx3Tu0fa/pdFFSdPg==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-id": "1.1.1",
        "@radix-ui/react-presence": "1.1.4",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-use-controllable-state": "1.2.2",
        "@radix-ui/react-use-layout-effect": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-collection": {
      "version": "1.1.7",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-collection/-/react-collection-1.1.7.tgz",
      "integrity": "sha512-Fh9rGN0MoI4ZFUNyfFVNU4y9LUz93u9/0K+yLgA2bwRojxM8JU1DyvvMBabnZPBgMWREAJvU2jjVzq+LrFUglw==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-slot": "1.2.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-compose-refs": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-compose-refs/-/react-compose-refs-1.1.2.tgz",
      "integrity": "sha512-z4eqJvfiNnFMHIIvXP3CY57y2WJs5g2v3X0zm9mEJkrkNv4rDxu+sg9Jh8EkXyeqBkB7SOcboo9dMVqhyrACIg==",
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-context": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-context/-/react-context-1.1.2.tgz",
      "integrity": "sha512-jCi/QKUM2r1Ju5a3J64TH2A5SpKAgh0LpknyqdQ4m6DCV0xJ2HG1xARRwNGPQfi1SLdLWZ1OJz6F4OMBBNiGJA==",
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-context-menu": {
      "version": "2.2.15",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-context-menu/-/react-context-menu-2.2.15.tgz",
      "integrity": "sha512-UsQUMjcYTsBjTSXw0P3GO0werEQvUY2plgRQuKoCTtkNr45q1DiL51j4m7gxhABzZ0BadoXNsIbg7F3KwiUBbw==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-menu": "2.1.15",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-use-callback-ref": "1.1.1",
        "@radix-ui/react-use-controllable-state": "1.2.2"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-dialog": {
      "version": "1.1.14",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-dialog/-/react-dialog-1.1.14.tgz",
      "integrity": "sha512-+CpweKjqpzTmwRwcYECQcNYbI8V9VSQt0SNFKeEBLgfucbsLssU6Ppq7wUdNXEGb573bMjFhVjKVll8rmV6zMw==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-dismissable-layer": "1.1.10",
        "@radix-ui/react-focus-guards": "1.1.2",
        "@radix-ui/react-focus-scope": "1.1.7",
        "@radix-ui/react-id": "1.1.1",
        "@radix-ui/react-portal": "1.1.9",
        "@radix-ui/react-presence": "1.1.4",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-slot": "1.2.3",
        "@radix-ui/react-use-controllable-state": "1.2.2",
        "aria-hidden": "^1.2.4",
        "react-remove-scroll": "^2.6.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-direction": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-direction/-/react-direction-1.1.1.tgz",
      "integrity": "sha512-1UEWRX6jnOA2y4H5WczZ44gOOjTEmlqv1uNW4GAJEO5+bauCBhv8snY65Iw5/VOS/ghKN9gr2KjnLKxrsvoMVw==",
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-dismissable-layer": {
      "version": "1.1.10",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-dismissable-layer/-/react-dismissable-layer-1.1.10.tgz",
      "integrity": "sha512-IM1zzRV4W3HtVgftdQiiOmA0AdJlCtMLe00FXaHwgt3rAnNsIyDqshvkIW3hj/iu5hu8ERP7KIYki6NkqDxAwQ==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-use-callback-ref": "1.1.1",
        "@radix-ui/react-use-escape-keydown": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-dropdown-menu": {
      "version": "2.1.15",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-dropdown-menu/-/react-dropdown-menu-2.1.15.tgz",
      "integrity": "sha512-mIBnOjgwo9AH3FyKaSWoSu/dYj6VdhJ7frEPiGTeXCdUFHjl9h3mFh2wwhEtINOmYXWhdpf1rY2minFsmaNgVQ==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-id": "1.1.1",
        "@radix-ui/react-menu": "2.1.15",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-use-controllable-state": "1.2.2"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-focus-guards": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-focus-guards/-/react-focus-guards-1.1.2.tgz",
      "integrity": "sha512-fyjAACV62oPV925xFCrH8DR5xWhg9KYtJT4s3u54jxp+L/hbpTY2kIeEFFbFe+a/HCE94zGQMZLIpVTPVZDhaA==",
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-focus-scope": {
      "version": "1.1.7",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-focus-scope/-/react-focus-scope-1.1.7.tgz",
      "integrity": "sha512-t2ODlkXBQyn7jkl6TNaw/MtVEVvIGelJDCG41Okq/KwUsJBwQ4XVZsHAVUkK4mBv3ewiAS3PGuUWuY2BoK4ZUw==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-use-callback-ref": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-hover-card": {
      "version": "1.1.14",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-hover-card/-/react-hover-card-1.1.14.tgz",
      "integrity": "sha512-CPYZ24Mhirm+g6D8jArmLzjYu4Eyg3TTUHswR26QgzXBHBe64BO/RHOJKzmF/Dxb4y4f9PKyJdwm/O/AhNkb+Q==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-dismissable-layer": "1.1.10",
        "@radix-ui/react-popper": "1.2.7",
        "@radix-ui/react-portal": "1.1.9",
        "@radix-ui/react-presence": "1.1.4",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-use-controllable-state": "1.2.2"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-id": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-id/-/react-id-1.1.1.tgz",
      "integrity": "sha512-kGkGegYIdQsOb4XjsfM97rXsiHaBwco+hFI66oO4s9LU+PLAC5oJ7khdOVFxkhsmlbpUqDAvXw11CluXP+jkHg==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-use-layout-effect": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-label": {
      "version": "2.1.7",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-label/-/react-label-2.1.7.tgz",
      "integrity": "sha512-YT1GqPSL8kJn20djelMX7/cTRp/Y9w5IZHvfxQTVHrOqa2yMl7i/UfMqKRU5V7mEyKTrUVgJXhNQPVCG8PBLoQ==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-primitive": "2.1.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-menu": {
      "version": "2.1.15",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-menu/-/react-menu-2.1.15.tgz",
      "integrity": "sha512-tVlmA3Vb9n8SZSd+YSbuFR66l87Wiy4du+YE+0hzKQEANA+7cWKH1WgqcEX4pXqxUFQKrWQGHdvEfw00TjFiew==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-collection": "1.1.7",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-direction": "1.1.1",
        "@radix-ui/react-dismissable-layer": "1.1.10",
        "@radix-ui/react-focus-guards": "1.1.2",
        "@radix-ui/react-focus-scope": "1.1.7",
        "@radix-ui/react-id": "1.1.1",
        "@radix-ui/react-popper": "1.2.7",
        "@radix-ui/react-portal": "1.1.9",
        "@radix-ui/react-presence": "1.1.4",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-roving-focus": "1.1.10",
        "@radix-ui/react-slot": "1.2.3",
        "@radix-ui/react-use-callback-ref": "1.1.1",
        "aria-hidden": "^1.2.4",
        "react-remove-scroll": "^2.6.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-menubar": {
      "version": "1.1.15",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-menubar/-/react-menubar-1.1.15.tgz",
      "integrity": "sha512-Z71C7LGD+YDYo3TV81paUs8f3Zbmkvg6VLRQpKYfzioOE6n7fOhA3ApK/V/2Odolxjoc4ENk8AYCjohCNayd5A==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-collection": "1.1.7",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-direction": "1.1.1",
        "@radix-ui/react-id": "1.1.1",
        "@radix-ui/react-menu": "2.1.15",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-roving-focus": "1.1.10",
        "@radix-ui/react-use-controllable-state": "1.2.2"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-navigation-menu": {
      "version": "1.2.13",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-navigation-menu/-/react-navigation-menu-1.2.13.tgz",
      "integrity": "sha512-WG8wWfDiJlSF5hELjwfjSGOXcBR/ZMhBFCGYe8vERpC39CQYZeq1PQ2kaYHdye3V95d06H89KGMsVCIE4LWo3g==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-collection": "1.1.7",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-direction": "1.1.1",
        "@radix-ui/react-dismissable-layer": "1.1.10",
        "@radix-ui/react-id": "1.1.1",
        "@radix-ui/react-presence": "1.1.4",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-use-callback-ref": "1.1.1",
        "@radix-ui/react-use-controllable-state": "1.2.2",
        "@radix-ui/react-use-layout-effect": "1.1.1",
        "@radix-ui/react-use-previous": "1.1.1",
        "@radix-ui/react-visually-hidden": "1.2.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-popover": {
      "version": "1.1.14",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-popover/-/react-popover-1.1.14.tgz",
      "integrity": "sha512-ODz16+1iIbGUfFEfKx2HTPKizg2MN39uIOV8MXeHnmdd3i/N9Wt7vU46wbHsqA0xoaQyXVcs0KIlBdOA2Y95bw==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-dismissable-layer": "1.1.10",
        "@radix-ui/react-focus-guards": "1.1.2",
        "@radix-ui/react-focus-scope": "1.1.7",
        "@radix-ui/react-id": "1.1.1",
        "@radix-ui/react-popper": "1.2.7",
        "@radix-ui/react-portal": "1.1.9",
        "@radix-ui/react-presence": "1.1.4",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-slot": "1.2.3",
        "@radix-ui/react-use-controllable-state": "1.2.2",
        "aria-hidden": "^1.2.4",
        "react-remove-scroll": "^2.6.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-popper": {
      "version": "1.2.7",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-popper/-/react-popper-1.2.7.tgz",
      "integrity": "sha512-IUFAccz1JyKcf/RjB552PlWwxjeCJB8/4KxT7EhBHOJM+mN7LdW+B3kacJXILm32xawcMMjb2i0cIZpo+f9kiQ==",
      "license": "MIT",
      "dependencies": {
        "@floating-ui/react-dom": "^2.0.0",
        "@radix-ui/react-arrow": "1.1.7",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-use-callback-ref": "1.1.1",
        "@radix-ui/react-use-layout-effect": "1.1.1",
        "@radix-ui/react-use-rect": "1.1.1",
        "@radix-ui/react-use-size": "1.1.1",
        "@radix-ui/rect": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-portal": {
      "version": "1.1.9",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-portal/-/react-portal-1.1.9.tgz",
      "integrity": "sha512-bpIxvq03if6UNwXZ+HTK71JLh4APvnXntDc6XOX8UVq4XQOVl7lwok0AvIl+b8zgCw3fSaVTZMpAPPagXbKmHQ==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-use-layout-effect": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-presence": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-presence/-/react-presence-1.1.4.tgz",
      "integrity": "sha512-ueDqRbdc4/bkaQT3GIpLQssRlFgWaL/U2z/S31qRwwLWoxHLgry3SIfCwhxeQNbirEUXFa+lq3RL3oBYXtcmIA==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-use-layout-effect": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-primitive": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-primitive/-/react-primitive-2.1.3.tgz",
      "integrity": "sha512-m9gTwRkhy2lvCPe6QJp4d3G1TYEUHn/FzJUtq9MjH46an1wJU+GdoGC5VLof8RX8Ft/DlpshApkhswDLZzHIcQ==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-slot": "1.2.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-progress": {
      "version": "1.1.7",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-progress/-/react-progress-1.1.7.tgz",
      "integrity": "sha512-vPdg/tF6YC/ynuBIJlk1mm7Le0VgW6ub6J2UWnTQ7/D23KXcPI1qy+0vBkgKgd38RCMJavBXpB83HPNFMTb0Fg==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-primitive": "2.1.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-radio-group": {
      "version": "1.3.7",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-radio-group/-/react-radio-group-1.3.7.tgz",
      "integrity": "sha512-9w5XhD0KPOrm92OTTE0SysH3sYzHsSTHNvZgUBo/VZ80VdYyB5RneDbc0dKpURS24IxkoFRu/hI0i4XyfFwY6g==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-direction": "1.1.1",
        "@radix-ui/react-presence": "1.1.4",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-roving-focus": "1.1.10",
        "@radix-ui/react-use-controllable-state": "1.2.2",
        "@radix-ui/react-use-previous": "1.1.1",
        "@radix-ui/react-use-size": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-roving-focus": {
      "version": "1.1.10",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-roving-focus/-/react-roving-focus-1.1.10.tgz",
      "integrity": "sha512-dT9aOXUen9JSsxnMPv/0VqySQf5eDQ6LCk5Sw28kamz8wSOW2bJdlX2Bg5VUIIcV+6XlHpWTIuTPCf/UNIyq8Q==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-collection": "1.1.7",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-direction": "1.1.1",
        "@radix-ui/react-id": "1.1.1",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-use-callback-ref": "1.1.1",
        "@radix-ui/react-use-controllable-state": "1.2.2"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-scroll-area": {
      "version": "1.2.9",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-scroll-area/-/react-scroll-area-1.2.9.tgz",
      "integrity": "sha512-YSjEfBXnhUELsO2VzjdtYYD4CfQjvao+lhhrX5XsHD7/cyUNzljF1FHEbgTPN7LH2MClfwRMIsYlqTYpKTTe2A==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/number": "1.1.1",
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-direction": "1.1.1",
        "@radix-ui/react-presence": "1.1.4",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-use-callback-ref": "1.1.1",
        "@radix-ui/react-use-layout-effect": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-select": {
      "version": "2.2.5",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-select/-/react-select-2.2.5.tgz",
      "integrity": "sha512-HnMTdXEVuuyzx63ME0ut4+sEMYW6oouHWNGUZc7ddvUWIcfCva/AMoqEW/3wnEllriMWBa0RHspCYnfCWJQYmA==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/number": "1.1.1",
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-collection": "1.1.7",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-direction": "1.1.1",
        "@radix-ui/react-dismissable-layer": "1.1.10",
        "@radix-ui/react-focus-guards": "1.1.2",
        "@radix-ui/react-focus-scope": "1.1.7",
        "@radix-ui/react-id": "1.1.1",
        "@radix-ui/react-popper": "1.2.7",
        "@radix-ui/react-portal": "1.1.9",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-slot": "1.2.3",
        "@radix-ui/react-use-callback-ref": "1.1.1",
        "@radix-ui/react-use-controllable-state": "1.2.2",
        "@radix-ui/react-use-layout-effect": "1.1.1",
        "@radix-ui/react-use-previous": "1.1.1",
        "@radix-ui/react-visually-hidden": "1.2.3",
        "aria-hidden": "^1.2.4",
        "react-remove-scroll": "^2.6.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-separator": {
      "version": "1.1.7",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-separator/-/react-separator-1.1.7.tgz",
      "integrity": "sha512-0HEb8R9E8A+jZjvmFCy/J4xhbXy3TV+9XSnGJ3KvTtjlIUy/YQ/p6UYZvi7YbeoeXdyU9+Y3scizK6hkY37baA==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-primitive": "2.1.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-slider": {
      "version": "1.3.5",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-slider/-/react-slider-1.3.5.tgz",
      "integrity": "sha512-rkfe2pU2NBAYfGaxa3Mqosi7VZEWX5CxKaanRv0vZd4Zhl9fvQrg0VM93dv3xGLGfrHuoTRF3JXH8nb9g+B3fw==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/number": "1.1.1",
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-collection": "1.1.7",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-direction": "1.1.1",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-use-controllable-state": "1.2.2",
        "@radix-ui/react-use-layout-effect": "1.1.1",
        "@radix-ui/react-use-previous": "1.1.1",
        "@radix-ui/react-use-size": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-slot": {
      "version": "1.2.3",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-slot/-/react-slot-1.2.3.tgz",
      "integrity": "sha512-aeNmHnBxbi2St0au6VBVC7JXFlhLlOnvIIlePNniyUNAClzmtAUEY8/pBiK3iHjufOlwA+c20/8jngo7xcrg8A==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-compose-refs": "1.1.2"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-switch": {
      "version": "1.2.5",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-switch/-/react-switch-1.2.5.tgz",
      "integrity": "sha512-5ijLkak6ZMylXsaImpZ8u4Rlf5grRmoc0p0QeX9VJtlrM4f5m3nCTX8tWga/zOA8PZYIR/t0p2Mnvd7InrJ6yQ==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-use-controllable-state": "1.2.2",
        "@radix-ui/react-use-previous": "1.1.1",
        "@radix-ui/react-use-size": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-tabs": {
      "version": "1.1.12",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-tabs/-/react-tabs-1.1.12.tgz",
      "integrity": "sha512-GTVAlRVrQrSw3cEARM0nAx73ixrWDPNZAruETn3oHCNP6SbZ/hNxdxp+u7VkIEv3/sFoLq1PfcHrl7Pnp0CDpw==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-direction": "1.1.1",
        "@radix-ui/react-id": "1.1.1",
        "@radix-ui/react-presence": "1.1.4",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-roving-focus": "1.1.10",
        "@radix-ui/react-use-controllable-state": "1.2.2"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-toast": {
      "version": "1.2.14",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-toast/-/react-toast-1.2.14.tgz",
      "integrity": "sha512-nAP5FBxBJGQ/YfUB+r+O6USFVkWq3gAInkxyEnmvEV5jtSbfDhfa4hwX8CraCnbjMLsE7XSf/K75l9xXY7joWg==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-collection": "1.1.7",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-dismissable-layer": "1.1.10",
        "@radix-ui/react-portal": "1.1.9",
        "@radix-ui/react-presence": "1.1.4",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-use-callback-ref": "1.1.1",
        "@radix-ui/react-use-controllable-state": "1.2.2",
        "@radix-ui/react-use-layout-effect": "1.1.1",
        "@radix-ui/react-visually-hidden": "1.2.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-toggle": {
      "version": "1.1.9",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-toggle/-/react-toggle-1.1.9.tgz",
      "integrity": "sha512-ZoFkBBz9zv9GWer7wIjvdRxmh2wyc2oKWw6C6CseWd6/yq1DK/l5lJ+wnsmFwJZbBYqr02mrf8A2q/CVCuM3ZA==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-use-controllable-state": "1.2.2"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-toggle-group": {
      "version": "1.1.10",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-toggle-group/-/react-toggle-group-1.1.10.tgz",
      "integrity": "sha512-kiU694Km3WFLTC75DdqgM/3Jauf3rD9wxeS9XtyWFKsBUeZA337lC+6uUazT7I1DhanZ5gyD5Stf8uf2dbQxOQ==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-direction": "1.1.1",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-roving-focus": "1.1.10",
        "@radix-ui/react-toggle": "1.1.9",
        "@radix-ui/react-use-controllable-state": "1.2.2"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-tooltip": {
      "version": "1.2.7",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-tooltip/-/react-tooltip-1.2.7.tgz",
      "integrity": "sha512-Ap+fNYwKTYJ9pzqW+Xe2HtMRbQ/EeWkj2qykZ6SuEV4iS/o1bZI5ssJbk4D2r8XuDuOBVz/tIx2JObtuqU+5Zw==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.2",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-dismissable-layer": "1.1.10",
        "@radix-ui/react-id": "1.1.1",
        "@radix-ui/react-popper": "1.2.7",
        "@radix-ui/react-portal": "1.1.9",
        "@radix-ui/react-presence": "1.1.4",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-slot": "1.2.3",
        "@radix-ui/react-use-controllable-state": "1.2.2",
        "@radix-ui/react-visually-hidden": "1.2.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-use-callback-ref": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-use-callback-ref/-/react-use-callback-ref-1.1.1.tgz",
      "integrity": "sha512-FkBMwD+qbGQeMu1cOHnuGB6x4yzPjho8ap5WtbEJ26umhgqVXbhekKUQO+hZEL1vU92a3wHwdp0HAcqAUF5iDg==",
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-use-controllable-state": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-use-controllable-state/-/react-use-controllable-state-1.2.2.tgz",
      "integrity": "sha512-BjasUjixPFdS+NKkypcyyN5Pmg83Olst0+c6vGov0diwTEo6mgdqVR6hxcEgFuh4QrAs7Rc+9KuGJ9TVCj0Zzg==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-use-effect-event": "0.0.2",
        "@radix-ui/react-use-layout-effect": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-use-effect-event": {
      "version": "0.0.2",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-use-effect-event/-/react-use-effect-event-0.0.2.tgz",
      "integrity": "sha512-Qp8WbZOBe+blgpuUT+lw2xheLP8q0oatc9UpmiemEICxGvFLYmHm9QowVZGHtJlGbS6A6yJ3iViad/2cVjnOiA==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-use-layout-effect": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-use-escape-keydown": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-use-escape-keydown/-/react-use-escape-keydown-1.1.1.tgz",
      "integrity": "sha512-Il0+boE7w/XebUHyBjroE+DbByORGR9KKmITzbR7MyQ4akpORYP/ZmbhAr0DG7RmmBqoOnZdy2QlvajJ2QA59g==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-use-callback-ref": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-use-is-hydrated": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-use-is-hydrated/-/react-use-is-hydrated-0.1.0.tgz",
      "integrity": "sha512-U+UORVEq+cTnRIaostJv9AGdV3G6Y+zbVd+12e18jQ5A3c0xL03IhnHuiU4UV69wolOQp5GfR58NW/EgdQhwOA==",
      "license": "MIT",
      "dependencies": {
        "use-sync-external-store": "^1.5.0"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-use-layout-effect": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-use-layout-effect/-/react-use-layout-effect-1.1.1.tgz",
      "integrity": "sha512-RbJRS4UWQFkzHTTwVymMTUv8EqYhOp8dOOviLj2ugtTiXRaRQS7GLGxZTLL1jWhMeoSCf5zmcZkqTl9IiYfXcQ==",
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-use-previous": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-use-previous/-/react-use-previous-1.1.1.tgz",
      "integrity": "sha512-2dHfToCj/pzca2Ck724OZ5L0EVrr3eHRNsG/b3xQJLA2hZpVCS99bLAX+hm1IHXDEnzU6by5z/5MIY794/a8NQ==",
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-use-rect": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-use-rect/-/react-use-rect-1.1.1.tgz",
      "integrity": "sha512-QTYuDesS0VtuHNNvMh+CjlKJ4LJickCMUAqjlE3+j8w+RlRpwyX3apEQKGFzbZGdo7XNG1tXa+bQqIE7HIXT2w==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/rect": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-use-size": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-use-size/-/react-use-size-1.1.1.tgz",
      "integrity": "sha512-ewrXRDTAqAXlkl6t/fkXWNAhFX9I+CkKlw6zjEwk86RSPKwZr3xpBRso655aqYafwtnbpHLj6toFzmd6xdVptQ==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-use-layout-effect": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-visually-hidden": {
      "version": "1.2.3",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-visually-hidden/-/react-visually-hidden-1.2.3.tgz",
      "integrity": "sha512-pzJq12tEaaIhqjbzpCuv/OypJY/BPavOofm+dbab+MHLajy277+1lLm6JFcGgF5eskJ6mquGirhXY2GD/8u8Ug==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-primitive": "2.1.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/rect": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/@radix-ui/rect/-/rect-1.1.1.tgz",
      "integrity": "sha512-HPwpGIzkl28mWyZqG52jiqDJ12waP11Pa1lGoiyUkIEuMLBP0oeK/C89esbXrxsky5we7dfd8U58nm0SgAWpVw==",
      "license": "MIT"
    },
    "node_modules/@remix-run/router": {
      "version": "1.23.0",
      "resolved": "https://registry.npmjs.org/@remix-run/router/-/router-1.23.0.tgz",
      "integrity": "sha512-O3rHJzAQKamUz1fvE0Qaw0xSFqsA/yafi2iqeE0pvdFtCO1viYx8QL6f3Ln/aCCTLxs68SLf0KPM9eSeM8yBnA==",
      "license": "MIT",
      "engines": {
        "node": ">=14.0.0"
      }
    },
    "node_modules/@rolldown/pluginutils": {
      "version": "1.0.0-beta.27",
      "resolved": "https://registry.npmjs.org/@rolldown/pluginutils/-/pluginutils-1.0.0-beta.27.tgz",
      "integrity": "sha512-+d0F4MKMCbeVUJwG96uQ4SgAznZNSq93I3V+9NHA4OpvqG8mRCpGdKmK8l/dl02h2CCDHwW2FqilnTyDcAnqjA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@rollup/rollup-android-arm-eabi": {
      "version": "4.24.0",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-android-arm-eabi/-/rollup-android-arm-eabi-4.24.0.tgz",
      "integrity": "sha512-Q6HJd7Y6xdB48x8ZNVDOqsbh2uByBhgK8PiQgPhwkIw/HC/YX5Ghq2mQY5sRMZWHb3VsFkWooUVOZHKr7DmDIA==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ]
    },
    "node_modules/@rollup/rollup-android-arm64": {
      "version": "4.24.0",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-android-arm64/-/rollup-android-arm64-4.24.0.tgz",
      "integrity": "sha512-ijLnS1qFId8xhKjT81uBHuuJp2lU4x2yxa4ctFPtG+MqEE6+C5f/+X/bStmxapgmwLwiL3ih122xv8kVARNAZA==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ]
    },
    "node_modules/@rollup/rollup-darwin-arm64": {
      "version": "4.24.0",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-darwin-arm64/-/rollup-darwin-arm64-4.24.0.tgz",
      "integrity": "sha512-bIv+X9xeSs1XCk6DVvkO+S/z8/2AMt/2lMqdQbMrmVpgFvXlmde9mLcbQpztXm1tajC3raFDqegsH18HQPMYtA==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ]
    },
    "node_modules/@rollup/rollup-darwin-x64": {
      "version": "4.24.0",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-darwin-x64/-/rollup-darwin-x64-4.24.0.tgz",
      "integrity": "sha512-X6/nOwoFN7RT2svEQWUsW/5C/fYMBe4fnLK9DQk4SX4mgVBiTA9h64kjUYPvGQ0F/9xwJ5U5UfTbl6BEjaQdBQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ]
    },
    "node_modules/@rollup/rollup-linux-arm-gnueabihf": {
      "version": "4.24.0",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-arm-gnueabihf/-/rollup-linux-arm-gnueabihf-4.24.0.tgz",
      "integrity": "sha512-0KXvIJQMOImLCVCz9uvvdPgfyWo93aHHp8ui3FrtOP57svqrF/roSSR5pjqL2hcMp0ljeGlU4q9o/rQaAQ3AYA==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-arm-musleabihf": {
      "version": "4.24.0",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-arm-musleabihf/-/rollup-linux-arm-musleabihf-4.24.0.tgz",
      "integrity": "sha512-it2BW6kKFVh8xk/BnHfakEeoLPv8STIISekpoF+nBgWM4d55CZKc7T4Dx1pEbTnYm/xEKMgy1MNtYuoA8RFIWw==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-arm64-gnu": {
      "version": "4.24.0",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-arm64-gnu/-/rollup-linux-arm64-gnu-4.24.0.tgz",
      "integrity": "sha512-i0xTLXjqap2eRfulFVlSnM5dEbTVque/3Pi4g2y7cxrs7+a9De42z4XxKLYJ7+OhE3IgxvfQM7vQc43bwTgPwA==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-arm64-musl": {
      "version": "4.24.0",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-arm64-musl/-/rollup-linux-arm64-musl-4.24.0.tgz",
      "integrity": "sha512-9E6MKUJhDuDh604Qco5yP/3qn3y7SLXYuiC0Rpr89aMScS2UAmK1wHP2b7KAa1nSjWJc/f/Lc0Wl1L47qjiyQw==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-powerpc64le-gnu": {
      "version": "4.24.0",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-powerpc64le-gnu/-/rollup-linux-powerpc64le-gnu-4.24.0.tgz",
      "integrity": "sha512-2XFFPJ2XMEiF5Zi2EBf4h73oR1V/lycirxZxHZNc93SqDN/IWhYYSYj8I9381ikUFXZrz2v7r2tOVk2NBwxrWw==",
      "cpu": [
        "ppc64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-riscv64-gnu": {
      "version": "4.24.0",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-riscv64-gnu/-/rollup-linux-riscv64-gnu-4.24.0.tgz",
      "integrity": "sha512-M3Dg4hlwuntUCdzU7KjYqbbd+BLq3JMAOhCKdBE3TcMGMZbKkDdJ5ivNdehOssMCIokNHFOsv7DO4rlEOfyKpg==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-s390x-gnu": {
      "version": "4.24.0",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-s390x-gnu/-/rollup-linux-s390x-gnu-4.24.0.tgz",
      "integrity": "sha512-mjBaoo4ocxJppTorZVKWFpy1bfFj9FeCMJqzlMQGjpNPY9JwQi7OuS1axzNIk0nMX6jSgy6ZURDZ2w0QW6D56g==",
      "cpu": [
        "s390x"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-x64-gnu": {
      "version": "4.24.0",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-x64-gnu/-/rollup-linux-x64-gnu-4.24.0.tgz",
      "integrity": "sha512-ZXFk7M72R0YYFN5q13niV0B7G8/5dcQ9JDp8keJSfr3GoZeXEoMHP/HlvqROA3OMbMdfr19IjCeNAnPUG93b6A==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-x64-musl": {
      "version": "4.24.0",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-x64-musl/-/rollup-linux-x64-musl-4.24.0.tgz",
      "integrity": "sha512-w1i+L7kAXZNdYl+vFvzSZy8Y1arS7vMgIy8wusXJzRrPyof5LAb02KGr1PD2EkRcl73kHulIID0M501lN+vobQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-win32-arm64-msvc": {
      "version": "4.24.0",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-win32-arm64-msvc/-/rollup-win32-arm64-msvc-4.24.0.tgz",
      "integrity": "sha512-VXBrnPWgBpVDCVY6XF3LEW0pOU51KbaHhccHw6AS6vBWIC60eqsH19DAeeObl+g8nKAz04QFdl/Cefta0xQtUQ==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@rollup/rollup-win32-ia32-msvc": {
      "version": "4.24.0",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-win32-ia32-msvc/-/rollup-win32-ia32-msvc-4.24.0.tgz",
      "integrity": "sha512-xrNcGDU0OxVcPTH/8n/ShH4UevZxKIO6HJFK0e15XItZP2UcaiLFd5kiX7hJnqCbSztUF8Qot+JWBC/QXRPYWQ==",
      "cpu": [
        "ia32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@rollup/rollup-win32-x64-msvc": {
      "version": "4.24.0",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-win32-x64-msvc/-/rollup-win32-x64-msvc-4.24.0.tgz",
      "integrity": "sha512-fbMkAF7fufku0N2dE5TBXcNlg0pt0cJue4xBRE2Qc5Vqikxr4VCgKj/ht6SMdFcOacVA9rqF70APJ8RN/4vMJw==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@swc/core": {
      "version": "1.13.2",
      "resolved": "https://registry.npmjs.org/@swc/core/-/core-1.13.2.tgz",
      "integrity": "sha512-YWqn+0IKXDhqVLKoac4v2tV6hJqB/wOh8/Br8zjqeqBkKa77Qb0Kw2i7LOFzjFNZbZaPH6AlMGlBwNrxaauaAg==",
      "dev": true,
      "hasInstallScript": true,
      "license": "Apache-2.0",
      "dependencies": {
        "@swc/counter": "^0.1.3",
        "@swc/types": "^0.1.23"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/swc"
      },
      "optionalDependencies": {
        "@swc/core-darwin-arm64": "1.13.2",
        "@swc/core-darwin-x64": "1.13.2",
        "@swc/core-linux-arm-gnueabihf": "1.13.2",
        "@swc/core-linux-arm64-gnu": "1.13.2",
        "@swc/core-linux-arm64-musl": "1.13.2",
        "@swc/core-linux-x64-gnu": "1.13.2",
        "@swc/core-linux-x64-musl": "1.13.2",
        "@swc/core-win32-arm64-msvc": "1.13.2",
        "@swc/core-win32-ia32-msvc": "1.13.2",
        "@swc/core-win32-x64-msvc": "1.13.2"
      },
      "peerDependencies": {
        "@swc/helpers": ">=0.5.17"
      },
      "peerDependenciesMeta": {
        "@swc/helpers": {
          "optional": true
        }
      }
    },
    "node_modules/@swc/core-darwin-arm64": {
      "version": "1.13.2",
      "resolved": "https://registry.npmjs.org/@swc/core-darwin-arm64/-/core-darwin-arm64-1.13.2.tgz",
      "integrity": "sha512-44p7ivuLSGFJ15Vly4ivLJjg3ARo4879LtEBAabcHhSZygpmkP8eyjyWxrH3OxkY1eRZSIJe8yRZPFw4kPXFPw==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "Apache-2.0 AND MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/@swc/core-darwin-x64": {
      "version": "1.13.2",
      "resolved": "https://registry.npmjs.org/@swc/core-darwin-x64/-/core-darwin-x64-1.13.2.tgz",
      "integrity": "sha512-Lb9EZi7X2XDAVmuUlBm2UvVAgSCbD3qKqDCxSI4jEOddzVOpNCnyZ/xEampdngUIyDDhhJLYU9duC+Mcsv5Y+A==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "Apache-2.0 AND MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/@swc/core-linux-arm-gnueabihf": {
      "version": "1.13.2",
      "resolved": "https://registry.npmjs.org/@swc/core-linux-arm-gnueabihf/-/core-linux-arm-gnueabihf-1.13.2.tgz",
      "integrity": "sha512-9TDe/92ee1x57x+0OqL1huG4BeljVx0nWW4QOOxp8CCK67Rpc/HHl2wciJ0Kl9Dxf2NvpNtkPvqj9+BUmM9WVA==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "Apache-2.0",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/@swc/core-linux-arm64-gnu": {
      "version": "1.13.2",
      "resolved": "https://registry.npmjs.org/@swc/core-linux-arm64-gnu/-/core-linux-arm64-gnu-1.13.2.tgz",
      "integrity": "sha512-KJUSl56DBk7AWMAIEcU83zl5mg3vlQYhLELhjwRFkGFMvghQvdqQ3zFOYa4TexKA7noBZa3C8fb24rI5sw9Exg==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "Apache-2.0 AND MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/@swc/core-linux-arm64-musl": {
      "version": "1.13.2",
      "resolved": "https://registry.npmjs.org/@swc/core-linux-arm64-musl/-/core-linux-arm64-musl-1.13.2.tgz",
      "integrity": "sha512-teU27iG1oyWpNh9CzcGQ48ClDRt/RCem7mYO7ehd2FY102UeTws2+OzLESS1TS1tEZipq/5xwx3FzbVgiolCiQ==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "Apache-2.0 AND MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/@swc/core-linux-x64-gnu": {
      "version": "1.13.2",
      "resolved": "https://registry.npmjs.org/@swc/core-linux-x64-gnu/-/core-linux-x64-gnu-1.13.2.tgz",
      "integrity": "sha512-dRPsyPyqpLD0HMRCRpYALIh4kdOir8pPg4AhNQZLehKowigRd30RcLXGNVZcc31Ua8CiPI4QSgjOIxK+EQe4LQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "Apache-2.0 AND MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/@swc/core-linux-x64-musl": {
      "version": "1.13.2",
      "resolved": "https://registry.npmjs.org/@swc/core-linux-x64-musl/-/core-linux-x64-musl-1.13.2.tgz",
      "integrity": "sha512-CCxETW+KkYEQDqz1SYC15YIWYheqFC+PJVOW76Maa/8yu8Biw+HTAcblKf2isrlUtK8RvrQN94v3UXkC2NzCEw==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "Apache-2.0 AND MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/@swc/core-win32-arm64-msvc": {
      "version": "1.13.2",
      "resolved": "https://registry.npmjs.org/@swc/core-win32-arm64-msvc/-/core-win32-arm64-msvc-1.13.2.tgz",
      "integrity": "sha512-Wv/QTA6PjyRLlmKcN6AmSI4jwSMRl0VTLGs57PHTqYRwwfwd7y4s2fIPJVBNbAlXd795dOEP6d/bGSQSyhOX3A==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "Apache-2.0 AND MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/@swc/core-win32-ia32-msvc": {
      "version": "1.13.2",
      "resolved": "https://registry.npmjs.org/@swc/core-win32-ia32-msvc/-/core-win32-ia32-msvc-1.13.2.tgz",
      "integrity": "sha512-PuCdtNynEkUNbUXX/wsyUC+t4mamIU5y00lT5vJcAvco3/r16Iaxl5UCzhXYaWZSNVZMzPp9qN8NlSL8M5pPxw==",
      "cpu": [
        "ia32"
      ],
      "dev": true,
      "license": "Apache-2.0 AND MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/@swc/core-win32-x64-msvc": {
      "version": "1.13.2",
      "resolved": "https://registry.npmjs.org/@swc/core-win32-x64-msvc/-/core-win32-x64-msvc-1.13.2.tgz",
      "integrity": "sha512-qlmMkFZJus8cYuBURx1a3YAG2G7IW44i+FEYV5/32ylKkzGNAr9tDJSA53XNnNXkAB5EXSPsOz7bn5C3JlEtdQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "Apache-2.0 AND MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/@swc/counter": {
      "version": "0.1.3",
      "resolved": "https://registry.npmjs.org/@swc/counter/-/counter-0.1.3.tgz",
      "integrity": "sha512-e2BR4lsJkkRlKZ/qCHPw9ZaSxc0MVUd7gtbtaB7aMvHeJVYe8sOB8DBZkP2DtISHGSku9sCK6T6cnY0CtXrOCQ==",
      "dev": true,
      "license": "Apache-2.0"
    },
    "node_modules/@swc/types": {
      "version": "0.1.23",
      "resolved": "https://registry.npmjs.org/@swc/types/-/types-0.1.23.tgz",
      "integrity": "sha512-u1iIVZV9Q0jxY+yM2vw/hZGDNudsN85bBpTqzAQ9rzkxW9D+e3aEM4Han+ow518gSewkXgjmEK0BD79ZcNVgPw==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "@swc/counter": "^0.1.3"
      }
    },
    "node_modules/@tailwindcss/typography": {
      "version": "0.5.16",
      "resolved": "https://registry.npmjs.org/@tailwindcss/typography/-/typography-0.5.16.tgz",
      "integrity": "sha512-0wDLwCVF5V3x3b1SGXPCDcdsbDHMBe+lkFzBRaHeLvNi+nrrnZ1lA18u+OTWO8iSWU2GxUOCvlXtDuqftc1oiA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "lodash.castarray": "^4.4.0",
        "lodash.isplainobject": "^4.0.6",
        "lodash.merge": "^4.6.2",
        "postcss-selector-parser": "6.0.10"
      },
      "peerDependencies": {
        "tailwindcss": ">=3.0.0 || insiders || >=4.0.0-alpha.20 || >=4.0.0-beta.1"
      }
    },
    "node_modules/@tailwindcss/typography/node_modules/postcss-selector-parser": {
      "version": "6.0.10",
      "resolved": "https://registry.npmjs.org/postcss-selector-parser/-/postcss-selector-parser-6.0.10.tgz",
      "integrity": "sha512-IQ7TZdoaqbT+LCpShg46jnZVlhWD2w6iQYAcYXfHARZ7X1t/UGhhceQDs5X0cGqKvYlHNOuv7Oa1xmb0oQuA3w==",
      "dev": true,
      "dependencies": {
        "cssesc": "^3.0.0",
        "util-deprecate": "^1.0.2"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/@tanstack/query-core": {
      "version": "5.83.0",
      "resolved": "https://registry.npmjs.org/@tanstack/query-core/-/query-core-5.83.0.tgz",
      "integrity": "sha512-0M8dA+amXUkyz5cVUm/B+zSk3xkQAcuXuz5/Q/LveT4ots2rBpPTZOzd7yJa2Utsf8D2Upl5KyjhHRY+9lB/XA==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/tannerlinsley"
      }
    },
    "node_modules/@tanstack/react-query": {
      "version": "5.83.0",
      "resolved": "https://registry.npmjs.org/@tanstack/react-query/-/react-query-5.83.0.tgz",
      "integrity": "sha512-/XGYhZ3foc5H0VM2jLSD/NyBRIOK4q9kfeml4+0x2DlL6xVuAcVEW+hTlTapAmejObg0i3eNqhkr2dT+eciwoQ==",
      "license": "MIT",
      "dependencies": {
        "@tanstack/query-core": "5.83.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/tannerlinsley"
      },
      "peerDependencies": {
        "react": "^18 || ^19"
      }
    },
    "node_modules/@types/d3-array": {
      "version": "3.2.1",
      "resolved": "https://registry.npmjs.org/@types/d3-array/-/d3-array-3.2.1.tgz",
      "integrity": "sha512-Y2Jn2idRrLzUfAKV2LyRImR+y4oa2AntrgID95SHJxuMUrkNXmanDSed71sRNZysveJVt1hLLemQZIady0FpEg==",
      "license": "MIT"
    },
    "node_modules/@types/d3-color": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/@types/d3-color/-/d3-color-3.1.3.tgz",
      "integrity": "sha512-iO90scth9WAbmgv7ogoq57O9YpKmFBbmoEoCHDB2xMBY0+/KVrqAaCDyCE16dUspeOvIxFFRI+0sEtqDqy2b4A==",
      "license": "MIT"
    },
    "node_modules/@types/d3-ease": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/@types/d3-ease/-/d3-ease-3.0.2.tgz",
      "integrity": "sha512-NcV1JjO5oDzoK26oMzbILE6HW7uVXOHLQvHshBUW4UMdZGfiY6v5BeQwh9a9tCzv+CeefZQHJt5SRgK154RtiA==",
      "license": "MIT"
    },
    "node_modules/@types/d3-interpolate": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/@types/d3-interpolate/-/d3-interpolate-3.0.4.tgz",
      "integrity": "sha512-mgLPETlrpVV1YRJIglr4Ez47g7Yxjl1lj7YKsiMCb27VJH9W8NVM6Bb9d8kkpG/uAQS5AmbA48q2IAolKKo1MA==",
      "license": "MIT",
      "dependencies": {
        "@types/d3-color": "*"
      }
    },
    "node_modules/@types/d3-path": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/@types/d3-path/-/d3-path-3.1.0.tgz",
      "integrity": "sha512-P2dlU/q51fkOc/Gfl3Ul9kicV7l+ra934qBFXCFhrZMOL6du1TM0pm1ThYvENukyOn5h9v+yMJ9Fn5JK4QozrQ==",
      "license": "MIT"
    },
    "node_modules/@types/d3-scale": {
      "version": "4.0.8",
      "resolved": "https://registry.npmjs.org/@types/d3-scale/-/d3-scale-4.0.8.tgz",
      "integrity": "sha512-gkK1VVTr5iNiYJ7vWDI+yUFFlszhNMtVeneJ6lUTKPjprsvLLI9/tgEGiXJOnlINJA8FyA88gfnQsHbybVZrYQ==",
      "license": "MIT",
      "dependencies": {
        "@types/d3-time": "*"
      }
    },
    "node_modules/@types/d3-shape": {
      "version": "3.1.6",
      "resolved": "https://registry.npmjs.org/@types/d3-shape/-/d3-shape-3.1.6.tgz",
      "integrity": "sha512-5KKk5aKGu2I+O6SONMYSNflgiP0WfZIQvVUMan50wHsLG1G94JlxEVnCpQARfTtzytuY0p/9PXXZb3I7giofIA==",
      "license": "MIT",
      "dependencies": {
        "@types/d3-path": "*"
      }
    },
    "node_modules/@types/d3-time": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/@types/d3-time/-/d3-time-3.0.3.tgz",
      "integrity": "sha512-2p6olUZ4w3s+07q3Tm2dbiMZy5pCDfYwtLXXHUnVzXgQlZ/OyPtUz6OL382BkOuGlLXqfT+wqv8Fw2v8/0geBw==",
      "license": "MIT"
    },
    "node_modules/@types/d3-timer": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/@types/d3-timer/-/d3-timer-3.0.2.tgz",
      "integrity": "sha512-Ps3T8E8dZDam6fUyNiMkekK3XUsaUEik+idO9/YjPtfj2qruF8tFBXS7XhtE4iIXBLxhmLjP3SXpLhVf21I9Lw==",
      "license": "MIT"
    },
    "node_modules/@types/debug": {
      "version": "4.1.12",
      "resolved": "https://registry.npmjs.org/@types/debug/-/debug-4.1.12.tgz",
      "integrity": "sha512-vIChWdVG3LG1SMxEvI/AK+FWJthlrqlTu7fbrlywTkkaONwk/UAGaULXRlf8vkzFBLVm0zkMdCquhL5aOjhXPQ==",
      "license": "MIT",
      "dependencies": {
        "@types/ms": "*"
      }
    },
    "node_modules/@types/estree": {
      "version": "1.0.6",
      "resolved": "https://registry.npmjs.org/@types/estree/-/estree-1.0.6.tgz",
      "integrity": "sha512-AYnb1nQyY49te+VRAVgmzfcgjYS91mY5P0TKUDCLEM+gNnA+3T6rWITXRLYCpahpqSQbN5cE+gHpnPyXjHWxcw==",
      "license": "MIT"
    },
    "node_modules/@types/estree-jsx": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/@types/estree-jsx/-/estree-jsx-1.0.5.tgz",
      "integrity": "sha512-52CcUVNFyfb1A2ALocQw/Dd1BQFNmSdkuC3BkZ6iqhdMfQz7JWOFRuJFloOzjk+6WijU56m9oKXFAXc7o3Towg==",
      "license": "MIT",
      "dependencies": {
        "@types/estree": "*"
      }
    },
    "node_modules/@types/hast": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/@types/hast/-/hast-3.0.4.tgz",
      "integrity": "sha512-WPs+bbQw5aCj+x6laNGWLH3wviHtoCv/P3+otBhbOhJgG8qtpdAMlTCxLtsTWA7LH1Oh/bFCHsBn0TPS5m30EQ==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "*"
      }
    },
    "node_modules/@types/json-schema": {
      "version": "7.0.15",
      "resolved": "https://registry.npmjs.org/@types/json-schema/-/json-schema-7.0.15.tgz",
      "integrity": "sha512-5+fP8P8MFNC+AyZCDxrB2pkZFPGzqQWUzpSeuuVLvm8VMcorNYavBqoFcxK8bQz4Qsbn4oUEEem4wDLfcysGHA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@types/mdast": {
      "version": "4.0.4",
      "resolved": "https://registry.npmjs.org/@types/mdast/-/mdast-4.0.4.tgz",
      "integrity": "sha512-kGaNbPh1k7AFzgpud/gMdvIm5xuECykRR+JnWKQno9TAXVa6WIVCGTPvYGekIDL4uwCZQSYbUxNBSb1aUo79oA==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "*"
      }
    },
    "node_modules/@types/ms": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/@types/ms/-/ms-2.1.0.tgz",
      "integrity": "sha512-GsCCIZDE/p3i96vtEqx+7dBUGXrc7zeSK3wwPHIaRThS+9OhWIXRqzs4d6k1SVU8g91DrNRWxWUGhp5KXQb2VA==",
      "license": "MIT"
    },
    "node_modules/@types/node": {
      "version": "22.16.5",
      "resolved": "https://registry.npmjs.org/@types/node/-/node-22.16.5.tgz",
      "integrity": "sha512-bJFoMATwIGaxxx8VJPeM8TonI8t579oRvgAuT8zFugJsJZgzqv0Fu8Mhp68iecjzG7cnN3mO2dJQ5uUM2EFrgQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "undici-types": "~6.21.0"
      }
    },
    "node_modules/@types/prop-types": {
      "version": "15.7.13",
      "resolved": "https://registry.npmjs.org/@types/prop-types/-/prop-types-15.7.13.tgz",
      "integrity": "sha512-hCZTSvwbzWGvhqxp/RqVqwU999pBf2vp7hzIjiYOsl8wqOmUxkQ6ddw1cV3l8811+kdUFus/q4d1Y3E3SyEifA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@types/react": {
      "version": "18.3.23",
      "resolved": "https://registry.npmjs.org/@types/react/-/react-18.3.23.tgz",
      "integrity": "sha512-/LDXMQh55EzZQ0uVAZmKKhfENivEvWz6E+EYzh+/MCjMhNsotd+ZHhBGIjFDTi6+fz0OhQQQLbTgdQIxxCsC0w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/prop-types": "*",
        "csstype": "^3.0.2"
      }
    },
    "node_modules/@types/react-dom": {
      "version": "18.3.7",
      "resolved": "https://registry.npmjs.org/@types/react-dom/-/react-dom-18.3.7.tgz",
      "integrity": "sha512-MEe3UeoENYVFXzoXEWsvcpg6ZvlrFNlOQ7EOsvhI3CfAXwzPfO8Qwuxd40nepsYKqyyVQnTdEfv68q91yLcKrQ==",
      "dev": true,
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "^18.0.0"
      }
    },
    "node_modules/@types/unist": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/@types/unist/-/unist-3.0.3.tgz",
      "integrity": "sha512-ko/gIFJRv177XgZsZcBwnqJN5x/Gien8qNOn0D5bQU/zAzVf9Zt3BlcUiLqhV9y4ARk0GbT3tnUiPNgnTXzc/Q==",
      "license": "MIT"
    },
    "node_modules/@typescript-eslint/eslint-plugin": {
      "version": "8.38.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/eslint-plugin/-/eslint-plugin-8.38.0.tgz",
      "integrity": "sha512-CPoznzpuAnIOl4nhj4tRr4gIPj5AfKgkiJmGQDaq+fQnRJTYlcBjbX3wbciGmpoPf8DREufuPRe1tNMZnGdanA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@eslint-community/regexpp": "^4.10.0",
        "@typescript-eslint/scope-manager": "8.38.0",
        "@typescript-eslint/type-utils": "8.38.0",
        "@typescript-eslint/utils": "8.38.0",
        "@typescript-eslint/visitor-keys": "8.38.0",
        "graphemer": "^1.4.0",
        "ignore": "^7.0.0",
        "natural-compare": "^1.4.0",
        "ts-api-utils": "^2.1.0"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependencies": {
        "@typescript-eslint/parser": "^8.38.0",
        "eslint": "^8.57.0 || ^9.0.0",
        "typescript": ">=4.8.4 <5.9.0"
      }
    },
    "node_modules/@typescript-eslint/eslint-plugin/node_modules/ignore": {
      "version": "7.0.5",
      "resolved": "https://registry.npmjs.org/ignore/-/ignore-7.0.5.tgz",
      "integrity": "sha512-Hs59xBNfUIunMFgWAbGX5cq6893IbWg4KnrjbYwX3tx0ztorVgTDA6B2sxf8ejHJ4wz8BqGUMYlnzNBer5NvGg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 4"
      }
    },
    "node_modules/@typescript-eslint/parser": {
      "version": "8.38.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/parser/-/parser-8.38.0.tgz",
      "integrity": "sha512-Zhy8HCvBUEfBECzIl1PKqF4p11+d0aUJS1GeUiuqK9WmOug8YCmC4h4bjyBvMyAMI9sbRczmrYL5lKg/YMbrcQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@typescript-eslint/scope-manager": "8.38.0",
        "@typescript-eslint/types": "8.38.0",
        "@typescript-eslint/typescript-estree": "8.38.0",
        "@typescript-eslint/visitor-keys": "8.38.0",
        "debug": "^4.3.4"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependencies": {
        "eslint": "^8.57.0 || ^9.0.0",
        "typescript": ">=4.8.4 <5.9.0"
      }
    },
    "node_modules/@typescript-eslint/project-service": {
      "version": "8.38.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/project-service/-/project-service-8.38.0.tgz",
      "integrity": "sha512-dbK7Jvqcb8c9QfH01YB6pORpqX1mn5gDZc9n63Ak/+jD67oWXn3Gs0M6vddAN+eDXBCS5EmNWzbSxsn9SzFWWg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@typescript-eslint/tsconfig-utils": "^8.38.0",
        "@typescript-eslint/types": "^8.38.0",
        "debug": "^4.3.4"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependencies": {
        "typescript": ">=4.8.4 <5.9.0"
      }
    },
    "node_modules/@typescript-eslint/scope-manager": {
      "version": "8.38.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/scope-manager/-/scope-manager-8.38.0.tgz",
      "integrity": "sha512-WJw3AVlFFcdT9Ri1xs/lg8LwDqgekWXWhH3iAF+1ZM+QPd7oxQ6jvtW/JPwzAScxitILUIFs0/AnQ/UWHzbATQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@typescript-eslint/types": "8.38.0",
        "@typescript-eslint/visitor-keys": "8.38.0"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      }
    },
    "node_modules/@typescript-eslint/tsconfig-utils": {
      "version": "8.38.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/tsconfig-utils/-/tsconfig-utils-8.38.0.tgz",
      "integrity": "sha512-Lum9RtSE3EroKk/bYns+sPOodqb2Fv50XOl/gMviMKNvanETUuUcC9ObRbzrJ4VSd2JalPqgSAavwrPiPvnAiQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependencies": {
        "typescript": ">=4.8.4 <5.9.0"
      }
    },
    "node_modules/@typescript-eslint/type-utils": {
      "version": "8.38.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/type-utils/-/type-utils-8.38.0.tgz",
      "integrity": "sha512-c7jAvGEZVf0ao2z+nnz8BUaHZD09Agbh+DY7qvBQqLiz8uJzRgVPj5YvOh8I8uEiH8oIUGIfHzMwUcGVco/SJg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@typescript-eslint/types": "8.38.0",
        "@typescript-eslint/typescript-estree": "8.38.0",
        "@typescript-eslint/utils": "8.38.0",
        "debug": "^4.3.4",
        "ts-api-utils": "^2.1.0"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependencies": {
        "eslint": "^8.57.0 || ^9.0.0",
        "typescript": ">=4.8.4 <5.9.0"
      }
    },
    "node_modules/@typescript-eslint/types": {
      "version": "8.38.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/types/-/types-8.38.0.tgz",
      "integrity": "sha512-wzkUfX3plUqij4YwWaJyqhiPE5UCRVlFpKn1oCRn2O1bJ592XxWJj8ROQ3JD5MYXLORW84063z3tZTb/cs4Tyw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      }
    },
    "node_modules/@typescript-eslint/typescript-estree": {
      "version": "8.38.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/typescript-estree/-/typescript-estree-8.38.0.tgz",
      "integrity": "sha512-fooELKcAKzxux6fA6pxOflpNS0jc+nOQEEOipXFNjSlBS6fqrJOVY/whSn70SScHrcJ2LDsxWrneFoWYSVfqhQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@typescript-eslint/project-service": "8.38.0",
        "@typescript-eslint/tsconfig-utils": "8.38.0",
        "@typescript-eslint/types": "8.38.0",
        "@typescript-eslint/visitor-keys": "8.38.0",
        "debug": "^4.3.4",
        "fast-glob": "^3.3.2",
        "is-glob": "^4.0.3",
        "minimatch": "^9.0.4",
        "semver": "^7.6.0",
        "ts-api-utils": "^2.1.0"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependencies": {
        "typescript": ">=4.8.4 <5.9.0"
      }
    },
    "node_modules/@typescript-eslint/typescript-estree/node_modules/brace-expansion": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-2.0.2.tgz",
      "integrity": "sha512-Jt0vHyM+jmUBqojB7E1NIYadt0vI0Qxjxd2TErW94wDz+E2LAm5vKMXXwg6ZZBTHPuUlDgQHKXvjGBdfcF1ZDQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0"
      }
    },
    "node_modules/@typescript-eslint/typescript-estree/node_modules/minimatch": {
      "version": "9.0.5",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-9.0.5.tgz",
      "integrity": "sha512-G6T0ZX48xgozx7587koeX9Ys2NYy6Gmv//P89sEte9V9whIapMNF4idKxnW2QtCcLiTWlb/wfCabAtAFWhhBow==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^2.0.1"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/@typescript-eslint/utils": {
      "version": "8.38.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/utils/-/utils-8.38.0.tgz",
      "integrity": "sha512-hHcMA86Hgt+ijJlrD8fX0j1j8w4C92zue/8LOPAFioIno+W0+L7KqE8QZKCcPGc/92Vs9x36w/4MPTJhqXdyvg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@eslint-community/eslint-utils": "^4.7.0",
        "@typescript-eslint/scope-manager": "8.38.0",
        "@typescript-eslint/types": "8.38.0",
        "@typescript-eslint/typescript-estree": "8.38.0"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependencies": {
        "eslint": "^8.57.0 || ^9.0.0",
        "typescript": ">=4.8.4 <5.9.0"
      }
    },
    "node_modules/@typescript-eslint/visitor-keys": {
      "version": "8.38.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/visitor-keys/-/visitor-keys-8.38.0.tgz",
      "integrity": "sha512-pWrTcoFNWuwHlA9CvlfSsGWs14JxfN1TH25zM5L7o0pRLhsoZkDnTsXfQRJBEWJoV5DL0jf+Z+sxiud+K0mq1g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@typescript-eslint/types": "8.38.0",
        "eslint-visitor-keys": "^4.2.1"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      }
    },
    "node_modules/@ungap/structured-clone": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/@ungap/structured-clone/-/structured-clone-1.3.0.tgz",
      "integrity": "sha512-WmoN8qaIAo7WTYWbAZuG8PYEhn5fkz7dZrqTBZ7dtt//lL2Gwms1IcnQ5yHqjDfX8Ft5j4YzDM23f87zBfDe9g==",
      "license": "ISC"
    },
    "node_modules/@vitejs/plugin-react-swc": {
      "version": "3.11.0",
      "resolved": "https://registry.npmjs.org/@vitejs/plugin-react-swc/-/plugin-react-swc-3.11.0.tgz",
      "integrity": "sha512-YTJCGFdNMHCMfjODYtxRNVAYmTWQ1Lb8PulP/2/f/oEEtglw8oKxKIZmmRkyXrVrHfsKOaVkAc3NT9/dMutO5w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@rolldown/pluginutils": "1.0.0-beta.27",
        "@swc/core": "^1.12.11"
      },
      "peerDependencies": {
        "vite": "^4 || ^5 || ^6 || ^7"
      }
    },
    "node_modules/acorn": {
      "version": "8.15.0",
      "resolved": "https://registry.npmjs.org/acorn/-/acorn-8.15.0.tgz",
      "integrity": "sha512-NZyJarBfL7nWwIq+FDL6Zp/yHEhePMNnnJ0y3qfieCrmNvYct8uvtiV41UvlSe6apAfk0fY1FbWx+NwfmpvtTg==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "acorn": "bin/acorn"
      },
      "engines": {
        "node": ">=0.4.0"
      }
    },
    "node_modules/acorn-jsx": {
      "version": "5.3.2",
      "resolved": "https://registry.npmjs.org/acorn-jsx/-/acorn-jsx-5.3.2.tgz",
      "integrity": "sha512-rq9s+JNhf0IChjtDXxllJ7g41oZk5SlXtp0LHwyA5cejwn7vKmKp4pPri6YEePv2PU65sAsegbXtIinmDFDXgQ==",
      "dev": true,
      "license": "MIT",
      "peerDependencies": {
        "acorn": "^6.0.0 || ^7.0.0 || ^8.0.0"
      }
    },
    "node_modules/ajv": {
      "version": "6.12.6",
      "resolved": "https://registry.npmjs.org/ajv/-/ajv-6.12.6.tgz",
      "integrity": "sha512-j3fVLgvTo527anyYyJOGTYJbG+vnnQYvE0m5mmkc1TK+nxAppkCLMIL0aZ4dblVCNoGShhm+kzE4ZUykBoMg4g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "fast-deep-equal": "^3.1.1",
        "fast-json-stable-stringify": "^2.0.0",
        "json-schema-traverse": "^0.4.1",
        "uri-js": "^4.2.2"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/epoberezkin"
      }
    },
    "node_modules/ansi-regex": {
      "version": "6.1.0",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-6.1.0.tgz",
      "integrity": "sha512-7HSX4QQb4CspciLpVFwyRe79O3xsIZDDLER21kERQ71oaPodF8jL725AgJMFAYbooIqolJoRLuM81SpeUkpkvA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-regex?sponsor=1"
      }
    },
    "node_modules/ansi-styles": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-4.3.0.tgz",
      "integrity": "sha512-zbB9rCJAT1rbjiVDb2hqKFHNYLxgtk8NURxZ3IZwD3F6NtxbXZQCnnSi1Lkx+IDohdPlFp222wVALIheZJQSEg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "color-convert": "^2.0.1"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/any-promise": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/any-promise/-/any-promise-1.3.0.tgz",
      "integrity": "sha512-7UvmKalWRt1wgjL1RrGxoSJW/0QZFIegpeGvZG9kjp8vrRu55XTHbwnqq2GpXm9uLbcuhxm3IqX9OB4MZR1b2A==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/anymatch": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/anymatch/-/anymatch-3.1.3.tgz",
      "integrity": "sha512-KMReFUr0B4t+D+OBkjR3KYqvocp2XaSzO55UcB6mgQMd3KbcE+mWTyvVV7D/zsdEbNnV6acZUutkiHQXvTr1Rw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "normalize-path": "^3.0.0",
        "picomatch": "^2.0.4"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/arg": {
      "version": "5.0.2",
      "resolved": "https://registry.npmjs.org/arg/-/arg-5.0.2.tgz",
      "integrity": "sha512-PYjyFOLKQ9y57JvQ6QLo8dAgNqswh8M1RMJYdQduT6xbWSgK36P/Z/v+p888pM69jMMfS8Xd8F6I1kQ/I9HUGg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/argparse": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/argparse/-/argparse-2.0.1.tgz",
      "integrity": "sha512-8+9WqebbFzpX9OR+Wa6O29asIogeRMzcGtAINdpMHHyAg10f05aSFVBbcEqGf/PXw1EjAZ+q2/bEBg3DvurK3Q==",
      "dev": true,
      "license": "Python-2.0"
    },
    "node_modules/aria-hidden": {
      "version": "1.2.4",
      "resolved": "https://registry.npmjs.org/aria-hidden/-/aria-hidden-1.2.4.tgz",
      "integrity": "sha512-y+CcFFwelSXpLZk/7fMB2mUbGtX9lKycf1MWJ7CaTIERyitVlyQx6C+sxcROU2BAJ24OiZyK+8wj2i8AlBoS3A==",
      "license": "MIT",
      "dependencies": {
        "tslib": "^2.0.0"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/asynckit": {
      "version": "0.4.0",
      "resolved": "https://registry.npmjs.org/asynckit/-/asynckit-0.4.0.tgz",
      "integrity": "sha512-Oei9OH4tRh0YqU3GxhX79dM/mwVgvbZJaSNaRk+bshkj0S5cfHcgYakreBjrHwatXKbz+IoIdYLxrKim2MjW0Q==",
      "license": "MIT"
    },
    "node_modules/autoprefixer": {
      "version": "10.4.21",
      "resolved": "https://registry.npmjs.org/autoprefixer/-/autoprefixer-10.4.21.tgz",
      "integrity": "sha512-O+A6LWV5LDHSJD3LjHYoNi4VLsj/Whi7k6zG12xTYaU4cQ8oxQGckXNX8cRHK5yOZ/ppVHe0ZBXGzSV9jXdVbQ==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/autoprefixer"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "browserslist": "^4.24.4",
        "caniuse-lite": "^1.0.30001702",
        "fraction.js": "^4.3.7",
        "normalize-range": "^0.1.2",
        "picocolors": "^1.1.1",
        "postcss-value-parser": "^4.2.0"
      },
      "bin": {
        "autoprefixer": "bin/autoprefixer"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      },
      "peerDependencies": {
        "postcss": "^8.1.0"
      }
    },
    "node_modules/axios": {
      "version": "1.13.2",
      "resolved": "https://registry.npmjs.org/axios/-/axios-1.13.2.tgz",
      "integrity": "sha512-VPk9ebNqPcy5lRGuSlKx752IlDatOjT9paPlm8A7yOuW2Fbvp4X3JznJtT4f0GzGLLiWE9W8onz51SqLYwzGaA==",
      "license": "MIT",
      "dependencies": {
        "follow-redirects": "^1.15.6",
        "form-data": "^4.0.4",
        "proxy-from-env": "^1.1.0"
      }
    },
    "node_modules/bail": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/bail/-/bail-2.0.2.tgz",
      "integrity": "sha512-0xO6mYd7JB2YesxDKplafRpsiOzPt9V02ddPCLbY1xYGPOX24NTyN50qnUxgCPcSoYMhKpAuBTjQoRZCAkUDRw==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/balanced-match": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/balanced-match/-/balanced-match-1.0.2.tgz",
      "integrity": "sha512-3oSeUO0TMV67hN1AmbXsK4yaqU7tjiHlbxRDZOpH0KW9+CeX4bRAaX0Anxt0tx2MrpRpWwQaPwIlISEJhYU5Pw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/binary-extensions": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/binary-extensions/-/binary-extensions-2.3.0.tgz",
      "integrity": "sha512-Ceh+7ox5qe7LJuLHoY0feh3pHuUDHAcRUeyL2VYghZwfpkNIy/+8Ocg0a3UuSoYzavmylwuLWQOf3hl0jjMMIw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/brace-expansion": {
      "version": "1.1.12",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.12.tgz",
      "integrity": "sha512-9T9UjW3r0UW5c1Q7GTwllptXwhvYmEzFhzMfZ9H7FQWt+uZePjZPjBP/W1ZEyZ1twGWom5/56TF4lPcqjnDHcg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0",
        "concat-map": "0.0.1"
      }
    },
    "node_modules/braces": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/braces/-/braces-3.0.3.tgz",
      "integrity": "sha512-yQbXgO/OSZVD2IsiLlro+7Hf6Q18EJrKSEsdoMzKePKXct3gvD8oLcOQdIzGupr5Fj+EDe8gO/lxc1BzfMpxvA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "fill-range": "^7.1.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/browserslist": {
      "version": "4.25.1",
      "resolved": "https://registry.npmjs.org/browserslist/-/browserslist-4.25.1.tgz",
      "integrity": "sha512-KGj0KoOMXLpSNkkEI6Z6mShmQy0bc1I+T7K9N81k4WWMrfz+6fQ6es80B/YLAeRoKvjYE1YSHHOW1qe9xIVzHw==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/browserslist"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "caniuse-lite": "^1.0.30001726",
        "electron-to-chromium": "^1.5.173",
        "node-releases": "^2.0.19",
        "update-browserslist-db": "^1.1.3"
      },
      "bin": {
        "browserslist": "cli.js"
      },
      "engines": {
        "node": "^6 || ^7 || ^8 || ^9 || ^10 || ^11 || ^12 || >=13.7"
      }
    },
    "node_modules/call-bind-apply-helpers": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/call-bind-apply-helpers/-/call-bind-apply-helpers-1.0.2.tgz",
      "integrity": "sha512-Sp1ablJ0ivDkSzjcaJdxEunN5/XvksFJ2sMBFfq6x0ryhQV/2b/KwFe21cMpmHtPOSij8K99/wSfoEuTObmuMQ==",
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/callsites": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/callsites/-/callsites-3.1.0.tgz",
      "integrity": "sha512-P8BjAsXvZS+VIDUI11hHCQEv74YT67YUi5JJFNWIqL235sBmjX4+qx9Muvls5ivyNENctx46xQLQ3aTuE7ssaQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/camelcase-css": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/camelcase-css/-/camelcase-css-2.0.1.tgz",
      "integrity": "sha512-QOSvevhslijgYwRx6Rv7zKdMF8lbRmx+uQGx2+vDc+KI/eBnsy9kit5aj23AgGu3pa4t9AgwbnXWqS+iOY+2aA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/caniuse-lite": {
      "version": "1.0.30001727",
      "resolved": "https://registry.npmjs.org/caniuse-lite/-/caniuse-lite-1.0.30001727.tgz",
      "integrity": "sha512-pB68nIHmbN6L/4C6MH1DokyR3bYqFwjaSs/sWDHGj4CTcFtQUQMuJftVwWkXq7mNWOybD3KhUv3oWHoGxgP14Q==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/caniuse-lite"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "CC-BY-4.0"
    },
    "node_modules/ccount": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/ccount/-/ccount-2.0.1.tgz",
      "integrity": "sha512-eyrF0jiFpY+3drT6383f1qhkbGsLSifNAjA61IUjZjmLCWjItY6LB9ft9YhoDgwfmclB2zhu51Lc7+95b8NRAg==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/chalk": {
      "version": "4.1.2",
      "resolved": "https://registry.npmjs.org/chalk/-/chalk-4.1.2.tgz",
      "integrity": "sha512-oKnbhFyRIXpUuez8iBMmyEa4nbj4IOQyuhc/wy9kY7/WVPcwIO9VA668Pu8RkO7+0G76SLROeyw9CpQ061i4mA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^4.1.0",
        "supports-color": "^7.1.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/chalk?sponsor=1"
      }
    },
    "node_modules/character-entities": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/character-entities/-/character-entities-2.0.2.tgz",
      "integrity": "sha512-shx7oQ0Awen/BRIdkjkvz54PnEEI/EjwXDSIZp86/KKdbafHh1Df/RYGBhn4hbe2+uKC9FnT5UCEdyPz3ai9hQ==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/character-entities-html4": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/character-entities-html4/-/character-entities-html4-2.1.0.tgz",
      "integrity": "sha512-1v7fgQRj6hnSwFpq1Eu0ynr/CDEw0rXo2B61qXrLNdHZmPKgb7fqS1a2JwF0rISo9q77jDI8VMEHoApn8qDoZA==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/character-entities-legacy": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/character-entities-legacy/-/character-entities-legacy-3.0.0.tgz",
      "integrity": "sha512-RpPp0asT/6ufRm//AJVwpViZbGM/MkjQFxJccQRHmISF/22NBtsHqAWmL+/pmkPWoIUJdWyeVleTl1wydHATVQ==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/character-reference-invalid": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/character-reference-invalid/-/character-reference-invalid-2.0.1.tgz",
      "integrity": "sha512-iBZ4F4wRbyORVsu0jPV7gXkOsGYjGHPmAyv+HiHG8gi5PtC9KI2j1+v8/tlibRvjoWX027ypmG/n0HtO5t7unw==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/chart.js": {
      "version": "4.5.1",
      "resolved": "https://registry.npmjs.org/chart.js/-/chart.js-4.5.1.tgz",
      "integrity": "sha512-GIjfiT9dbmHRiYi6Nl2yFCq7kkwdkp1W/lp2J99rX0yo9tgJGn3lKQATztIjb5tVtevcBtIdICNWqlq5+E8/Pw==",
      "license": "MIT",
      "dependencies": {
        "@kurkle/color": "^0.3.0"
      },
      "engines": {
        "pnpm": ">=8"
      }
    },
    "node_modules/chokidar": {
      "version": "3.6.0",
      "resolved": "https://registry.npmjs.org/chokidar/-/chokidar-3.6.0.tgz",
      "integrity": "sha512-7VT13fmjotKpGipCW9JEQAusEPE+Ei8nl6/g4FBAmIm0GOOLMua9NDDo/DWp0ZAxCr3cPq5ZpBqmPAQgDda2Pw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "anymatch": "~3.1.2",
        "braces": "~3.0.2",
        "glob-parent": "~5.1.2",
        "is-binary-path": "~2.1.0",
        "is-glob": "~4.0.1",
        "normalize-path": "~3.0.0",
        "readdirp": "~3.6.0"
      },
      "engines": {
        "node": ">= 8.10.0"
      },
      "funding": {
        "url": "https://paulmillr.com/funding/"
      },
      "optionalDependencies": {
        "fsevents": "~2.3.2"
      }
    },
    "node_modules/chokidar/node_modules/glob-parent": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-5.1.2.tgz",
      "integrity": "sha512-AOIgSQCepiJYwP3ARnGx+5VnTu2HBYdzbGP45eLw1vr3zB3vZLeyed1sC9hnbcOc9/SrMyM5RPQrkGz4aS9Zow==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "is-glob": "^4.0.1"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/class-variance-authority": {
      "version": "0.7.1",
      "resolved": "https://registry.npmjs.org/class-variance-authority/-/class-variance-authority-0.7.1.tgz",
      "integrity": "sha512-Ka+9Trutv7G8M6WT6SeiRWz792K5qEqIGEGzXKhAE6xOWAY6pPH8U+9IY3oCMv6kqTmLsv7Xh/2w2RigkePMsg==",
      "dependencies": {
        "clsx": "^2.1.1"
      },
      "funding": {
        "url": "https://polar.sh/cva"
      }
    },
    "node_modules/clsx": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/clsx/-/clsx-2.1.1.tgz",
      "integrity": "sha512-eYm0QWBtUrBWZWG0d386OGAw16Z995PiOVo2B7bjWSbHedGl5e0ZWaq65kOGgUSNesEIDkB9ISbTg/JK9dhCZA==",
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/cmdk": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/cmdk/-/cmdk-1.1.1.tgz",
      "integrity": "sha512-Vsv7kFaXm+ptHDMZ7izaRsP70GgrW9NBNGswt9OZaVBLlE0SNpDq8eu/VGXyF9r7M0azK3Wy7OlYXsuyYLFzHg==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-compose-refs": "^1.1.1",
        "@radix-ui/react-dialog": "^1.1.6",
        "@radix-ui/react-id": "^1.1.0",
        "@radix-ui/react-primitive": "^2.0.2"
      },
      "peerDependencies": {
        "react": "^18 || ^19 || ^19.0.0-rc",
        "react-dom": "^18 || ^19 || ^19.0.0-rc"
      }
    },
    "node_modules/color-convert": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/color-convert/-/color-convert-2.0.1.tgz",
      "integrity": "sha512-RRECPsj7iu/xb5oKYcsFHSppFNnsj/52OVTRKb4zP5onXwVF3zVmmToNcOfGC+CRDpfK/U584fMg38ZHCaElKQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "color-name": "~1.1.4"
      },
      "engines": {
        "node": ">=7.0.0"
      }
    },
    "node_modules/color-name": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/color-name/-/color-name-1.1.4.tgz",
      "integrity": "sha512-dOy+3AuW3a2wNbZHIuMZpTcgjGuLU/uBL/ubcZF9OXbDo8ff4O8yVp5Bf0efS8uEoYo5q4Fx7dY9OgQGXgAsQA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/combined-stream": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/combined-stream/-/combined-stream-1.0.8.tgz",
      "integrity": "sha512-FQN4MRfuJeHf7cBbBMJFXhKSDq+2kAArBlmRBvcvFE5BB1HZKXtSFASDhdlz9zOYwxh8lDdnvmMOe/+5cdoEdg==",
      "license": "MIT",
      "dependencies": {
        "delayed-stream": "~1.0.0"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/comma-separated-tokens": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/comma-separated-tokens/-/comma-separated-tokens-2.0.3.tgz",
      "integrity": "sha512-Fu4hJdvzeylCfQPp9SGWidpzrMs7tTrlu6Vb8XGaRGck8QSNZJJp538Wrb60Lax4fPwR64ViY468OIUTbRlGZg==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/commander": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/commander/-/commander-4.1.1.tgz",
      "integrity": "sha512-NOKm8xhkzAjzFx8B2v5OAHT+u5pRQc2UCa2Vq9jYL/31o2wi9mxBA7LIFs3sV5VSC49z6pEhfbMULvShKj26WA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/concat-map": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/concat-map/-/concat-map-0.0.1.tgz",
      "integrity": "sha512-/Srv4dswyQNBfohGpz9o6Yb3Gz3SrUDqBH5rTuhGR7ahtlbYKnVxw2bCFMRljaA7EXHaXZ8wsHdodFvbkhKmqg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/cross-spawn": {
      "version": "7.0.6",
      "resolved": "https://registry.npmjs.org/cross-spawn/-/cross-spawn-7.0.6.tgz",
      "integrity": "sha512-uV2QOWP2nWzsy2aMp8aRibhi9dlzF5Hgh5SHaB9OiTGEyDTiJJyx0uy51QXdyWbtAHNua4XJzUKca3OzKUd3vA==",
      "dev": true,
      "dependencies": {
        "path-key": "^3.1.0",
        "shebang-command": "^2.0.0",
        "which": "^2.0.1"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/cssesc": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/cssesc/-/cssesc-3.0.0.tgz",
      "integrity": "sha512-/Tb/JcjK111nNScGob5MNtsntNM1aCNUDipB/TkwZFhyDrrE47SOx/18wF2bbjgc3ZzCSKW1T5nt5EbFoAz/Vg==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "cssesc": "bin/cssesc"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/csstype": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/csstype/-/csstype-3.1.3.tgz",
      "integrity": "sha512-M1uQkMl8rQK/szD0LNhtqxIPLpimGm8sOBwU7lLnCpSbTyY3yeU1Vc7l4KT5zT4s/yOxHH5O7tIuuLOCnLADRw==",
      "license": "MIT"
    },
    "node_modules/d3-array": {
      "version": "3.2.4",
      "resolved": "https://registry.npmjs.org/d3-array/-/d3-array-3.2.4.tgz",
      "integrity": "sha512-tdQAmyA18i4J7wprpYq8ClcxZy3SC31QMeByyCFyRt7BVHdREQZ5lpzoe5mFEYZUWe+oq8HBvk9JjpibyEV4Jg==",
      "license": "ISC",
      "dependencies": {
        "internmap": "1 - 2"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-cloud": {
      "version": "1.2.7",
      "resolved": "https://registry.npmjs.org/d3-cloud/-/d3-cloud-1.2.7.tgz",
      "integrity": "sha512-8TrgcgwRIpoZYQp7s3fGB7tATWfhckRb8KcVd1bOgqkNdkJRDGWfdSf4HkHHzZxSczwQJdSxvfPudwir5IAJ3w==",
      "license": "BSD-3-Clause",
      "dependencies": {
        "d3-dispatch": "^1.0.3"
      }
    },
    "node_modules/d3-color": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/d3-color/-/d3-color-3.1.0.tgz",
      "integrity": "sha512-zg/chbXyeBtMQ1LbD/WSoW2DpC3I0mpmPdW+ynRTj/x2DAWYrIY7qeZIHidozwV24m4iavr15lNwIwLxRmOxhA==",
      "license": "ISC",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-dispatch": {
      "version": "1.0.6",
      "resolved": "https://registry.npmjs.org/d3-dispatch/-/d3-dispatch-1.0.6.tgz",
      "integrity": "sha512-fVjoElzjhCEy+Hbn8KygnmMS7Or0a9sI2UzGwoB7cCtvI1XpVN9GpoYlnb3xt2YV66oXYb1fLJ8GMvP4hdU1RA==",
      "license": "BSD-3-Clause"
    },
    "node_modules/d3-ease": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/d3-ease/-/d3-ease-3.0.1.tgz",
      "integrity": "sha512-wR/XK3D3XcLIZwpbvQwQ5fK+8Ykds1ip7A2Txe0yxncXSdq1L9skcG7blcedkOX+ZcgxGAmLX1FrRGbADwzi0w==",
      "license": "BSD-3-Clause",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-format": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/d3-format/-/d3-format-3.1.0.tgz",
      "integrity": "sha512-YyUI6AEuY/Wpt8KWLgZHsIU86atmikuoOmCfommt0LYHiQSPjvX2AcFc38PX0CBpr2RCyZhjex+NS/LPOv6YqA==",
      "license": "ISC",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-interpolate": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/d3-interpolate/-/d3-interpolate-3.0.1.tgz",
      "integrity": "sha512-3bYs1rOD33uo8aqJfKP3JWPAibgw8Zm2+L9vBKEHJ2Rg+viTR7o5Mmv5mZcieN+FRYaAOWX5SJATX6k1PWz72g==",
      "license": "ISC",
      "dependencies": {
        "d3-color": "1 - 3"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-path": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/d3-path/-/d3-path-3.1.0.tgz",
      "integrity": "sha512-p3KP5HCf/bvjBSSKuXid6Zqijx7wIfNW+J/maPs+iwR35at5JCbLUT0LzF1cnjbCHWhqzQTIN2Jpe8pRebIEFQ==",
      "license": "ISC",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-scale": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/d3-scale/-/d3-scale-4.0.2.tgz",
      "integrity": "sha512-GZW464g1SH7ag3Y7hXjf8RoUuAFIqklOAq3MRl4OaWabTFJY9PN/E1YklhXLh+OQ3fM9yS2nOkCoS+WLZ6kvxQ==",
      "license": "ISC",
      "dependencies": {
        "d3-array": "2.10.0 - 3",
        "d3-format": "1 - 3",
        "d3-interpolate": "1.2.0 - 3",
        "d3-time": "2.1.1 - 3",
        "d3-time-format": "2 - 4"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-scale-chromatic": {
      "version": "1.5.0",
      "resolved": "https://registry.npmjs.org/d3-scale-chromatic/-/d3-scale-chromatic-1.5.0.tgz",
      "integrity": "sha512-ACcL46DYImpRFMBcpk9HhtIyC7bTBR4fNOPxwVSl0LfulDAwyiHyPOTqcDG1+t5d4P9W7t/2NAuWu59aKko/cg==",
      "license": "BSD-3-Clause",
      "dependencies": {
        "d3-color": "1",
        "d3-interpolate": "1"
      }
    },
    "node_modules/d3-scale-chromatic/node_modules/d3-color": {
      "version": "1.4.1",
      "resolved": "https://registry.npmjs.org/d3-color/-/d3-color-1.4.1.tgz",
      "integrity": "sha512-p2sTHSLCJI2QKunbGb7ocOh7DgTAn8IrLx21QRc/BSnodXM4sv6aLQlnfpvehFMLZEfBc6g9pH9SWQccFYfJ9Q==",
      "license": "BSD-3-Clause"
    },
    "node_modules/d3-scale-chromatic/node_modules/d3-interpolate": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/d3-interpolate/-/d3-interpolate-1.4.0.tgz",
      "integrity": "sha512-V9znK0zc3jOPV4VD2zZn0sDhZU3WAE2bmlxdIwwQPPzPjvyLkd8B3JUVdS1IDUFDkWZ72c9qnv1GK2ZagTZ8EA==",
      "license": "BSD-3-Clause",
      "dependencies": {
        "d3-color": "1"
      }
    },
    "node_modules/d3-selection": {
      "version": "1.4.2",
      "resolved": "https://registry.npmjs.org/d3-selection/-/d3-selection-1.4.2.tgz",
      "integrity": "sha512-SJ0BqYihzOjDnnlfyeHT0e30k0K1+5sR3d5fNueCNeuhZTnGw4M4o8mqJchSwgKMXCNFo+e2VTChiSJ0vYtXkg==",
      "license": "BSD-3-Clause"
    },
    "node_modules/d3-shape": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/d3-shape/-/d3-shape-3.2.0.tgz",
      "integrity": "sha512-SaLBuwGm3MOViRq2ABk3eLoxwZELpH6zhl3FbAoJ7Vm1gofKx6El1Ib5z23NUEhF9AsGl7y+dzLe5Cw2AArGTA==",
      "license": "ISC",
      "dependencies": {
        "d3-path": "^3.1.0"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-time": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/d3-time/-/d3-time-3.1.0.tgz",
      "integrity": "sha512-VqKjzBLejbSMT4IgbmVgDjpkYrNWUYJnbCGo874u7MMKIWsILRX+OpX/gTk8MqjpT1A/c6HY2dCA77ZN0lkQ2Q==",
      "license": "ISC",
      "dependencies": {
        "d3-array": "2 - 3"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-time-format": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/d3-time-format/-/d3-time-format-4.1.0.tgz",
      "integrity": "sha512-dJxPBlzC7NugB2PDLwo9Q8JiTR3M3e4/XANkreKSUxF8vvXKqm1Yfq4Q5dl8budlunRVlUUaDUgFt7eA8D6NLg==",
      "license": "ISC",
      "dependencies": {
        "d3-time": "1 - 3"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-timer": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/d3-timer/-/d3-timer-3.0.1.tgz",
      "integrity": "sha512-ndfJ/JxxMd3nw31uyKoY2naivF+r29V+Lc0svZxe1JvvIRmi8hUsrMvdOwgS1o6uBHmiz91geQ0ylPP0aj1VUA==",
      "license": "ISC",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-transition": {
      "version": "1.3.2",
      "resolved": "https://registry.npmjs.org/d3-transition/-/d3-transition-1.3.2.tgz",
      "integrity": "sha512-sc0gRU4PFqZ47lPVHloMn9tlPcv8jxgOQg+0zjhfZXMQuvppjG6YuwdMBE0TuqCZjeJkLecku/l9R0JPcRhaDA==",
      "license": "BSD-3-Clause",
      "dependencies": {
        "d3-color": "1",
        "d3-dispatch": "1",
        "d3-ease": "1",
        "d3-interpolate": "1",
        "d3-selection": "^1.1.0",
        "d3-timer": "1"
      }
    },
    "node_modules/d3-transition/node_modules/d3-color": {
      "version": "1.4.1",
      "resolved": "https://registry.npmjs.org/d3-color/-/d3-color-1.4.1.tgz",
      "integrity": "sha512-p2sTHSLCJI2QKunbGb7ocOh7DgTAn8IrLx21QRc/BSnodXM4sv6aLQlnfpvehFMLZEfBc6g9pH9SWQccFYfJ9Q==",
      "license": "BSD-3-Clause"
    },
    "node_modules/d3-transition/node_modules/d3-ease": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/d3-ease/-/d3-ease-1.0.7.tgz",
      "integrity": "sha512-lx14ZPYkhNx0s/2HX5sLFUI3mbasHjSSpwO/KaaNACweVwxUruKyWVcb293wMv1RqTPZyZ8kSZ2NogUZNcLOFQ==",
      "license": "BSD-3-Clause"
    },
    "node_modules/d3-transition/node_modules/d3-interpolate": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/d3-interpolate/-/d3-interpolate-1.4.0.tgz",
      "integrity": "sha512-V9znK0zc3jOPV4VD2zZn0sDhZU3WAE2bmlxdIwwQPPzPjvyLkd8B3JUVdS1IDUFDkWZ72c9qnv1GK2ZagTZ8EA==",
      "license": "BSD-3-Clause",
      "dependencies": {
        "d3-color": "1"
      }
    },
    "node_modules/d3-transition/node_modules/d3-timer": {
      "version": "1.0.10",
      "resolved": "https://registry.npmjs.org/d3-timer/-/d3-timer-1.0.10.tgz",
      "integrity": "sha512-B1JDm0XDaQC+uvo4DT79H0XmBskgS3l6Ve+1SBCfxgmtIb1AVrPIoqd+nPSv+loMX8szQ0sVUhGngL7D5QPiXw==",
      "license": "BSD-3-Clause"
    },
    "node_modules/date-fns": {
      "version": "3.6.0",
      "resolved": "https://registry.npmjs.org/date-fns/-/date-fns-3.6.0.tgz",
      "integrity": "sha512-fRHTG8g/Gif+kSh50gaGEdToemgfj74aRX3swtiouboip5JDLAyDE9F11nHMIcvOaXeOC6D7SpNhi7uFyB7Uww==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/kossnocorp"
      }
    },
    "node_modules/debug": {
      "version": "4.3.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.3.7.tgz",
      "integrity": "sha512-Er2nc/H7RrMXZBFCEim6TCmMk02Z8vLC2Rbi1KEBggpo0fS6l0S1nnapwmIi3yW/+GOJap1Krg4w0Hg80oCqgQ==",
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/decimal.js-light": {
      "version": "2.5.1",
      "resolved": "https://registry.npmjs.org/decimal.js-light/-/decimal.js-light-2.5.1.tgz",
      "integrity": "sha512-qIMFpTMZmny+MMIitAB6D7iVPEorVw6YQRWkvarTkT4tBeSLLiHzcwj6q0MmYSFCiVpiqPJTJEYIrpcPzVEIvg==",
      "license": "MIT"
    },
    "node_modules/decode-named-character-reference": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/decode-named-character-reference/-/decode-named-character-reference-1.2.0.tgz",
      "integrity": "sha512-c6fcElNV6ShtZXmsgNgFFV5tVX2PaV4g+MOAkb8eXHvn6sryJBrZa9r0zV6+dtTyoCKxtDy5tyQ5ZwQuidtd+Q==",
      "license": "MIT",
      "dependencies": {
        "character-entities": "^2.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/deep-is": {
      "version": "0.1.4",
      "resolved": "https://registry.npmjs.org/deep-is/-/deep-is-0.1.4.tgz",
      "integrity": "sha512-oIPzksmTg4/MriiaYGO+okXDT7ztn/w3Eptv/+gSIdMdKsJo0u4CfYNFJPy+4SKMuCqGw2wxnA+URMg3t8a/bQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/delayed-stream": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/delayed-stream/-/delayed-stream-1.0.0.tgz",
      "integrity": "sha512-ZySD7Nf91aLB0RxL4KGrKHBXl7Eds1DAmEdcoVawXnLD7SDhpNgtuII2aAkg7a7QS41jxPSZ17p4VdGnMHk3MQ==",
      "license": "MIT",
      "engines": {
        "node": ">=0.4.0"
      }
    },
    "node_modules/dequal": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/dequal/-/dequal-2.0.3.tgz",
      "integrity": "sha512-0je+qPKHEMohvfRTCEo3CrPG6cAzAYgmzKyxRiYSSDkS6eGJdyVJm7WaYA5ECaAD9wLB2T4EEeymA5aFVcYXCA==",
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/detect-node-es": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/detect-node-es/-/detect-node-es-1.1.0.tgz",
      "integrity": "sha512-ypdmJU/TbBby2Dxibuv7ZLW3Bs1QEmM7nHjEANfohJLvE0XVujisn1qPJcZxg+qDucsr+bP6fLD1rPS3AhJ7EQ==",
      "license": "MIT"
    },
    "node_modules/devlop": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/devlop/-/devlop-1.1.0.tgz",
      "integrity": "sha512-RWmIqhcFf1lRYBvNmr7qTNuyCt/7/ns2jbpp1+PalgE/rDQcBT0fioSMUpJ93irlUhC5hrg4cYqe6U+0ImW0rA==",
      "license": "MIT",
      "dependencies": {
        "dequal": "^2.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/didyoumean": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/didyoumean/-/didyoumean-1.2.2.tgz",
      "integrity": "sha512-gxtyfqMg7GKyhQmb056K7M3xszy/myH8w+B4RT+QXBQsvAOdc3XymqDDPHx1BgPgsdAA5SIifona89YtRATDzw==",
      "dev": true,
      "license": "Apache-2.0"
    },
    "node_modules/dlv": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/dlv/-/dlv-1.1.3.tgz",
      "integrity": "sha512-+HlytyjlPKnIG8XuRG8WvmBP8xs8P71y+SKKS6ZXWoEgLuePxtDoUEiH7WkdePWrQ5JBpE6aoVqfZfJUQkjXwA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/dom-helpers": {
      "version": "5.2.1",
      "resolved": "https://registry.npmjs.org/dom-helpers/-/dom-helpers-5.2.1.tgz",
      "integrity": "sha512-nRCa7CK3VTrM2NmGkIy4cbK7IZlgBE/PYMn55rrXefr5xXDP0LdtfPnblFDoVdcAfslJ7or6iqAUnx0CCGIWQA==",
      "license": "MIT",
      "dependencies": {
        "@babel/runtime": "^7.8.7",
        "csstype": "^3.0.2"
      }
    },
    "node_modules/dunder-proto": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/dunder-proto/-/dunder-proto-1.0.1.tgz",
      "integrity": "sha512-KIN/nDJBQRcXw0MLVhZE9iQHmG68qAVIBg9CqmUYjmQIhgij9U5MFvrqkUL5FbtyyzZuOeOt0zdeRe4UY7ct+A==",
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.1",
        "es-errors": "^1.3.0",
        "gopd": "^1.2.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/eastasianwidth": {
      "version": "0.2.0",
      "resolved": "https://registry.npmjs.org/eastasianwidth/-/eastasianwidth-0.2.0.tgz",
      "integrity": "sha512-I88TYZWc9XiYHRQ4/3c5rjjfgkjhLyW2luGIheGERbNQ6OY7yTybanSpDXZa8y7VUP9YmDcYa+eyq4ca7iLqWA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/electron-to-chromium": {
      "version": "1.5.192",
      "resolved": "https://registry.npmjs.org/electron-to-chromium/-/electron-to-chromium-1.5.192.tgz",
      "integrity": "sha512-rP8Ez0w7UNw/9j5eSXCe10o1g/8B1P5SM90PCCMVkIRQn2R0LEHWz4Eh9RnxkniuDe1W0cTSOB3MLlkTGDcuCg==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/embla-carousel": {
      "version": "8.6.0",
      "resolved": "https://registry.npmjs.org/embla-carousel/-/embla-carousel-8.6.0.tgz",
      "integrity": "sha512-SjWyZBHJPbqxHOzckOfo8lHisEaJWmwd23XppYFYVh10bU66/Pn5tkVkbkCMZVdbUE5eTCI2nD8OyIP4Z+uwkA==",
      "license": "MIT"
    },
    "node_modules/embla-carousel-react": {
      "version": "8.6.0",
      "resolved": "https://registry.npmjs.org/embla-carousel-react/-/embla-carousel-react-8.6.0.tgz",
      "integrity": "sha512-0/PjqU7geVmo6F734pmPqpyHqiM99olvyecY7zdweCw+6tKEXnrE90pBiBbMMU8s5tICemzpQ3hi5EpxzGW+JA==",
      "license": "MIT",
      "dependencies": {
        "embla-carousel": "8.6.0",
        "embla-carousel-reactive-utils": "8.6.0"
      },
      "peerDependencies": {
        "react": "^16.8.0 || ^17.0.1 || ^18.0.0 || ^19.0.0 || ^19.0.0-rc"
      }
    },
    "node_modules/embla-carousel-reactive-utils": {
      "version": "8.6.0",
      "resolved": "https://registry.npmjs.org/embla-carousel-reactive-utils/-/embla-carousel-reactive-utils-8.6.0.tgz",
      "integrity": "sha512-fMVUDUEx0/uIEDM0Mz3dHznDhfX+znCCDCeIophYb1QGVM7YThSWX+wz11zlYwWFOr74b4QLGg0hrGPJeG2s4A==",
      "license": "MIT",
      "peerDependencies": {
        "embla-carousel": "8.6.0"
      }
    },
    "node_modules/emoji-regex": {
      "version": "9.2.2",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-9.2.2.tgz",
      "integrity": "sha512-L18DaJsXSUk2+42pv8mLs5jJT2hqFkFE4j21wOmgbUqsZ2hL72NsUU785g9RXgo3s0ZNgVl42TiHp3ZtOv/Vyg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/es-define-property": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/es-define-property/-/es-define-property-1.0.1.tgz",
      "integrity": "sha512-e3nRfgfUZ4rNGL232gUgX06QNyyez04KdjFrF+LTRoOXmrOgFKDg4BCdsjW8EnT69eqdYGmRpJwiPVYNrCaW3g==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-errors": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/es-errors/-/es-errors-1.3.0.tgz",
      "integrity": "sha512-Zf5H2Kxt2xjTvbJvP2ZWLEICxA6j+hAmMzIlypy4xcBg1vKVnx89Wy0GbS+kf5cwCVFFzdCFh2XSCFNULS6csw==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-object-atoms": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/es-object-atoms/-/es-object-atoms-1.1.1.tgz",
      "integrity": "sha512-FGgH2h8zKNim9ljj7dankFPcICIK9Cp5bm+c2gQSYePhpaG5+esrLODihIorn+Pe6FGJzWhXQotPv73jTaldXA==",
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-set-tostringtag": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/es-set-tostringtag/-/es-set-tostringtag-2.1.0.tgz",
      "integrity": "sha512-j6vWzfrGVfyXxge+O0x5sh6cvxAog0a/4Rdd2K36zCMV5eJ+/+tOAngRO8cODMNWbVRdVlmGZQL2YS3yR8bIUA==",
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.6",
        "has-tostringtag": "^1.0.2",
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/esbuild": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/esbuild/-/esbuild-0.21.5.tgz",
      "integrity": "sha512-mg3OPMV4hXywwpoDxu3Qda5xCKQi+vCTZq8S9J/EpkhB2HzKXq4SNFZE3+NK93JYxc8VMSep+lOUSC/RVKaBqw==",
      "dev": true,
      "hasInstallScript": true,
      "license": "MIT",
      "bin": {
        "esbuild": "bin/esbuild"
      },
      "engines": {
        "node": ">=12"
      },
      "optionalDependencies": {
        "@esbuild/aix-ppc64": "0.21.5",
        "@esbuild/android-arm": "0.21.5",
        "@esbuild/android-arm64": "0.21.5",
        "@esbuild/android-x64": "0.21.5",
        "@esbuild/darwin-arm64": "0.21.5",
        "@esbuild/darwin-x64": "0.21.5",
        "@esbuild/freebsd-arm64": "0.21.5",
        "@esbuild/freebsd-x64": "0.21.5",
        "@esbuild/linux-arm": "0.21.5",
        "@esbuild/linux-arm64": "0.21.5",
        "@esbuild/linux-ia32": "0.21.5",
        "@esbuild/linux-loong64": "0.21.5",
        "@esbuild/linux-mips64el": "0.21.5",
        "@esbuild/linux-ppc64": "0.21.5",
        "@esbuild/linux-riscv64": "0.21.5",
        "@esbuild/linux-s390x": "0.21.5",
        "@esbuild/linux-x64": "0.21.5",
        "@esbuild/netbsd-x64": "0.21.5",
        "@esbuild/openbsd-x64": "0.21.5",
        "@esbuild/sunos-x64": "0.21.5",
        "@esbuild/win32-arm64": "0.21.5",
        "@esbuild/win32-ia32": "0.21.5",
        "@esbuild/win32-x64": "0.21.5"
      }
    },
    "node_modules/escalade": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/escalade/-/escalade-3.2.0.tgz",
      "integrity": "sha512-WUj2qlxaQtO4g6Pq5c29GTcWGDyd8itL8zTlipgECz3JesAiiOKotd8JU6otB3PACgG6xkJUyVhboMS+bje/jA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/escape-string-regexp": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/escape-string-regexp/-/escape-string-regexp-4.0.0.tgz",
      "integrity": "sha512-TtpcNJ3XAzx3Gq8sWRzJaVajRs0uVxA2YAkdb1jm2YkPz4G6egUFAyA3n5vtEIZefPk5Wa4UXbKuS5fKkJWdgA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/eslint": {
      "version": "9.32.0",
      "resolved": "https://registry.npmjs.org/eslint/-/eslint-9.32.0.tgz",
      "integrity": "sha512-LSehfdpgMeWcTZkWZVIJl+tkZ2nuSkyyB9C27MZqFWXuph7DvaowgcTvKqxvpLW1JZIk8PN7hFY3Rj9LQ7m7lg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@eslint-community/eslint-utils": "^4.2.0",
        "@eslint-community/regexpp": "^4.12.1",
        "@eslint/config-array": "^0.21.0",
        "@eslint/config-helpers": "^0.3.0",
        "@eslint/core": "^0.15.0",
        "@eslint/eslintrc": "^3.3.1",
        "@eslint/js": "9.32.0",
        "@eslint/plugin-kit": "^0.3.4",
        "@humanfs/node": "^0.16.6",
        "@humanwhocodes/module-importer": "^1.0.1",
        "@humanwhocodes/retry": "^0.4.2",
        "@types/estree": "^1.0.6",
        "@types/json-schema": "^7.0.15",
        "ajv": "^6.12.4",
        "chalk": "^4.0.0",
        "cross-spawn": "^7.0.6",
        "debug": "^4.3.2",
        "escape-string-regexp": "^4.0.0",
        "eslint-scope": "^8.4.0",
        "eslint-visitor-keys": "^4.2.1",
        "espree": "^10.4.0",
        "esquery": "^1.5.0",
        "esutils": "^2.0.2",
        "fast-deep-equal": "^3.1.3",
        "file-entry-cache": "^8.0.0",
        "find-up": "^5.0.0",
        "glob-parent": "^6.0.2",
        "ignore": "^5.2.0",
        "imurmurhash": "^0.1.4",
        "is-glob": "^4.0.0",
        "json-stable-stringify-without-jsonify": "^1.0.1",
        "lodash.merge": "^4.6.2",
        "minimatch": "^3.1.2",
        "natural-compare": "^1.4.0",
        "optionator": "^0.9.3"
      },
      "bin": {
        "eslint": "bin/eslint.js"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "url": "https://eslint.org/donate"
      },
      "peerDependencies": {
        "jiti": "*"
      },
      "peerDependenciesMeta": {
        "jiti": {
          "optional": true
        }
      }
    },
    "node_modules/eslint-plugin-react-hooks": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/eslint-plugin-react-hooks/-/eslint-plugin-react-hooks-5.2.0.tgz",
      "integrity": "sha512-+f15FfK64YQwZdJNELETdn5ibXEUQmW1DZL6KXhNnc2heoy/sg9VJJeT7n8TlMWouzWqSWavFkIhHyIbIAEapg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "peerDependencies": {
        "eslint": "^3.0.0 || ^4.0.0 || ^5.0.0 || ^6.0.0 || ^7.0.0 || ^8.0.0-0 || ^9.0.0"
      }
    },
    "node_modules/eslint-plugin-react-refresh": {
      "version": "0.4.20",
      "resolved": "https://registry.npmjs.org/eslint-plugin-react-refresh/-/eslint-plugin-react-refresh-0.4.20.tgz",
      "integrity": "sha512-XpbHQ2q5gUF8BGOX4dHe+71qoirYMhApEPZ7sfhF/dNnOF1UXnCMGZf79SFTBO7Bz5YEIT4TMieSlJBWhP9WBA==",
      "dev": true,
      "license": "MIT",
      "peerDependencies": {
        "eslint": ">=8.40"
      }
    },
    "node_modules/eslint-scope": {
      "version": "8.4.0",
      "resolved": "https://registry.npmjs.org/eslint-scope/-/eslint-scope-8.4.0.tgz",
      "integrity": "sha512-sNXOfKCn74rt8RICKMvJS7XKV/Xk9kA7DyJr8mJik3S7Cwgy3qlkkmyS2uQB3jiJg6VNdZd/pDBJu0nvG2NlTg==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "esrecurse": "^4.3.0",
        "estraverse": "^5.2.0"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/eslint-visitor-keys": {
      "version": "4.2.1",
      "resolved": "https://registry.npmjs.org/eslint-visitor-keys/-/eslint-visitor-keys-4.2.1.tgz",
      "integrity": "sha512-Uhdk5sfqcee/9H/rCOJikYz67o0a2Tw2hGRPOG2Y1R2dg7brRe1uG0yaNQDHu+TO/uQPF/5eCapvYSmHUjt7JQ==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/espree": {
      "version": "10.4.0",
      "resolved": "https://registry.npmjs.org/espree/-/espree-10.4.0.tgz",
      "integrity": "sha512-j6PAQ2uUr79PZhBjP5C5fhl8e39FmRnOjsD5lGnWrFU8i2G776tBK7+nP8KuQUTTyAZUwfQqXAgrVH5MbH9CYQ==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "acorn": "^8.15.0",
        "acorn-jsx": "^5.3.2",
        "eslint-visitor-keys": "^4.2.1"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/esquery": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/esquery/-/esquery-1.6.0.tgz",
      "integrity": "sha512-ca9pw9fomFcKPvFLXhBKUK90ZvGibiGOvRJNbjljY7s7uq/5YO4BOzcYtJqExdx99rF6aAcnRxHmcUHcz6sQsg==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "estraverse": "^5.1.0"
      },
      "engines": {
        "node": ">=0.10"
      }
    },
    "node_modules/esrecurse": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/esrecurse/-/esrecurse-4.3.0.tgz",
      "integrity": "sha512-KmfKL3b6G+RXvP8N1vr3Tq1kL/oCFgn2NYXEtqP8/L3pKapUA4G8cFVaoF3SU323CD4XypR/ffioHmkti6/Tag==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "estraverse": "^5.2.0"
      },
      "engines": {
        "node": ">=4.0"
      }
    },
    "node_modules/estraverse": {
      "version": "5.3.0",
      "resolved": "https://registry.npmjs.org/estraverse/-/estraverse-5.3.0.tgz",
      "integrity": "sha512-MMdARuVEQziNTeJD8DgMqmhwR11BRQ/cBP+pLtYdSTnf3MIO8fFeiINEbX36ZdNlfU/7A9f3gUw49B3oQsvwBA==",
      "dev": true,
      "license": "BSD-2-Clause",
      "engines": {
        "node": ">=4.0"
      }
    },
    "node_modules/estree-util-is-identifier-name": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/estree-util-is-identifier-name/-/estree-util-is-identifier-name-3.0.0.tgz",
      "integrity": "sha512-hFtqIDZTIUZ9BXLb8y4pYGyk6+wekIivNVTcmvk8NoOh+VeRn5y6cEHzbURrWbfp1fIqdVipilzj+lfaadNZmg==",
      "license": "MIT",
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/esutils": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/esutils/-/esutils-2.0.3.tgz",
      "integrity": "sha512-kVscqXk4OCp68SZ0dkgEKVi6/8ij300KBWTJq32P/dYeWTSwK41WyTxalN1eRmA5Z9UU/LX9D7FWSmV9SAYx6g==",
      "dev": true,
      "license": "BSD-2-Clause",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/eventemitter3": {
      "version": "4.0.7",
      "resolved": "https://registry.npmjs.org/eventemitter3/-/eventemitter3-4.0.7.tgz",
      "integrity": "sha512-8guHBZCwKnFhYdHr2ysuRWErTwhoN2X8XELRlrRwpmfeY2jjuUN4taQMsULKUVo1K4DvZl+0pgfyoysHxvmvEw==",
      "license": "MIT"
    },
    "node_modules/extend": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/extend/-/extend-3.0.2.tgz",
      "integrity": "sha512-fjquC59cD7CyW6urNXK0FBufkZcoiGG80wTuPujX590cB5Ttln20E2UB4S/WARVqhXffZl2LNgS+gQdPIIim/g==",
      "license": "MIT"
    },
    "node_modules/fast-deep-equal": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/fast-deep-equal/-/fast-deep-equal-3.1.3.tgz",
      "integrity": "sha512-f3qQ9oQy9j2AhBe/H9VC91wLmKBCCU/gDOnKNAYG5hswO7BLKj09Hc5HYNz9cGI++xlpDCIgDaitVs03ATR84Q==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fast-equals": {
      "version": "5.2.2",
      "resolved": "https://registry.npmjs.org/fast-equals/-/fast-equals-5.2.2.tgz",
      "integrity": "sha512-V7/RktU11J3I36Nwq2JnZEM7tNm17eBJz+u25qdxBZeCKiX6BkVSZQjwWIr+IobgnZy+ag73tTZgZi7tr0LrBw==",
      "license": "MIT",
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/fast-glob": {
      "version": "3.3.2",
      "resolved": "https://registry.npmjs.org/fast-glob/-/fast-glob-3.3.2.tgz",
      "integrity": "sha512-oX2ruAFQwf/Orj8m737Y5adxDQO0LAB7/S5MnxCdTNDd4p6BsyIVsv9JQsATbTSq8KHRpLwIHbVlUNatxd+1Ow==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@nodelib/fs.stat": "^2.0.2",
        "@nodelib/fs.walk": "^1.2.3",
        "glob-parent": "^5.1.2",
        "merge2": "^1.3.0",
        "micromatch": "^4.0.4"
      },
      "engines": {
        "node": ">=8.6.0"
      }
    },
    "node_modules/fast-glob/node_modules/glob-parent": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-5.1.2.tgz",
      "integrity": "sha512-AOIgSQCepiJYwP3ARnGx+5VnTu2HBYdzbGP45eLw1vr3zB3vZLeyed1sC9hnbcOc9/SrMyM5RPQrkGz4aS9Zow==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "is-glob": "^4.0.1"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/fast-json-stable-stringify": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/fast-json-stable-stringify/-/fast-json-stable-stringify-2.1.0.tgz",
      "integrity": "sha512-lhd/wF+Lk98HZoTCtlVraHtfh5XYijIjalXck7saUtuanSDyLMxnHhSXEDJqHxD7msR8D0uCmqlkwjCV8xvwHw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fast-levenshtein": {
      "version": "2.0.6",
      "resolved": "https://registry.npmjs.org/fast-levenshtein/-/fast-levenshtein-2.0.6.tgz",
      "integrity": "sha512-DCXu6Ifhqcks7TZKY3Hxp3y6qphY5SJZmrWMDrKcERSOXWQdMhU9Ig/PYrzyw/ul9jOIyh0N4M0tbC5hodg8dw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fastq": {
      "version": "1.17.1",
      "resolved": "https://registry.npmjs.org/fastq/-/fastq-1.17.1.tgz",
      "integrity": "sha512-sRVD3lWVIXWg6By68ZN7vho9a1pQcN/WBFaAAsDDFzlJjvoGx0P8z7V1t72grFJfJhu3YPZBuu25f7Kaw2jN1w==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "reusify": "^1.0.4"
      }
    },
    "node_modules/file-entry-cache": {
      "version": "8.0.0",
      "resolved": "https://registry.npmjs.org/file-entry-cache/-/file-entry-cache-8.0.0.tgz",
      "integrity": "sha512-XXTUwCvisa5oacNGRP9SfNtYBNAMi+RPwBFmblZEF7N7swHYQS6/Zfk7SRwx4D5j3CH211YNRco1DEMNVfZCnQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "flat-cache": "^4.0.0"
      },
      "engines": {
        "node": ">=16.0.0"
      }
    },
    "node_modules/fill-range": {
      "version": "7.1.1",
      "resolved": "https://registry.npmjs.org/fill-range/-/fill-range-7.1.1.tgz",
      "integrity": "sha512-YsGpe3WHLK8ZYi4tWDg2Jy3ebRz2rXowDxnld4bkQB00cc/1Zw9AWnC0i9ztDJitivtQvaI9KaLyKrc+hBW0yg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "to-regex-range": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/find-up": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/find-up/-/find-up-5.0.0.tgz",
      "integrity": "sha512-78/PXT1wlLLDgTzDs7sjq9hzz0vXD+zn+7wypEe4fXQxCmdmqfGsEPQxmiCSQI3ajFV91bVSsvNtrJRiW6nGng==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "locate-path": "^6.0.0",
        "path-exists": "^4.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/flat-cache": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/flat-cache/-/flat-cache-4.0.1.tgz",
      "integrity": "sha512-f7ccFPK3SXFHpx15UIGyRJ/FJQctuKZ0zVuN3frBo4HnK3cay9VEW0R6yPYFHC0AgqhukPzKjq22t5DmAyqGyw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "flatted": "^3.2.9",
        "keyv": "^4.5.4"
      },
      "engines": {
        "node": ">=16"
      }
    },
    "node_modules/flatted": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/flatted/-/flatted-3.3.1.tgz",
      "integrity": "sha512-X8cqMLLie7KsNUDSdzeN8FYK9rEt4Dt67OsG/DNGnYTSDBG4uFAJFBnUeiV+zCVAvwFy56IjM9sH51jVaEhNxw==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/follow-redirects": {
      "version": "1.15.11",
      "resolved": "https://registry.npmjs.org/follow-redirects/-/follow-redirects-1.15.11.tgz",
      "integrity": "sha512-deG2P0JfjrTxl50XGCDyfI97ZGVCxIpfKYmfyrQ54n5FO/0gfIES8C/Psl6kWVDolizcaaxZJnTS0QSMxvnsBQ==",
      "funding": [
        {
          "type": "individual",
          "url": "https://github.com/sponsors/RubenVerborgh"
        }
      ],
      "license": "MIT",
      "engines": {
        "node": ">=4.0"
      },
      "peerDependenciesMeta": {
        "debug": {
          "optional": true
        }
      }
    },
    "node_modules/foreground-child": {
      "version": "3.3.0",
      "resolved": "https://registry.npmjs.org/foreground-child/-/foreground-child-3.3.0.tgz",
      "integrity": "sha512-Ld2g8rrAyMYFXBhEqMz8ZAHBi4J4uS1i/CxGMDnjyFWddMXLVcDp051DZfu+t7+ab7Wv6SMqpWmyFIj5UbfFvg==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "cross-spawn": "^7.0.0",
        "signal-exit": "^4.0.1"
      },
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/form-data": {
      "version": "4.0.4",
      "resolved": "https://registry.npmjs.org/form-data/-/form-data-4.0.4.tgz",
      "integrity": "sha512-KrGhL9Q4zjj0kiUt5OO4Mr/A/jlI2jDYs5eHBpYHPcBEVSiipAvn2Ko2HnPe20rmcuuvMHNdZFp+4IlGTMF0Ow==",
      "license": "MIT",
      "dependencies": {
        "asynckit": "^0.4.0",
        "combined-stream": "^1.0.8",
        "es-set-tostringtag": "^2.1.0",
        "hasown": "^2.0.2",
        "mime-types": "^2.1.12"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/fraction.js": {
      "version": "4.3.7",
      "resolved": "https://registry.npmjs.org/fraction.js/-/fraction.js-4.3.7.tgz",
      "integrity": "sha512-ZsDfxO51wGAXREY55a7la9LScWpwv9RxIrYABrlvOFBlH/ShPnrtsXeuUIfXKKOVicNxQ+o8JTbJvjS4M89yew==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "*"
      },
      "funding": {
        "type": "patreon",
        "url": "https://github.com/sponsors/rawify"
      }
    },
    "node_modules/fsevents": {
      "version": "2.3.3",
      "resolved": "https://registry.npmjs.org/fsevents/-/fsevents-2.3.3.tgz",
      "integrity": "sha512-5xoDfX+fL7faATnagmWPpbFtwh/R77WmMMqqHGS65C3vvB0YHrgF+B1YmZ3441tMj5n63k0212XNoJwzlhffQw==",
      "dev": true,
      "hasInstallScript": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": "^8.16.0 || ^10.6.0 || >=11.0.0"
      }
    },
    "node_modules/function-bind": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/function-bind/-/function-bind-1.1.2.tgz",
      "integrity": "sha512-7XHNxH7qX9xG5mIwxkhumTox/MIRNcOgDrxWsMt2pAr23WHp6MrRlN7FBSFpCpr+oVO0F744iUgR82nJMfG2SA==",
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-intrinsic": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/get-intrinsic/-/get-intrinsic-1.3.0.tgz",
      "integrity": "sha512-9fSjSaos/fRIVIp+xSJlE6lfwhES7LNtKaCBIamHsjr2na1BiABJPo0mOjjz8GJDURarmCPGqaiVg5mfjb98CQ==",
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.2",
        "es-define-property": "^1.0.1",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.1.1",
        "function-bind": "^1.1.2",
        "get-proto": "^1.0.1",
        "gopd": "^1.2.0",
        "has-symbols": "^1.1.0",
        "hasown": "^2.0.2",
        "math-intrinsics": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-nonce": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/get-nonce/-/get-nonce-1.0.1.tgz",
      "integrity": "sha512-FJhYRoDaiatfEkUK8HKlicmu/3SGFD51q3itKDGoSTysQJBnfOcxU5GxnhE1E6soB76MbT0MBtnKJuXyAx+96Q==",
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/get-proto": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/get-proto/-/get-proto-1.0.1.tgz",
      "integrity": "sha512-sTSfBjoXBp89JvIKIefqw7U2CCebsc74kiY6awiGogKtoSGbgjYE/G/+l9sF3MWFPNc9IcoOC4ODfKHfxFmp0g==",
      "license": "MIT",
      "dependencies": {
        "dunder-proto": "^1.0.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/glob": {
      "version": "10.4.5",
      "resolved": "https://registry.npmjs.org/glob/-/glob-10.4.5.tgz",
      "integrity": "sha512-7Bv8RF0k6xjo7d4A/PxYLbUCfb6c+Vpd2/mB2yRDlew7Jb5hEXiCD9ibfO7wpk8i4sevK6DFny9h7EYbM3/sHg==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "foreground-child": "^3.1.0",
        "jackspeak": "^3.1.2",
        "minimatch": "^9.0.4",
        "minipass": "^7.1.2",
        "package-json-from-dist": "^1.0.0",
        "path-scurry": "^1.11.1"
      },
      "bin": {
        "glob": "dist/esm/bin.mjs"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/glob-parent": {
      "version": "6.0.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-6.0.2.tgz",
      "integrity": "sha512-XxwI8EOhVQgWp6iDL+3b0r86f4d6AX6zSU55HfB4ydCEuXLXc5FcYeOu+nnGftS4TEju/11rt4KJPTMgbfmv4A==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "is-glob": "^4.0.3"
      },
      "engines": {
        "node": ">=10.13.0"
      }
    },
    "node_modules/glob/node_modules/brace-expansion": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-2.0.2.tgz",
      "integrity": "sha512-Jt0vHyM+jmUBqojB7E1NIYadt0vI0Qxjxd2TErW94wDz+E2LAm5vKMXXwg6ZZBTHPuUlDgQHKXvjGBdfcF1ZDQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0"
      }
    },
    "node_modules/glob/node_modules/minimatch": {
      "version": "9.0.5",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-9.0.5.tgz",
      "integrity": "sha512-G6T0ZX48xgozx7587koeX9Ys2NYy6Gmv//P89sEte9V9whIapMNF4idKxnW2QtCcLiTWlb/wfCabAtAFWhhBow==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^2.0.1"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/globals": {
      "version": "15.15.0",
      "resolved": "https://registry.npmjs.org/globals/-/globals-15.15.0.tgz",
      "integrity": "sha512-7ACyT3wmyp3I61S4fG682L0VA2RGD9otkqGJIwNUMF1SWUombIIk+af1unuDYgMm082aHYwD+mzJvv9Iu8dsgg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=18"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/gopd": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/gopd/-/gopd-1.2.0.tgz",
      "integrity": "sha512-ZUKRh6/kUFoAiTAtTYPZJ3hw9wNxx+BIBOijnlG9PnrJsCcSjs1wyyD6vJpaYtgnzDrKYRSqf3OO6Rfa93xsRg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/graphemer": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/graphemer/-/graphemer-1.4.0.tgz",
      "integrity": "sha512-EtKwoO6kxCL9WO5xipiHTZlSzBm7WLT627TqC/uVRd0HKmq8NXyebnNYxDoBi7wt8eTWrUrKXCOVaFq9x1kgag==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/has-flag": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/has-flag/-/has-flag-4.0.0.tgz",
      "integrity": "sha512-EykJT/Q1KjTWctppgIAgfSO0tKVuZUjhgMr17kqTumMl6Afv3EISleU7qZUzoXDFTAHTDC4NOoG/ZxU3EvlMPQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/has-symbols": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/has-symbols/-/has-symbols-1.1.0.tgz",
      "integrity": "sha512-1cDNdwJ2Jaohmb3sg4OmKaMBwuC48sYni5HUw2DvsC8LjGTLK9h+eb1X6RyuOHe4hT0ULCW68iomhjUoKUqlPQ==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-tostringtag": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/has-tostringtag/-/has-tostringtag-1.0.2.tgz",
      "integrity": "sha512-NqADB8VjPFLM2V0VvHUewwwsw0ZWBaIdgo+ieHtK3hasLz4qeCRjYcqfB6AQrBggRKppKF8L52/VqdVsO47Dlw==",
      "license": "MIT",
      "dependencies": {
        "has-symbols": "^1.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/hasown": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/hasown/-/hasown-2.0.2.tgz",
      "integrity": "sha512-0hJU9SCPvmMzIBdZFqNPXWa6dqh7WdH0cII9y+CyS8rG3nL48Bclra9HmKhVVUHyPWNH5Y7xDwAB7bfgSjkUMQ==",
      "license": "MIT",
      "dependencies": {
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/hast-util-to-jsx-runtime": {
      "version": "2.3.6",
      "resolved": "https://registry.npmjs.org/hast-util-to-jsx-runtime/-/hast-util-to-jsx-runtime-2.3.6.tgz",
      "integrity": "sha512-zl6s8LwNyo1P9uw+XJGvZtdFF1GdAkOg8ujOw+4Pyb76874fLps4ueHXDhXWdk6YHQ6OgUtinliG7RsYvCbbBg==",
      "license": "MIT",
      "dependencies": {
        "@types/estree": "^1.0.0",
        "@types/hast": "^3.0.0",
        "@types/unist": "^3.0.0",
        "comma-separated-tokens": "^2.0.0",
        "devlop": "^1.0.0",
        "estree-util-is-identifier-name": "^3.0.0",
        "hast-util-whitespace": "^3.0.0",
        "mdast-util-mdx-expression": "^2.0.0",
        "mdast-util-mdx-jsx": "^3.0.0",
        "mdast-util-mdxjs-esm": "^2.0.0",
        "property-information": "^7.0.0",
        "space-separated-tokens": "^2.0.0",
        "style-to-js": "^1.0.0",
        "unist-util-position": "^5.0.0",
        "vfile-message": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/hast-util-whitespace": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/hast-util-whitespace/-/hast-util-whitespace-3.0.0.tgz",
      "integrity": "sha512-88JUN06ipLwsnv+dVn+OIYOvAuvBMy/Qoi6O7mQHxdPXpjy+Cd6xRkWwux7DKO+4sYILtLBRIKgsdpS2gQc7qw==",
      "license": "MIT",
      "dependencies": {
        "@types/hast": "^3.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/html-url-attributes": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/html-url-attributes/-/html-url-attributes-3.0.1.tgz",
      "integrity": "sha512-ol6UPyBWqsrO6EJySPz2O7ZSr856WDrEzM5zMqp+FJJLGMW35cLYmmZnl0vztAZxRUoNZJFTCohfjuIJ8I4QBQ==",
      "license": "MIT",
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/ignore": {
      "version": "5.3.2",
      "resolved": "https://registry.npmjs.org/ignore/-/ignore-5.3.2.tgz",
      "integrity": "sha512-hsBTNUqQTDwkWtcdYI2i06Y/nUBEsNEDJKjWdigLvegy8kDuJAS8uRlpkkcQpyEXL0Z/pjDy5HBmMjRCJ2gq+g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 4"
      }
    },
    "node_modules/import-fresh": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/import-fresh/-/import-fresh-3.3.1.tgz",
      "integrity": "sha512-TR3KfrTZTYLPB6jUjfx6MF9WcWrHL9su5TObK4ZkYgBdWKPOFoSoQIdEuTuR82pmtxH2spWG9h6etwfr1pLBqQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "parent-module": "^1.0.0",
        "resolve-from": "^4.0.0"
      },
      "engines": {
        "node": ">=6"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/imurmurhash": {
      "version": "0.1.4",
      "resolved": "https://registry.npmjs.org/imurmurhash/-/imurmurhash-0.1.4.tgz",
      "integrity": "sha512-JmXMZ6wuvDmLiHEml9ykzqO6lwFbof0GG4IkcGaENdCRDDmMVnny7s5HsIgHCbaq0w2MyPhDqkhTUgS2LU2PHA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.8.19"
      }
    },
    "node_modules/inline-style-parser": {
      "version": "0.2.7",
      "resolved": "https://registry.npmjs.org/inline-style-parser/-/inline-style-parser-0.2.7.tgz",
      "integrity": "sha512-Nb2ctOyNR8DqQoR0OwRG95uNWIC0C1lCgf5Naz5H6Ji72KZ8OcFZLz2P5sNgwlyoJ8Yif11oMuYs5pBQa86csA==",
      "license": "MIT"
    },
    "node_modules/input-otp": {
      "version": "1.4.2",
      "resolved": "https://registry.npmjs.org/input-otp/-/input-otp-1.4.2.tgz",
      "integrity": "sha512-l3jWwYNvrEa6NTCt7BECfCm48GvwuZzkoeG3gBL2w4CHeOXW3eKFmf9UNYkNfYc3mxMrthMnxjIE07MT0zLBQA==",
      "license": "MIT",
      "peerDependencies": {
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0.0 || ^19.0.0-rc"
      }
    },
    "node_modules/internmap": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/internmap/-/internmap-2.0.3.tgz",
      "integrity": "sha512-5Hh7Y1wQbvY5ooGgPbDaL5iYLAPzMTUrjMulskHLH6wnv/A+1q5rgEaiuqEjB+oxGXIVZs1FF+R/KPN3ZSQYYg==",
      "license": "ISC",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/is-alphabetical": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/is-alphabetical/-/is-alphabetical-2.0.1.tgz",
      "integrity": "sha512-FWyyY60MeTNyeSRpkM2Iry0G9hpr7/9kD40mD/cGQEuilcZYS4okz8SN2Q6rLCJ8gbCt6fN+rC+6tMGS99LaxQ==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/is-alphanumerical": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/is-alphanumerical/-/is-alphanumerical-2.0.1.tgz",
      "integrity": "sha512-hmbYhX/9MUMF5uh7tOXyK/n0ZvWpad5caBA17GsC6vyuCqaWliRG5K1qS9inmUhEMaOBIW7/whAnSwveW/LtZw==",
      "license": "MIT",
      "dependencies": {
        "is-alphabetical": "^2.0.0",
        "is-decimal": "^2.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/is-binary-path": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/is-binary-path/-/is-binary-path-2.1.0.tgz",
      "integrity": "sha512-ZMERYes6pDydyuGidse7OsHxtbI7WVeUEozgR/g7rd0xUimYNlvZRE/K2MgZTjWy725IfelLeVcEM97mmtRGXw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "binary-extensions": "^2.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/is-core-module": {
      "version": "2.15.1",
      "resolved": "https://registry.npmjs.org/is-core-module/-/is-core-module-2.15.1.tgz",
      "integrity": "sha512-z0vtXSwucUJtANQWldhbtbt7BnL0vxiFjIdDLAatwhDYty2bad6s+rijD6Ri4YuYJubLzIJLUidCh09e1djEVQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-decimal": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/is-decimal/-/is-decimal-2.0.1.tgz",
      "integrity": "sha512-AAB9hiomQs5DXWcRB1rqsxGUstbRroFOPPVAomNk/3XHR5JyEZChOyTWe2oayKnsSsr/kcGqF+z6yuH6HHpN0A==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/is-extglob": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/is-extglob/-/is-extglob-2.1.1.tgz",
      "integrity": "sha512-SbKbANkN603Vi4jEZv49LeVJMn4yGwsbzZworEoyEiutsN3nJYdbO36zfhGJ6QEDpOZIFkDtnq5JRxmvl3jsoQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/is-fullwidth-code-point": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/is-fullwidth-code-point/-/is-fullwidth-code-point-3.0.0.tgz",
      "integrity": "sha512-zymm5+u+sCsSWyD9qNaejV3DFvhCKclKdizYaJUuHA83RLjb7nSuGnddCHGv0hk+KY7BMAlsWeK4Ueg6EV6XQg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/is-glob": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/is-glob/-/is-glob-4.0.3.tgz",
      "integrity": "sha512-xelSayHH36ZgE7ZWhli7pW34hNbNl8Ojv5KVmkJD4hBdD3th8Tfk9vYasLM+mXWOZhFkgZfxhLSnrwRr4elSSg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-extglob": "^2.1.1"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/is-hexadecimal": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/is-hexadecimal/-/is-hexadecimal-2.0.1.tgz",
      "integrity": "sha512-DgZQp241c8oO6cA1SbTEWiXeoxV42vlcJxgH+B3hi1AiqqKruZR3ZGF8In3fj4+/y/7rHvlOZLZtgJ/4ttYGZg==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/is-number": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/is-number/-/is-number-7.0.0.tgz",
      "integrity": "sha512-41Cifkg6e8TylSpdtTpeLVMqvSBEVzTttHvERD741+pnZ8ANv0004MRL43QKPDlK9cGvNp6NZWZUBlbGXYxxng==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.12.0"
      }
    },
    "node_modules/is-plain-obj": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/is-plain-obj/-/is-plain-obj-4.1.0.tgz",
      "integrity": "sha512-+Pgi+vMuUNkJyExiMBt5IlFoMyKnr5zhJ4Uspz58WOhBF5QoIZkFyNHIbBAtHwzVAgk5RtndVNsDRN61/mmDqg==",
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/isexe": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/isexe/-/isexe-2.0.0.tgz",
      "integrity": "sha512-RHxMLp9lnKHGHRng9QFhRCMbYAcVpn69smSGcq3f36xjgVVWThj4qqLbTLlq7Ssj8B+fIQ1EuCEGI2lKsyQeIw==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/jackspeak": {
      "version": "3.4.3",
      "resolved": "https://registry.npmjs.org/jackspeak/-/jackspeak-3.4.3.tgz",
      "integrity": "sha512-OGlZQpz2yfahA/Rd1Y8Cd9SIEsqvXkLVoSw/cgwhnhFMDbsQFeZYoJJ7bIZBS9BcamUW96asq/npPWugM+RQBw==",
      "dev": true,
      "license": "BlueOak-1.0.0",
      "dependencies": {
        "@isaacs/cliui": "^8.0.2"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      },
      "optionalDependencies": {
        "@pkgjs/parseargs": "^0.11.0"
      }
    },
    "node_modules/jiti": {
      "version": "1.21.6",
      "resolved": "https://registry.npmjs.org/jiti/-/jiti-1.21.6.tgz",
      "integrity": "sha512-2yTgeWTWzMWkHu6Jp9NKgePDaYHbntiwvYuuJLbbN9vl7DC9DvXKOB2BC3ZZ92D3cvV/aflH0osDfwpHepQ53w==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "jiti": "bin/jiti.js"
      }
    },
    "node_modules/js-tokens": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/js-tokens/-/js-tokens-4.0.0.tgz",
      "integrity": "sha512-RdJUflcE3cUzKiMqQgsCu06FPu9UdIJO0beYbPhHN4k6apgJtifcoCtT9bcxOpYBtpD2kCM6Sbzg4CausW/PKQ==",
      "license": "MIT"
    },
    "node_modules/js-yaml": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/js-yaml/-/js-yaml-4.1.0.tgz",
      "integrity": "sha512-wpxZs9NoxZaJESJGIZTyDEaYpl0FKSA+FB9aJiyemKhMwkxQg63h4T1KJgUGHpTqPDNRcmmYLugrRjJlBtWvRA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "argparse": "^2.0.1"
      },
      "bin": {
        "js-yaml": "bin/js-yaml.js"
      }
    },
    "node_modules/json-buffer": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/json-buffer/-/json-buffer-3.0.1.tgz",
      "integrity": "sha512-4bV5BfR2mqfQTJm+V5tPPdf+ZpuhiIvTuAB5g8kcrXOZpTT/QwwVRWBywX1ozr6lEuPdbHxwaJlm9G6mI2sfSQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json-schema-traverse": {
      "version": "0.4.1",
      "resolved": "https://registry.npmjs.org/json-schema-traverse/-/json-schema-traverse-0.4.1.tgz",
      "integrity": "sha512-xbbCH5dCYU5T8LcEhhuh7HJ88HXuW3qsI3Y0zOZFKfZEHcpWiHU/Jxzk629Brsab/mMiHQti9wMP+845RPe3Vg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json-stable-stringify-without-jsonify": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/json-stable-stringify-without-jsonify/-/json-stable-stringify-without-jsonify-1.0.1.tgz",
      "integrity": "sha512-Bdboy+l7tA3OGW6FjyFHWkP5LuByj1Tk33Ljyq0axyzdk9//JSi2u3fP1QSmd1KNwq6VOKYGlAu87CisVir6Pw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/keyv": {
      "version": "4.5.4",
      "resolved": "https://registry.npmjs.org/keyv/-/keyv-4.5.4.tgz",
      "integrity": "sha512-oxVHkHR/EJf2CNXnWxRLW6mg7JyCCUcG0DtEGmL2ctUo1PNTin1PUil+r/+4r5MpVgC/fn1kjsx7mjSujKqIpw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "json-buffer": "3.0.1"
      }
    },
    "node_modules/levn": {
      "version": "0.4.1",
      "resolved": "https://registry.npmjs.org/levn/-/levn-0.4.1.tgz",
      "integrity": "sha512-+bT2uH4E5LGE7h/n3evcS/sQlJXCpIp6ym8OWJ5eV6+67Dsql/LaaT7qJBAt2rzfoa/5QBGBhxDix1dMt2kQKQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "prelude-ls": "^1.2.1",
        "type-check": "~0.4.0"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/lilconfig": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/lilconfig/-/lilconfig-3.1.3.tgz",
      "integrity": "sha512-/vlFKAoH5Cgt3Ie+JLhRbwOsCQePABiU3tJ1egGvyQ+33R/vcwM2Zl2QR/LzjsBeItPt3oSVXapn+m4nQDvpzw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/sponsors/antonk52"
      }
    },
    "node_modules/lines-and-columns": {
      "version": "1.2.4",
      "resolved": "https://registry.npmjs.org/lines-and-columns/-/lines-and-columns-1.2.4.tgz",
      "integrity": "sha512-7ylylesZQ/PV29jhEDl3Ufjo6ZX7gCqJr5F7PKrqc93v7fzSymt1BpwEU8nAUXs8qzzvqhbjhK5QZg6Mt/HkBg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/locate-path": {
      "version": "6.0.0",
      "resolved": "https://registry.npmjs.org/locate-path/-/locate-path-6.0.0.tgz",
      "integrity": "sha512-iPZK6eYjbxRu3uB4/WZ3EsEIMJFMqAoopl3R+zuq0UjcAm/MO6KCweDgPfP3elTztoKP3KtnVHxTn2NHBSDVUw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-locate": "^5.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/lodash": {
      "version": "4.17.21",
      "resolved": "https://registry.npmjs.org/lodash/-/lodash-4.17.21.tgz",
      "integrity": "sha512-v2kDEe57lecTulaDIuNTPy3Ry4gLGJ6Z1O3vE1krgXZNrsQ+LFTGHVxVjcXPs17LhbZVGedAJv8XZ1tvj5FvSg==",
      "license": "MIT"
    },
    "node_modules/lodash.castarray": {
      "version": "4.4.0",
      "resolved": "https://registry.npmjs.org/lodash.castarray/-/lodash.castarray-4.4.0.tgz",
      "integrity": "sha512-aVx8ztPv7/2ULbArGJ2Y42bG1mEQ5mGjpdvrbJcJFU3TbYybe+QlLS4pst9zV52ymy2in1KpFPiZnAOATxD4+Q==",
      "dev": true
    },
    "node_modules/lodash.clonedeep": {
      "version": "4.5.0",
      "resolved": "https://registry.npmjs.org/lodash.clonedeep/-/lodash.clonedeep-4.5.0.tgz",
      "integrity": "sha512-H5ZhCF25riFd9uB5UCkVKo61m3S/xZk1x4wA6yp/L3RFP6Z/eHH1ymQcGLo7J3GMPfm0V/7m1tryHuGVxpqEBQ==",
      "license": "MIT"
    },
    "node_modules/lodash.debounce": {
      "version": "4.0.8",
      "resolved": "https://registry.npmjs.org/lodash.debounce/-/lodash.debounce-4.0.8.tgz",
      "integrity": "sha512-FT1yDzDYEoYWhnSGnpE/4Kj1fLZkDFyqRb7fNt6FdYOSxlUWAtp42Eh6Wb0rGIv/m9Bgo7x4GhQbm5Ys4SG5ow==",
      "license": "MIT"
    },
    "node_modules/lodash.isplainobject": {
      "version": "4.0.6",
      "resolved": "https://registry.npmjs.org/lodash.isplainobject/-/lodash.isplainobject-4.0.6.tgz",
      "integrity": "sha512-oSXzaWypCMHkPC3NvBEaPHf0KsA5mvPrOPgQWDsbg8n7orZ290M0BmC/jgRZ4vcJ6DTAhjrsSYgdsW/F+MFOBA==",
      "dev": true
    },
    "node_modules/lodash.merge": {
      "version": "4.6.2",
      "resolved": "https://registry.npmjs.org/lodash.merge/-/lodash.merge-4.6.2.tgz",
      "integrity": "sha512-0KpjqXRVvrYyCsX1swR/XTK0va6VQkQM6MNo7PqW77ByjAhoARA8EfrP1N4+KlKj8YS0ZUCtRT/YUuhyYDujIQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/longest-streak": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/longest-streak/-/longest-streak-3.1.0.tgz",
      "integrity": "sha512-9Ri+o0JYgehTaVBBDoMqIl8GXtbWg711O3srftcHhZ0dqnETqLaoIK0x17fUw9rFSlK/0NlsKe0Ahhyl5pXE2g==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/loose-envify": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/loose-envify/-/loose-envify-1.4.0.tgz",
      "integrity": "sha512-lyuxPGr/Wfhrlem2CL/UcnUc1zcqKAImBDzukY7Y5F/yQiNdko6+fRLevlw1HgMySw7f611UIY408EtxRSoK3Q==",
      "license": "MIT",
      "dependencies": {
        "js-tokens": "^3.0.0 || ^4.0.0"
      },
      "bin": {
        "loose-envify": "cli.js"
      }
    },
    "node_modules/lru-cache": {
      "version": "10.4.3",
      "resolved": "https://registry.npmjs.org/lru-cache/-/lru-cache-10.4.3.tgz",
      "integrity": "sha512-JNAzZcXrCt42VGLuYz0zfAzDfAvJWW6AfYlDBQyDV5DClI2m5sAmK+OIO7s59XfsRsWHp02jAJrRadPRGTt6SQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/lucide-react": {
      "version": "0.462.0",
      "resolved": "https://registry.npmjs.org/lucide-react/-/lucide-react-0.462.0.tgz",
      "integrity": "sha512-NTL7EbAao9IFtuSivSZgrAh4fZd09Lr+6MTkqIxuHaH2nnYiYIzXPo06cOxHg9wKLdj6LL8TByG4qpePqwgx/g==",
      "peerDependencies": {
        "react": "^16.5.1 || ^17.0.0 || ^18.0.0 || ^19.0.0-rc"
      }
    },
    "node_modules/markdown-table": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/markdown-table/-/markdown-table-3.0.4.tgz",
      "integrity": "sha512-wiYz4+JrLyb/DqW2hkFJxP7Vd7JuTDm77fvbM8VfEQdmSMqcImWeeRbHwZjBjIFki/VaMK2BhFi7oUUZeM5bqw==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/math-intrinsics": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/math-intrinsics/-/math-intrinsics-1.1.0.tgz",
      "integrity": "sha512-/IXtbwEk5HTPyEwyKX6hGkYXxM9nbj64B+ilVJnC/R6B0pH5G4V3b0pVbL7DBj4tkhBAppbQUlf6F6Xl9LHu1g==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/mdast-util-find-and-replace": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/mdast-util-find-and-replace/-/mdast-util-find-and-replace-3.0.2.tgz",
      "integrity": "sha512-Tmd1Vg/m3Xz43afeNxDIhWRtFZgM2VLyaf4vSTYwudTyeuTneoL3qtWMA5jeLyz/O1vDJmmV4QuScFCA2tBPwg==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "escape-string-regexp": "^5.0.0",
        "unist-util-is": "^6.0.0",
        "unist-util-visit-parents": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-find-and-replace/node_modules/escape-string-regexp": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/escape-string-regexp/-/escape-string-regexp-5.0.0.tgz",
      "integrity": "sha512-/veY75JbMK4j1yjvuUxuVsiS/hr/4iHs9FTT6cgTexxdE0Ly/glccBAkloH/DofkjRbZU3bnoj38mOmhkZ0lHw==",
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/mdast-util-from-markdown": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/mdast-util-from-markdown/-/mdast-util-from-markdown-2.0.2.tgz",
      "integrity": "sha512-uZhTV/8NBuw0WHkPTrCqDOl0zVe1BIng5ZtHoDk49ME1qqcjYmmLmOf0gELgcRMxN4w2iuIeVso5/6QymSrgmA==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "@types/unist": "^3.0.0",
        "decode-named-character-reference": "^1.0.0",
        "devlop": "^1.0.0",
        "mdast-util-to-string": "^4.0.0",
        "micromark": "^4.0.0",
        "micromark-util-decode-numeric-character-reference": "^2.0.0",
        "micromark-util-decode-string": "^2.0.0",
        "micromark-util-normalize-identifier": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0",
        "unist-util-stringify-position": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm/-/mdast-util-gfm-3.1.0.tgz",
      "integrity": "sha512-0ulfdQOM3ysHhCJ1p06l0b0VKlhU0wuQs3thxZQagjcjPrlFRqY215uZGHHJan9GEAXd9MbfPjFJz+qMkVR6zQ==",
      "license": "MIT",
      "dependencies": {
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-gfm-autolink-literal": "^2.0.0",
        "mdast-util-gfm-footnote": "^2.0.0",
        "mdast-util-gfm-strikethrough": "^2.0.0",
        "mdast-util-gfm-table": "^2.0.0",
        "mdast-util-gfm-task-list-item": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm-autolink-literal": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm-autolink-literal/-/mdast-util-gfm-autolink-literal-2.0.1.tgz",
      "integrity": "sha512-5HVP2MKaP6L+G6YaxPNjuL0BPrq9orG3TsrZ9YXbA3vDw/ACI4MEsnoDpn6ZNm7GnZgtAcONJyPhOP8tNJQavQ==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "ccount": "^2.0.0",
        "devlop": "^1.0.0",
        "mdast-util-find-and-replace": "^3.0.0",
        "micromark-util-character": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm-footnote": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm-footnote/-/mdast-util-gfm-footnote-2.1.0.tgz",
      "integrity": "sha512-sqpDWlsHn7Ac9GNZQMeUzPQSMzR6Wv0WKRNvQRg0KqHh02fpTz69Qc1QSseNX29bhz1ROIyNyxExfawVKTm1GQ==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "devlop": "^1.1.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0",
        "micromark-util-normalize-identifier": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm-strikethrough": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm-strikethrough/-/mdast-util-gfm-strikethrough-2.0.0.tgz",
      "integrity": "sha512-mKKb915TF+OC5ptj5bJ7WFRPdYtuHv0yTRxK2tJvi+BDqbkiG7h7u/9SI89nRAYcmap2xHQL9D+QG/6wSrTtXg==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm-table": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm-table/-/mdast-util-gfm-table-2.0.0.tgz",
      "integrity": "sha512-78UEvebzz/rJIxLvE7ZtDd/vIQ0RHv+3Mh5DR96p7cS7HsBhYIICDBCu8csTNWNO6tBWfqXPWekRuj2FNOGOZg==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "devlop": "^1.0.0",
        "markdown-table": "^3.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm-task-list-item": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm-task-list-item/-/mdast-util-gfm-task-list-item-2.0.0.tgz",
      "integrity": "sha512-IrtvNvjxC1o06taBAVJznEnkiHxLFTzgonUdy8hzFVeDun0uTjxxrRGVaNFqkU1wJR3RBPEfsxmU6jDWPofrTQ==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "devlop": "^1.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-mdx-expression": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/mdast-util-mdx-expression/-/mdast-util-mdx-expression-2.0.1.tgz",
      "integrity": "sha512-J6f+9hUp+ldTZqKRSg7Vw5V6MqjATc+3E4gf3CFNcuZNWD8XdyI6zQ8GqH7f8169MM6P7hMBRDVGnn7oHB9kXQ==",
      "license": "MIT",
      "dependencies": {
        "@types/estree-jsx": "^1.0.0",
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "devlop": "^1.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-mdx-jsx": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/mdast-util-mdx-jsx/-/mdast-util-mdx-jsx-3.2.0.tgz",
      "integrity": "sha512-lj/z8v0r6ZtsN/cGNNtemmmfoLAFZnjMbNyLzBafjzikOM+glrjNHPlf6lQDOTccj9n5b0PPihEBbhneMyGs1Q==",
      "license": "MIT",
      "dependencies": {
        "@types/estree-jsx": "^1.0.0",
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "@types/unist": "^3.0.0",
        "ccount": "^2.0.0",
        "devlop": "^1.1.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0",
        "parse-entities": "^4.0.0",
        "stringify-entities": "^4.0.0",
        "unist-util-stringify-position": "^4.0.0",
        "vfile-message": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-mdxjs-esm": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/mdast-util-mdxjs-esm/-/mdast-util-mdxjs-esm-2.0.1.tgz",
      "integrity": "sha512-EcmOpxsZ96CvlP03NghtH1EsLtr0n9Tm4lPUJUBccV9RwUOneqSycg19n5HGzCf+10LozMRSObtVr3ee1WoHtg==",
      "license": "MIT",
      "dependencies": {
        "@types/estree-jsx": "^1.0.0",
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "devlop": "^1.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-phrasing": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/mdast-util-phrasing/-/mdast-util-phrasing-4.1.0.tgz",
      "integrity": "sha512-TqICwyvJJpBwvGAMZjj4J2n0X8QWp21b9l0o7eXyVJ25YNWYbJDVIyD1bZXE6WtV6RmKJVYmQAKWa0zWOABz2w==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "unist-util-is": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-to-hast": {
      "version": "13.2.1",
      "resolved": "https://registry.npmjs.org/mdast-util-to-hast/-/mdast-util-to-hast-13.2.1.tgz",
      "integrity": "sha512-cctsq2wp5vTsLIcaymblUriiTcZd0CwWtCbLvrOzYCDZoWyMNV8sZ7krj09FSnsiJi3WVsHLM4k6Dq/yaPyCXA==",
      "license": "MIT",
      "dependencies": {
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "@ungap/structured-clone": "^1.0.0",
        "devlop": "^1.0.0",
        "micromark-util-sanitize-uri": "^2.0.0",
        "trim-lines": "^3.0.0",
        "unist-util-position": "^5.0.0",
        "unist-util-visit": "^5.0.0",
        "vfile": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-to-markdown": {
      "version": "2.1.2",
      "resolved": "https://registry.npmjs.org/mdast-util-to-markdown/-/mdast-util-to-markdown-2.1.2.tgz",
      "integrity": "sha512-xj68wMTvGXVOKonmog6LwyJKrYXZPvlwabaryTjLh9LuvovB/KAH+kvi8Gjj+7rJjsFi23nkUxRQv1KqSroMqA==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "@types/unist": "^3.0.0",
        "longest-streak": "^3.0.0",
        "mdast-util-phrasing": "^4.0.0",
        "mdast-util-to-string": "^4.0.0",
        "micromark-util-classify-character": "^2.0.0",
        "micromark-util-decode-string": "^2.0.0",
        "unist-util-visit": "^5.0.0",
        "zwitch": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-to-string": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/mdast-util-to-string/-/mdast-util-to-string-4.0.0.tgz",
      "integrity": "sha512-0H44vDimn51F0YwvxSJSm0eCDOJTRlmN0R1yBh4HLj9wiV1Dn0QoXGbvFAWj2hSItVTlCmBF1hqKlIyUBVFLPg==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/merge2": {
      "version": "1.4.1",
      "resolved": "https://registry.npmjs.org/merge2/-/merge2-1.4.1.tgz",
      "integrity": "sha512-8q7VEgMJW4J8tcfVPy8g09NcQwZdbwFEqhe/WZkoIzjn/3TGDwtOCYtXGxA3O8tPzpczCCDgv+P2P5y00ZJOOg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/micromark": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/micromark/-/micromark-4.0.2.tgz",
      "integrity": "sha512-zpe98Q6kvavpCr1NPVSCMebCKfD7CA2NqZ+rykeNhONIJBpc1tFKt9hucLGwha3jNTNI8lHpctWJWoimVF4PfA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "@types/debug": "^4.0.0",
        "debug": "^4.0.0",
        "decode-named-character-reference": "^1.0.0",
        "devlop": "^1.0.0",
        "micromark-core-commonmark": "^2.0.0",
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-chunked": "^2.0.0",
        "micromark-util-combine-extensions": "^2.0.0",
        "micromark-util-decode-numeric-character-reference": "^2.0.0",
        "micromark-util-encode": "^2.0.0",
        "micromark-util-normalize-identifier": "^2.0.0",
        "micromark-util-resolve-all": "^2.0.0",
        "micromark-util-sanitize-uri": "^2.0.0",
        "micromark-util-subtokenize": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-core-commonmark": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/micromark-core-commonmark/-/micromark-core-commonmark-2.0.3.tgz",
      "integrity": "sha512-RDBrHEMSxVFLg6xvnXmb1Ayr2WzLAWjeSATAoxwKYJV94TeNavgoIdA0a9ytzDSVzBy2YKFK+emCPOEibLeCrg==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "decode-named-character-reference": "^1.0.0",
        "devlop": "^1.0.0",
        "micromark-factory-destination": "^2.0.0",
        "micromark-factory-label": "^2.0.0",
        "micromark-factory-space": "^2.0.0",
        "micromark-factory-title": "^2.0.0",
        "micromark-factory-whitespace": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-chunked": "^2.0.0",
        "micromark-util-classify-character": "^2.0.0",
        "micromark-util-html-tag-name": "^2.0.0",
        "micromark-util-normalize-identifier": "^2.0.0",
        "micromark-util-resolve-all": "^2.0.0",
        "micromark-util-subtokenize": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-extension-gfm": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm/-/micromark-extension-gfm-3.0.0.tgz",
      "integrity": "sha512-vsKArQsicm7t0z2GugkCKtZehqUm31oeGBV/KVSorWSy8ZlNAv7ytjFhvaryUiCUJYqs+NoE6AFhpQvBTM6Q4w==",
      "license": "MIT",
      "dependencies": {
        "micromark-extension-gfm-autolink-literal": "^2.0.0",
        "micromark-extension-gfm-footnote": "^2.0.0",
        "micromark-extension-gfm-strikethrough": "^2.0.0",
        "micromark-extension-gfm-table": "^2.0.0",
        "micromark-extension-gfm-tagfilter": "^2.0.0",
        "micromark-extension-gfm-task-list-item": "^2.0.0",
        "micromark-util-combine-extensions": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-autolink-literal": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-autolink-literal/-/micromark-extension-gfm-autolink-literal-2.1.0.tgz",
      "integrity": "sha512-oOg7knzhicgQ3t4QCjCWgTmfNhvQbDDnJeVu9v81r7NltNCVmhPy1fJRX27pISafdjL+SVc4d3l48Gb6pbRypw==",
      "license": "MIT",
      "dependencies": {
        "micromark-util-character": "^2.0.0",
        "micromark-util-sanitize-uri": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-footnote": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-footnote/-/micromark-extension-gfm-footnote-2.1.0.tgz",
      "integrity": "sha512-/yPhxI1ntnDNsiHtzLKYnE3vf9JZ6cAisqVDauhp4CEHxlb4uoOTxOCJ+9s51bIB8U1N1FJ1RXOKTIlD5B/gqw==",
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-core-commonmark": "^2.0.0",
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-normalize-identifier": "^2.0.0",
        "micromark-util-sanitize-uri": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-strikethrough": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-strikethrough/-/micromark-extension-gfm-strikethrough-2.1.0.tgz",
      "integrity": "sha512-ADVjpOOkjz1hhkZLlBiYA9cR2Anf8F4HqZUO6e5eDcPQd0Txw5fxLzzxnEkSkfnD0wziSGiv7sYhk/ktvbf1uw==",
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-util-chunked": "^2.0.0",
        "micromark-util-classify-character": "^2.0.0",
        "micromark-util-resolve-all": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-table": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-table/-/micromark-extension-gfm-table-2.1.1.tgz",
      "integrity": "sha512-t2OU/dXXioARrC6yWfJ4hqB7rct14e8f7m0cbI5hUmDyyIlwv5vEtooptH8INkbLzOatzKuVbQmAYcbWoyz6Dg==",
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-tagfilter": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-tagfilter/-/micromark-extension-gfm-tagfilter-2.0.0.tgz",
      "integrity": "sha512-xHlTOmuCSotIA8TW1mDIM6X2O1SiX5P9IuDtqGonFhEK0qgRI4yeC6vMxEV2dgyr2TiD+2PQ10o+cOhdVAcwfg==",
      "license": "MIT",
      "dependencies": {
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-task-list-item": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-task-list-item/-/micromark-extension-gfm-task-list-item-2.1.0.tgz",
      "integrity": "sha512-qIBZhqxqI6fjLDYFTBIa4eivDMnP+OZqsNwmQ3xNLE4Cxwc+zfQEfbs6tzAo2Hjq+bh6q5F+Z8/cksrLFYWQQw==",
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-factory-destination": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-factory-destination/-/micromark-factory-destination-2.0.1.tgz",
      "integrity": "sha512-Xe6rDdJlkmbFRExpTOmRj9N3MaWmbAgdpSrBQvCFqhezUn4AHqJHbaEnfbVYYiexVSs//tqOdY/DxhjdCiJnIA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-factory-label": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-factory-label/-/micromark-factory-label-2.0.1.tgz",
      "integrity": "sha512-VFMekyQExqIW7xIChcXn4ok29YE3rnuyveW3wZQWWqF4Nv9Wk5rgJ99KzPvHjkmPXF93FXIbBp6YdW3t71/7Vg==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-factory-space": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-factory-space/-/micromark-factory-space-2.0.1.tgz",
      "integrity": "sha512-zRkxjtBxxLd2Sc0d+fbnEunsTj46SWXgXciZmHq0kDYGnck/ZSGj9/wULTV95uoeYiK5hRXP2mJ98Uo4cq/LQg==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-character": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-factory-title": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-factory-title/-/micromark-factory-title-2.0.1.tgz",
      "integrity": "sha512-5bZ+3CjhAd9eChYTHsjy6TGxpOFSKgKKJPJxr293jTbfry2KDoWkhBb6TcPVB4NmzaPhMs1Frm9AZH7OD4Cjzw==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-factory-whitespace": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-factory-whitespace/-/micromark-factory-whitespace-2.0.1.tgz",
      "integrity": "sha512-Ob0nuZ3PKt/n0hORHyvoD9uZhr+Za8sFoP+OnMcnWK5lngSzALgQYKMr9RJVOWLqQYuyn6ulqGWSXdwf6F80lQ==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-character": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/micromark-util-character/-/micromark-util-character-2.1.1.tgz",
      "integrity": "sha512-wv8tdUTJ3thSFFFJKtpYKOYiGP2+v96Hvk4Tu8KpCAsTMs6yi+nVmGh1syvSCsaxz45J6Jbw+9DD6g97+NV67Q==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-chunked": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-chunked/-/micromark-util-chunked-2.0.1.tgz",
      "integrity": "sha512-QUNFEOPELfmvv+4xiNg2sRYeS/P84pTW0TCgP5zc9FpXetHY0ab7SxKyAQCNCc1eK0459uoLI1y5oO5Vc1dbhA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-symbol": "^2.0.0"
      }
    },
    "node_modules/micromark-util-classify-character": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-classify-character/-/micromark-util-classify-character-2.0.1.tgz",
      "integrity": "sha512-K0kHzM6afW/MbeWYWLjoHQv1sgg2Q9EccHEDzSkxiP/EaagNzCm7T/WMKZ3rjMbvIpvBiZgwR3dKMygtA4mG1Q==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-combine-extensions": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-combine-extensions/-/micromark-util-combine-extensions-2.0.1.tgz",
      "integrity": "sha512-OnAnH8Ujmy59JcyZw8JSbK9cGpdVY44NKgSM7E9Eh7DiLS2E9RNQf0dONaGDzEG9yjEl5hcqeIsj4hfRkLH/Bg==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-chunked": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-decode-numeric-character-reference": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/micromark-util-decode-numeric-character-reference/-/micromark-util-decode-numeric-character-reference-2.0.2.tgz",
      "integrity": "sha512-ccUbYk6CwVdkmCQMyr64dXz42EfHGkPQlBj5p7YVGzq8I7CtjXZJrubAYezf7Rp+bjPseiROqe7G6foFd+lEuw==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-symbol": "^2.0.0"
      }
    },
    "node_modules/micromark-util-decode-string": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-decode-string/-/micromark-util-decode-string-2.0.1.tgz",
      "integrity": "sha512-nDV/77Fj6eH1ynwscYTOsbK7rR//Uj0bZXBwJZRfaLEJ1iGBR6kIfNmlNqaqJf649EP0F3NWNdeJi03elllNUQ==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "decode-named-character-reference": "^1.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-decode-numeric-character-reference": "^2.0.0",
        "micromark-util-symbol": "^2.0.0"
      }
    },
    "node_modules/micromark-util-encode": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-encode/-/micromark-util-encode-2.0.1.tgz",
      "integrity": "sha512-c3cVx2y4KqUnwopcO9b/SCdo2O67LwJJ/UyqGfbigahfegL9myoEFoDYZgkT7f36T0bLrM9hZTAaAyH+PCAXjw==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT"
    },
    "node_modules/micromark-util-html-tag-name": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-html-tag-name/-/micromark-util-html-tag-name-2.0.1.tgz",
      "integrity": "sha512-2cNEiYDhCWKI+Gs9T0Tiysk136SnR13hhO8yW6BGNyhOC4qYFnwF1nKfD3HFAIXA5c45RrIG1ub11GiXeYd1xA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT"
    },
    "node_modules/micromark-util-normalize-identifier": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-normalize-identifier/-/micromark-util-normalize-identifier-2.0.1.tgz",
      "integrity": "sha512-sxPqmo70LyARJs0w2UclACPUUEqltCkJ6PhKdMIDuJ3gSf/Q+/GIe3WKl0Ijb/GyH9lOpUkRAO2wp0GVkLvS9Q==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-symbol": "^2.0.0"
      }
    },
    "node_modules/micromark-util-resolve-all": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-resolve-all/-/micromark-util-resolve-all-2.0.1.tgz",
      "integrity": "sha512-VdQyxFWFT2/FGJgwQnJYbe1jjQoNTS4RjglmSjTUlpUMa95Htx9NHeYW4rGDJzbjvCsl9eLjMQwGeElsqmzcHg==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-sanitize-uri": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-sanitize-uri/-/micromark-util-sanitize-uri-2.0.1.tgz",
      "integrity": "sha512-9N9IomZ/YuGGZZmQec1MbgxtlgougxTodVwDzzEouPKo3qFWvymFHWcnDi2vzV1ff6kas9ucW+o3yzJK9YB1AQ==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-character": "^2.0.0",
        "micromark-util-encode": "^2.0.0",
        "micromark-util-symbol": "^2.0.0"
      }
    },
    "node_modules/micromark-util-subtokenize": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/micromark-util-subtokenize/-/micromark-util-subtokenize-2.1.0.tgz",
      "integrity": "sha512-XQLu552iSctvnEcgXw6+Sx75GflAPNED1qx7eBJ+wydBb2KCbRZe+NwvIEEMM83uml1+2WSXpBAcp9IUCgCYWA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-util-chunked": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-symbol": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-symbol/-/micromark-util-symbol-2.0.1.tgz",
      "integrity": "sha512-vs5t8Apaud9N28kgCrRUdEed4UJ+wWNvicHLPxCa9ENlYuAY31M0ETy5y1vA33YoNPDFTghEbnh6efaE8h4x0Q==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT"
    },
    "node_modules/micromark-util-types": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/micromark-util-types/-/micromark-util-types-2.0.2.tgz",
      "integrity": "sha512-Yw0ECSpJoViF1qTU4DC6NwtC4aWGt1EkzaQB8KPPyCRR8z9TWeV0HbEFGTO+ZY1wB22zmxnJqhPyTpOVCpeHTA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT"
    },
    "node_modules/micromatch": {
      "version": "4.0.8",
      "resolved": "https://registry.npmjs.org/micromatch/-/micromatch-4.0.8.tgz",
      "integrity": "sha512-PXwfBhYu0hBCPw8Dn0E+WDYb7af3dSLVWKi3HGv84IdF4TyFoC0ysxFd0Goxw7nSv4T/PzEJQxsYsEiFCKo2BA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "braces": "^3.0.3",
        "picomatch": "^2.3.1"
      },
      "engines": {
        "node": ">=8.6"
      }
    },
    "node_modules/mime-db": {
      "version": "1.52.0",
      "resolved": "https://registry.npmjs.org/mime-db/-/mime-db-1.52.0.tgz",
      "integrity": "sha512-sPU4uV7dYlvtWJxwwxHD0PuihVNiE7TyAbQ5SWxDCB9mUYvOgroQOwYQQOKPJ8CIbE+1ETVlOoK1UC2nU3gYvg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/mime-types": {
      "version": "2.1.35",
      "resolved": "https://registry.npmjs.org/mime-types/-/mime-types-2.1.35.tgz",
      "integrity": "sha512-ZDY+bPm5zTTF+YpCrAU9nK0UgICYPT0QtT1NZWFv4s++TNkcgVaT0g6+4R2uI4MjQjzysHB1zxuWL50hzaeXiw==",
      "license": "MIT",
      "dependencies": {
        "mime-db": "1.52.0"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/minimatch": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz",
      "integrity": "sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^1.1.7"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/minipass": {
      "version": "7.1.2",
      "resolved": "https://registry.npmjs.org/minipass/-/minipass-7.1.2.tgz",
      "integrity": "sha512-qOOzS1cBTWYF4BH8fVePDBOO9iptMnGUEZwNc/cMWnTV2nVLZ7VoNWEPHkYczZA0pdoA7dl6e7FL659nX9S2aw==",
      "dev": true,
      "license": "ISC",
      "engines": {
        "node": ">=16 || 14 >=14.17"
      }
    },
    "node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "license": "MIT"
    },
    "node_modules/mz": {
      "version": "2.7.0",
      "resolved": "https://registry.npmjs.org/mz/-/mz-2.7.0.tgz",
      "integrity": "sha512-z81GNO7nnYMEhrGh9LeymoE4+Yr0Wn5McHIZMK5cfQCl+NDX08sCZgUc9/6MHni9IWuFLm1Z3HTCXu2z9fN62Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "any-promise": "^1.0.0",
        "object-assign": "^4.0.1",
        "thenify-all": "^1.0.0"
      }
    },
    "node_modules/nanoid": {
      "version": "3.3.11",
      "resolved": "https://registry.npmjs.org/nanoid/-/nanoid-3.3.11.tgz",
      "integrity": "sha512-N8SpfPUnUp1bK+PMYW8qSWdl9U+wwNWI4QKxOYDy9JAro3WMX7p2OeVRF9v+347pnakNevPmiHhNmZ2HbFA76w==",
      "dev": true,
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "bin": {
        "nanoid": "bin/nanoid.cjs"
      },
      "engines": {
        "node": "^10 || ^12 || ^13.7 || ^14 || >=15.0.1"
      }
    },
    "node_modules/natural-compare": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/natural-compare/-/natural-compare-1.4.0.tgz",
      "integrity": "sha512-OWND8ei3VtNC9h7V60qff3SVobHr996CTwgxubgyQYEpg290h9J0buyECNNJexkFm5sOajh5G116RYA1c8ZMSw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/next-themes": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/next-themes/-/next-themes-0.3.0.tgz",
      "integrity": "sha512-/QHIrsYpd6Kfk7xakK4svpDI5mmXP0gfvCoJdGpZQ2TOrQZmsW0QxjaiLn8wbIKjtm4BTSqLoix4lxYYOnLJ/w==",
      "license": "MIT",
      "peerDependencies": {
        "react": "^16.8 || ^17 || ^18",
        "react-dom": "^16.8 || ^17 || ^18"
      }
    },
    "node_modules/node-releases": {
      "version": "2.0.19",
      "resolved": "https://registry.npmjs.org/node-releases/-/node-releases-2.0.19.tgz",
      "integrity": "sha512-xxOWJsBKtzAq7DY0J+DTzuz58K8e7sJbdgwkbMWQe8UYB6ekmsQ45q0M/tJDsGaZmbC+l7n57UV8Hl5tHxO9uw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/normalize-path": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/normalize-path/-/normalize-path-3.0.0.tgz",
      "integrity": "sha512-6eZs5Ls3WtCisHWp9S2GUy8dqkpGi4BVSz3GaqiE6ezub0512ESztXUwUB6C6IKbQkY2Pnb/mD4WYojCRwcwLA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/normalize-range": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/normalize-range/-/normalize-range-0.1.2.tgz",
      "integrity": "sha512-bdok/XvKII3nUpklnV6P2hxtMNrCboOjAcyBuQnWEhO665FwrSNRxU+AqpsyvO6LgGYPspN+lu5CLtw4jPRKNA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/object-assign": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/object-assign/-/object-assign-4.1.1.tgz",
      "integrity": "sha512-rJgTQnkUnH1sFw8yT6VSU3zD3sWmu6sZhIseY8VX+GRu3P6F7Fu+JNDoXfklElbLJSnc3FUQHVe4cU5hj+BcUg==",
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/object-hash": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/object-hash/-/object-hash-3.0.0.tgz",
      "integrity": "sha512-RSn9F68PjH9HqtltsSnqYC1XXoWe9Bju5+213R98cNGttag9q9yAOTzdbsqvIa7aNm5WffBZFpWYr2aWrklWAw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/optionator": {
      "version": "0.9.4",
      "resolved": "https://registry.npmjs.org/optionator/-/optionator-0.9.4.tgz",
      "integrity": "sha512-6IpQ7mKUxRcZNLIObR0hz7lxsapSSIYNZJwXPGeF0mTVqGKFIXj1DQcMoT22S3ROcLyY/rz0PWaWZ9ayWmad9g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "deep-is": "^0.1.3",
        "fast-levenshtein": "^2.0.6",
        "levn": "^0.4.1",
        "prelude-ls": "^1.2.1",
        "type-check": "^0.4.0",
        "word-wrap": "^1.2.5"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/p-limit": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/p-limit/-/p-limit-3.1.0.tgz",
      "integrity": "sha512-TYOanM3wGwNGsZN2cVTYPArw454xnXj5qmWF1bEoAc4+cU/ol7GVh7odevjp1FNHduHc3KZMcFduxU5Xc6uJRQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "yocto-queue": "^0.1.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/p-locate": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/p-locate/-/p-locate-5.0.0.tgz",
      "integrity": "sha512-LaNjtRWUBY++zB5nE/NwcaoMylSPk+S+ZHNB1TzdbMJMny6dynpAGt7X/tl/QYq3TIeE6nxHppbo2LGymrG5Pw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-limit": "^3.0.2"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/package-json-from-dist": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/package-json-from-dist/-/package-json-from-dist-1.0.1.tgz",
      "integrity": "sha512-UEZIS3/by4OC8vL3P2dTXRETpebLI2NiI5vIrjaD/5UtrkFX/tNbwjTSRAGC/+7CAo2pIcBaRgWmcBBHcsaCIw==",
      "dev": true,
      "license": "BlueOak-1.0.0"
    },
    "node_modules/parent-module": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/parent-module/-/parent-module-1.0.1.tgz",
      "integrity": "sha512-GQ2EWRpQV8/o+Aw8YqtfZZPfNRWZYkbidE9k5rpl/hC3vtHHBfGm2Ifi6qWV+coDGkrUKZAxE3Lot5kcsRlh+g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "callsites": "^3.0.0"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/parse-entities": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/parse-entities/-/parse-entities-4.0.2.tgz",
      "integrity": "sha512-GG2AQYWoLgL877gQIKeRPGO1xF9+eG1ujIb5soS5gPvLQ1y2o8FL90w2QWNdf9I361Mpp7726c+lj3U0qK1uGw==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^2.0.0",
        "character-entities-legacy": "^3.0.0",
        "character-reference-invalid": "^2.0.0",
        "decode-named-character-reference": "^1.0.0",
        "is-alphanumerical": "^2.0.0",
        "is-decimal": "^2.0.0",
        "is-hexadecimal": "^2.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/parse-entities/node_modules/@types/unist": {
      "version": "2.0.11",
      "resolved": "https://registry.npmjs.org/@types/unist/-/unist-2.0.11.tgz",
      "integrity": "sha512-CmBKiL6NNo/OqgmMn95Fk9Whlp2mtvIv+KNpQKN2F4SjvrEesubTRWGYSg+BnWZOnlCaSTU1sMpsBOzgbYhnsA==",
      "license": "MIT"
    },
    "node_modules/path-exists": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/path-exists/-/path-exists-4.0.0.tgz",
      "integrity": "sha512-ak9Qy5Q7jYb2Wwcey5Fpvg2KoAc/ZIhLSLOSBmRmygPsGwkVVt0fZa0qrtMz+m6tJTAHfZQ8FnmB4MG4LWy7/w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/path-key": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/path-key/-/path-key-3.1.1.tgz",
      "integrity": "sha512-ojmeN0qd+y0jszEtoY48r0Peq5dwMEkIlCOu6Q5f41lfkswXuKtYrhgoTpLnyIcHm24Uhqx+5Tqm2InSwLhE6Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/path-parse": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/path-parse/-/path-parse-1.0.7.tgz",
      "integrity": "sha512-LDJzPVEEEPR+y48z93A0Ed0yXb8pAByGWo/k5YYdYgpY2/2EsOsksJrq7lOHxryrVOn1ejG6oAp8ahvOIQD8sw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/path-scurry": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/path-scurry/-/path-scurry-1.11.1.tgz",
      "integrity": "sha512-Xa4Nw17FS9ApQFJ9umLiJS4orGjm7ZzwUrwamcGQuHSzDyth9boKDaycYdDcZDuqYATXw4HFXgaqWTctW/v1HA==",
      "dev": true,
      "license": "BlueOak-1.0.0",
      "dependencies": {
        "lru-cache": "^10.2.0",
        "minipass": "^5.0.0 || ^6.0.2 || ^7.0.0"
      },
      "engines": {
        "node": ">=16 || 14 >=14.18"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/picocolors": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/picocolors/-/picocolors-1.1.1.tgz",
      "integrity": "sha512-xceH2snhtb5M9liqDsmEw56le376mTZkEX/jEb/RxNFyegNul7eNslCXP9FDj/Lcu0X8KEyMceP2ntpaHrDEVA==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/picomatch": {
      "version": "2.3.1",
      "resolved": "https://registry.npmjs.org/picomatch/-/picomatch-2.3.1.tgz",
      "integrity": "sha512-JU3teHTNjmE2VCGFzuY8EXzCDVwEqB2a8fsIvwaStHhAWJEeVd1o1QD80CU6+ZdEXXSLbSsuLwJjkCBWqRQUVA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8.6"
      },
      "funding": {
        "url": "https://github.com/sponsors/jonschlinkert"
      }
    },
    "node_modules/pify": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/pify/-/pify-2.3.0.tgz",
      "integrity": "sha512-udgsAY+fTnvv7kI7aaxbqwWNb0AHiB0qBO89PZKPkoTmGOgdbrHDKD+0B2X4uTfJ/FT1R09r9gTsjUjNJotuog==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/pirates": {
      "version": "4.0.6",
      "resolved": "https://registry.npmjs.org/pirates/-/pirates-4.0.6.tgz",
      "integrity": "sha512-saLsH7WeYYPiD25LDuLRRY/i+6HaPYr6G1OUlN39otzkSTxKnubR9RTxS3/Kk50s1g2JTgFwWQDQyplC5/SHZg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/playwright": {
      "version": "1.57.0",
      "resolved": "https://registry.npmjs.org/playwright/-/playwright-1.57.0.tgz",
      "integrity": "sha512-ilYQj1s8sr2ppEJ2YVadYBN0Mb3mdo9J0wQ+UuDhzYqURwSoW4n1Xs5vs7ORwgDGmyEh33tRMeS8KhdkMoLXQw==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "playwright-core": "1.57.0"
      },
      "bin": {
        "playwright": "cli.js"
      },
      "engines": {
        "node": ">=18"
      },
      "optionalDependencies": {
        "fsevents": "2.3.2"
      }
    },
    "node_modules/playwright-core": {
      "version": "1.57.0",
      "resolved": "https://registry.npmjs.org/playwright-core/-/playwright-core-1.57.0.tgz",
      "integrity": "sha512-agTcKlMw/mjBWOnD6kFZttAAGHgi/Nw0CZ2o6JqWSbMlI219lAFLZZCyqByTsvVAJq5XA5H8cA6PrvBRpBWEuQ==",
      "dev": true,
      "license": "Apache-2.0",
      "bin": {
        "playwright-core": "cli.js"
      },
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/playwright/node_modules/fsevents": {
      "version": "2.3.2",
      "resolved": "https://registry.npmjs.org/fsevents/-/fsevents-2.3.2.tgz",
      "integrity": "sha512-xiqMQR4xAeHTuB9uWm+fFRcIOgKBMiOBP+eXiyT7jsgVCq1bkVygt00oASowB7EdtpOHaaPgKt812P9ab+DDKA==",
      "dev": true,
      "hasInstallScript": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": "^8.16.0 || ^10.6.0 || >=11.0.0"
      }
    },
    "node_modules/postcss": {
      "version": "8.5.6",
      "resolved": "https://registry.npmjs.org/postcss/-/postcss-8.5.6.tgz",
      "integrity": "sha512-3Ybi1tAuwAP9s0r1UQ2J4n5Y0G05bJkpUIO0/bI9MhwmD70S5aTWbXGBwxHrelT+XM1k6dM0pk+SwNkpTRN7Pg==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/postcss"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "nanoid": "^3.3.11",
        "picocolors": "^1.1.1",
        "source-map-js": "^1.2.1"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      }
    },
    "node_modules/postcss-import": {
      "version": "15.1.0",
      "resolved": "https://registry.npmjs.org/postcss-import/-/postcss-import-15.1.0.tgz",
      "integrity": "sha512-hpr+J05B2FVYUAXHeK1YyI267J/dDDhMU6B6civm8hSY1jYJnBXxzKDKDswzJmtLHryrjhnDjqqp/49t8FALew==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "postcss-value-parser": "^4.0.0",
        "read-cache": "^1.0.0",
        "resolve": "^1.1.7"
      },
      "engines": {
        "node": ">=14.0.0"
      },
      "peerDependencies": {
        "postcss": "^8.0.0"
      }
    },
    "node_modules/postcss-js": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/postcss-js/-/postcss-js-4.0.1.tgz",
      "integrity": "sha512-dDLF8pEO191hJMtlHFPRa8xsizHaM82MLfNkUHdUtVEV3tgTp5oj+8qbEqYM57SLfc74KSbw//4SeJma2LRVIw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "camelcase-css": "^2.0.1"
      },
      "engines": {
        "node": "^12 || ^14 || >= 16"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/postcss/"
      },
      "peerDependencies": {
        "postcss": "^8.4.21"
      }
    },
    "node_modules/postcss-load-config": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/postcss-load-config/-/postcss-load-config-4.0.2.tgz",
      "integrity": "sha512-bSVhyJGL00wMVoPUzAVAnbEoWyqRxkjv64tUl427SKnPrENtq6hJwUojroMz2VB+Q1edmi4IfrAPpami5VVgMQ==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "lilconfig": "^3.0.0",
        "yaml": "^2.3.4"
      },
      "engines": {
        "node": ">= 14"
      },
      "peerDependencies": {
        "postcss": ">=8.0.9",
        "ts-node": ">=9.0.0"
      },
      "peerDependenciesMeta": {
        "postcss": {
          "optional": true
        },
        "ts-node": {
          "optional": true
        }
      }
    },
    "node_modules/postcss-nested": {
      "version": "6.2.0",
      "resolved": "https://registry.npmjs.org/postcss-nested/-/postcss-nested-6.2.0.tgz",
      "integrity": "sha512-HQbt28KulC5AJzG+cZtj9kvKB93CFCdLvog1WFLf1D+xmMvPGlBstkpTEZfK5+AN9hfJocyBFCNiqyS48bpgzQ==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "postcss-selector-parser": "^6.1.1"
      },
      "engines": {
        "node": ">=12.0"
      },
      "peerDependencies": {
        "postcss": "^8.2.14"
      }
    },
    "node_modules/postcss-selector-parser": {
      "version": "6.1.2",
      "resolved": "https://registry.npmjs.org/postcss-selector-parser/-/postcss-selector-parser-6.1.2.tgz",
      "integrity": "sha512-Q8qQfPiZ+THO/3ZrOrO0cJJKfpYCagtMUkXbnEfmgUjwXg6z/WBeOyS9APBBPCTSiDV+s4SwQGu8yFsiMRIudg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "cssesc": "^3.0.0",
        "util-deprecate": "^1.0.2"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/postcss-value-parser": {
      "version": "4.2.0",
      "resolved": "https://registry.npmjs.org/postcss-value-parser/-/postcss-value-parser-4.2.0.tgz",
      "integrity": "sha512-1NNCs6uurfkVbeXG4S8JFT9t19m45ICnif8zWLd5oPSZ50QnwMfK+H3jv408d4jw/7Bttv5axS5IiHoLaVNHeQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/prelude-ls": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/prelude-ls/-/prelude-ls-1.2.1.tgz",
      "integrity": "sha512-vkcDPrRZo1QZLbn5RLGPpg/WmIQ65qoWWhcGKf/b5eplkkarX0m9z8ppCat4mlOqUsWpyNuYgO3VRyrYHSzX5g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/prop-types": {
      "version": "15.8.1",
      "resolved": "https://registry.npmjs.org/prop-types/-/prop-types-15.8.1.tgz",
      "integrity": "sha512-oj87CgZICdulUohogVAR7AjlC0327U4el4L6eAvOqCeudMDVU0NThNaV+b9Df4dXgSP1gXMTnPdhfe/2qDH5cg==",
      "license": "MIT",
      "dependencies": {
        "loose-envify": "^1.4.0",
        "object-assign": "^4.1.1",
        "react-is": "^16.13.1"
      }
    },
    "node_modules/prop-types/node_modules/react-is": {
      "version": "16.13.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-16.13.1.tgz",
      "integrity": "sha512-24e6ynE2H+OKt4kqsOvNd8kBpV65zoxbA4BVsEOB3ARVWQki/DHzaUoC5KuON/BiccDaCCTZBuOcfZs70kR8bQ==",
      "license": "MIT"
    },
    "node_modules/property-information": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/property-information/-/property-information-7.1.0.tgz",
      "integrity": "sha512-TwEZ+X+yCJmYfL7TPUOcvBZ4QfoT5YenQiJuX//0th53DE6w0xxLEtfK3iyryQFddXuvkIk51EEgrJQ0WJkOmQ==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/proxy-from-env": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/proxy-from-env/-/proxy-from-env-1.1.0.tgz",
      "integrity": "sha512-D+zkORCbA9f1tdWRK0RaCR3GPv50cMxcrz4X8k5LTSUD1Dkw47mKJEZQNunItRTkWwgtaUSo1RVFRIG9ZXiFYg==",
      "license": "MIT"
    },
    "node_modules/punycode": {
      "version": "2.3.1",
      "resolved": "https://registry.npmjs.org/punycode/-/punycode-2.3.1.tgz",
      "integrity": "sha512-vYt7UD1U9Wg6138shLtLOvdAu+8DsC/ilFtEVHcH+wydcSpNE20AfSOduf6MkRFahL5FY7X1oU7nKVZFtfq8Fg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/queue-microtask": {
      "version": "1.2.3",
      "resolved": "https://registry.npmjs.org/queue-microtask/-/queue-microtask-1.2.3.tgz",
      "integrity": "sha512-NuaNSa6flKT5JaSYQzJok04JzTL1CA6aGhv5rfLW3PgqA+M2ChpZQnAC8h8i4ZFkBS8X5RqkDBHA7r4hej3K9A==",
      "dev": true,
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ],
      "license": "MIT"
    },
    "node_modules/react": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react/-/react-18.3.1.tgz",
      "integrity": "sha512-wS+hAgJShR0KhEvPJArfuPVN1+Hz1t0Y6n5jLrGQbkb4urgPE/0Rve+1kMB1v/oWgHgm4WIcV+i7F2pTVj+2iQ==",
      "license": "MIT",
      "dependencies": {
        "loose-envify": "^1.1.0"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/react-chartjs-2": {
      "version": "5.3.1",
      "resolved": "https://registry.npmjs.org/react-chartjs-2/-/react-chartjs-2-5.3.1.tgz",
      "integrity": "sha512-h5IPXKg9EXpjoBzUfyWJvllMjG2mQ4EiuHQFhms/AjUm0XSZHhyRy2xVmLXHKrtcdrPO4mnGqRtYoD0vp95A0A==",
      "license": "MIT",
      "peerDependencies": {
        "chart.js": "^4.1.1",
        "react": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0"
      }
    },
    "node_modules/react-day-picker": {
      "version": "8.10.1",
      "resolved": "https://registry.npmjs.org/react-day-picker/-/react-day-picker-8.10.1.tgz",
      "integrity": "sha512-TMx7fNbhLk15eqcMt+7Z7S2KF7mfTId/XJDjKE8f+IUcFn0l08/kI4FiYTL/0yuOLmEcbR4Fwe3GJf/NiiMnPA==",
      "license": "MIT",
      "funding": {
        "type": "individual",
        "url": "https://github.com/sponsors/gpbl"
      },
      "peerDependencies": {
        "date-fns": "^2.28.0 || ^3.0.0",
        "react": "^16.8.0 || ^17.0.0 || ^18.0.0"
      }
    },
    "node_modules/react-dom": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react-dom/-/react-dom-18.3.1.tgz",
      "integrity": "sha512-5m4nQKp+rZRb09LNH59GM4BxTh9251/ylbKIbpe7TpGxfJ+9kv6BLkLBXIjjspbgbnIBNqlI23tRnTWT0snUIw==",
      "license": "MIT",
      "dependencies": {
        "loose-envify": "^1.1.0",
        "scheduler": "^0.23.2"
      },
      "peerDependencies": {
        "react": "^18.3.1"
      }
    },
    "node_modules/react-hook-form": {
      "version": "7.61.1",
      "resolved": "https://registry.npmjs.org/react-hook-form/-/react-hook-form-7.61.1.tgz",
      "integrity": "sha512-2vbXUFDYgqEgM2RcXcAT2PwDW/80QARi+PKmHy5q2KhuKvOlG8iIYgf7eIlIANR5trW9fJbP4r5aub3a4egsew==",
      "license": "MIT",
      "engines": {
        "node": ">=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/react-hook-form"
      },
      "peerDependencies": {
        "react": "^16.8.0 || ^17 || ^18 || ^19"
      }
    },
    "node_modules/react-is": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-18.3.1.tgz",
      "integrity": "sha512-/LLMVyas0ljjAtoYiPqYiL8VWXzUUdThrmU5+n20DZv+a+ClRoevUzw5JxU+Ieh5/c87ytoTBV9G1FiKfNJdmg==",
      "license": "MIT"
    },
    "node_modules/react-markdown": {
      "version": "9.1.0",
      "resolved": "https://registry.npmjs.org/react-markdown/-/react-markdown-9.1.0.tgz",
      "integrity": "sha512-xaijuJB0kzGiUdG7nc2MOMDUDBWPyGAjZtUrow9XxUeua8IqeP+VlIfAZ3bphpcLTnSZXz6z9jcVC/TCwbfgdw==",
      "license": "MIT",
      "dependencies": {
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "devlop": "^1.0.0",
        "hast-util-to-jsx-runtime": "^2.0.0",
        "html-url-attributes": "^3.0.0",
        "mdast-util-to-hast": "^13.0.0",
        "remark-parse": "^11.0.0",
        "remark-rehype": "^11.0.0",
        "unified": "^11.0.0",
        "unist-util-visit": "^5.0.0",
        "vfile": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      },
      "peerDependencies": {
        "@types/react": ">=18",
        "react": ">=18"
      }
    },
    "node_modules/react-remove-scroll": {
      "version": "2.7.1",
      "resolved": "https://registry.npmjs.org/react-remove-scroll/-/react-remove-scroll-2.7.1.tgz",
      "integrity": "sha512-HpMh8+oahmIdOuS5aFKKY6Pyog+FNaZV/XyJOq7b4YFwsFHe5yYfdbIalI4k3vU2nSDql7YskmUseHsRrJqIPA==",
      "license": "MIT",
      "dependencies": {
        "react-remove-scroll-bar": "^2.3.7",
        "react-style-singleton": "^2.2.3",
        "tslib": "^2.1.0",
        "use-callback-ref": "^1.3.3",
        "use-sidecar": "^1.1.3"
      },
      "engines": {
        "node": ">=10"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/react-remove-scroll-bar": {
      "version": "2.3.8",
      "resolved": "https://registry.npmjs.org/react-remove-scroll-bar/-/react-remove-scroll-bar-2.3.8.tgz",
      "integrity": "sha512-9r+yi9+mgU33AKcj6IbT9oRCO78WriSj6t/cF8DWBZJ9aOGPOTEDvdUDz1FwKim7QXWwmHqtdHnRJfhAxEG46Q==",
      "license": "MIT",
      "dependencies": {
        "react-style-singleton": "^2.2.2",
        "tslib": "^2.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/react-resizable-panels": {
      "version": "2.1.9",
      "resolved": "https://registry.npmjs.org/react-resizable-panels/-/react-resizable-panels-2.1.9.tgz",
      "integrity": "sha512-z77+X08YDIrgAes4jl8xhnUu1LNIRp4+E7cv4xHmLOxxUPO/ML7PSrE813b90vj7xvQ1lcf7g2uA9GeMZonjhQ==",
      "license": "MIT",
      "peerDependencies": {
        "react": "^16.14.0 || ^17.0.0 || ^18.0.0 || ^19.0.0 || ^19.0.0-rc",
        "react-dom": "^16.14.0 || ^17.0.0 || ^18.0.0 || ^19.0.0 || ^19.0.0-rc"
      }
    },
    "node_modules/react-router": {
      "version": "6.30.1",
      "resolved": "https://registry.npmjs.org/react-router/-/react-router-6.30.1.tgz",
      "integrity": "sha512-X1m21aEmxGXqENEPG3T6u0Th7g0aS4ZmoNynhbs+Cn+q+QGTLt+d5IQ2bHAXKzKcxGJjxACpVbnYQSCRcfxHlQ==",
      "license": "MIT",
      "dependencies": {
        "@remix-run/router": "1.23.0"
      },
      "engines": {
        "node": ">=14.0.0"
      },
      "peerDependencies": {
        "react": ">=16.8"
      }
    },
    "node_modules/react-router-dom": {
      "version": "6.30.1",
      "resolved": "https://registry.npmjs.org/react-router-dom/-/react-router-dom-6.30.1.tgz",
      "integrity": "sha512-llKsgOkZdbPU1Eg3zK8lCn+sjD9wMRZZPuzmdWWX5SUs8OFkN5HnFVC0u5KMeMaC9aoancFI/KoLuKPqN+hxHw==",
      "license": "MIT",
      "dependencies": {
        "@remix-run/router": "1.23.0",
        "react-router": "6.30.1"
      },
      "engines": {
        "node": ">=14.0.0"
      },
      "peerDependencies": {
        "react": ">=16.8",
        "react-dom": ">=16.8"
      }
    },
    "node_modules/react-smooth": {
      "version": "4.0.4",
      "resolved": "https://registry.npmjs.org/react-smooth/-/react-smooth-4.0.4.tgz",
      "integrity": "sha512-gnGKTpYwqL0Iii09gHobNolvX4Kiq4PKx6eWBCYYix+8cdw+cGo3do906l1NBPKkSWx1DghC1dlWG9L2uGd61Q==",
      "license": "MIT",
      "dependencies": {
        "fast-equals": "^5.0.1",
        "prop-types": "^15.8.1",
        "react-transition-group": "^4.4.5"
      },
      "peerDependencies": {
        "react": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0",
        "react-dom": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0"
      }
    },
    "node_modules/react-style-singleton": {
      "version": "2.2.3",
      "resolved": "https://registry.npmjs.org/react-style-singleton/-/react-style-singleton-2.2.3.tgz",
      "integrity": "sha512-b6jSvxvVnyptAiLjbkWLE/lOnR4lfTtDAl+eUC7RZy+QQWc6wRzIV2CE6xBuMmDxc2qIihtDCZD5NPOFl7fRBQ==",
      "license": "MIT",
      "dependencies": {
        "get-nonce": "^1.0.0",
        "tslib": "^2.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/react-transition-group": {
      "version": "4.4.5",
      "resolved": "https://registry.npmjs.org/react-transition-group/-/react-transition-group-4.4.5.tgz",
      "integrity": "sha512-pZcd1MCJoiKiBR2NRxeCRg13uCXbydPnmB4EOeRrY7480qNWO8IIgQG6zlDkm6uRMsURXPuKq0GWtiM59a5Q6g==",
      "license": "BSD-3-Clause",
      "dependencies": {
        "@babel/runtime": "^7.5.5",
        "dom-helpers": "^5.0.1",
        "loose-envify": "^1.4.0",
        "prop-types": "^15.6.2"
      },
      "peerDependencies": {
        "react": ">=16.6.0",
        "react-dom": ">=16.6.0"
      }
    },
    "node_modules/react-wordcloud": {
      "version": "1.2.7",
      "resolved": "https://registry.npmjs.org/react-wordcloud/-/react-wordcloud-1.2.7.tgz",
      "integrity": "sha512-pyXvL8Iu2J258Qk2/kAwY23dIVhNpMC3dnvbXRkw5+Ert5EkJWwnwVjs9q8CmX38NWbfCKhGmpjuumBoQEtniw==",
      "license": "MIT",
      "dependencies": {
        "d3-array": "^2.5.0",
        "d3-cloud": "^1.2.5",
        "d3-dispatch": "^1.0.6",
        "d3-scale": "^3.2.1",
        "d3-scale-chromatic": "^1.5.0",
        "d3-selection": "1.4.2",
        "d3-transition": "^1.3.2",
        "lodash.clonedeep": "^4.5.0",
        "lodash.debounce": "^4.0.8",
        "resize-observer-polyfill": "^1.5.1",
        "seedrandom": "^3.0.5",
        "tippy.js": "^6.2.6"
      },
      "peerDependencies": {
        "react": "^16.13.0"
      }
    },
    "node_modules/react-wordcloud/node_modules/d3-array": {
      "version": "2.12.1",
      "resolved": "https://registry.npmjs.org/d3-array/-/d3-array-2.12.1.tgz",
      "integrity": "sha512-B0ErZK/66mHtEsR1TkPEEkwdy+WDesimkM5gpZr5Dsg54BiTA5RXtYW5qTLIAcekaS9xfZrzBLF/OAkB3Qn1YQ==",
      "license": "BSD-3-Clause",
      "dependencies": {
        "internmap": "^1.0.0"
      }
    },
    "node_modules/react-wordcloud/node_modules/d3-color": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/d3-color/-/d3-color-2.0.0.tgz",
      "integrity": "sha512-SPXi0TSKPD4g9tw0NMZFnR95XVgUZiBH+uUTqQuDu1OsE2zomHU7ho0FISciaPvosimixwHFl3WHLGabv6dDgQ==",
      "license": "BSD-3-Clause"
    },
    "node_modules/react-wordcloud/node_modules/d3-format": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/d3-format/-/d3-format-2.0.0.tgz",
      "integrity": "sha512-Ab3S6XuE/Q+flY96HXT0jOXcM4EAClYFnRGY5zsjRGNy6qCYrQsMffs7cV5Q9xejb35zxW5hf/guKw34kvIKsA==",
      "license": "BSD-3-Clause"
    },
    "node_modules/react-wordcloud/node_modules/d3-interpolate": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/d3-interpolate/-/d3-interpolate-2.0.1.tgz",
      "integrity": "sha512-c5UhwwTs/yybcmTpAVqwSFl6vrQ8JZJoT5F7xNFK9pymv5C0Ymcc9/LIJHtYIggg/yS9YHw8i8O8tgb9pupjeQ==",
      "license": "BSD-3-Clause",
      "dependencies": {
        "d3-color": "1 - 2"
      }
    },
    "node_modules/react-wordcloud/node_modules/d3-scale": {
      "version": "3.3.0",
      "resolved": "https://registry.npmjs.org/d3-scale/-/d3-scale-3.3.0.tgz",
      "integrity": "sha512-1JGp44NQCt5d1g+Yy+GeOnZP7xHo0ii8zsQp6PGzd+C1/dl0KGsp9A7Mxwp+1D1o4unbTTxVdU/ZOIEBoeZPbQ==",
      "license": "BSD-3-Clause",
      "dependencies": {
        "d3-array": "^2.3.0",
        "d3-format": "1 - 2",
        "d3-interpolate": "1.2.0 - 2",
        "d3-time": "^2.1.1",
        "d3-time-format": "2 - 3"
      }
    },
    "node_modules/react-wordcloud/node_modules/d3-time": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/d3-time/-/d3-time-2.1.1.tgz",
      "integrity": "sha512-/eIQe/eR4kCQwq7yxi7z4c6qEXf2IYGcjoWB5OOQy4Tq9Uv39/947qlDcN2TLkiTzQWzvnsuYPB9TrWaNfipKQ==",
      "license": "BSD-3-Clause",
      "dependencies": {
        "d3-array": "2"
      }
    },
    "node_modules/react-wordcloud/node_modules/d3-time-format": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/d3-time-format/-/d3-time-format-3.0.0.tgz",
      "integrity": "sha512-UXJh6EKsHBTjopVqZBhFysQcoXSv/5yLONZvkQ5Kk3qbwiUYkdX17Xa1PT6U1ZWXGGfB1ey5L8dKMlFq2DO0Ag==",
      "license": "BSD-3-Clause",
      "dependencies": {
        "d3-time": "1 - 2"
      }
    },
    "node_modules/react-wordcloud/node_modules/internmap": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/internmap/-/internmap-1.0.1.tgz",
      "integrity": "sha512-lDB5YccMydFBtasVtxnZ3MRBHuaoE8GKsppq+EchKL2U4nK/DmEpPHNH8MZe5HkMtpSiTSOZwfN0tzYjO/lJEw==",
      "license": "ISC"
    },
    "node_modules/read-cache": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/read-cache/-/read-cache-1.0.0.tgz",
      "integrity": "sha512-Owdv/Ft7IjOgm/i0xvNDZ1LrRANRfew4b2prF3OWMQLxLfu3bS8FVhCsrSCMK4lR56Y9ya+AThoTpDCTxCmpRA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "pify": "^2.3.0"
      }
    },
    "node_modules/readdirp": {
      "version": "3.6.0",
      "resolved": "https://registry.npmjs.org/readdirp/-/readdirp-3.6.0.tgz",
      "integrity": "sha512-hOS089on8RduqdbhvQ5Z37A0ESjsqz6qnRcffsMU3495FuTdqSm+7bhJ29JvIOsBDEEnan5DPu9t3To9VRlMzA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "picomatch": "^2.2.1"
      },
      "engines": {
        "node": ">=8.10.0"
      }
    },
    "node_modules/recharts": {
      "version": "2.15.4",
      "resolved": "https://registry.npmjs.org/recharts/-/recharts-2.15.4.tgz",
      "integrity": "sha512-UT/q6fwS3c1dHbXv2uFgYJ9BMFHu3fwnd7AYZaEQhXuYQ4hgsxLvsUXzGdKeZrW5xopzDCvuA2N41WJ88I7zIw==",
      "license": "MIT",
      "dependencies": {
        "clsx": "^2.0.0",
        "eventemitter3": "^4.0.1",
        "lodash": "^4.17.21",
        "react-is": "^18.3.1",
        "react-smooth": "^4.0.4",
        "recharts-scale": "^0.4.4",
        "tiny-invariant": "^1.3.1",
        "victory-vendor": "^36.6.8"
      },
      "engines": {
        "node": ">=14"
      },
      "peerDependencies": {
        "react": "^16.0.0 || ^17.0.0 || ^18.0.0 || ^19.0.0",
        "react-dom": "^16.0.0 || ^17.0.0 || ^18.0.0 || ^19.0.0"
      }
    },
    "node_modules/recharts-scale": {
      "version": "0.4.5",
      "resolved": "https://registry.npmjs.org/recharts-scale/-/recharts-scale-0.4.5.tgz",
      "integrity": "sha512-kivNFO+0OcUNu7jQquLXAxz1FIwZj8nrj+YkOKc5694NbjCvcT6aSZiIzNzd2Kul4o4rTto8QVR9lMNtxD4G1w==",
      "license": "MIT",
      "dependencies": {
        "decimal.js-light": "^2.4.1"
      }
    },
    "node_modules/remark-gfm": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/remark-gfm/-/remark-gfm-4.0.1.tgz",
      "integrity": "sha512-1quofZ2RQ9EWdeN34S79+KExV1764+wCUGop5CPL1WGdD0ocPpu91lzPGbwWMECpEpd42kJGQwzRfyov9j4yNg==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "mdast-util-gfm": "^3.0.0",
        "micromark-extension-gfm": "^3.0.0",
        "remark-parse": "^11.0.0",
        "remark-stringify": "^11.0.0",
        "unified": "^11.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/remark-parse": {
      "version": "11.0.0",
      "resolved": "https://registry.npmjs.org/remark-parse/-/remark-parse-11.0.0.tgz",
      "integrity": "sha512-FCxlKLNGknS5ba/1lmpYijMUzX2esxW5xQqjWxw2eHFfS2MSdaHVINFmhjo+qN1WhZhNimq0dZATN9pH0IDrpA==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "micromark-util-types": "^2.0.0",
        "unified": "^11.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/remark-rehype": {
      "version": "11.1.2",
      "resolved": "https://registry.npmjs.org/remark-rehype/-/remark-rehype-11.1.2.tgz",
      "integrity": "sha512-Dh7l57ianaEoIpzbp0PC9UKAdCSVklD8E5Rpw7ETfbTl3FqcOOgq5q2LVDhgGCkaBv7p24JXikPdvhhmHvKMsw==",
      "license": "MIT",
      "dependencies": {
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "mdast-util-to-hast": "^13.0.0",
        "unified": "^11.0.0",
        "vfile": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/remark-stringify": {
      "version": "11.0.0",
      "resolved": "https://registry.npmjs.org/remark-stringify/-/remark-stringify-11.0.0.tgz",
      "integrity": "sha512-1OSmLd3awB/t8qdoEOMazZkNsfVTeY4fTsgzcQFdXNq8ToTN4ZGwrMnlda4K6smTFKD+GRV6O48i6Z4iKgPPpw==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "mdast-util-to-markdown": "^2.0.0",
        "unified": "^11.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/resize-observer-polyfill": {
      "version": "1.5.1",
      "resolved": "https://registry.npmjs.org/resize-observer-polyfill/-/resize-observer-polyfill-1.5.1.tgz",
      "integrity": "sha512-LwZrotdHOo12nQuZlHEmtuXdqGoOD0OhaxopaNFxWzInpEgaLWoVuAMbTzixuosCx2nEG58ngzW3vxdWoxIgdg==",
      "license": "MIT"
    },
    "node_modules/resolve": {
      "version": "1.22.8",
      "resolved": "https://registry.npmjs.org/resolve/-/resolve-1.22.8.tgz",
      "integrity": "sha512-oKWePCxqpd6FlLvGV1VU0x7bkPmmCNolxzjMf4NczoDnQcIWrAF+cPtZn5i6n+RfD2d9i0tzpKnG6Yk168yIyw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-core-module": "^2.13.0",
        "path-parse": "^1.0.7",
        "supports-preserve-symlinks-flag": "^1.0.0"
      },
      "bin": {
        "resolve": "bin/resolve"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/resolve-from": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/resolve-from/-/resolve-from-4.0.0.tgz",
      "integrity": "sha512-pb/MYmXstAkysRFx8piNI1tGFNQIFA3vkE3Gq4EuA1dF6gHp/+vgZqsCGJapvy8N3Q+4o7FwvquPJcnZ7RYy4g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/reusify": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/reusify/-/reusify-1.0.4.tgz",
      "integrity": "sha512-U9nH88a3fc/ekCF1l0/UP1IosiuIjyTh7hBvXVMHYgVcfGvt897Xguj2UOLDeI5BG2m7/uwyaLVT6fbtCwTyzw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "iojs": ">=1.0.0",
        "node": ">=0.10.0"
      }
    },
    "node_modules/rollup": {
      "version": "4.24.0",
      "resolved": "https://registry.npmjs.org/rollup/-/rollup-4.24.0.tgz",
      "integrity": "sha512-DOmrlGSXNk1DM0ljiQA+i+o0rSLhtii1je5wgk60j49d1jHT5YYttBv1iWOnYSTG+fZZESUOSNiAl89SIet+Cg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/estree": "1.0.6"
      },
      "bin": {
        "rollup": "dist/bin/rollup"
      },
      "engines": {
        "node": ">=18.0.0",
        "npm": ">=8.0.0"
      },
      "optionalDependencies": {
        "@rollup/rollup-android-arm-eabi": "4.24.0",
        "@rollup/rollup-android-arm64": "4.24.0",
        "@rollup/rollup-darwin-arm64": "4.24.0",
        "@rollup/rollup-darwin-x64": "4.24.0",
        "@rollup/rollup-linux-arm-gnueabihf": "4.24.0",
        "@rollup/rollup-linux-arm-musleabihf": "4.24.0",
        "@rollup/rollup-linux-arm64-gnu": "4.24.0",
        "@rollup/rollup-linux-arm64-musl": "4.24.0",
        "@rollup/rollup-linux-powerpc64le-gnu": "4.24.0",
        "@rollup/rollup-linux-riscv64-gnu": "4.24.0",
        "@rollup/rollup-linux-s390x-gnu": "4.24.0",
        "@rollup/rollup-linux-x64-gnu": "4.24.0",
        "@rollup/rollup-linux-x64-musl": "4.24.0",
        "@rollup/rollup-win32-arm64-msvc": "4.24.0",
        "@rollup/rollup-win32-ia32-msvc": "4.24.0",
        "@rollup/rollup-win32-x64-msvc": "4.24.0",
        "fsevents": "~2.3.2"
      }
    },
    "node_modules/run-parallel": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/run-parallel/-/run-parallel-1.2.0.tgz",
      "integrity": "sha512-5l4VyZR86LZ/lDxZTR6jqL8AFE2S0IFLMP26AbjsLVADxHdhB/c0GUsH+y39UfCi3dzz8OlQuPmnaJOMoDHQBA==",
      "dev": true,
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "queue-microtask": "^1.2.2"
      }
    },
    "node_modules/scheduler": {
      "version": "0.23.2",
      "resolved": "https://registry.npmjs.org/scheduler/-/scheduler-0.23.2.tgz",
      "integrity": "sha512-UOShsPwz7NrMUqhR6t0hWjFduvOzbtv7toDH1/hIrfRNIDBnnBWd0CwJTGvTpngVlmwGCdP9/Zl/tVrDqcuYzQ==",
      "license": "MIT",
      "dependencies": {
        "loose-envify": "^1.1.0"
      }
    },
    "node_modules/seedrandom": {
      "version": "3.0.5",
      "resolved": "https://registry.npmjs.org/seedrandom/-/seedrandom-3.0.5.tgz",
      "integrity": "sha512-8OwmbklUNzwezjGInmZ+2clQmExQPvomqjL7LFqOYqtmuxRgQYqOD3mHaU+MvZn5FLUeVxVfQjwLZW/n/JFuqg==",
      "license": "MIT"
    },
    "node_modules/semver": {
      "version": "7.7.2",
      "resolved": "https://registry.npmjs.org/semver/-/semver-7.7.2.tgz",
      "integrity": "sha512-RF0Fw+rO5AMf9MAyaRXI4AV0Ulj5lMHqVxxdSgiVbixSCXoEmmX/jk0CuJw4+3SqroYO9VoUh+HcuJivvtJemA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/shebang-command": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/shebang-command/-/shebang-command-2.0.0.tgz",
      "integrity": "sha512-kHxr2zZpYtdmrN1qDjrrX/Z1rR1kG8Dx+gkpK1G4eXmvXswmcE1hTWBWYUzlraYw1/yZp6YuDY77YtvbN0dmDA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "shebang-regex": "^3.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/shebang-regex": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/shebang-regex/-/shebang-regex-3.0.0.tgz",
      "integrity": "sha512-7++dFhtcx3353uBaq8DDR4NuxBetBzC7ZQOhmTQInHEd6bSrXdiEyzCvG07Z44UYdLShWUyXt5M/yhz8ekcb1A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/signal-exit": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/signal-exit/-/signal-exit-4.1.0.tgz",
      "integrity": "sha512-bzyZ1e88w9O1iNJbKnOlvYTrWPDl46O1bG0D3XInv+9tkPrxrN8jUUTiFlDkkmKWgn1M6CfIA13SuGqOa9Korw==",
      "dev": true,
      "license": "ISC",
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/sonner": {
      "version": "1.7.4",
      "resolved": "https://registry.npmjs.org/sonner/-/sonner-1.7.4.tgz",
      "integrity": "sha512-DIS8z4PfJRbIyfVFDVnK9rO3eYDtse4Omcm6bt0oEr5/jtLgysmjuBl1frJ9E/EQZrFmKx2A8m/s5s9CRXIzhw==",
      "license": "MIT",
      "peerDependencies": {
        "react": "^18.0.0 || ^19.0.0 || ^19.0.0-rc",
        "react-dom": "^18.0.0 || ^19.0.0 || ^19.0.0-rc"
      }
    },
    "node_modules/source-map-js": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/source-map-js/-/source-map-js-1.2.1.tgz",
      "integrity": "sha512-UXWMKhLOwVKb728IUtQPXxfYU+usdybtUrK/8uGE8CQMvrhOpwvzDBwj0QhSL7MQc7vIsISBG8VQ8+IDQxpfQA==",
      "dev": true,
      "license": "BSD-3-Clause",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/space-separated-tokens": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/space-separated-tokens/-/space-separated-tokens-2.0.2.tgz",
      "integrity": "sha512-PEGlAwrG8yXGXRjW32fGbg66JAlOAwbObuqVoJpv/mRgoWDQfgH1wDPvtzWyUSNAXBGSk8h755YDbbcEy3SH2Q==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/string-width": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-5.1.2.tgz",
      "integrity": "sha512-HnLOCR3vjcY8beoNLtcjZ5/nxn2afmME6lhrDrebokqMap+XbeW8n9TXpPDOqdGK5qcI3oT0GKTW6wC7EMiVqA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "eastasianwidth": "^0.2.0",
        "emoji-regex": "^9.2.2",
        "strip-ansi": "^7.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/string-width-cjs": {
      "name": "string-width",
      "version": "4.2.3",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz",
      "integrity": "sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "emoji-regex": "^8.0.0",
        "is-fullwidth-code-point": "^3.0.0",
        "strip-ansi": "^6.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/string-width-cjs/node_modules/ansi-regex": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-5.0.1.tgz",
      "integrity": "sha512-quJQXlTSUGL2LH9SUXo8VwsY4soanhgo6LNSm84E1LBcE8s3O0wpdiRzyR9z/ZZJMlMWv37qOOb9pdJlMUEKFQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/string-width-cjs/node_modules/emoji-regex": {
      "version": "8.0.0",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-8.0.0.tgz",
      "integrity": "sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/string-width-cjs/node_modules/strip-ansi": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz",
      "integrity": "sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/stringify-entities": {
      "version": "4.0.4",
      "resolved": "https://registry.npmjs.org/stringify-entities/-/stringify-entities-4.0.4.tgz",
      "integrity": "sha512-IwfBptatlO+QCJUo19AqvrPNqlVMpW9YEL2LIVY+Rpv2qsjCGxaDLNRgeGsQWJhfItebuJhsGSLjaBbNSQ+ieg==",
      "license": "MIT",
      "dependencies": {
        "character-entities-html4": "^2.0.0",
        "character-entities-legacy": "^3.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/strip-ansi": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-7.1.0.tgz",
      "integrity": "sha512-iq6eVVI64nQQTRYq2KtEg2d2uU7LElhTJwsH4YzIHZshxlgZms/wIc4VoDQTlG/IvVIrBKG06CrZnp0qv7hkcQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^6.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/strip-ansi?sponsor=1"
      }
    },
    "node_modules/strip-ansi-cjs": {
      "name": "strip-ansi",
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz",
      "integrity": "sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/strip-ansi-cjs/node_modules/ansi-regex": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-5.0.1.tgz",
      "integrity": "sha512-quJQXlTSUGL2LH9SUXo8VwsY4soanhgo6LNSm84E1LBcE8s3O0wpdiRzyR9z/ZZJMlMWv37qOOb9pdJlMUEKFQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/strip-json-comments": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/strip-json-comments/-/strip-json-comments-3.1.1.tgz",
      "integrity": "sha512-6fPc+R4ihwqP6N/aIv2f1gMH8lOVtWQHoqC4yK6oSDVVocumAsfCqjkXnqiYMhmMwS/mEHLp7Vehlt3ql6lEig==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/style-to-js": {
      "version": "1.1.21",
      "resolved": "https://registry.npmjs.org/style-to-js/-/style-to-js-1.1.21.tgz",
      "integrity": "sha512-RjQetxJrrUJLQPHbLku6U/ocGtzyjbJMP9lCNK7Ag0CNh690nSH8woqWH9u16nMjYBAok+i7JO1NP2pOy8IsPQ==",
      "license": "MIT",
      "dependencies": {
        "style-to-object": "1.0.14"
      }
    },
    "node_modules/style-to-object": {
      "version": "1.0.14",
      "resolved": "https://registry.npmjs.org/style-to-object/-/style-to-object-1.0.14.tgz",
      "integrity": "sha512-LIN7rULI0jBscWQYaSswptyderlarFkjQ+t79nzty8tcIAceVomEVlLzH5VP4Cmsv6MtKhs7qaAiwlcp+Mgaxw==",
      "license": "MIT",
      "dependencies": {
        "inline-style-parser": "0.2.7"
      }
    },
    "node_modules/sucrase": {
      "version": "3.35.0",
      "resolved": "https://registry.npmjs.org/sucrase/-/sucrase-3.35.0.tgz",
      "integrity": "sha512-8EbVDiu9iN/nESwxeSxDKe0dunta1GOlHufmSSXxMD2z2/tMZpDMpvXQGsc+ajGo8y2uYUmixaSRUc/QPoQ0GA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/gen-mapping": "^0.3.2",
        "commander": "^4.0.0",
        "glob": "^10.3.10",
        "lines-and-columns": "^1.1.6",
        "mz": "^2.7.0",
        "pirates": "^4.0.1",
        "ts-interface-checker": "^0.1.9"
      },
      "bin": {
        "sucrase": "bin/sucrase",
        "sucrase-node": "bin/sucrase-node"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      }
    },
    "node_modules/supports-color": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/supports-color/-/supports-color-7.2.0.tgz",
      "integrity": "sha512-qpCAvRl9stuOHveKsn7HncJRvv501qIacKzQlO/+Lwxc9+0q2wLyv4Dfvt80/DPn2pqOBsJdDiogXGR9+OvwRw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "has-flag": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/supports-preserve-symlinks-flag": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/supports-preserve-symlinks-flag/-/supports-preserve-symlinks-flag-1.0.0.tgz",
      "integrity": "sha512-ot0WnXS9fgdkgIcePe6RHNk1WA8+muPa6cSjeR3V8K27q9BB1rTE3R1p7Hv0z1ZyAc8s6Vvv8DIyWf681MAt0w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/tailwind-merge": {
      "version": "2.6.0",
      "resolved": "https://registry.npmjs.org/tailwind-merge/-/tailwind-merge-2.6.0.tgz",
      "integrity": "sha512-P+Vu1qXfzediirmHOC3xKGAYeZtPcV9g76X+xg2FD4tYgR71ewMA35Y3sCz3zhiN/dwefRpJX0yBcgwi1fXNQA==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/dcastil"
      }
    },
    "node_modules/tailwindcss": {
      "version": "3.4.17",
      "resolved": "https://registry.npmjs.org/tailwindcss/-/tailwindcss-3.4.17.tgz",
      "integrity": "sha512-w33E2aCvSDP0tW9RZuNXadXlkHXqFzSkQew/aIa2i/Sj8fThxwovwlXHSPXTbAHwEIhBFXAedUhP2tueAKP8Og==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@alloc/quick-lru": "^5.2.0",
        "arg": "^5.0.2",
        "chokidar": "^3.6.0",
        "didyoumean": "^1.2.2",
        "dlv": "^1.1.3",
        "fast-glob": "^3.3.2",
        "glob-parent": "^6.0.2",
        "is-glob": "^4.0.3",
        "jiti": "^1.21.6",
        "lilconfig": "^3.1.3",
        "micromatch": "^4.0.8",
        "normalize-path": "^3.0.0",
        "object-hash": "^3.0.0",
        "picocolors": "^1.1.1",
        "postcss": "^8.4.47",
        "postcss-import": "^15.1.0",
        "postcss-js": "^4.0.1",
        "postcss-load-config": "^4.0.2",
        "postcss-nested": "^6.2.0",
        "postcss-selector-parser": "^6.1.2",
        "resolve": "^1.22.8",
        "sucrase": "^3.35.0"
      },
      "bin": {
        "tailwind": "lib/cli.js",
        "tailwindcss": "lib/cli.js"
      },
      "engines": {
        "node": ">=14.0.0"
      }
    },
    "node_modules/tailwindcss-animate": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/tailwindcss-animate/-/tailwindcss-animate-1.0.7.tgz",
      "integrity": "sha512-bl6mpH3T7I3UFxuvDEXLxy/VuFxBk5bbzplh7tXI68mwMokNYd1t9qPBHlnyTwfa4JGC4zP516I1hYYtQ/vspA==",
      "license": "MIT",
      "peerDependencies": {
        "tailwindcss": ">=3.0.0 || insiders"
      }
    },
    "node_modules/thenify": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/thenify/-/thenify-3.3.1.tgz",
      "integrity": "sha512-RVZSIV5IG10Hk3enotrhvz0T9em6cyHBLkH/YAZuKqd8hRkKhSfCGIcP2KUY0EPxndzANBmNllzWPwak+bheSw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "any-promise": "^1.0.0"
      }
    },
    "node_modules/thenify-all": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/thenify-all/-/thenify-all-1.6.0.tgz",
      "integrity": "sha512-RNxQH/qI8/t3thXJDwcstUO4zeqo64+Uy/+sNVRBx4Xn2OX+OZ9oP+iJnNFqplFra2ZUVeKCSa2oVWi3T4uVmA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "thenify": ">= 3.1.0 < 4"
      },
      "engines": {
        "node": ">=0.8"
      }
    },
    "node_modules/tiny-invariant": {
      "version": "1.3.3",
      "resolved": "https://registry.npmjs.org/tiny-invariant/-/tiny-invariant-1.3.3.tgz",
      "integrity": "sha512-+FbBPE1o9QAYvviau/qC5SE3caw21q3xkvWKBtja5vgqOWIHHJ3ioaq1VPfn/Szqctz2bU/oYeKd9/z5BL+PVg==",
      "license": "MIT"
    },
    "node_modules/tippy.js": {
      "version": "6.3.7",
      "resolved": "https://registry.npmjs.org/tippy.js/-/tippy.js-6.3.7.tgz",
      "integrity": "sha512-E1d3oP2emgJ9dRQZdf3Kkn0qJgI6ZLpyS5z6ZkY1DF3kaQaBsGZsndEpHwx+eC+tYM41HaSNvNtLx8tU57FzTQ==",
      "license": "MIT",
      "dependencies": {
        "@popperjs/core": "^2.9.0"
      }
    },
    "node_modules/to-regex-range": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/to-regex-range/-/to-regex-range-5.0.1.tgz",
      "integrity": "sha512-65P7iz6X5yEr1cwcgvQxbbIw7Uk3gOy5dIdtZ4rDveLqhrdJP+Li/Hx6tyK0NEb+2GCyneCMJiGqrADCSNk8sQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-number": "^7.0.0"
      },
      "engines": {
        "node": ">=8.0"
      }
    },
    "node_modules/trim-lines": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/trim-lines/-/trim-lines-3.0.1.tgz",
      "integrity": "sha512-kRj8B+YHZCc9kQYdWfJB2/oUl9rA99qbowYYBtr4ui4mZyAQ2JpvVBd/6U2YloATfqBhBTSMhTpgBHtU0Mf3Rg==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/trough": {
      "version": "2.2.0",
      "resolved": "https://registry.npmjs.org/trough/-/trough-2.2.0.tgz",
      "integrity": "sha512-tmMpK00BjZiUyVyvrBK7knerNgmgvcV/KLVyuma/SC+TQN167GrMRciANTz09+k3zW8L8t60jWO1GpfkZdjTaw==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/ts-api-utils": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/ts-api-utils/-/ts-api-utils-2.1.0.tgz",
      "integrity": "sha512-CUgTZL1irw8u29bzrOD/nH85jqyc74D6SshFgujOIA7osm2Rz7dYH77agkx7H4FBNxDq7Cjf+IjaX/8zwFW+ZQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=18.12"
      },
      "peerDependencies": {
        "typescript": ">=4.8.4"
      }
    },
    "node_modules/ts-interface-checker": {
      "version": "0.1.13",
      "resolved": "https://registry.npmjs.org/ts-interface-checker/-/ts-interface-checker-0.1.13.tgz",
      "integrity": "sha512-Y/arvbn+rrz3JCKl9C4kVNfTfSm2/mEp5FSz5EsZSANGPSlQrpRI5M4PKF+mJnE52jOO90PnPSc3Ur3bTQw0gA==",
      "dev": true,
      "license": "Apache-2.0"
    },
    "node_modules/tslib": {
      "version": "2.8.0",
      "resolved": "https://registry.npmjs.org/tslib/-/tslib-2.8.0.tgz",
      "integrity": "sha512-jWVzBLplnCmoaTr13V9dYbiQ99wvZRd0vNWaDRg+aVYRcjDF3nDksxFDE/+fkXnKhpnUUkmx5pK/v8mCtLVqZA==",
      "license": "0BSD"
    },
    "node_modules/type-check": {
      "version": "0.4.0",
      "resolved": "https://registry.npmjs.org/type-check/-/type-check-0.4.0.tgz",
      "integrity": "sha512-XleUoc9uwGXqjWwXaUTZAmzMcFZ5858QA2vvx1Ur5xIcixXIP+8LnFDgRplU30us6teqdlskFfu+ae4K79Ooew==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "prelude-ls": "^1.2.1"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/typescript": {
      "version": "5.8.3",
      "resolved": "https://registry.npmjs.org/typescript/-/typescript-5.8.3.tgz",
      "integrity": "sha512-p1diW6TqL9L07nNxvRMM7hMMw4c5XOo/1ibL4aAIGmSAt9slTE1Xgw5KWuof2uTOvCg9BY7ZRi+GaF+7sfgPeQ==",
      "dev": true,
      "license": "Apache-2.0",
      "bin": {
        "tsc": "bin/tsc",
        "tsserver": "bin/tsserver"
      },
      "engines": {
        "node": ">=14.17"
      }
    },
    "node_modules/typescript-eslint": {
      "version": "8.38.0",
      "resolved": "https://registry.npmjs.org/typescript-eslint/-/typescript-eslint-8.38.0.tgz",
      "integrity": "sha512-FsZlrYK6bPDGoLeZRuvx2v6qrM03I0U0SnfCLPs/XCCPCFD80xU9Pg09H/K+XFa68uJuZo7l/Xhs+eDRg2l3hg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@typescript-eslint/eslint-plugin": "8.38.0",
        "@typescript-eslint/parser": "8.38.0",
        "@typescript-eslint/typescript-estree": "8.38.0",
        "@typescript-eslint/utils": "8.38.0"
      },
      "engines": {
        "node": "^18.18.0 || ^20.9.0 || >=21.1.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependencies": {
        "eslint": "^8.57.0 || ^9.0.0",
        "typescript": ">=4.8.4 <5.9.0"
      }
    },
    "node_modules/undici-types": {
      "version": "6.21.0",
      "resolved": "https://registry.npmjs.org/undici-types/-/undici-types-6.21.0.tgz",
      "integrity": "sha512-iwDZqg0QAGrg9Rav5H4n0M64c3mkR59cJ6wQp+7C4nI0gsmExaedaYLNO44eT4AtBBwjbTiGPMlt2Md0T9H9JQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/unified": {
      "version": "11.0.5",
      "resolved": "https://registry.npmjs.org/unified/-/unified-11.0.5.tgz",
      "integrity": "sha512-xKvGhPWw3k84Qjh8bI3ZeJjqnyadK+GEFtazSfZv/rKeTkTjOJho6mFqh2SM96iIcZokxiOpg78GazTSg8+KHA==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0",
        "bail": "^2.0.0",
        "devlop": "^1.0.0",
        "extend": "^3.0.0",
        "is-plain-obj": "^4.0.0",
        "trough": "^2.0.0",
        "vfile": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/unist-util-is": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/unist-util-is/-/unist-util-is-6.0.1.tgz",
      "integrity": "sha512-LsiILbtBETkDz8I9p1dQ0uyRUWuaQzd/cuEeS1hoRSyW5E5XGmTzlwY1OrNzzakGowI9Dr/I8HVaw4hTtnxy8g==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/unist-util-position": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/unist-util-position/-/unist-util-position-5.0.0.tgz",
      "integrity": "sha512-fucsC7HjXvkB5R3kTCO7kUjRdrS0BJt3M/FPxmHMBOm8JQi2BsHAHFsy27E0EolP8rp0NzXsJ+jNPyDWvOJZPA==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/unist-util-stringify-position": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/unist-util-stringify-position/-/unist-util-stringify-position-4.0.0.tgz",
      "integrity": "sha512-0ASV06AAoKCDkS2+xw5RXJywruurpbC4JZSm7nr7MOt1ojAzvyyaO+UxZf18j8FCF6kmzCZKcAgN/yu2gm2XgQ==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/unist-util-visit": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/unist-util-visit/-/unist-util-visit-5.0.0.tgz",
      "integrity": "sha512-MR04uvD+07cwl/yhVuVWAtw+3GOR/knlL55Nd/wAdblk27GCVt3lqpTivy/tkJcZoNPzTwS1Y+KMojlLDhoTzg==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0",
        "unist-util-is": "^6.0.0",
        "unist-util-visit-parents": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/unist-util-visit-parents": {
      "version": "6.0.2",
      "resolved": "https://registry.npmjs.org/unist-util-visit-parents/-/unist-util-visit-parents-6.0.2.tgz",
      "integrity": "sha512-goh1s1TBrqSqukSc8wrjwWhL0hiJxgA8m4kFxGlQ+8FYQ3C/m11FcTs4YYem7V664AhHVvgoQLk890Ssdsr2IQ==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0",
        "unist-util-is": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/update-browserslist-db": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/update-browserslist-db/-/update-browserslist-db-1.1.3.tgz",
      "integrity": "sha512-UxhIZQ+QInVdunkDAaiazvvT/+fXL5Osr0JZlJulepYu6Jd7qJtDZjlur0emRlT71EN3ScPoE7gvsuIKKNavKw==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/browserslist"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "escalade": "^3.2.0",
        "picocolors": "^1.1.1"
      },
      "bin": {
        "update-browserslist-db": "cli.js"
      },
      "peerDependencies": {
        "browserslist": ">= 4.21.0"
      }
    },
    "node_modules/uri-js": {
      "version": "4.4.1",
      "resolved": "https://registry.npmjs.org/uri-js/-/uri-js-4.4.1.tgz",
      "integrity": "sha512-7rKUyy33Q1yc98pQ1DAmLtwX109F7TIfWlW1Ydo8Wl1ii1SeHieeh0HHfPeL2fMXK6z0s8ecKs9frCuLJvndBg==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "punycode": "^2.1.0"
      }
    },
    "node_modules/use-callback-ref": {
      "version": "1.3.3",
      "resolved": "https://registry.npmjs.org/use-callback-ref/-/use-callback-ref-1.3.3.tgz",
      "integrity": "sha512-jQL3lRnocaFtu3V00JToYz/4QkNWswxijDaCVNZRiRTO3HQDLsdu1ZtmIUvV4yPp+rvWm5j0y0TG/S61cuijTg==",
      "license": "MIT",
      "dependencies": {
        "tslib": "^2.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/use-sidecar": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/use-sidecar/-/use-sidecar-1.1.3.tgz",
      "integrity": "sha512-Fedw0aZvkhynoPYlA5WXrMCAMm+nSWdZt6lzJQ7Ok8S6Q+VsHmHpRWndVRJ8Be0ZbkfPc5LRYH+5XrzXcEeLRQ==",
      "license": "MIT",
      "dependencies": {
        "detect-node-es": "^1.1.0",
        "tslib": "^2.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/use-sync-external-store": {
      "version": "1.5.0",
      "resolved": "https://registry.npmjs.org/use-sync-external-store/-/use-sync-external-store-1.5.0.tgz",
      "integrity": "sha512-Rb46I4cGGVBmjamjphe8L/UnvJD+uPPtTkNvX5mZgqdbavhI4EbgIWJiIHXJ8bc/i9EQGPRh4DwEURJ552Do0A==",
      "license": "MIT",
      "peerDependencies": {
        "react": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0"
      }
    },
    "node_modules/util-deprecate": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/util-deprecate/-/util-deprecate-1.0.2.tgz",
      "integrity": "sha512-EPD5q1uXyFxJpCrLnCc1nHnq3gOa6DZBocAIiI2TaSCA7VCJ1UJDMagCzIkXNsUYfD1daK//LTEQ8xiIbrHtcw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/vaul": {
      "version": "0.9.9",
      "resolved": "https://registry.npmjs.org/vaul/-/vaul-0.9.9.tgz",
      "integrity": "sha512-7afKg48srluhZwIkaU+lgGtFCUsYBSGOl8vcc8N/M3YQlZFlynHD15AE+pwrYdc826o7nrIND4lL9Y6b9WWZZQ==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-dialog": "^1.1.1"
      },
      "peerDependencies": {
        "react": "^16.8 || ^17.0 || ^18.0",
        "react-dom": "^16.8 || ^17.0 || ^18.0"
      }
    },
    "node_modules/vfile": {
      "version": "6.0.3",
      "resolved": "https://registry.npmjs.org/vfile/-/vfile-6.0.3.tgz",
      "integrity": "sha512-KzIbH/9tXat2u30jf+smMwFCsno4wHVdNmzFyL+T/L3UGqqk6JKfVqOFOZEpZSHADH1k40ab6NUIXZq422ov3Q==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0",
        "vfile-message": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/vfile-message": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/vfile-message/-/vfile-message-4.0.3.tgz",
      "integrity": "sha512-QTHzsGd1EhbZs4AsQ20JX1rC3cOlt/IWJruk893DfLRr57lcnOeMaWG4K0JrRta4mIJZKth2Au3mM3u03/JWKw==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0",
        "unist-util-stringify-position": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/victory-vendor": {
      "version": "36.9.2",
      "resolved": "https://registry.npmjs.org/victory-vendor/-/victory-vendor-36.9.2.tgz",
      "integrity": "sha512-PnpQQMuxlwYdocC8fIJqVXvkeViHYzotI+NJrCuav0ZYFoq912ZHBk3mCeuj+5/VpodOjPe1z0Fk2ihgzlXqjQ==",
      "license": "MIT AND ISC",
      "dependencies": {
        "@types/d3-array": "^3.0.3",
        "@types/d3-ease": "^3.0.0",
        "@types/d3-interpolate": "^3.0.1",
        "@types/d3-scale": "^4.0.2",
        "@types/d3-shape": "^3.1.0",
        "@types/d3-time": "^3.0.0",
        "@types/d3-timer": "^3.0.0",
        "d3-array": "^3.1.6",
        "d3-ease": "^3.0.1",
        "d3-interpolate": "^3.0.1",
        "d3-scale": "^4.0.2",
        "d3-shape": "^3.1.0",
        "d3-time": "^3.0.0",
        "d3-timer": "^3.0.1"
      }
    },
    "node_modules/vite": {
      "version": "5.4.19",
      "resolved": "https://registry.npmjs.org/vite/-/vite-5.4.19.tgz",
      "integrity": "sha512-qO3aKv3HoQC8QKiNSTuUM1l9o/XX3+c+VTgLHbJWHZGeTPVAg2XwazI9UWzoxjIJCGCV2zU60uqMzjeLZuULqA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "esbuild": "^0.21.3",
        "postcss": "^8.4.43",
        "rollup": "^4.20.0"
      },
      "bin": {
        "vite": "bin/vite.js"
      },
      "engines": {
        "node": "^18.0.0 || >=20.0.0"
      },
      "funding": {
        "url": "https://github.com/vitejs/vite?sponsor=1"
      },
      "optionalDependencies": {
        "fsevents": "~2.3.3"
      },
      "peerDependencies": {
        "@types/node": "^18.0.0 || >=20.0.0",
        "less": "*",
        "lightningcss": "^1.21.0",
        "sass": "*",
        "sass-embedded": "*",
        "stylus": "*",
        "sugarss": "*",
        "terser": "^5.4.0"
      },
      "peerDependenciesMeta": {
        "@types/node": {
          "optional": true
        },
        "less": {
          "optional": true
        },
        "lightningcss": {
          "optional": true
        },
        "sass": {
          "optional": true
        },
        "sass-embedded": {
          "optional": true
        },
        "stylus": {
          "optional": true
        },
        "sugarss": {
          "optional": true
        },
        "terser": {
          "optional": true
        }
      }
    },
    "node_modules/which": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/which/-/which-2.0.2.tgz",
      "integrity": "sha512-BLI3Tl1TW3Pvl70l3yq3Y64i+awpwXqsGBYWkkqMtnbXgrMD+yj7rhW0kuEDxzJaYXGjEW5ogapKNMEKNMjibA==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "isexe": "^2.0.0"
      },
      "bin": {
        "node-which": "bin/node-which"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/word-wrap": {
      "version": "1.2.5",
      "resolved": "https://registry.npmjs.org/word-wrap/-/word-wrap-1.2.5.tgz",
      "integrity": "sha512-BN22B5eaMMI9UMtjrGd5g5eCYPpCPDUy0FJXbYsaT5zYxjFOckS53SQDE3pWkVoWpHXVb3BrYcEN4Twa55B5cA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/wrap-ansi": {
      "version": "8.1.0",
      "resolved": "https://registry.npmjs.org/wrap-ansi/-/wrap-ansi-8.1.0.tgz",
      "integrity": "sha512-si7QWI6zUMq56bESFvagtmzMdGOtoxfR+Sez11Mobfc7tm+VkUckk9bW2UeffTGVUbOksxmSw0AA2gs8g71NCQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^6.1.0",
        "string-width": "^5.0.1",
        "strip-ansi": "^7.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/wrap-ansi?sponsor=1"
      }
    },
    "node_modules/wrap-ansi-cjs": {
      "name": "wrap-ansi",
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/wrap-ansi/-/wrap-ansi-7.0.0.tgz",
      "integrity": "sha512-YVGIj2kamLSTxw6NsZjoBxfSwsn0ycdesmc4p+Q21c5zPuZ1pl+NfxVdxPtdHvmNVOQ6XSYG4AUtyt/Fi7D16Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^4.0.0",
        "string-width": "^4.1.0",
        "strip-ansi": "^6.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/wrap-ansi?sponsor=1"
      }
    },
    "node_modules/wrap-ansi-cjs/node_modules/ansi-regex": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-5.0.1.tgz",
      "integrity": "sha512-quJQXlTSUGL2LH9SUXo8VwsY4soanhgo6LNSm84E1LBcE8s3O0wpdiRzyR9z/ZZJMlMWv37qOOb9pdJlMUEKFQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/wrap-ansi-cjs/node_modules/emoji-regex": {
      "version": "8.0.0",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-8.0.0.tgz",
      "integrity": "sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/wrap-ansi-cjs/node_modules/string-width": {
      "version": "4.2.3",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz",
      "integrity": "sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "emoji-regex": "^8.0.0",
        "is-fullwidth-code-point": "^3.0.0",
        "strip-ansi": "^6.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/wrap-ansi-cjs/node_modules/strip-ansi": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz",
      "integrity": "sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/wrap-ansi/node_modules/ansi-styles": {
      "version": "6.2.1",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-6.2.1.tgz",
      "integrity": "sha512-bN798gFfQX+viw3R7yrGWRqnrN2oRkEkUjjl4JNn4E8GxxbjtG3FbrEIIY3l8/hrwUwIeCZvi4QuOTP4MErVug==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/yaml": {
      "version": "2.6.0",
      "resolved": "https://registry.npmjs.org/yaml/-/yaml-2.6.0.tgz",
      "integrity": "sha512-a6ae//JvKDEra2kdi1qzCyrJW/WZCgFi8ydDV+eXExl95t+5R+ijnqHJbz9tmMh8FUjx3iv2fCQ4dclAQlO2UQ==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "yaml": "bin.mjs"
      },
      "engines": {
        "node": ">= 14"
      }
    },
    "node_modules/yocto-queue": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/yocto-queue/-/yocto-queue-0.1.0.tgz",
      "integrity": "sha512-rVksvsnNCdJ/ohGc6xgPwyN8eheCxsiLM8mxuE/t/mOVqJewPuO1miLpTHQiRgTKCLexL4MeAFVagts7HmNZ2Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/zod": {
      "version": "3.25.76",
      "resolved": "https://registry.npmjs.org/zod/-/zod-3.25.76.tgz",
      "integrity": "sha512-gzUt/qt81nXsFGKIFcC3YnfEAx5NkunCfnDlvuBSSFS02bcXu4Lmea0AFIUwbLWxWPx3d9p8S5QoaujKcNQxcQ==",
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/colinhacks"
      }
    },
    "node_modules/zwitch": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/zwitch/-/zwitch-2.0.4.tgz",
      "integrity": "sha512-bXE4cR/kVZhKZX/RjPEflHaKVhUVl85noU3v6b8apfQEc1x4A+zBxjZ4lN8LqGd6WZ3dl98pY4o717VFmoPp+A==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    }
  }
}

```

---

## frontend/package.json

```json
{
  "name": "vite_react_shadcn_ts",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "build:dev": "vite build --mode development",
    "lint": "eslint .",
    "preview": "vite preview",
    "test:e2e": "playwright test",
    "test:e2e:ui": "playwright test --ui",
    "test:e2e:headed": "playwright test --headed",
    "test:e2e:debug": "playwright test --debug",
    "test:e2e:chromium": "playwright test --project=chromium",
    "test:e2e:report": "playwright show-report"
  },
  "dependencies": {
    "@hookform/resolvers": "^3.10.0",
    "@radix-ui/react-accordion": "^1.2.11",
    "@radix-ui/react-alert-dialog": "^1.1.14",
    "@radix-ui/react-aspect-ratio": "^1.1.7",
    "@radix-ui/react-avatar": "^1.1.10",
    "@radix-ui/react-checkbox": "^1.3.2",
    "@radix-ui/react-collapsible": "^1.1.11",
    "@radix-ui/react-context-menu": "^2.2.15",
    "@radix-ui/react-dialog": "^1.1.14",
    "@radix-ui/react-dropdown-menu": "^2.1.15",
    "@radix-ui/react-hover-card": "^1.1.14",
    "@radix-ui/react-label": "^2.1.7",
    "@radix-ui/react-menubar": "^1.1.15",
    "@radix-ui/react-navigation-menu": "^1.2.13",
    "@radix-ui/react-popover": "^1.1.14",
    "@radix-ui/react-progress": "^1.1.7",
    "@radix-ui/react-radio-group": "^1.3.7",
    "@radix-ui/react-scroll-area": "^1.2.9",
    "@radix-ui/react-select": "^2.2.5",
    "@radix-ui/react-separator": "^1.1.7",
    "@radix-ui/react-slider": "^1.3.5",
    "@radix-ui/react-slot": "^1.2.3",
    "@radix-ui/react-switch": "^1.2.5",
    "@radix-ui/react-tabs": "^1.1.12",
    "@radix-ui/react-toast": "^1.2.14",
    "@radix-ui/react-toggle": "^1.1.9",
    "@radix-ui/react-toggle-group": "^1.1.10",
    "@radix-ui/react-tooltip": "^1.2.7",
    "@tanstack/react-query": "^5.83.0",
    "axios": "^1.13.2",
    "chart.js": "^4.5.1",
    "class-variance-authority": "^0.7.1",
    "clsx": "^2.1.1",
    "cmdk": "^1.1.1",
    "d3-cloud": "^1.2.7",
    "date-fns": "^3.6.0",
    "embla-carousel-react": "^8.6.0",
    "input-otp": "^1.4.2",
    "lucide-react": "^0.462.0",
    "next-themes": "^0.3.0",
    "react": "^18.3.1",
    "react-chartjs-2": "^5.3.1",
    "react-day-picker": "^8.10.1",
    "react-dom": "^18.3.1",
    "react-hook-form": "^7.61.1",
    "react-resizable-panels": "^2.1.9",
    "react-router-dom": "^6.30.1",
    "react-wordcloud": "^1.2.7",
    "react-markdown": "^9.0.1",
    "recharts": "^2.15.4",
    "remark-gfm": "^4.0.0",
    "sonner": "^1.7.4",
    "tailwind-merge": "^2.6.0",
    "tailwindcss-animate": "^1.0.7",
    "vaul": "^0.9.9",
    "zod": "^3.25.76"
  },
  "devDependencies": {
    "@eslint/js": "^9.32.0",
    "@playwright/test": "^1.40.0",
    "@tailwindcss/typography": "^0.5.16",
    "@types/node": "^22.16.5",
    "@types/react": "^18.3.23",
    "@types/react-dom": "^18.3.7",
    "@vitejs/plugin-react-swc": "^3.11.0",
    "autoprefixer": "^10.4.21",
    "eslint": "^9.32.0",
    "eslint-plugin-react-hooks": "^5.2.0",
    "eslint-plugin-react-refresh": "^0.4.20",
    "globals": "^15.15.0",
    "postcss": "^8.5.6",
    "tailwindcss": "^3.4.17",
    "typescript": "^5.8.3",
    "typescript-eslint": "^8.38.0",
    "vite": "^5.4.19"
  }
}

```

---

## frontend/playwright.config.ts

```ts
import { defineConfig, devices } from '@playwright/test';

/**
 * NewsInsight Frontend E2E 테스트 설정
 * @see https://playwright.dev/docs/test-configuration
 */
export default defineConfig({
  testDir: './tests/e2e',
  
  /* 테스트 병렬 실행 */
  fullyParallel: true,
  
  /* CI에서 재시도 비활성화 */
  forbidOnly: !!process.env.CI,
  
  /* CI에서 실패 시 2번 재시도 */
  retries: process.env.CI ? 2 : 0,
  
  /* CI에서 병렬 워커 수 제한 */
  workers: process.env.CI ? 1 : undefined,
  
  /* 리포터 설정 */
  reporter: [
    ['html', { open: 'never' }],
    ['list'],
  ],
  
  /* 모든 테스트에 적용되는 설정 */
  use: {
    /* 테스트 실패 시 스크린샷 저장 */
    screenshot: 'only-on-failure',
    
    /* 테스트 실패 시 트레이스 저장 */
    trace: 'on-first-retry',
    
    /* 기본 URL */
    baseURL: process.env.PLAYWRIGHT_BASE_URL || 'http://localhost:8080',
    
    /* 요청 타임아웃 */
    actionTimeout: 15000,
    
    /* 네비게이션 타임아웃 */
    navigationTimeout: 30000,
  },

  /* 프로젝트 설정 - 다양한 브라우저 테스트 */
  projects: [
    {
      name: 'chromium',
      use: { ...devices['Desktop Chrome'] },
    },
    {
      name: 'firefox',
      use: { ...devices['Desktop Firefox'] },
    },
    {
      name: 'webkit',
      use: { ...devices['Desktop Safari'] },
    },
    /* 모바일 뷰포트 테스트 */
    {
      name: 'Mobile Chrome',
      use: { ...devices['Pixel 5'] },
    },
    {
      name: 'Mobile Safari',
      use: { ...devices['iPhone 12'] },
    },
  ],

  /* 로컬 개발 서버 자동 시작 (CI에서는 별도 실행 필요) */
  webServer: process.env.CI ? undefined : {
    command: 'npm run dev',
    url: 'http://localhost:5173',
    reuseExistingServer: !process.env.CI,
    timeout: 120 * 1000,
  },
  
  /* 테스트 출력 디렉토리 */
  outputDir: 'test-results/',
});

```

---

## frontend/postcss.config.js

```js
export default {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
};

```

---

## frontend/src/App.tsx

```tsx
import { Toaster } from "@/components/ui/toaster";
import { Toaster as Sonner } from "@/components/ui/sonner";
import { TooltipProvider } from "@/components/ui/tooltip";
import { QueryClient, QueryClientProvider } from "@tanstack/react-query";
import { BrowserRouter, Routes, Route, Navigate, useLocation } from "react-router-dom";
import { BackgroundTaskProvider } from "@/contexts/BackgroundTaskContext";
import { SearchJobProvider } from "@/contexts/SearchJobContext";
import { ThemeProvider } from "@/contexts/ThemeContext";
import { NotificationProvider } from "@/contexts/NotificationContext";
import { AuthProvider } from "@/contexts/AuthContext";
import { QuickAccessProvider } from "@/contexts/QuickAccessContext";
import { AppLayout } from "@/components/layout/AppLayout";
import { ActiveJobsIndicator } from "@/components/ActiveJobsIndicator";
import { CommandPalette } from "@/components/CommandPalette";
import { QuickAccessPanel } from "@/components/QuickAccessPanel";
import { useQuickAccess } from "@/contexts/QuickAccessContext";
import NotFound from "./pages/NotFound";
import AdminSources from "./pages/AdminSources";
import BrowserAgent from "./pages/BrowserAgent";
import UrlCollections from "./pages/UrlCollections";
import SearchHistory from "./pages/SearchHistory";
import SmartSearch from "./pages/SmartSearch";
import Settings from "./pages/Settings";
import MLAddons from "./pages/MLAddons";
import MLResults from "./pages/MLResults";
import MLTraining from "./pages/MLTraining";
import Projects from "./pages/Projects";
import ProjectDashboard from "./pages/ProjectDashboard";
import ProjectSettings from "./pages/ProjectSettings";
import LiveDashboard from "./pages/LiveDashboard";
import Operations from "./pages/Operations";
import AiJobs from "./pages/AiJobs";
import CollectedDataPage from "./pages/CollectedDataPage";
import ParallelSearch from "./pages/ParallelSearch";
import FactCheck from "./pages/FactCheck";

// New Pages
import NewHome from "./pages/NewHome";
import ToolsHub from "./pages/ToolsHub";
import WorkspaceHub from "./pages/WorkspaceHub";

// Auth Pages (Public)
import Login from "./pages/Login";
import Register from "./pages/Register";

// Admin Pages
import AdminEnvironments from "./pages/admin/AdminEnvironments";
import AdminScripts from "./pages/admin/AdminScripts";
import AdminAuditLogs from "./pages/admin/AdminAuditLogs";
import AdminUsers from "./pages/admin/AdminUsers";
import AdminLogin from "./pages/admin/AdminLogin";
import AdminSetup from "./pages/admin/AdminSetup";
import { ProtectedRoute } from "@/components/ProtectedRoute";

const queryClient = new QueryClient();

const RedirectWithState = ({ to }: { to: string }) => {
  const location = useLocation();
  return <Navigate to={to} replace state={location.state} />;
};

const AppContent = () => {
  const { isOpen, close } = useQuickAccess();
  return (
    <>
      <CommandPalette />
      <QuickAccessPanel isOpen={isOpen} onClose={close} />
      <AppLayout>
                  <Routes>
                {/* NEW: Home - 새 대시보드 스타일 홈 */}
                <Route path="/" element={<NewHome />} />
                
                {/* Search - SmartSearch (기존 홈이 여기로 이동) */}
                <Route path="/search" element={<SmartSearch />} />
                
                {/* Dashboard Section */}
                <Route path="/dashboard" element={<LiveDashboard />} />
                <Route path="/operations" element={<Operations />} />
                <Route path="/collected-data" element={<CollectedDataPage />} />
                
                {/* Tools Section */}
                <Route path="/tools" element={<ToolsHub />} />
                <Route path="/ml-addons" element={<MLAddons />} />
                <Route path="/ml-results" element={<MLResults />} />
                <Route path="/ml-training" element={<MLTraining />} />
                <Route path="/ai-agent" element={<BrowserAgent />} />
                <Route path="/ai-jobs" element={<AiJobs />} />
                <Route path="/parallel-search" element={<ParallelSearch />} />
                <Route path="/factcheck" element={<FactCheck />} />
                
                {/* Workspace Section */}
                <Route path="/workspace" element={<WorkspaceHub />} />
                <Route path="/projects" element={<Projects />} />
                <Route path="/projects/:id" element={<ProjectDashboard />} />
                <Route path="/projects/:id/settings" element={<ProjectSettings />} />
                <Route path="/history" element={<SearchHistory />} />
                <Route path="/url-collections" element={<UrlCollections />} />

                {/* Backward compatibility redirects */}
                <Route path="/smart-search" element={<RedirectWithState to="/search" />} />
                <Route path="/deep-search" element={<RedirectWithState to="/search?mode=deep" />} />
                <Route path="/fact-check" element={<RedirectWithState to="/factcheck" />} />
                
                {/* Public Auth Routes */}
                <Route path="/login" element={<Login />} />
                <Route path="/register" element={<Register />} />
                
                {/* Admin Routes */}
                <Route path="/admin/login" element={<AdminLogin />} />
                <Route path="/admin/setup" element={<ProtectedRoute allowSetup><AdminSetup /></ProtectedRoute>} />
                <Route path="/admin/sources" element={<ProtectedRoute><AdminSources /></ProtectedRoute>} />
                <Route path="/admin/operations" element={<ProtectedRoute><Operations /></ProtectedRoute>} />
                <Route path="/admin/environments" element={<ProtectedRoute requiredRole="operator"><AdminEnvironments /></ProtectedRoute>} />
                <Route path="/admin/scripts" element={<ProtectedRoute requiredRole="operator"><AdminScripts /></ProtectedRoute>} />
                <Route path="/admin/audit-logs" element={<ProtectedRoute requiredRole="admin"><AdminAuditLogs /></ProtectedRoute>} />
                <Route path="/admin/users" element={<ProtectedRoute requiredRole="admin"><AdminUsers /></ProtectedRoute>} />
                
                {/* Settings */}
                <Route path="/settings" element={<Settings />} />
                
                {/* ADD ALL CUSTOM ROUTES ABOVE THE CATCH-ALL "*" ROUTE */}
                <Route path="*" element={<NotFound />} />
              </Routes>
      </AppLayout>
      {/* Active Jobs Indicator - floating UI */}
      <ActiveJobsIndicator position="bottom-right" />
    </>
  );
};

const App = () => (
  <QueryClientProvider client={queryClient}>
    <ThemeProvider>
      <AuthProvider>
        <NotificationProvider>
          <BackgroundTaskProvider>
            <SearchJobProvider>
              <QuickAccessProvider>
                <TooltipProvider>
                  <Toaster />
                  <Sonner />
                  <BrowserRouter>
                    <AppContent />
                  </BrowserRouter>
                </TooltipProvider>
              </QuickAccessProvider>
            </SearchJobProvider>
          </BackgroundTaskProvider>
        </NotificationProvider>
      </AuthProvider>
    </ThemeProvider>
  </QueryClientProvider>
);

export default App;

```

---

## frontend/src/components/ActiveJobsIndicator.tsx

```tsx
/**
 * ActiveJobsIndicator - Floating indicator showing active search jobs
 * 
 * Displays a compact badge when jobs are running, expanding to a list
 * when clicked. Shows real-time progress updates via SSE.
 */

import React, { useState } from 'react';
import { useSearchJobs, JOB_TYPE_LABELS, JOB_STATUS_LABELS } from '@/contexts/SearchJobContext';
import { Badge } from '@/components/ui/badge';
import { Button } from '@/components/ui/button';
import { Progress } from '@/components/ui/progress';
import { ScrollArea } from '@/components/ui/scroll-area';
import {
  Popover,
  PopoverContent,
  PopoverTrigger,
} from '@/components/ui/popover';
import {
  Tooltip,
  TooltipContent,
  TooltipProvider,
  TooltipTrigger,
} from '@/components/ui/tooltip';
import { cn } from '@/lib/utils';
import type { SearchJob, SearchJobStatus } from '@/lib/api';

// Icons using simple SVG for consistency
const LoaderIcon = ({ className }: { className?: string }) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    width="16"
    height="16"
    viewBox="0 0 24 24"
    fill="none"
    stroke="currentColor"
    strokeWidth="2"
    strokeLinecap="round"
    strokeLinejoin="round"
    className={cn('animate-spin', className)}
  >
    <path d="M21 12a9 9 0 1 1-6.219-8.56" />
  </svg>
);

const CheckIcon = ({ className }: { className?: string }) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    width="16"
    height="16"
    viewBox="0 0 24 24"
    fill="none"
    stroke="currentColor"
    strokeWidth="2"
    strokeLinecap="round"
    strokeLinejoin="round"
    className={className}
  >
    <path d="M20 6 9 17l-5-5" />
  </svg>
);

const XIcon = ({ className }: { className?: string }) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    width="16"
    height="16"
    viewBox="0 0 24 24"
    fill="none"
    stroke="currentColor"
    strokeWidth="2"
    strokeLinecap="round"
    strokeLinejoin="round"
    className={className}
  >
    <path d="M18 6 6 18" />
    <path d="m6 6 12 12" />
  </svg>
);

const ClockIcon = ({ className }: { className?: string }) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    width="16"
    height="16"
    viewBox="0 0 24 24"
    fill="none"
    stroke="currentColor"
    strokeWidth="2"
    strokeLinecap="round"
    strokeLinejoin="round"
    className={className}
  >
    <circle cx="12" cy="12" r="10" />
    <polyline points="12 6 12 12 16 14" />
  </svg>
);

const TrashIcon = ({ className }: { className?: string }) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    width="16"
    height="16"
    viewBox="0 0 24 24"
    fill="none"
    stroke="currentColor"
    strokeWidth="2"
    strokeLinecap="round"
    strokeLinejoin="round"
    className={className}
  >
    <path d="M3 6h18" />
    <path d="M19 6v14c0 1-1 2-2 2H7c-1 0-2-1-2-2V6" />
    <path d="M8 6V4c0-1 1-2 2-2h4c1 0 2 1 2 2v2" />
  </svg>
);

const WifiOffIcon = ({ className }: { className?: string }) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    width="16"
    height="16"
    viewBox="0 0 24 24"
    fill="none"
    stroke="currentColor"
    strokeWidth="2"
    strokeLinecap="round"
    strokeLinejoin="round"
    className={className}
  >
    <path d="M12 20h.01" />
    <path d="M8.5 16.429a5 5 0 0 1 7 0" />
    <path d="M5 12.859a10 10 0 0 1 5.17-2.69" />
    <path d="M19 12.859a10 10 0 0 0-2.007-1.523" />
    <path d="M2 8.82a15 15 0 0 1 4.177-2.643" />
    <path d="M22 8.82a15 15 0 0 0-11.288-3.764" />
    <path d="m2 2 20 20" />
  </svg>
);

// Status icon component
function StatusIcon({ status, className }: { status: SearchJobStatus; className?: string }) {
  switch (status) {
    case 'PENDING':
      return <ClockIcon className={cn('text-muted-foreground', className)} />;
    case 'RUNNING':
      return <LoaderIcon className={cn('text-blue-500', className)} />;
    case 'COMPLETED':
      return <CheckIcon className={cn('text-green-500', className)} />;
    case 'FAILED':
      return <XIcon className={cn('text-red-500', className)} />;
    case 'CANCELLED':
      return <XIcon className={cn('text-muted-foreground', className)} />;
    default:
      return <ClockIcon className={cn('text-muted-foreground', className)} />;
  }
}

// Status badge variant
function getStatusVariant(status: SearchJobStatus): 'default' | 'secondary' | 'destructive' | 'outline' {
  switch (status) {
    case 'RUNNING':
      return 'default';
    case 'COMPLETED':
      return 'secondary';
    case 'FAILED':
      return 'destructive';
    default:
      return 'outline';
  }
}

// Single job item component
function JobItem({ 
  job, 
  onCancel,
  onRemove,
}: { 
  job: SearchJob;
  onCancel?: (jobId: string) => void;
  onRemove?: (jobId: string) => void;
}) {
  const isActive = job.status === 'PENDING' || job.status === 'RUNNING';
  const isTerminal = job.status === 'COMPLETED' || job.status === 'FAILED' || job.status === 'CANCELLED';

  return (
    <div className="p-3 border-b border-border last:border-b-0 hover:bg-muted/50 transition-colors">
      <div className="flex items-start gap-2">
        <StatusIcon status={job.status} className="mt-1 flex-shrink-0" />
        
        <div className="flex-1 min-w-0">
          <div className="flex items-center gap-2 mb-1">
            <span className="text-xs text-muted-foreground">
              {JOB_TYPE_LABELS[job.type]}
            </span>
            <Badge variant={getStatusVariant(job.status)} className="text-xs h-5">
              {JOB_STATUS_LABELS[job.status]}
            </Badge>
          </div>
          
          <p className="text-sm font-medium truncate" title={job.query}>
            {job.query}
          </p>
          
          {isActive && (
            <div className="mt-2">
              <Progress value={job.progress} className="h-1.5" />
              <p className="text-xs text-muted-foreground mt-1">
                {job.currentPhase || `${job.progress}%`}
              </p>
            </div>
          )}
          
          {job.status === 'FAILED' && job.errorMessage && (
            <p className="text-xs text-red-500 mt-1 truncate" title={job.errorMessage}>
              {job.errorMessage}
            </p>
          )}
        </div>

        {/* Action buttons */}
        <div className="flex-shrink-0 flex gap-1">
          {isActive && onCancel && (
            <TooltipProvider>
              <Tooltip>
                <TooltipTrigger asChild>
                  <Button
                    variant="ghost"
                    size="icon"
                    className="h-6 w-6"
                    onClick={() => onCancel(job.jobId)}
                  >
                    <XIcon className="h-3 w-3" />
                  </Button>
                </TooltipTrigger>
                <TooltipContent>취소</TooltipContent>
              </Tooltip>
            </TooltipProvider>
          )}
          
          {isTerminal && onRemove && (
            <TooltipProvider>
              <Tooltip>
                <TooltipTrigger asChild>
                  <Button
                    variant="ghost"
                    size="icon"
                    className="h-6 w-6"
                    onClick={() => onRemove(job.jobId)}
                  >
                    <TrashIcon className="h-3 w-3" />
                  </Button>
                </TooltipTrigger>
                <TooltipContent>제거</TooltipContent>
              </Tooltip>
            </TooltipProvider>
          )}
        </div>
      </div>
    </div>
  );
}

interface ActiveJobsIndicatorProps {
  className?: string;
  position?: 'bottom-right' | 'bottom-left' | 'top-right' | 'top-left';
  showWhenEmpty?: boolean;
}

export function ActiveJobsIndicator({
  className,
  position = 'bottom-right',
  showWhenEmpty = false,
}: ActiveJobsIndicatorProps) {
  const [isOpen, setIsOpen] = useState(false);
  const {
    jobs,
    activeJobs,
    completedJobs,
    hasActiveJobs,
    activeJobCount,
    isConnected,
    connectionError,
    cancelJob,
    clearCompletedJobs,
    refreshJobs,
  } = useSearchJobs();

  // Position classes
  const positionClasses = {
    'bottom-right': 'fixed bottom-4 right-4',
    'bottom-left': 'fixed bottom-4 left-4',
    'top-right': 'fixed top-4 right-4',
    'top-left': 'fixed top-4 left-4',
  };

  // Don't render if no jobs and showWhenEmpty is false
  if (!showWhenEmpty && jobs.length === 0) {
    return null;
  }

  const handleCancel = async (jobId: string) => {
    await cancelJob(jobId);
  };

  const handleRemove = (jobId: string) => {
    // Just refresh to update the list
    refreshJobs();
  };

  return (
    <div className={cn(positionClasses[position], 'z-50', className)}>
      <Popover open={isOpen} onOpenChange={setIsOpen}>
        <PopoverTrigger asChild>
          <Button
            variant={hasActiveJobs ? 'default' : 'secondary'}
            size="sm"
            className={cn(
              'gap-2 shadow-lg',
              hasActiveJobs && 'animate-pulse'
            )}
          >
            {hasActiveJobs ? (
              <LoaderIcon className="h-4 w-4" />
            ) : (
              <CheckIcon className="h-4 w-4" />
            )}
            
            <span>
              {hasActiveJobs 
                ? `${activeJobCount}개 작업 진행 중` 
                : `${jobs.length}개 작업`
              }
            </span>
            
            {!isConnected && (
              <TooltipProvider>
                <Tooltip>
                  <TooltipTrigger>
                    <WifiOffIcon className="h-3 w-3 text-yellow-500" />
                  </TooltipTrigger>
                  <TooltipContent>
                    {connectionError || '실시간 연결 끊김'}
                  </TooltipContent>
                </Tooltip>
              </TooltipProvider>
            )}
          </Button>
        </PopoverTrigger>

        <PopoverContent 
          className="w-80 p-0" 
          align={position.includes('right') ? 'end' : 'start'}
          side={position.includes('bottom') ? 'top' : 'bottom'}
        >
          <div className="p-3 border-b border-border flex items-center justify-between">
            <h4 className="font-medium">검색 작업</h4>
            {completedJobs.length > 0 && (
              <Button
                variant="ghost"
                size="sm"
                className="h-7 text-xs"
                onClick={clearCompletedJobs}
              >
                완료 항목 지우기
              </Button>
            )}
          </div>

          {jobs.length === 0 ? (
            <div className="p-6 text-center text-muted-foreground text-sm">
              진행 중인 작업이 없습니다
            </div>
          ) : (
            <ScrollArea className="max-h-80">
              {/* Active jobs first */}
              {activeJobs.length > 0 && (
                <div>
                  <div className="px-3 py-1.5 bg-muted/50 text-xs font-medium text-muted-foreground">
                    진행 중 ({activeJobs.length})
                  </div>
                  {activeJobs.map(job => (
                    <JobItem
                      key={job.jobId}
                      job={job}
                      onCancel={handleCancel}
                    />
                  ))}
                </div>
              )}

              {/* Completed jobs */}
              {completedJobs.length > 0 && (
                <div>
                  <div className="px-3 py-1.5 bg-muted/50 text-xs font-medium text-muted-foreground">
                    완료됨 ({completedJobs.length})
                  </div>
                  {completedJobs.slice(0, 10).map(job => (
                    <JobItem
                      key={job.jobId}
                      job={job}
                      onRemove={handleRemove}
                    />
                  ))}
                </div>
              )}
            </ScrollArea>
          )}

          {/* Connection status footer */}
          <div className="p-2 border-t border-border flex items-center justify-between text-xs text-muted-foreground">
            <span className="flex items-center gap-1.5">
              <span 
                className={cn(
                  'w-2 h-2 rounded-full',
                  isConnected ? 'bg-green-500' : 'bg-yellow-500'
                )} 
              />
              {isConnected ? '실시간 연결됨' : '연결 끊김'}
            </span>
            <Button
              variant="ghost"
              size="sm"
              className="h-6 text-xs"
              onClick={() => refreshJobs()}
            >
              새로고침
            </Button>
          </div>
        </PopoverContent>
      </Popover>
    </div>
  );
}

/**
 * Compact version for header/navbar integration
 */
export function ActiveJobsBadge({ className }: { className?: string }) {
  const { hasActiveJobs, activeJobCount, isConnected } = useSearchJobs();

  if (!hasActiveJobs) {
    return null;
  }

  return (
    <TooltipProvider>
      <Tooltip>
        <TooltipTrigger asChild>
          <Badge 
            variant="default" 
            className={cn('gap-1.5 cursor-pointer', className)}
          >
            <LoaderIcon className="h-3 w-3" />
            {activeJobCount}
            {!isConnected && (
              <WifiOffIcon className="h-3 w-3 text-yellow-300" />
            )}
          </Badge>
        </TooltipTrigger>
        <TooltipContent>
          {activeJobCount}개 작업 진행 중
        </TooltipContent>
      </Tooltip>
    </TooltipProvider>
  );
}

export default ActiveJobsIndicator;

```

---

## frontend/src/components/AdvancedFilters.tsx

```tsx
import { useState, useCallback } from "react";
import {
  ChevronDown,
  ChevronUp,
  Filter,
  Calendar as CalendarIcon,
  Globe,
  Database,
  Brain,
  X,
  RotateCcw,
} from "lucide-react";
import { format } from "date-fns";
import { ko } from "date-fns/locale";
import { Button } from "@/components/ui/button";
import { Badge } from "@/components/ui/badge";
import { Checkbox } from "@/components/ui/checkbox";
import { Label } from "@/components/ui/label";
import {
  Select,
  SelectContent,
  SelectItem,
  SelectTrigger,
  SelectValue,
} from "@/components/ui/select";
import {
  Collapsible,
  CollapsibleContent,
  CollapsibleTrigger,
} from "@/components/ui/collapsible";
import {
  Popover,
  PopoverContent,
  PopoverTrigger,
} from "@/components/ui/popover";
import { Calendar } from "@/components/ui/calendar";
import { Separator } from "@/components/ui/separator";
import { cn } from "@/lib/utils";

export interface SearchFilters {
  /** 시간 범위 (preset) */
  timeWindow: string;
  /** 커스텀 시작 날짜 (timeWindow가 "custom"일 때 사용) */
  customStartDate?: Date;
  /** 커스텀 종료 날짜 (timeWindow가 "custom"일 때 사용) */
  customEndDate?: Date;
  /** 활성화된 소스 */
  sources: {
    database: boolean;
    web: boolean;
    ai: boolean;
  };
  /** 정렬 기준 */
  sortBy: "relevance" | "date" | "reliability";
  /** 정렬 순서 */
  sortOrder: "asc" | "desc";
  /** 언어 필터 */
  language: "all" | "ko" | "en";
  /** 신뢰도 최소값 */
  minReliability?: number;
}

export const defaultFilters: SearchFilters = {
  timeWindow: "7d",
  customStartDate: undefined,
  customEndDate: undefined,
  sources: {
    database: true,
    web: true,
    ai: true,
  },
  sortBy: "relevance",
  sortOrder: "desc",
  language: "all",
  minReliability: undefined,
};

interface AdvancedFiltersProps {
  /** 현재 필터 값 */
  filters: SearchFilters;
  /** 필터 변경 핸들러 */
  onFiltersChange: (filters: SearchFilters) => void;
  /** 비활성화 여부 */
  disabled?: boolean;
  /** 추가 CSS 클래스 */
  className?: string;
  /** 컴팩트 모드 (인라인 표시) */
  compact?: boolean;
}

const sourceConfig = {
  database: { icon: Database, label: "저장된 뉴스", color: "text-blue-600" },
  web: { icon: Globe, label: "웹 검색", color: "text-green-600" },
  ai: { icon: Brain, label: "AI 분석", color: "text-purple-600" },
};

const timeOptions = [
  { value: "1h", label: "최근 1시간" },
  { value: "24h", label: "최근 24시간" },
  { value: "3d", label: "최근 3일" },
  { value: "7d", label: "최근 7일" },
  { value: "14d", label: "최근 2주" },
  { value: "30d", label: "최근 30일" },
  { value: "90d", label: "최근 3개월" },
  { value: "180d", label: "최근 6개월" },
  { value: "365d", label: "최근 1년" },
  { value: "all", label: "전체 기간" },
  { value: "custom", label: "직접 선택" },
];

const sortOptions = [
  { value: "relevance", label: "관련도순" },
  { value: "date", label: "최신순" },
  { value: "reliability", label: "신뢰도순" },
];

const languageOptions = [
  { value: "all", label: "전체 언어" },
  { value: "ko", label: "한국어" },
  { value: "en", label: "English" },
];

/** 활성 필터 수 계산 */
const getActiveFilterCount = (filters: SearchFilters): number => {
  let count = 0;
  if (filters.timeWindow !== defaultFilters.timeWindow) count++;
  if (filters.timeWindow === "custom" && (filters.customStartDate || filters.customEndDate)) count++;
  if (filters.sortBy !== defaultFilters.sortBy) count++;
  if (filters.language !== defaultFilters.language) count++;
  if (filters.minReliability !== undefined) count++;
  const sourcesChanged =
    filters.sources.database !== defaultFilters.sources.database ||
    filters.sources.web !== defaultFilters.sources.web ||
    filters.sources.ai !== defaultFilters.sources.ai;
  if (sourcesChanged) count++;
  return count;
};

/** 날짜 범위 라벨 생성 */
const getDateRangeLabel = (filters: SearchFilters): string => {
  if (filters.timeWindow === "custom") {
    if (filters.customStartDate && filters.customEndDate) {
      return `${format(filters.customStartDate, "yy.MM.dd")} - ${format(filters.customEndDate, "yy.MM.dd")}`;
    } else if (filters.customStartDate) {
      return `${format(filters.customStartDate, "yy.MM.dd")} ~`;
    } else if (filters.customEndDate) {
      return `~ ${format(filters.customEndDate, "yy.MM.dd")}`;
    }
    return "직접 선택";
  }
  const opt = timeOptions.find((o) => o.value === filters.timeWindow);
  return opt?.label || filters.timeWindow;
};

export function AdvancedFilters({
  filters,
  onFiltersChange,
  disabled = false,
  className,
  compact = false,
}: AdvancedFiltersProps) {
  const [isOpen, setIsOpen] = useState(false);
  const [datePickerOpen, setDatePickerOpen] = useState(false);
  const activeCount = getActiveFilterCount(filters);

  const updateFilter = useCallback(
    <K extends keyof SearchFilters>(key: K, value: SearchFilters[K]) => {
      onFiltersChange({ ...filters, [key]: value });
    },
    [filters, onFiltersChange]
  );

  const updateSource = useCallback(
    (source: keyof SearchFilters["sources"], checked: boolean) => {
      // 최소 하나의 소스는 활성화되어야 함
      const newSources = { ...filters.sources, [source]: checked };
      if (!newSources.database && !newSources.web && !newSources.ai) {
        return; // 모두 비활성화 방지
      }
      onFiltersChange({ ...filters, sources: newSources });
    },
    [filters, onFiltersChange]
  );

  const updateCustomDateRange = useCallback(
    (startDate: Date | undefined, endDate: Date | undefined) => {
      onFiltersChange({
        ...filters,
        timeWindow: "custom",
        customStartDate: startDate,
        customEndDate: endDate,
      });
    },
    [filters, onFiltersChange]
  );

  const resetFilters = useCallback(() => {
    onFiltersChange(defaultFilters);
  }, [onFiltersChange]);

  // 컴팩트 모드: 인라인 칩으로 표시
  if (compact) {
    return (
      <div className={cn("flex flex-wrap items-center gap-2", className)}>
        {/* 시간 범위 - with custom date picker */}
        <Popover open={datePickerOpen} onOpenChange={setDatePickerOpen}>
          <PopoverTrigger asChild>
            <Button
              variant="outline"
              size="sm"
              className={cn(
                "h-8 text-sm justify-start",
                filters.timeWindow === "custom" ? "w-auto min-w-[160px]" : "w-[130px]"
              )}
              disabled={disabled}
            >
              <CalendarIcon className="h-3 w-3 mr-1" />
              <span className="truncate">{getDateRangeLabel(filters)}</span>
            </Button>
          </PopoverTrigger>
          <PopoverContent className="w-auto p-0" align="start">
            <div className="p-2 border-b">
              <div className="grid grid-cols-3 gap-1">
                {timeOptions.filter(opt => opt.value !== "custom").map((opt) => (
                  <Button
                    key={opt.value}
                    variant={filters.timeWindow === opt.value ? "secondary" : "ghost"}
                    size="sm"
                    className="text-xs h-7"
                    onClick={() => {
                      onFiltersChange({
                        ...filters,
                        timeWindow: opt.value,
                        customStartDate: undefined,
                        customEndDate: undefined,
                      });
                      setDatePickerOpen(false);
                    }}
                  >
                    {opt.label}
                  </Button>
                ))}
              </div>
            </div>
            <Separator />
            <div className="p-2">
              <Label className="text-xs text-muted-foreground mb-2 block">직접 선택</Label>
              <div className="flex gap-2">
                <div className="flex-1">
                  <Label className="text-xs mb-1 block">시작일</Label>
                  <Popover>
                    <PopoverTrigger asChild>
                      <Button
                        variant="outline"
                        size="sm"
                        className={cn(
                          "w-full justify-start text-left text-xs",
                          !filters.customStartDate && "text-muted-foreground"
                        )}
                      >
                        {filters.customStartDate ? (
                          format(filters.customStartDate, "yyyy.MM.dd", { locale: ko })
                        ) : (
                          "선택"
                        )}
                      </Button>
                    </PopoverTrigger>
                    <PopoverContent className="w-auto p-0" align="start">
                      <Calendar
                        mode="single"
                        selected={filters.customStartDate}
                        onSelect={(date) => {
                          updateCustomDateRange(date, filters.customEndDate);
                        }}
                        disabled={(date) =>
                          date > new Date() || (filters.customEndDate ? date > filters.customEndDate : false)
                        }
                        locale={ko}
                        initialFocus
                      />
                    </PopoverContent>
                  </Popover>
                </div>
                <div className="flex-1">
                  <Label className="text-xs mb-1 block">종료일</Label>
                  <Popover>
                    <PopoverTrigger asChild>
                      <Button
                        variant="outline"
                        size="sm"
                        className={cn(
                          "w-full justify-start text-left text-xs",
                          !filters.customEndDate && "text-muted-foreground"
                        )}
                      >
                        {filters.customEndDate ? (
                          format(filters.customEndDate, "yyyy.MM.dd", { locale: ko })
                        ) : (
                          "선택"
                        )}
                      </Button>
                    </PopoverTrigger>
                    <PopoverContent className="w-auto p-0" align="start">
                      <Calendar
                        mode="single"
                        selected={filters.customEndDate}
                        onSelect={(date) => {
                          updateCustomDateRange(filters.customStartDate, date);
                        }}
                        disabled={(date) =>
                          date > new Date() || (filters.customStartDate ? date < filters.customStartDate : false)
                        }
                        locale={ko}
                        initialFocus
                      />
                    </PopoverContent>
                  </Popover>
                </div>
              </div>
              {(filters.customStartDate || filters.customEndDate) && (
                <Button
                  variant="ghost"
                  size="sm"
                  className="w-full mt-2 text-xs"
                  onClick={() => {
                    updateCustomDateRange(undefined, undefined);
                  }}
                >
                  날짜 초기화
                </Button>
              )}
            </div>
          </PopoverContent>
        </Popover>

        {/* 정렬 */}
        <Select
          value={filters.sortBy}
          onValueChange={(v) => updateFilter("sortBy", v as SearchFilters["sortBy"])}
          disabled={disabled}
        >
          <SelectTrigger className="w-[110px] h-8 text-sm">
            <SelectValue />
          </SelectTrigger>
          <SelectContent>
            {sortOptions.map((opt) => (
              <SelectItem key={opt.value} value={opt.value}>
                {opt.label}
              </SelectItem>
            ))}
          </SelectContent>
        </Select>

        {/* 소스 토글 버튼 */}
        {(Object.entries(sourceConfig) as [keyof typeof sourceConfig, typeof sourceConfig.database][]).map(
          ([key, config]) => {
            const Icon = config.icon;
            const isActive = filters.sources[key];
            return (
              <Button
                key={key}
                variant={isActive ? "secondary" : "outline"}
                size="sm"
                className={cn(
                  "h-8 gap-1",
                  isActive && config.color,
                  !isActive && "opacity-50"
                )}
                onClick={() => updateSource(key, !isActive)}
                disabled={disabled}
              >
                <Icon className="h-3 w-3" />
                <span className="hidden sm:inline">{config.label}</span>
              </Button>
            );
          }
        )}

        {/* 리셋 버튼 */}
        {activeCount > 0 && (
          <Button
            variant="ghost"
            size="sm"
            className="h-8"
            onClick={resetFilters}
            disabled={disabled}
          >
            <RotateCcw className="h-3 w-3 mr-1" />
            초기화
          </Button>
        )}
      </div>
    );
  }

  // 펼침 모드: Collapsible 패널
  return (
    <Collapsible open={isOpen} onOpenChange={setIsOpen} className={className}>
      <CollapsibleTrigger asChild>
        <Button
          variant="outline"
          className="w-full justify-between"
          disabled={disabled}
        >
          <div className="flex items-center gap-2">
            <Filter className="h-4 w-4" />
            <span>고급 필터</span>
            {activeCount > 0 && (
              <Badge variant="secondary" className="ml-1">
                {activeCount}
              </Badge>
            )}
          </div>
          {isOpen ? (
            <ChevronUp className="h-4 w-4" />
          ) : (
            <ChevronDown className="h-4 w-4" />
          )}
        </Button>
      </CollapsibleTrigger>

      <CollapsibleContent className="mt-4 space-y-4 p-4 border rounded-lg bg-muted/30">
        {/* 시간 범위 & 정렬 */}
        <div className="grid grid-cols-1 sm:grid-cols-3 gap-4">
          <div className="space-y-2">
            <Label className="text-sm font-medium">기간</Label>
            <Select
              value={filters.timeWindow}
              onValueChange={(v) => {
                if (v === "custom") {
                  onFiltersChange({ ...filters, timeWindow: "custom" });
                } else {
                  onFiltersChange({
                    ...filters,
                    timeWindow: v,
                    customStartDate: undefined,
                    customEndDate: undefined,
                  });
                }
              }}
              disabled={disabled}
            >
              <SelectTrigger>
                <SelectValue>{getDateRangeLabel(filters)}</SelectValue>
              </SelectTrigger>
              <SelectContent>
                {timeOptions.map((opt) => (
                  <SelectItem key={opt.value} value={opt.value}>
                    {opt.label}
                  </SelectItem>
                ))}
              </SelectContent>
            </Select>
          </div>

          {/* Custom date range pickers */}
          {filters.timeWindow === "custom" && (
            <>
              <div className="space-y-2">
                <Label className="text-sm font-medium">시작일</Label>
                <Popover>
                  <PopoverTrigger asChild>
                    <Button
                      variant="outline"
                      className={cn(
                        "w-full justify-start text-left font-normal",
                        !filters.customStartDate && "text-muted-foreground"
                      )}
                      disabled={disabled}
                    >
                      <CalendarIcon className="mr-2 h-4 w-4" />
                      {filters.customStartDate ? (
                        format(filters.customStartDate, "yyyy년 MM월 dd일", { locale: ko })
                      ) : (
                        "시작일 선택"
                      )}
                    </Button>
                  </PopoverTrigger>
                  <PopoverContent className="w-auto p-0" align="start">
                    <Calendar
                      mode="single"
                      selected={filters.customStartDate}
                      onSelect={(date) => updateCustomDateRange(date, filters.customEndDate)}
                      disabled={(date) =>
                        date > new Date() || (filters.customEndDate ? date > filters.customEndDate : false)
                      }
                      locale={ko}
                      initialFocus
                    />
                  </PopoverContent>
                </Popover>
              </div>

              <div className="space-y-2">
                <Label className="text-sm font-medium">종료일</Label>
                <Popover>
                  <PopoverTrigger asChild>
                    <Button
                      variant="outline"
                      className={cn(
                        "w-full justify-start text-left font-normal",
                        !filters.customEndDate && "text-muted-foreground"
                      )}
                      disabled={disabled}
                    >
                      <CalendarIcon className="mr-2 h-4 w-4" />
                      {filters.customEndDate ? (
                        format(filters.customEndDate, "yyyy년 MM월 dd일", { locale: ko })
                      ) : (
                        "종료일 선택"
                      )}
                    </Button>
                  </PopoverTrigger>
                  <PopoverContent className="w-auto p-0" align="start">
                    <Calendar
                      mode="single"
                      selected={filters.customEndDate}
                      onSelect={(date) => updateCustomDateRange(filters.customStartDate, date)}
                      disabled={(date) =>
                        date > new Date() || (filters.customStartDate ? date < filters.customStartDate : false)
                      }
                      locale={ko}
                      initialFocus
                    />
                  </PopoverContent>
                </Popover>
              </div>
            </>
          )}

          {filters.timeWindow !== "custom" && (
            <>
              <div className="space-y-2">
                <Label className="text-sm font-medium">정렬</Label>
                <Select
                  value={filters.sortBy}
                  onValueChange={(v) => updateFilter("sortBy", v as SearchFilters["sortBy"])}
                  disabled={disabled}
                >
                  <SelectTrigger>
                    <SelectValue />
                  </SelectTrigger>
                  <SelectContent>
                    {sortOptions.map((opt) => (
                      <SelectItem key={opt.value} value={opt.value}>
                        {opt.label}
                      </SelectItem>
                    ))}
                  </SelectContent>
                </Select>
              </div>

              <div className="space-y-2">
                <Label className="text-sm font-medium">언어</Label>
                <Select
                  value={filters.language}
                  onValueChange={(v) => updateFilter("language", v as SearchFilters["language"])}
                  disabled={disabled}
                >
                  <SelectTrigger>
                    <SelectValue />
                  </SelectTrigger>
                  <SelectContent>
                    {languageOptions.map((opt) => (
                      <SelectItem key={opt.value} value={opt.value}>
                        {opt.label}
                      </SelectItem>
                    ))}
                  </SelectContent>
                </Select>
              </div>
            </>
          )}
        </div>

        {/* 정렬 & 언어 row when custom date is selected */}
        {filters.timeWindow === "custom" && (
          <div className="grid grid-cols-1 sm:grid-cols-2 gap-4">
            <div className="space-y-2">
              <Label className="text-sm font-medium">정렬</Label>
              <Select
                value={filters.sortBy}
                onValueChange={(v) => updateFilter("sortBy", v as SearchFilters["sortBy"])}
                disabled={disabled}
              >
                <SelectTrigger>
                  <SelectValue />
                </SelectTrigger>
                <SelectContent>
                  {sortOptions.map((opt) => (
                    <SelectItem key={opt.value} value={opt.value}>
                      {opt.label}
                    </SelectItem>
                  ))}
                </SelectContent>
              </Select>
            </div>

            <div className="space-y-2">
              <Label className="text-sm font-medium">언어</Label>
              <Select
                value={filters.language}
                onValueChange={(v) => updateFilter("language", v as SearchFilters["language"])}
                disabled={disabled}
              >
                <SelectTrigger>
                  <SelectValue />
                </SelectTrigger>
                <SelectContent>
                  {languageOptions.map((opt) => (
                    <SelectItem key={opt.value} value={opt.value}>
                      {opt.label}
                    </SelectItem>
                  ))}
                </SelectContent>
              </Select>
            </div>
          </div>
        )}

        <Separator />

        {/* 소스 선택 */}
        <div className="space-y-3">
          <Label className="text-sm font-medium">검색 소스</Label>
          <div className="flex flex-wrap gap-4">
            {(Object.entries(sourceConfig) as [keyof typeof sourceConfig, typeof sourceConfig.database][]).map(
              ([key, config]) => {
                const Icon = config.icon;
                return (
                  <div key={key} className="flex items-center space-x-2">
                    <Checkbox
                      id={`source-${key}`}
                      checked={filters.sources[key]}
                      onCheckedChange={(checked) => updateSource(key, checked === true)}
                      disabled={disabled}
                    />
                    <Label
                      htmlFor={`source-${key}`}
                      className={cn(
                        "flex items-center gap-1.5 cursor-pointer",
                        config.color
                      )}
                    >
                      <Icon className="h-4 w-4" />
                      {config.label}
                    </Label>
                  </div>
                );
              }
            )}
          </div>
        </div>

        {/* 액션 버튼 */}
        <div className="flex justify-end gap-2 pt-2">
          {activeCount > 0 && (
            <Button variant="ghost" size="sm" onClick={resetFilters} disabled={disabled}>
              <RotateCcw className="h-4 w-4 mr-1" />
              초기화
            </Button>
          )}
          <Button size="sm" onClick={() => setIsOpen(false)}>
            적용
          </Button>
        </div>
      </CollapsibleContent>
    </Collapsible>
  );
}

/** 활성 필터 표시 배지 */
export function ActiveFilterBadges({
  filters,
  onRemove,
  className,
}: {
  filters: SearchFilters;
  onRemove: (key: keyof SearchFilters, resetValue: unknown) => void;
  className?: string;
}) {
  const badges: { key: keyof SearchFilters; label: string; resetValue: unknown }[] = [];

  if (filters.timeWindow !== defaultFilters.timeWindow) {
    const label = getDateRangeLabel(filters);
    badges.push({ key: "timeWindow", label, resetValue: defaultFilters.timeWindow });
  }

  if (filters.sortBy !== defaultFilters.sortBy) {
    const opt = sortOptions.find((o) => o.value === filters.sortBy);
    badges.push({ key: "sortBy", label: opt?.label || filters.sortBy, resetValue: defaultFilters.sortBy });
  }

  if (filters.language !== defaultFilters.language) {
    const opt = languageOptions.find((o) => o.value === filters.language);
    badges.push({ key: "language", label: opt?.label || filters.language, resetValue: defaultFilters.language });
  }

  if (badges.length === 0) return null;

  return (
    <div className={cn("flex flex-wrap gap-2", className)}>
      {badges.map((badge) => (
        <Badge key={badge.key} variant="secondary" className="gap-1 pr-1">
          {badge.label}
          <button
            onClick={() => onRemove(badge.key, badge.resetValue)}
            className="ml-1 rounded-full p-0.5 hover:bg-muted"
          >
            <X className="h-3 w-3" />
          </button>
        </Badge>
      ))}
    </div>
  );
}

export default AdvancedFilters;

```

---

## frontend/src/components/AnalysisBadges.tsx

```tsx
import React from "react";
import { Badge } from "@/components/ui/badge";
import {
  Tooltip,
  TooltipContent,
  TooltipProvider,
  TooltipTrigger,
} from "@/components/ui/tooltip";
import { Skeleton } from "@/components/ui/skeleton";
import {
  Shield,
  AlertTriangle,
  CheckCircle,
  XCircle,
  TrendingUp,
  TrendingDown,
  Minus,
  MessageSquare,
  AlertCircle,
  HelpCircle,
} from "lucide-react";
import { cn } from "@/lib/utils";

// ========== Types ==========

export interface AnalysisData {
  analyzed?: boolean;
  analysisStatus?: "pending" | "partial" | "complete";
  reliabilityScore?: number;
  reliabilityGrade?: "high" | "medium" | "low";
  reliabilityColor?: "green" | "yellow" | "red";
  sentimentLabel?: "positive" | "negative" | "neutral";
  sentimentScore?: number;
  biasLabel?: string;
  biasScore?: number;
  factcheckStatus?: "verified" | "suspicious" | "conflicting" | "unverified";
  misinfoRisk?: "low" | "mid" | "high";
  riskTags?: string[];
  topics?: string[];
  hasDiscussion?: boolean;
  totalCommentCount?: number;
  discussionSentiment?: string;
}

// ========== Reliability Badge ==========

interface ReliabilityBadgeProps {
  score?: number;
  grade?: string;
  color?: string;
  loading?: boolean;
  size?: "sm" | "md" | "lg";
}

export const ReliabilityBadge: React.FC<ReliabilityBadgeProps> = ({
  score,
  grade,
  color,
  loading = false,
  size = "md",
}) => {
  if (loading) {
    return <Skeleton className={cn("h-6", size === "sm" ? "w-12" : "w-16")} />;
  }

  if (score === undefined || score === null) {
    return (
      <TooltipProvider>
        <Tooltip>
          <TooltipTrigger asChild>
            <Badge variant="outline" className="gap-1 text-muted-foreground">
              <HelpCircle className="h-3 w-3" />
              {size !== "sm" && "분석 중"}
            </Badge>
          </TooltipTrigger>
          <TooltipContent>
            <p>신뢰도 분석 대기 중</p>
          </TooltipContent>
        </Tooltip>
      </TooltipProvider>
    );
  }

  const colorClasses = {
    green: "bg-green-100 text-green-800 border-green-300 dark:bg-green-900/30 dark:text-green-400",
    yellow: "bg-yellow-100 text-yellow-800 border-yellow-300 dark:bg-yellow-900/30 dark:text-yellow-400",
    red: "bg-red-100 text-red-800 border-red-300 dark:bg-red-900/30 dark:text-red-400",
  };

  const iconColor = {
    green: "text-green-600",
    yellow: "text-yellow-600",
    red: "text-red-600",
  };

  const badgeColor = colorClasses[color as keyof typeof colorClasses] || colorClasses.yellow;
  const Icon = color === "green" ? Shield : color === "red" ? AlertTriangle : AlertCircle;

  return (
    <TooltipProvider>
      <Tooltip>
        <TooltipTrigger asChild>
          <Badge variant="outline" className={cn("gap-1", badgeColor)}>
            <Icon className={cn("h-3 w-3", iconColor[color as keyof typeof iconColor])} />
            {size !== "sm" && `신뢰도 ${Math.round(score)}%`}
            {size === "sm" && `${Math.round(score)}%`}
          </Badge>
        </TooltipTrigger>
        <TooltipContent>
          <div className="text-sm">
            <p className="font-semibold">신뢰도: {Math.round(score)}점</p>
            <p className="text-muted-foreground">
              {grade === "high" && "높은 신뢰도 - 검증된 출처"}
              {grade === "medium" && "보통 신뢰도 - 추가 검증 권장"}
              {grade === "low" && "낮은 신뢰도 - 주의 필요"}
            </p>
          </div>
        </TooltipContent>
      </Tooltip>
    </TooltipProvider>
  );
};

// ========== Sentiment Badge ==========

interface SentimentBadgeProps {
  label?: string;
  score?: number;
  loading?: boolean;
  size?: "sm" | "md" | "lg";
}

export const SentimentBadge: React.FC<SentimentBadgeProps> = ({
  label,
  score,
  loading = false,
  size = "md",
}) => {
  if (loading) {
    return <Skeleton className={cn("h-6", size === "sm" ? "w-12" : "w-14")} />;
  }

  if (!label) {
    return null;
  }

  const config = {
    positive: {
      icon: TrendingUp,
      label: "긍정",
      classes: "bg-emerald-100 text-emerald-800 border-emerald-300 dark:bg-emerald-900/30 dark:text-emerald-400",
    },
    negative: {
      icon: TrendingDown,
      label: "부정",
      classes: "bg-rose-100 text-rose-800 border-rose-300 dark:bg-rose-900/30 dark:text-rose-400",
    },
    neutral: {
      icon: Minus,
      label: "중립",
      classes: "bg-slate-100 text-slate-800 border-slate-300 dark:bg-slate-800/50 dark:text-slate-400",
    },
  };

  const { icon: Icon, label: displayLabel, classes } = config[label as keyof typeof config] || config.neutral;

  return (
    <TooltipProvider>
      <Tooltip>
        <TooltipTrigger asChild>
          <Badge variant="outline" className={cn("gap-1", classes)}>
            <Icon className="h-3 w-3" />
            {size !== "sm" && displayLabel}
          </Badge>
        </TooltipTrigger>
        <TooltipContent>
          <p>감정 분석: {displayLabel}</p>
          {score !== undefined && <p className="text-muted-foreground">점수: {score.toFixed(2)}</p>}
        </TooltipContent>
      </Tooltip>
    </TooltipProvider>
  );
};

// ========== Factcheck Badge ==========

interface FactcheckBadgeProps {
  status?: string;
  misinfoRisk?: string;
  loading?: boolean;
  size?: "sm" | "md" | "lg";
}

export const FactcheckBadge: React.FC<FactcheckBadgeProps> = ({
  status,
  misinfoRisk,
  loading = false,
  size = "md",
}) => {
  if (loading) {
    return <Skeleton className={cn("h-6", size === "sm" ? "w-12" : "w-16")} />;
  }

  if (!status && !misinfoRisk) {
    return null;
  }

  const config = {
    verified: {
      icon: CheckCircle,
      label: "검증됨",
      classes: "bg-green-100 text-green-800 border-green-300 dark:bg-green-900/30 dark:text-green-400",
    },
    suspicious: {
      icon: AlertTriangle,
      label: "의심",
      classes: "bg-orange-100 text-orange-800 border-orange-300 dark:bg-orange-900/30 dark:text-orange-400",
    },
    conflicting: {
      icon: AlertCircle,
      label: "상충",
      classes: "bg-yellow-100 text-yellow-800 border-yellow-300 dark:bg-yellow-900/30 dark:text-yellow-400",
    },
    unverified: {
      icon: HelpCircle,
      label: "미검증",
      classes: "bg-slate-100 text-slate-700 border-slate-300 dark:bg-slate-800/50 dark:text-slate-400",
    },
  };

  const { icon: Icon, label, classes } = config[status as keyof typeof config] || config.unverified;

  return (
    <TooltipProvider>
      <Tooltip>
        <TooltipTrigger asChild>
          <Badge variant="outline" className={cn("gap-1", classes)}>
            <Icon className="h-3 w-3" />
            {size !== "sm" && label}
          </Badge>
        </TooltipTrigger>
        <TooltipContent>
          <div className="text-sm">
            <p className="font-semibold">팩트체크: {label}</p>
            {misinfoRisk && (
              <p className="text-muted-foreground">
                허위정보 위험도: {misinfoRisk === "high" ? "높음" : misinfoRisk === "mid" ? "중간" : "낮음"}
              </p>
            )}
          </div>
        </TooltipContent>
      </Tooltip>
    </TooltipProvider>
  );
};

// ========== Bias Badge ==========

interface BiasBadgeProps {
  label?: string;
  score?: number;
  loading?: boolean;
  size?: "sm" | "md" | "lg";
}

export const BiasBadge: React.FC<BiasBadgeProps> = ({
  label,
  score,
  loading = false,
  size = "md",
}) => {
  if (loading) {
    return <Skeleton className={cn("h-6", size === "sm" ? "w-12" : "w-14")} />;
  }

  if (!label) {
    return null;
  }

  const config: Record<string, { label: string; classes: string }> = {
    left: {
      label: "진보",
      classes: "bg-blue-100 text-blue-800 border-blue-300 dark:bg-blue-900/30 dark:text-blue-400",
    },
    right: {
      label: "보수",
      classes: "bg-red-100 text-red-800 border-red-300 dark:bg-red-900/30 dark:text-red-400",
    },
    center: {
      label: "중도",
      classes: "bg-purple-100 text-purple-800 border-purple-300 dark:bg-purple-900/30 dark:text-purple-400",
    },
  };

  const { label: displayLabel, classes } = config[label] || { label, classes: "bg-slate-100 text-slate-700" };

  return (
    <TooltipProvider>
      <Tooltip>
        <TooltipTrigger asChild>
          <Badge variant="outline" className={cn("gap-1", classes)}>
            {size !== "sm" && `편향: ${displayLabel}`}
            {size === "sm" && displayLabel}
          </Badge>
        </TooltipTrigger>
        <TooltipContent>
          <p>편향도 분석: {displayLabel}</p>
          {score !== undefined && <p className="text-muted-foreground">점수: {score.toFixed(2)}</p>}
        </TooltipContent>
      </Tooltip>
    </TooltipProvider>
  );
};

// ========== Discussion Badge ==========

interface DiscussionBadgeProps {
  hasDiscussion?: boolean;
  totalCommentCount?: number;
  sentiment?: string;
  loading?: boolean;
  size?: "sm" | "md" | "lg";
}

export const DiscussionBadge: React.FC<DiscussionBadgeProps> = ({
  hasDiscussion,
  totalCommentCount,
  sentiment,
  loading = false,
  size = "md",
}) => {
  if (loading) {
    return <Skeleton className={cn("h-6", size === "sm" ? "w-12" : "w-16")} />;
  }

  if (!hasDiscussion || !totalCommentCount) {
    return null;
  }

  const sentimentConfig: Record<string, string> = {
    positive: "text-emerald-600",
    negative: "text-rose-600",
    neutral: "text-slate-600",
    mixed: "text-amber-600",
  };

  const formatCount = (count: number) => {
    if (count >= 1000) return `${(count / 1000).toFixed(1)}k`;
    return count.toString();
  };

  return (
    <TooltipProvider>
      <Tooltip>
        <TooltipTrigger asChild>
          <Badge variant="outline" className="gap-1 bg-slate-50 dark:bg-slate-800/50">
            <MessageSquare className={cn("h-3 w-3", sentimentConfig[sentiment || "neutral"])} />
            {formatCount(totalCommentCount)}
          </Badge>
        </TooltipTrigger>
        <TooltipContent>
          <div className="text-sm">
            <p className="font-semibold">댓글/여론: {totalCommentCount}건</p>
            {sentiment && (
              <p className="text-muted-foreground">
                전반적 분위기:{" "}
                {sentiment === "positive"
                  ? "긍정적"
                  : sentiment === "negative"
                  ? "부정적"
                  : sentiment === "mixed"
                  ? "혼재"
                  : "중립적"}
              </p>
            )}
          </div>
        </TooltipContent>
      </Tooltip>
    </TooltipProvider>
  );
};

// ========== Risk Tags ==========

interface RiskTagsProps {
  tags?: string[];
  loading?: boolean;
  maxShow?: number;
}

export const RiskTags: React.FC<RiskTagsProps> = ({
  tags,
  loading = false,
  maxShow = 2,
}) => {
  if (loading) {
    return <Skeleton className="h-5 w-20" />;
  }

  if (!tags || tags.length === 0) {
    return null;
  }

  const tagLabels: Record<string, string> = {
    clickbait: "낚시성",
    sensational: "선정적",
    unverified_source: "미검증 출처",
    opinion_piece: "의견 기사",
    sponsored: "협찬/광고",
    outdated: "오래된 정보",
  };

  const visibleTags = tags.slice(0, maxShow);
  const hiddenCount = tags.length - maxShow;

  return (
    <div className="flex flex-wrap gap-1">
      {visibleTags.map((tag) => (
        <Badge
          key={tag}
          variant="outline"
          className="text-xs bg-amber-50 text-amber-700 border-amber-200 dark:bg-amber-900/20 dark:text-amber-400"
        >
          {tagLabels[tag] || tag}
        </Badge>
      ))}
      {hiddenCount > 0 && (
        <TooltipProvider>
          <Tooltip>
            <TooltipTrigger asChild>
              <Badge variant="outline" className="text-xs">
                +{hiddenCount}
              </Badge>
            </TooltipTrigger>
            <TooltipContent>
              <div className="text-sm">
                {tags.slice(maxShow).map((tag) => (
                  <p key={tag}>{tagLabels[tag] || tag}</p>
                ))}
              </div>
            </TooltipContent>
          </Tooltip>
        </TooltipProvider>
      )}
    </div>
  );
};

// ========== Combined Analysis Badges ==========

interface AnalysisBadgesProps {
  data: AnalysisData;
  loading?: boolean;
  size?: "sm" | "md" | "lg";
  showAll?: boolean;
}

export const AnalysisBadges: React.FC<AnalysisBadgesProps> = ({
  data,
  loading = false,
  size = "md",
  showAll = false,
}) => {
  const isLoading = loading || data.analysisStatus === "pending";

  return (
    <div className="flex flex-wrap items-center gap-1.5">
      <ReliabilityBadge
        score={data.reliabilityScore}
        grade={data.reliabilityGrade}
        color={data.reliabilityColor}
        loading={isLoading}
        size={size}
      />
      <SentimentBadge
        label={data.sentimentLabel}
        score={data.sentimentScore}
        loading={isLoading}
        size={size}
      />
      {(showAll || data.factcheckStatus) && (
        <FactcheckBadge
          status={data.factcheckStatus}
          misinfoRisk={data.misinfoRisk}
          loading={isLoading}
          size={size}
        />
      )}
      {(showAll || data.biasLabel) && (
        <BiasBadge
          label={data.biasLabel}
          score={data.biasScore}
          loading={isLoading}
          size={size}
        />
      )}
      <DiscussionBadge
        hasDiscussion={data.hasDiscussion}
        totalCommentCount={data.totalCommentCount}
        sentiment={data.discussionSentiment}
        loading={isLoading}
        size={size}
      />
      {data.riskTags && data.riskTags.length > 0 && (
        <RiskTags tags={data.riskTags} loading={isLoading} />
      )}
    </div>
  );
};

export default AnalysisBadges;

```

---

## frontend/src/components/AnalysisExportMenu.tsx

```tsx
/**
 * AnalysisExportMenu - AI 분석 결과 내보내기 메뉴
 * 
 * PDF, Markdown, HTML, 텍스트 형식으로 내보내기 지원
 */

import { useState, useCallback } from 'react';
import { 
  Download, 
  FileText, 
  FileCode, 
  FileType2, 
  Copy, 
  Check,
  Loader2,
  ChevronDown,
} from 'lucide-react';
import { Button } from '@/components/ui/button';
import {
  DropdownMenu,
  DropdownMenuContent,
  DropdownMenuItem,
  DropdownMenuLabel,
  DropdownMenuSeparator,
  DropdownMenuTrigger,
} from '@/components/ui/dropdown-menu';
import { toast } from 'sonner';
import {
  exportUnifiedSearchReport,
  triggerPdfDownload,
  type ReportRequest,
} from '@/lib/api';

interface AnalysisExportMenuProps {
  /** AI 분석 내용 (마크다운) */
  content: string;
  /** 검색 쿼리 */
  query: string;
  /** Job ID (PDF 생성용) */
  jobId?: string;
  /** 버튼 크기 */
  size?: 'default' | 'sm' | 'lg' | 'icon';
  /** 버튼 변형 */
  variant?: 'default' | 'outline' | 'ghost' | 'secondary';
  /** 비활성화 */
  disabled?: boolean;
}

/**
 * HTML 템플릿 생성
 */
const generateHtmlReport = (content: string, query: string): string => {
  const timestamp = new Date().toLocaleString('ko-KR');
  
  return `<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>NewsInsight AI 분석 - ${query}</title>
  <style>
    :root {
      --primary: #7c3aed;
      --primary-light: #a78bfa;
      --bg: #ffffff;
      --text: #1f2937;
      --text-muted: #6b7280;
      --border: #e5e7eb;
      --section-summary: #eff6ff;
      --section-verify: #f0fdf4;
      --section-data: #faf5ff;
      --section-view: #fff7ed;
      --section-warn: #fffbeb;
      --section-conclusion: #eef2ff;
    }
    
    @media (prefers-color-scheme: dark) {
      :root {
        --bg: #111827;
        --text: #f9fafb;
        --text-muted: #9ca3af;
        --border: #374151;
        --section-summary: #1e3a5f;
        --section-verify: #14532d;
        --section-data: #3b0764;
        --section-view: #431407;
        --section-warn: #422006;
        --section-conclusion: #1e1b4b;
      }
    }
    
    * { box-sizing: border-box; margin: 0; padding: 0; }
    
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Noto Sans KR', sans-serif;
      line-height: 1.7;
      color: var(--text);
      background: var(--bg);
      max-width: 900px;
      margin: 0 auto;
      padding: 2rem;
    }
    
    header {
      text-align: center;
      padding-bottom: 2rem;
      margin-bottom: 2rem;
      border-bottom: 2px solid var(--primary);
    }
    
    header h1 {
      color: var(--primary);
      font-size: 1.5rem;
      margin-bottom: 0.5rem;
    }
    
    header .query {
      font-size: 1.25rem;
      font-weight: 600;
      margin-bottom: 0.5rem;
    }
    
    header .meta {
      color: var(--text-muted);
      font-size: 0.875rem;
    }
    
    h2 {
      font-size: 1.25rem;
      padding: 0.75rem 1rem;
      margin: 1.5rem 0 1rem;
      border-left: 4px solid var(--primary);
      border-radius: 0 0.5rem 0.5rem 0;
    }
    
    h2:has(+ *):nth-of-type(1), h2:contains("요약") { background: var(--section-summary); }
    h2:contains("검증") { background: var(--section-verify); }
    h2:contains("데이터"), h2:contains("수치") { background: var(--section-data); }
    h2:contains("관점") { background: var(--section-view); }
    h2:contains("주의") { background: var(--section-warn); }
    h2:contains("결론") { background: var(--section-conclusion); }
    
    h3 {
      font-size: 1rem;
      margin: 1.25rem 0 0.75rem;
      padding-bottom: 0.5rem;
      border-bottom: 1px solid var(--border);
    }
    
    p { margin: 0.75rem 0; }
    
    ul, ol { padding-left: 1.5rem; margin: 0.75rem 0; }
    li { margin: 0.5rem 0; }
    
    strong { font-weight: 600; color: var(--text); }
    
    a { color: var(--primary); text-decoration: none; }
    a:hover { text-decoration: underline; }
    
    table {
      width: 100%;
      border-collapse: collapse;
      margin: 1rem 0;
      font-size: 0.9rem;
      border-radius: 0.5rem;
      overflow: hidden;
      box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    }
    
    th, td {
      padding: 0.75rem 1rem;
      text-align: left;
      border-bottom: 1px solid var(--border);
    }
    
    th {
      background: var(--border);
      font-weight: 600;
    }
    
    tr:hover { background: rgba(124, 58, 237, 0.05); }
    
    .badge {
      display: inline-block;
      padding: 0.25rem 0.5rem;
      border-radius: 0.25rem;
      font-size: 0.75rem;
      font-weight: 500;
    }
    
    .badge-high { background: #dcfce7; color: #166534; }
    .badge-medium { background: #fef9c3; color: #854d0e; }
    .badge-low { background: #fee2e2; color: #991b1b; }
    
    blockquote {
      margin: 1rem 0;
      padding: 0.75rem 1rem;
      border-left: 4px solid var(--primary-light);
      background: rgba(124, 58, 237, 0.05);
      border-radius: 0 0.5rem 0.5rem 0;
      font-style: italic;
      color: var(--text-muted);
    }
    
    code {
      background: var(--border);
      padding: 0.125rem 0.375rem;
      border-radius: 0.25rem;
      font-family: 'Fira Code', monospace;
      font-size: 0.875em;
    }
    
    hr {
      border: none;
      border-top: 2px dashed var(--border);
      margin: 2rem 0;
    }
    
    footer {
      margin-top: 3rem;
      padding-top: 1.5rem;
      border-top: 1px solid var(--border);
      text-align: center;
      color: var(--text-muted);
      font-size: 0.875rem;
    }
    
    @media print {
      body { padding: 1rem; }
      h2 { break-after: avoid; }
      table { break-inside: avoid; }
    }
  </style>
</head>
<body>
  <header>
    <h1>NewsInsight AI 분석 보고서</h1>
    <div class="query">"${query}"</div>
    <div class="meta">생성 시간: ${timestamp}</div>
  </header>
  
  <main>
    ${markdownToHtml(content)}
  </main>
  
  <footer>
    <p>이 보고서는 NewsInsight AI에 의해 자동 생성되었습니다.</p>
    <p>모든 정보는 참고용이며, 최종 판단은 사용자의 몫입니다.</p>
  </footer>
</body>
</html>`;
};

/**
 * 간단한 마크다운 -> HTML 변환
 */
const markdownToHtml = (md: string): string => {
  let html = md
    // 헤더
    .replace(/^### \[([^\]]+)\] (.+)$/gm, '<h3>$1: $2</h3>')
    .replace(/^### (.+)$/gm, '<h3>$1</h3>')
    .replace(/^## \[([^\]]+)\] (.+)$/gm, '<h2>$1: $2</h2>')
    .replace(/^## (.+)$/gm, '<h2>$1</h2>')
    // 테이블
    .replace(/\|(.+)\|/g, (match) => {
      const cells = match.split('|').filter(c => c.trim());
      if (cells.every(c => c.trim().match(/^-+$/))) {
        return ''; // 구분선 제거
      }
      const isHeader = cells.some(c => c.includes('사실') || c.includes('출처') || c.includes('검증'));
      const tag = isHeader ? 'th' : 'td';
      const row = cells.map(c => {
        let content = c.trim();
        // 검증 수준 배지
        if (content.match(/^(높음|중간|낮음)$/)) {
          const badgeClass = content === '높음' ? 'badge-high' : content === '중간' ? 'badge-medium' : 'badge-low';
          content = `<span class="badge ${badgeClass}">${content}</span>`;
        }
        return `<${tag}>${content}</${tag}>`;
      }).join('');
      return `<tr>${row}</tr>`;
    })
    // 테이블 래퍼
    .replace(/(<tr>.*<\/tr>\n?)+/gs, '<table>$&</table>')
    // 굵게
    .replace(/\*\*(.+?)\*\*/g, '<strong>$1</strong>')
    // 기울임
    .replace(/\*(.+?)\*/g, '<em>$1</em>')
    // 링크
    .replace(/\[([^\]]+)\]\(([^)]+)\)/g, '<a href="$2" target="_blank">$1</a>')
    // 리스트
    .replace(/^- (.+)$/gm, '<li>$1</li>')
    .replace(/(<li>.*<\/li>\n?)+/gs, '<ul>$&</ul>')
    // 인용
    .replace(/^> (.+)$/gm, '<blockquote>$1</blockquote>')
    // 코드
    .replace(/`([^`]+)`/g, '<code>$1</code>')
    // 구분선
    .replace(/^---$/gm, '<hr>')
    // 단락
    .replace(/^(?!<[a-z])(.*[^\n])$/gm, '<p>$1</p>')
    // 빈 p 태그 제거
    .replace(/<p>\s*<\/p>/g, '');
  
  return html;
};

/**
 * 파일 다운로드 트리거
 */
const downloadFile = (content: string, filename: string, mimeType: string) => {
  const blob = new Blob([content], { type: mimeType });
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url;
  a.download = filename;
  document.body.appendChild(a);
  a.click();
  document.body.removeChild(a);
  URL.revokeObjectURL(url);
};

/**
 * AI 분석 결과 내보내기 메뉴 컴포넌트
 */
export function AnalysisExportMenu({
  content,
  query,
  jobId,
  size = 'sm',
  variant = 'outline',
  disabled = false,
}: AnalysisExportMenuProps) {
  const [isExporting, setIsExporting] = useState(false);
  const [copied, setCopied] = useState(false);
  
  const timestamp = new Date().toISOString().slice(0, 10).replace(/-/g, '');
  const safeQuery = query.replace(/[^가-힣a-zA-Z0-9]/g, '_').slice(0, 30);
  const baseFilename = `NewsInsight_AI분석_${safeQuery}_${timestamp}`;

  // PDF 내보내기
  const handleExportPdf = useCallback(async () => {
    if (!jobId) {
      toast.error('PDF 내보내기는 검색 작업 ID가 필요합니다.');
      return;
    }
    
    setIsExporting(true);
    try {
      const request: ReportRequest = {
        reportType: 'UNIFIED_SEARCH',
        targetId: jobId,
        query,
        timeWindow: '7d',
        includeSections: ['COVER', 'EXECUTIVE_SUMMARY'],
        chartImages: {},
        language: 'ko',
      };
      
      const blob = await exportUnifiedSearchReport(jobId, request);
      triggerPdfDownload(blob, `${baseFilename}.pdf`);
      toast.success('PDF 보고서가 다운로드되었습니다.');
    } catch (error) {
      console.error('PDF export failed:', error);
      toast.error('PDF 생성에 실패했습니다.');
    } finally {
      setIsExporting(false);
    }
  }, [jobId, query, baseFilename]);

  // Markdown 내보내기
  const handleExportMarkdown = useCallback(() => {
    const mdContent = `# NewsInsight AI 분석 보고서

**검색어**: ${query}  
**생성 시간**: ${new Date().toLocaleString('ko-KR')}

---

${content}

---

*이 보고서는 NewsInsight AI에 의해 자동 생성되었습니다.*
`;
    downloadFile(mdContent, `${baseFilename}.md`, 'text/markdown;charset=utf-8');
    toast.success('Markdown 파일이 다운로드되었습니다.');
  }, [content, query, baseFilename]);

  // HTML 내보내기
  const handleExportHtml = useCallback(() => {
    const htmlContent = generateHtmlReport(content, query);
    downloadFile(htmlContent, `${baseFilename}.html`, 'text/html;charset=utf-8');
    toast.success('HTML 파일이 다운로드되었습니다.');
  }, [content, query, baseFilename]);

  // 텍스트 내보내기
  const handleExportText = useCallback(() => {
    // 마크다운 문법 제거
    const plainText = content
      .replace(/#{1,6}\s/g, '')
      .replace(/\*\*(.+?)\*\*/g, '$1')
      .replace(/\*(.+?)\*/g, '$1')
      .replace(/\[([^\]]+)\]\([^)]+\)/g, '$1')
      .replace(/`([^`]+)`/g, '$1')
      .replace(/\|/g, ' | ');
    
    const textContent = `NewsInsight AI 분석 보고서
========================================

검색어: ${query}
생성 시간: ${new Date().toLocaleString('ko-KR')}

========================================

${plainText}

========================================

이 보고서는 NewsInsight AI에 의해 자동 생성되었습니다.
`;
    downloadFile(textContent, `${baseFilename}.txt`, 'text/plain;charset=utf-8');
    toast.success('텍스트 파일이 다운로드되었습니다.');
  }, [content, query, baseFilename]);

  // 클립보드 복사
  const handleCopy = useCallback(async () => {
    try {
      await navigator.clipboard.writeText(content);
      setCopied(true);
      toast.success('클립보드에 복사되었습니다.');
      setTimeout(() => setCopied(false), 2000);
    } catch (error) {
      toast.error('복사에 실패했습니다.');
    }
  }, [content]);

  return (
    <DropdownMenu>
      <DropdownMenuTrigger asChild>
        <Button variant={variant} size={size} disabled={disabled || isExporting}>
          {isExporting ? (
            <Loader2 className="h-4 w-4 animate-spin" />
          ) : (
            <Download className="h-4 w-4" />
          )}
          <span className="ml-1.5">내보내기</span>
          <ChevronDown className="h-3 w-3 ml-1 opacity-70" />
        </Button>
      </DropdownMenuTrigger>
      <DropdownMenuContent align="end" className="w-48">
        <DropdownMenuLabel>내보내기 형식</DropdownMenuLabel>
        <DropdownMenuSeparator />
        
        {jobId && (
          <DropdownMenuItem onClick={handleExportPdf} disabled={isExporting}>
            <FileText className="h-4 w-4 mr-2 text-red-600" />
            PDF 보고서
          </DropdownMenuItem>
        )}
        
        <DropdownMenuItem onClick={handleExportMarkdown}>
          <FileCode className="h-4 w-4 mr-2 text-blue-600" />
          Markdown (.md)
        </DropdownMenuItem>
        
        <DropdownMenuItem onClick={handleExportHtml}>
          <FileType2 className="h-4 w-4 mr-2 text-orange-600" />
          HTML 웹페이지
        </DropdownMenuItem>
        
        <DropdownMenuItem onClick={handleExportText}>
          <FileText className="h-4 w-4 mr-2 text-gray-600" />
          텍스트 (.txt)
        </DropdownMenuItem>
        
        <DropdownMenuSeparator />
        
        <DropdownMenuItem onClick={handleCopy}>
          {copied ? (
            <Check className="h-4 w-4 mr-2 text-green-600" />
          ) : (
            <Copy className="h-4 w-4 mr-2" />
          )}
          클립보드 복사
        </DropdownMenuItem>
      </DropdownMenuContent>
    </DropdownMenu>
  );
}

export default AnalysisExportMenu;

```

---

## frontend/src/components/AnalysisProgressTimeline.tsx

```tsx
import { useMemo } from "react";
import {
  Search,
  Globe,
  FileText,
  Brain,
  CheckCircle2,
  Loader2,
  Circle,
  AlertCircle,
  Clock,
  Sparkles,
  Database,
  Filter,
} from "lucide-react";
import { cn } from "@/lib/utils";
import { Progress } from "@/components/ui/progress";
import { Badge } from "@/components/ui/badge";

/** 분석 단계 정의 */
export type AnalysisStep =
  | "queued"
  | "initializing"
  | "searching"
  | "collecting"
  | "analyzing"
  | "classifying"
  | "summarizing"
  | "completed"
  | "failed";

export interface AnalysisStepInfo {
  id: AnalysisStep;
  label: string;
  description: string;
  icon: typeof Search;
  estimatedDuration?: number; // seconds
}

/** 기본 분석 단계 설정 */
export const DEFAULT_ANALYSIS_STEPS: AnalysisStepInfo[] = [
  {
    id: "queued",
    label: "대기 중",
    description: "분석 요청이 대기열에 추가되었습니다",
    icon: Clock,
    estimatedDuration: 2,
  },
  {
    id: "initializing",
    label: "초기화",
    description: "분석 환경을 준비하고 있습니다",
    icon: Sparkles,
    estimatedDuration: 3,
  },
  {
    id: "searching",
    label: "검색 중",
    description: "웹에서 관련 정보를 검색하고 있습니다",
    icon: Globe,
    estimatedDuration: 15,
  },
  {
    id: "collecting",
    label: "수집 중",
    description: "검색된 페이지에서 정보를 수집하고 있습니다",
    icon: Database,
    estimatedDuration: 20,
  },
  {
    id: "analyzing",
    label: "분석 중",
    description: "AI가 수집된 정보를 분석하고 있습니다",
    icon: Brain,
    estimatedDuration: 30,
  },
  {
    id: "classifying",
    label: "분류 중",
    description: "증거를 입장별로 분류하고 있습니다",
    icon: Filter,
    estimatedDuration: 10,
  },
  {
    id: "summarizing",
    label: "요약 중",
    description: "분석 결과를 정리하고 있습니다",
    icon: FileText,
    estimatedDuration: 5,
  },
  {
    id: "completed",
    label: "완료",
    description: "분석이 완료되었습니다",
    icon: CheckCircle2,
  },
];

export interface StepProgress {
  step: AnalysisStep;
  status: "pending" | "active" | "completed" | "error";
  message?: string;
  startedAt?: string;
  completedAt?: string;
  itemsProcessed?: number;
  totalItems?: number;
}

interface AnalysisProgressTimelineProps {
  /** 현재 단계 */
  currentStep: AnalysisStep;
  /** 각 단계별 상세 진행 상황 */
  stepProgress?: StepProgress[];
  /** 전체 진행률 (0-100) */
  overallProgress?: number;
  /** 현재 진행 메시지 */
  message?: string;
  /** 수집된 항목 수 */
  collectedCount?: number;
  /** 실패 여부 */
  failed?: boolean;
  /** 에러 메시지 */
  errorMessage?: string;
  /** 분석 주제 */
  topic?: string;
  /** 단계 설정 (커스텀) */
  steps?: AnalysisStepInfo[];
  /** 컴팩트 모드 */
  compact?: boolean;
  /** 추가 CSS 클래스 */
  className?: string;
}

/** 단계 인덱스 계산 */
const getStepIndex = (step: AnalysisStep, steps: AnalysisStepInfo[]): number => {
  return steps.findIndex((s) => s.id === step);
};

/** 단계 상태 결정 */
const getStepStatus = (
  stepInfo: AnalysisStepInfo,
  currentStep: AnalysisStep,
  steps: AnalysisStepInfo[],
  failed: boolean
): "pending" | "active" | "completed" | "error" => {
  const currentIndex = getStepIndex(currentStep, steps);
  const stepIndex = getStepIndex(stepInfo.id, steps);

  if (failed && stepIndex === currentIndex) return "error";
  if (stepIndex < currentIndex) return "completed";
  if (stepIndex === currentIndex) return "active";
  return "pending";
};

export function AnalysisProgressTimeline({
  currentStep,
  stepProgress,
  overallProgress,
  message,
  collectedCount,
  failed = false,
  errorMessage,
  topic,
  steps = DEFAULT_ANALYSIS_STEPS,
  compact = false,
  className,
}: AnalysisProgressTimelineProps) {
  // 진행 중인 단계들만 표시 (completed 제외, 실패가 아닐 때)
  const visibleSteps = useMemo(() => {
    if (failed) return steps;
    const completedIndex = steps.findIndex((s) => s.id === "completed");
    if (currentStep === "completed") return steps;
    return steps.slice(0, completedIndex);
  }, [steps, currentStep, failed]);

  // 전체 진행률 계산
  const calculatedProgress = useMemo(() => {
    if (overallProgress !== undefined) return overallProgress;
    const currentIndex = getStepIndex(currentStep, steps);
    const totalSteps = steps.length - 1; // completed 제외
    if (currentStep === "completed") return 100;
    if (currentStep === "failed") return 0;
    return Math.round((currentIndex / totalSteps) * 100);
  }, [currentStep, steps, overallProgress]);

  // 컴팩트 모드
  if (compact) {
    return (
      <div className={cn("space-y-3", className)}>
        {/* 진행 바 */}
        <div className="space-y-1">
          <div className="flex items-center justify-between text-sm">
            <span className="text-muted-foreground">
              {message || steps.find((s) => s.id === currentStep)?.description}
            </span>
            <span className="font-medium">{calculatedProgress}%</span>
          </div>
          <Progress value={calculatedProgress} className="h-2" />
        </div>

        {/* 현재 단계 표시 */}
        <div className="flex items-center gap-2">
          {(() => {
            const stepInfo = steps.find((s) => s.id === currentStep);
            if (!stepInfo) return null;
            const Icon = stepInfo.icon;
            const status = getStepStatus(stepInfo, currentStep, steps, failed);

            return (
              <>
                {status === "active" ? (
                  <Loader2 className="h-4 w-4 animate-spin text-primary" />
                ) : status === "completed" ? (
                  <CheckCircle2 className="h-4 w-4 text-green-600" />
                ) : status === "error" ? (
                  <AlertCircle className="h-4 w-4 text-destructive" />
                ) : (
                  <Icon className="h-4 w-4 text-muted-foreground" />
                )}
                <span className="font-medium">{stepInfo.label}</span>
                {collectedCount !== undefined && collectedCount > 0 && (
                  <Badge variant="secondary" className="ml-auto">
                    {collectedCount}개 수집
                  </Badge>
                )}
              </>
            );
          })()}
        </div>
      </div>
    );
  }

  // 전체 타임라인 모드
  return (
    <div className={cn("space-y-6", className)}>
      {/* 헤더 */}
      {topic && (
        <div className="text-center">
          <h3 className="font-semibold text-lg">'{topic}' 분석 중</h3>
          <p className="text-sm text-muted-foreground mt-1">
            {message || "AI가 웹에서 정보를 수집하고 분석하고 있습니다."}
          </p>
        </div>
      )}

      {/* 전체 진행률 */}
      <div className="space-y-2">
        <div className="flex items-center justify-between text-sm">
          <span className="text-muted-foreground">전체 진행률</span>
          <span className="font-medium">{calculatedProgress}%</span>
        </div>
        <Progress value={calculatedProgress} className="h-3" />
        {collectedCount !== undefined && collectedCount > 0 && (
          <p className="text-sm text-center text-muted-foreground">
            현재까지 <span className="font-medium text-foreground">{collectedCount}개</span>의
            증거를 수집했습니다
          </p>
        )}
      </div>

      {/* 단계별 타임라인 */}
      <div className="relative">
        {/* 연결선 */}
        <div className="absolute left-[15px] top-0 bottom-0 w-0.5 bg-border" />

        <div className="space-y-1">
          {visibleSteps.map((stepInfo, index) => {
            const status = getStepStatus(stepInfo, currentStep, steps, failed);
            const Icon = stepInfo.icon;
            const progressInfo = stepProgress?.find((p) => p.step === stepInfo.id);

            return (
              <div
                key={stepInfo.id}
                className={cn(
                  "relative flex items-start gap-4 p-3 rounded-lg transition-all",
                  status === "active" && "bg-primary/5",
                  status === "error" && "bg-destructive/5"
                )}
              >
                {/* 아이콘 */}
                <div
                  className={cn(
                    "relative z-10 flex items-center justify-center w-8 h-8 rounded-full border-2 transition-all",
                    status === "completed" && "bg-green-500 border-green-500 text-white",
                    status === "active" && "bg-primary border-primary text-primary-foreground",
                    status === "error" && "bg-destructive border-destructive text-destructive-foreground",
                    status === "pending" && "bg-background border-muted-foreground/30 text-muted-foreground"
                  )}
                >
                  {status === "active" ? (
                    <Loader2 className="h-4 w-4 animate-spin" />
                  ) : status === "completed" ? (
                    <CheckCircle2 className="h-4 w-4" />
                  ) : status === "error" ? (
                    <AlertCircle className="h-4 w-4" />
                  ) : (
                    <Circle className="h-3 w-3" />
                  )}
                </div>

                {/* 내용 */}
                <div className="flex-1 min-w-0 pt-1">
                  <div className="flex items-center gap-2">
                    <span
                      className={cn(
                        "font-medium",
                        status === "active" && "text-primary",
                        status === "completed" && "text-green-600",
                        status === "error" && "text-destructive",
                        status === "pending" && "text-muted-foreground"
                      )}
                    >
                      {stepInfo.label}
                    </span>
                    {status === "active" && progressInfo?.itemsProcessed !== undefined && (
                      <Badge variant="secondary" className="text-xs">
                        {progressInfo.itemsProcessed}
                        {progressInfo.totalItems ? `/${progressInfo.totalItems}` : ""}
                      </Badge>
                    )}
                  </div>
                  <p
                    className={cn(
                      "text-sm",
                      status === "active" ? "text-muted-foreground" : "text-muted-foreground/70"
                    )}
                  >
                    {progressInfo?.message || stepInfo.description}
                  </p>
                  {status === "error" && errorMessage && (
                    <p className="text-sm text-destructive mt-1">{errorMessage}</p>
                  )}
                </div>

                {/* 시간 표시 */}
                {progressInfo?.completedAt && status === "completed" && (
                  <span className="text-xs text-muted-foreground shrink-0">
                    {new Date(progressInfo.completedAt).toLocaleTimeString("ko-KR", {
                      hour: "2-digit",
                      minute: "2-digit",
                    })}
                  </span>
                )}
              </div>
            );
          })}
        </div>
      </div>

      {/* 안내 메시지 */}
      <p className="text-xs text-center text-muted-foreground">
        다른 페이지로 이동해도 분석은 백그라운드에서 계속됩니다
      </p>
    </div>
  );
}

/** 간단한 인라인 진행률 표시 */
export function InlineAnalysisProgress({
  currentStep,
  progress,
  message,
  collectedCount,
  className,
}: {
  currentStep: AnalysisStep;
  progress?: number;
  message?: string;
  collectedCount?: number;
  className?: string;
}) {
  const stepInfo = DEFAULT_ANALYSIS_STEPS.find((s) => s.id === currentStep);
  const Icon = stepInfo?.icon || Search;

  return (
    <div className={cn("flex items-center gap-3", className)}>
      <div className="flex items-center gap-2 text-sm">
        {currentStep === "completed" ? (
          <CheckCircle2 className="h-4 w-4 text-green-600" />
        ) : (
          <Loader2 className="h-4 w-4 animate-spin text-primary" />
        )}
        <span className="font-medium">{stepInfo?.label || currentStep}</span>
      </div>
      {progress !== undefined && (
        <Progress value={progress} className="flex-1 h-2 max-w-[200px]" />
      )}
      {collectedCount !== undefined && collectedCount > 0 && (
        <Badge variant="outline" className="text-xs">
          {collectedCount}개 수집
        </Badge>
      )}
      {message && (
        <span className="text-xs text-muted-foreground truncate max-w-[200px]">
          {message}
        </span>
      )}
    </div>
  );
}

export default AnalysisProgressTimeline;

```

---

## frontend/src/components/BackgroundTaskIndicator.tsx

```tsx
import { useState } from 'react';
import { useNavigate } from 'react-router-dom';
import { Loader2, CheckCircle2, XCircle, Clock, Search, Trash2, X, ExternalLink } from 'lucide-react';
import { useBackgroundTasks, type BackgroundTask } from '@/contexts/BackgroundTaskContext';
import { Button } from '@/components/ui/button';
import { Badge } from '@/components/ui/badge';
import { Progress } from '@/components/ui/progress';
import { ScrollArea } from '@/components/ui/scroll-area';
import {
  Popover,
  PopoverContent,
  PopoverTrigger,
} from '@/components/ui/popover';
import { cn } from '@/lib/utils';
import { cancelDeepSearch } from '@/lib/api';

// ============================================
// Task Item Component
// ============================================

interface TaskItemProps {
  task: BackgroundTask;
  onNavigate: (url: string) => void;
  onRemove: (id: string) => void;
}

const TaskItem = ({ task, onNavigate, onRemove, onCancel }: TaskItemProps & { onCancel?: (task: BackgroundTask) => void }) => {
  const getStatusIcon = () => {
    switch (task.status) {
      case 'pending':
        return <Clock className="h-4 w-4 text-yellow-500" />;
      case 'running':
        return <Loader2 className="h-4 w-4 text-blue-500 animate-spin" />;
      case 'completed':
        return <CheckCircle2 className="h-4 w-4 text-green-500" />;
      case 'failed':
      case 'cancelled':
        return <XCircle className="h-4 w-4 text-red-500" />;
      default:
        return <Clock className="h-4 w-4 text-muted-foreground" />;
    }
  };

  const getStatusLabel = () => {
    switch (task.status) {
      case 'pending':
        return '대기 중';
      case 'running':
        return '진행 중';
      case 'completed':
        return '완료';
      case 'failed':
        return '실패';
      case 'cancelled':
        return '취소됨';
      default:
        return task.status;
    }
  };

  const getTypeIcon = () => {
    switch (task.type) {
      case 'deep-search':
        return <Search className="h-3 w-3" />;
      default:
        return null;
    }
  };

  const getTypeLabel = () => {
    switch (task.type) {
      case 'deep-search':
        return 'Deep Search';
      case 'browser-agent':
        return 'Browser Agent';
      case 'fact-check':
        return 'Fact Check';
      default:
        return task.type;
    }
  };

  const formatTime = (dateString: string) => {
    const date = new Date(dateString);
    const now = new Date();
    const diffMs = now.getTime() - date.getTime();
    const diffMins = Math.floor(diffMs / 60000);
    
    if (diffMins < 1) return '방금 전';
    if (diffMins < 60) return `${diffMins}분 전`;
    const diffHours = Math.floor(diffMins / 60);
    if (diffHours < 24) return `${diffHours}시간 전`;
    return date.toLocaleDateString('ko-KR');
  };

  const isActive = task.status === 'pending' || task.status === 'running';
  const isCompleted = task.status === 'completed';

  return (
    <div className={cn(
      "p-3 rounded-lg border transition-colors",
      isActive && "bg-blue-50 dark:bg-blue-950/20 border-blue-200 dark:border-blue-800",
      isCompleted && "bg-green-50 dark:bg-green-950/20 border-green-200 dark:border-green-800",
      !isActive && !isCompleted && "bg-muted/50"
    )}>
      <div className="flex items-start justify-between gap-2">
        <div className="flex-1 min-w-0 overflow-hidden">
          <div className="flex items-center gap-2 mb-1">
            <span className="shrink-0">{getStatusIcon()}</span>
            <span className="font-medium text-sm truncate" title={task.title}>{task.title}</span>
          </div>
          
          <div className="flex flex-wrap items-center gap-1.5 text-xs text-muted-foreground">
            <Badge variant="outline" className="h-5 gap-1 shrink-0">
              {getTypeIcon()}
              {getTypeLabel()}
            </Badge>
            <span className="shrink-0">{getStatusLabel()}</span>
            {task.evidenceCount !== undefined && task.evidenceCount > 0 && (
              <span className="shrink-0">| {task.evidenceCount}개 증거</span>
            )}
          </div>
          
          {/* Progress bar for running tasks */}
          {isActive && task.progress !== undefined && (
            <div className="mt-2 space-y-1">
              <Progress value={task.progress} className="h-1.5" />
              <div className="flex justify-between text-xs text-muted-foreground">
                <span className="truncate mr-2">{task.progressMessage || '처리 중...'}</span>
                <span className="shrink-0">{task.progress}%</span>
              </div>
            </div>
          )}
          
          {/* Error message */}
          {task.error && (
            <p className="mt-1 text-xs text-red-600 dark:text-red-400 line-clamp-2" title={task.error}>
              {task.error}
            </p>
          )}
          
          {/* Time info */}
          <div className="mt-1 text-xs text-muted-foreground">
            {task.completedAt 
              ? `완료: ${formatTime(task.completedAt)}`
              : `시작: ${formatTime(task.createdAt)}`
            }
          </div>
        </div>
        
        <div className="flex items-center gap-1 shrink-0">
          {task.resultUrl && (isCompleted || isActive) && (
            <Button
              variant="ghost"
              size="icon"
              className="h-7 w-7"
              onClick={() => onNavigate(task.resultUrl!)}
              title="결과 보기"
            >
              <ExternalLink className="h-3.5 w-3.5" />
            </Button>
          )}
          {isActive && onCancel && (
            <Button
              variant="ghost"
              size="icon"
              className="h-7 w-7 text-muted-foreground hover:text-red-500"
              onClick={() => onCancel(task)}
              title="작업 취소"
            >
              <XCircle className="h-3.5 w-3.5" />
            </Button>
          )}
          {!isActive && (
            <Button
              variant="ghost"
              size="icon"
              className="h-7 w-7 text-muted-foreground hover:text-destructive"
              onClick={() => onRemove(task.id)}
              title="삭제"
            >
              <Trash2 className="h-3.5 w-3.5" />
            </Button>
          )}
        </div>
      </div>
    </div>
  );
};

// ============================================
// Background Task Indicator
// ============================================

export function BackgroundTaskIndicator() {
  const navigate = useNavigate();
  const [open, setOpen] = useState(false);
  const { 
    activeTasks, 
    completedTasks, 
    hasActiveTasks, 
    activeTaskCount,
    removeTask,
    clearCompletedTasks,
    updateTask,
  } = useBackgroundTasks();

  const handleNavigate = (url: string) => {
    setOpen(false);
    navigate(url);
  };

  const handleCancelTask = async (task: BackgroundTask) => {
    if (task.status !== 'pending' && task.status !== 'running') {
      return;
    }

    try {
      if (task.type === 'deep-search') {
        await cancelDeepSearch(task.id);
      }
    } catch (error) {
      console.error('Failed to cancel background task:', error);
    } finally {
      updateTask(task.id, {
        status: 'cancelled',
        completedAt: new Date().toISOString(),
      });
    }
  };

  const allTasks = [...activeTasks, ...completedTasks];

  // Don't show if no tasks at all
  if (allTasks.length === 0) {
    return null;
  }

  return (
    <Popover open={open} onOpenChange={setOpen}>
      <PopoverTrigger asChild>
        <Button
          variant="ghost"
          size="sm"
          className={cn(
            "relative h-9 px-3 gap-2",
            hasActiveTasks && "text-blue-600 dark:text-blue-400"
          )}
        >
          {hasActiveTasks ? (
            <Loader2 className="h-4 w-4 animate-spin" />
          ) : (
            <CheckCircle2 className="h-4 w-4 text-green-500" />
          )}
          
          <span className="text-sm font-medium">
            {hasActiveTasks ? activeTaskCount : completedTasks.length}
          </span>
          
          {/* Pulse animation for active tasks */}
          {hasActiveTasks && (
            <span className="absolute top-1 right-1 h-2 w-2">
              <span className="animate-ping absolute inline-flex h-full w-full rounded-full bg-blue-400 opacity-75" />
              <span className="relative inline-flex rounded-full h-2 w-2 bg-blue-500" />
            </span>
          )}
        </Button>
      </PopoverTrigger>
      
      <PopoverContent 
        className="w-96 p-0" 
        align="end"
        sideOffset={8}
      >
        {/* Header - fixed */}
        <div className="flex items-center justify-between p-3 border-b bg-background sticky top-0 z-10">
          <h3 className="font-semibold">백그라운드 작업</h3>
          <Button
            variant="ghost"
            size="icon"
            className="h-7 w-7"
            onClick={() => setOpen(false)}
          >
            <X className="h-4 w-4" />
          </Button>
        </div>
        
        {/* Scrollable content area with explicit height */}
        <ScrollArea className="max-h-[60vh] overflow-auto">
          <div className="p-3 space-y-4">
            {/* Active Tasks */}
            {activeTasks.length > 0 && (
              <div className="space-y-2">
                <h4 className="text-sm font-medium flex items-center gap-2">
                  <Loader2 className="h-3 w-3 animate-spin text-blue-500" />
                  진행 중 ({activeTasks.length})
                </h4>
                <div className="space-y-2">
                  {activeTasks.map(task => (
                    <TaskItem
                      key={task.id}
                      task={task}
                      onNavigate={handleNavigate}
                      onRemove={removeTask}
                      onCancel={handleCancelTask}
                    />
                  ))}
                </div>
              </div>
            )}
            
            {/* Completed Tasks */}
            {completedTasks.length > 0 && (
              <div className="space-y-2">
                <h4 className="text-sm font-medium flex items-center gap-2">
                  <CheckCircle2 className="h-3 w-3 text-green-500" />
                  완료됨 ({completedTasks.length})
                </h4>
                <div className="space-y-2">
                  {completedTasks.map(task => (
                    <TaskItem
                      key={task.id}
                      task={task}
                      onNavigate={handleNavigate}
                      onRemove={removeTask}
                      onCancel={handleCancelTask}
                    />
                  ))}
                </div>
              </div>
            )}
            
            {/* Empty state */}
            {allTasks.length === 0 && (
              <div className="text-center py-8 text-muted-foreground">
                <Clock className="h-8 w-8 mx-auto mb-2 opacity-50" />
                <p className="text-sm">진행 중인 작업이 없습니다</p>
              </div>
            )}
          </div>
        </ScrollArea>
        
        {/* Footer with clear button - fixed */}
        {completedTasks.length > 0 && (
          <div className="p-3 border-t bg-background sticky bottom-0">
            <Button
              variant="outline"
              size="sm"
              className="w-full"
              onClick={clearCompletedTasks}
            >
              <Trash2 className="h-3.5 w-3.5 mr-2" />
              완료된 작업 모두 지우기
            </Button>
          </div>
        )}
      </PopoverContent>
    </Popover>
  );
}

export default BackgroundTaskIndicator;

```

---

## frontend/src/components/CommandPalette.tsx

```tsx
import { useState, useCallback, useMemo } from "react";
import { useNavigate } from "react-router-dom";
import {
  Search,
  Home,
  Bot,
  FolderOpen,
  History,
  Moon,
  Sun,
  FileJson,
  Command,
  Cpu,
  Brain,
  Shield,
  Database,
  Link as LinkIcon,
} from "lucide-react";
import {
  CommandDialog,
  CommandEmpty,
  CommandGroup,
  CommandInput,
  CommandItem,
  CommandList,
  CommandSeparator,
  CommandShortcut,
} from "@/components/ui/command";
import { useKeyboardShortcuts } from "@/hooks/useKeyboardShortcuts";
import { useTheme } from "@/contexts/ThemeContext";

interface CommandItem {
  id: string;
  label: string;
  icon: typeof Search;
  shortcut?: string;
  action: () => void;
  keywords?: string[];
  category: "navigation" | "search" | "settings" | "recent";
}

interface CommandPaletteProps {
  /** 외부에서 제어할 열림 상태 */
  open?: boolean;
  /** 열림 상태 변경 콜백 */
  onOpenChange?: (open: boolean) => void;
  /** 최근 검색어 목록 */
  recentSearches?: string[];
  /** 검색 실행 콜백 */
  onSearch?: (query: string) => void;
}

export function CommandPalette({
  open: externalOpen,
  onOpenChange,
  recentSearches = [],
  onSearch,
}: CommandPaletteProps) {
  const [internalOpen, setInternalOpen] = useState(false);
  const [search, setSearch] = useState("");
  const navigate = useNavigate();
  const { theme, setTheme } = useTheme();

  const isOpen = externalOpen ?? internalOpen;
  const setIsOpen = onOpenChange ?? setInternalOpen;

  // 단축키 등록
  useKeyboardShortcuts([
    {
      key: "ctrl+k",
      handler: () => setIsOpen(true),
      description: "검색 열기",
    },
    {
      key: "meta+k", // macOS Command+K
      handler: () => setIsOpen(true),
      description: "검색 열기",
    },
    {
      key: "escape",
      handler: () => setIsOpen(false),
      description: "닫기",
      enableInInput: true,
    },
  ]);

  // 명령어 목록 (Consolidated navigation)
  const commands = useMemo<CommandItem[]>(() => [
    // 네비게이션 - 통합 검색
    {
      id: "search",
      label: "검색 (통합/Deep/팩트체크/URL분석)",
      icon: Search,
      shortcut: "⌘H",
      action: () => { navigate("/"); setIsOpen(false); },
      keywords: ["home", "main", "홈", "메인", "검색", "search"],
      category: "navigation",
    },
    {
      id: "search-unified",
      label: "통합 검색 모드",
      icon: Search,
      action: () => { navigate("/?mode=unified"); setIsOpen(false); },
      keywords: ["unified", "통합", "검색"],
      category: "search",
    },
    {
      id: "search-deep",
      label: "Deep Search 모드",
      icon: Brain,
      shortcut: "⌘D",
      action: () => { navigate("/?mode=deep"); setIsOpen(false); },
      keywords: ["deep", "search", "ai", "분석", "심층"],
      category: "search",
    },
    {
      id: "search-factcheck",
      label: "팩트체크 모드",
      icon: Shield,
      shortcut: "⌘F",
      action: () => { navigate("/?mode=factcheck"); setIsOpen(false); },
      keywords: ["fact", "check", "verify", "팩트", "검증"],
      category: "search",
    },
    {
      id: "search-urlanalysis",
      label: "URL 분석 모드",
      icon: LinkIcon,
      shortcut: "⌘U",
      action: () => { navigate("/?mode=urlanalysis"); setIsOpen(false); },
      keywords: ["url", "analysis", "extract", "claim", "분석", "추출", "주장"],
      category: "search",
    },
    {
      id: "ml-addons",
      label: "ML Add-ons",
      icon: Cpu,
      action: () => { navigate("/ml-addons"); setIsOpen(false); },
      keywords: ["ml", "machine", "learning", "addon", "sentiment", "bias"],
      category: "navigation",
    },
    {
      id: "browser-agent",
      label: "브라우저 에이전트",
      icon: Bot,
      shortcut: "⌘B",
      action: () => { navigate("/ai-agent"); setIsOpen(false); },
      keywords: ["browser", "agent", "automation", "에이전트", "자동화"],
      category: "navigation",
    },
    {
      id: "url-collections",
      label: "URL 원천 관리",
      icon: Database,
      action: () => { navigate("/url-collections"); setIsOpen(false); },
      keywords: ["url", "source", "원천", "소스", "관리"],
      category: "navigation",
    },
    {
      id: "projects",
      label: "프로젝트",
      icon: FolderOpen,
      action: () => { navigate("/projects"); setIsOpen(false); },
      keywords: ["project", "프로젝트", "폴더", "collection"],
      category: "navigation",
    },
    {
      id: "search-history",
      label: "검색 기록",
      icon: History,
      action: () => { navigate("/history"); setIsOpen(false); },
      keywords: ["history", "기록", "이전"],
      category: "navigation",
    },
    {
      id: "admin-sources",
      label: "데이터 소스 관리 (Admin)",
      icon: FileJson,
      action: () => { navigate("/admin/sources"); setIsOpen(false); },
      keywords: ["admin", "source", "관리", "소스", "rss"],
      category: "navigation",
    },
    // 설정
    {
      id: "toggle-theme",
      label: theme === "dark" ? "라이트 모드로 전환" : "다크 모드로 전환",
      icon: theme === "dark" ? Sun : Moon,
      shortcut: "⌘⇧T",
      action: () => {
        setTheme(theme === "dark" ? "light" : "dark");
        setIsOpen(false);
      },
      keywords: ["theme", "dark", "light", "테마", "다크", "라이트"],
      category: "settings",
    },
  ], [navigate, setIsOpen, theme, setTheme]);

  // 최근 검색어 명령어 추가
  const recentCommands = useMemo<CommandItem[]>(() => {
    return recentSearches.slice(0, 5).map((query, index) => ({
      id: `recent-${index}`,
      label: query,
      icon: Search,
      action: () => {
        if (onSearch) {
          onSearch(query);
        } else {
          navigate(`/?q=${encodeURIComponent(query)}`);
        }
        setIsOpen(false);
      },
      keywords: [query.toLowerCase()],
      category: "recent" as const,
    }));
  }, [recentSearches, navigate, setIsOpen, onSearch]);

  // 검색 실행
  const handleSearch = useCallback(() => {
    if (search.trim()) {
      if (onSearch) {
        onSearch(search.trim());
      } else {
        navigate(`/?q=${encodeURIComponent(search.trim())}`);
      }
      setIsOpen(false);
      setSearch("");
    }
  }, [search, onSearch, navigate, setIsOpen]);

  // Enter 키로 검색
  const handleKeyDown = useCallback((e: React.KeyboardEvent) => {
    if (e.key === "Enter" && search.trim()) {
      // 선택된 항목이 없을 때만 검색 실행
      const selectedItem = document.querySelector('[data-selected="true"]');
      if (!selectedItem) {
        handleSearch();
      }
    }
  }, [search, handleSearch]);

  // 네비게이션 단축키
  useKeyboardShortcuts([
    {
      key: "ctrl+h",
      handler: () => { navigate("/"); },
      description: "검색으로",
    },
    {
      key: "ctrl+d",
      handler: () => { navigate("/?mode=deep"); },
      description: "Deep Search 모드",
    },
    {
      key: "ctrl+shift+t",
      handler: () => { setTheme(theme === "dark" ? "light" : "dark"); },
      description: "테마 전환",
    },
  ], { enabled: !isOpen });

  return (
    <CommandDialog open={isOpen} onOpenChange={setIsOpen}>
      <CommandInput
        placeholder="검색어를 입력하거나 명령을 선택하세요..."
        value={search}
        onValueChange={setSearch}
        onKeyDown={handleKeyDown}
      />
      <CommandList>
        <CommandEmpty>
          {search.trim() ? (
            <div className="p-4 text-center">
              <p className="text-sm text-muted-foreground mb-2">
                "{search}"에 대한 결과가 없습니다
              </p>
              <button
                onClick={handleSearch}
                className="text-sm text-primary hover:underline"
              >
                이 검색어로 통합 검색하기
              </button>
            </div>
          ) : (
            <p className="text-sm text-muted-foreground">명령어가 없습니다</p>
          )}
        </CommandEmpty>

        {/* 최근 검색 */}
        {recentCommands.length > 0 && (
          <CommandGroup heading="최근 검색">
            {recentCommands.map((cmd) => (
              <CommandItem
                key={cmd.id}
                onSelect={cmd.action}
                className="gap-2"
              >
                <cmd.icon className="h-4 w-4" />
                <span>{cmd.label}</span>
              </CommandItem>
            ))}
          </CommandGroup>
        )}

        {recentCommands.length > 0 && <CommandSeparator />}

        {/* 검색 모드 */}
        <CommandGroup heading="검색 모드">
          {commands
            .filter((cmd) => cmd.category === "search")
            .map((cmd) => (
              <CommandItem
                key={cmd.id}
                onSelect={cmd.action}
                className="gap-2"
              >
                <cmd.icon className="h-4 w-4" />
                <span>{cmd.label}</span>
                {cmd.shortcut && (
                  <CommandShortcut>{cmd.shortcut}</CommandShortcut>
                )}
              </CommandItem>
            ))}
        </CommandGroup>

        <CommandSeparator />

        {/* 페이지 이동 */}
        <CommandGroup heading="페이지 이동">
          {commands
            .filter((cmd) => cmd.category === "navigation")
            .map((cmd) => (
              <CommandItem
                key={cmd.id}
                onSelect={cmd.action}
                className="gap-2"
              >
                <cmd.icon className="h-4 w-4" />
                <span>{cmd.label}</span>
                {cmd.shortcut && (
                  <CommandShortcut>{cmd.shortcut}</CommandShortcut>
                )}
              </CommandItem>
            ))}
        </CommandGroup>

        <CommandSeparator />

        {/* 설정 */}
        <CommandGroup heading="설정">
          {commands
            .filter((cmd) => cmd.category === "settings")
            .map((cmd) => (
              <CommandItem
                key={cmd.id}
                onSelect={cmd.action}
                className="gap-2"
              >
                <cmd.icon className="h-4 w-4" />
                <span>{cmd.label}</span>
                {cmd.shortcut && (
                  <CommandShortcut>{cmd.shortcut}</CommandShortcut>
                )}
              </CommandItem>
            ))}
        </CommandGroup>
      </CommandList>
      
      {/* 단축키 힌트 */}
      <div className="border-t px-3 py-2 flex items-center justify-between text-xs text-muted-foreground">
        <div className="flex items-center gap-4">
          <span className="flex items-center gap-1">
            <kbd className="px-1.5 py-0.5 rounded bg-muted text-[10px]">↑↓</kbd>
            탐색
          </span>
          <span className="flex items-center gap-1">
            <kbd className="px-1.5 py-0.5 rounded bg-muted text-[10px]">↵</kbd>
            선택
          </span>
          <span className="flex items-center gap-1">
            <kbd className="px-1.5 py-0.5 rounded bg-muted text-[10px]">esc</kbd>
            닫기
          </span>
        </div>
        <div className="flex items-center gap-1">
          <Command className="h-3 w-3" />
          <span>+K로 열기</span>
        </div>
      </div>
    </CommandDialog>
  );
}

export default CommandPalette;

```

---

## frontend/src/components/DeriveSearchDialog.tsx

```tsx
import { useState, useCallback, useMemo } from "react";
import { useNavigate } from "react-router-dom";
import {
  Dialog,
  DialogContent,
  DialogDescription,
  DialogHeader,
  DialogTitle,
  DialogFooter,
} from "@/components/ui/dialog";
import { Button } from "@/components/ui/button";
import { Checkbox } from "@/components/ui/checkbox";
import { RadioGroup, RadioGroupItem } from "@/components/ui/radio-group";
import { Label } from "@/components/ui/label";
import { Badge } from "@/components/ui/badge";
import { ScrollArea } from "@/components/ui/scroll-area";
import { Input } from "@/components/ui/input";
import {
  Search,
  Microscope,
  Shield,
  Link as LinkIcon,
  ExternalLink,
  Filter,
  CheckCircle2,
  Globe,
} from "lucide-react";
import type { SearchHistoryRecord, SearchHistoryType } from "@/lib/api";
import { useSearchRecord, type PriorityUrl } from "@/hooks/useSearchRecord";

interface DeriveSearchDialogProps {
  open: boolean;
  onOpenChange: (open: boolean) => void;
  searchRecord: SearchHistoryRecord;
}

type ReuseOption = "query_only" | "query_and_all_urls" | "query_and_selected_urls";
type TargetPage = "unified" | "deep_search" | "fact_check";

const TARGET_PAGE_CONFIG: Record<TargetPage, { label: string; icon: typeof Search; path: string; color: string }> = {
  unified: {
    label: "통합 검색",
    icon: Search,
    path: "/search",
    color: "text-blue-600",
  },
  deep_search: {
    label: "Deep Search",
    icon: Microscope,
    path: "/deep-search",
    color: "text-purple-600",
  },
  fact_check: {
    label: "팩트체크",
    icon: Shield,
    path: "/fact-check",
    color: "text-green-600",
  },
};

// Suggest target page based on source search type
function suggestTargetPage(searchType: SearchHistoryType): TargetPage {
  switch (searchType) {
    case "UNIFIED":
      return "deep_search"; // Suggest deeper analysis
    case "DEEP_SEARCH":
      return "fact_check"; // Suggest verification
    case "FACT_CHECK":
      return "deep_search"; // Suggest more research
    default:
      return "unified";
  }
}

export function DeriveSearchDialog({
  open,
  onOpenChange,
  searchRecord,
}: DeriveSearchDialogProps) {
  const navigate = useNavigate();
  
  // Load URLs from the search record
  const { priorityUrls, loading } = useSearchRecord({
    searchId: searchRecord.id,
    autoLoad: open,
  });

  // State
  const [reuseOption, setReuseOption] = useState<ReuseOption>("query_and_all_urls");
  const [targetPage, setTargetPage] = useState<TargetPage>(() => suggestTargetPage(searchRecord.searchType));
  const [selectedUrlIds, setSelectedUrlIds] = useState<Set<string>>(new Set());
  const [urlFilter, setUrlFilter] = useState("");

  // Filter URLs based on search
  const filteredUrls = useMemo(() => {
    if (!urlFilter.trim()) return priorityUrls;
    const lowerFilter = urlFilter.toLowerCase();
    return priorityUrls.filter(
      (u) =>
        u.url.toLowerCase().includes(lowerFilter) ||
        u.name.toLowerCase().includes(lowerFilter)
    );
  }, [priorityUrls, urlFilter]);

  // Toggle URL selection
  const toggleUrl = useCallback((id: string) => {
    setSelectedUrlIds((prev) => {
      const next = new Set(prev);
      if (next.has(id)) {
        next.delete(id);
      } else {
        next.add(id);
      }
      return next;
    });
  }, []);

  // Select all visible URLs
  const selectAllVisible = useCallback(() => {
    setSelectedUrlIds((prev) => {
      const next = new Set(prev);
      filteredUrls.forEach((u) => next.add(u.id));
      return next;
    });
  }, [filteredUrls]);

  // Clear selection
  const clearSelection = useCallback(() => {
    setSelectedUrlIds(new Set());
  }, []);

  // Get URLs to pass based on reuse option
  const getUrlsToPass = useCallback((): PriorityUrl[] => {
    switch (reuseOption) {
      case "query_only":
        return [];
      case "query_and_all_urls":
        return priorityUrls;
      case "query_and_selected_urls":
        return priorityUrls.filter((u) => selectedUrlIds.has(u.id));
      default:
        return [];
    }
  }, [reuseOption, priorityUrls, selectedUrlIds]);

  // Handle derive action
  const handleDerive = useCallback(() => {
    const config = TARGET_PAGE_CONFIG[targetPage];
    const urlsToPass = getUrlsToPass();

    const navigationState = {
      query: searchRecord.query,
      parentSearchId: searchRecord.id,
      deriveFrom: searchRecord.id,
      depthLevel: (searchRecord.depthLevel || 0) + 1,
      priorityUrls: urlsToPass,
      fromDeriveDialog: true,
    };

    navigate(config.path, { state: navigationState });
    onOpenChange(false);
  }, [targetPage, getUrlsToPass, searchRecord, navigate, onOpenChange]);

  const selectedCount = selectedUrlIds.size;
  const totalCount = priorityUrls.length;

  return (
    <Dialog open={open} onOpenChange={onOpenChange}>
      <DialogContent className="sm:max-w-[600px] max-h-[90vh] flex flex-col">
        <DialogHeader>
          <DialogTitle className="flex items-center gap-2">
            <Globe className="h-5 w-5 text-primary" />
            파생 검색 설정
          </DialogTitle>
          <DialogDescription>
            "{searchRecord.query}" 검색 결과를 기반으로 새로운 검색을 시작합니다.
          </DialogDescription>
        </DialogHeader>

        <div className="flex-1 overflow-hidden space-y-6 py-4">
          {/* Target Page Selection */}
          <div className="space-y-3">
            <Label className="text-sm font-medium">대상 페이지</Label>
            <RadioGroup
              value={targetPage}
              onValueChange={(v) => setTargetPage(v as TargetPage)}
              className="grid grid-cols-3 gap-2"
            >
              {(Object.entries(TARGET_PAGE_CONFIG) as [TargetPage, typeof TARGET_PAGE_CONFIG[TargetPage]][]).map(
                ([key, config]) => {
                  const Icon = config.icon;
                  return (
                    <div key={key}>
                      <RadioGroupItem value={key} id={`target-${key}`} className="peer sr-only" />
                      <Label
                        htmlFor={`target-${key}`}
                        className={`
                          flex flex-col items-center gap-1.5 p-3 rounded-lg border-2 cursor-pointer
                          peer-data-[state=checked]:border-primary peer-data-[state=checked]:bg-primary/5
                          hover:bg-muted/50 transition-colors
                        `}
                      >
                        <Icon className={`h-5 w-5 ${config.color}`} />
                        <span className="text-xs font-medium">{config.label}</span>
                      </Label>
                    </div>
                  );
                }
              )}
            </RadioGroup>
          </div>

          {/* Reuse Option Selection */}
          <div className="space-y-3">
            <Label className="text-sm font-medium">재사용 옵션</Label>
            <RadioGroup
              value={reuseOption}
              onValueChange={(v) => setReuseOption(v as ReuseOption)}
              className="space-y-2"
            >
              <div className="flex items-center space-x-2">
                <RadioGroupItem value="query_only" id="reuse-query" />
                <Label htmlFor="reuse-query" className="text-sm cursor-pointer">
                  검색어만 재사용
                </Label>
              </div>
              <div className="flex items-center space-x-2">
                <RadioGroupItem value="query_and_all_urls" id="reuse-all" />
                <Label htmlFor="reuse-all" className="text-sm cursor-pointer flex items-center gap-2">
                  검색어 + 모든 URL ({totalCount}개)
                </Label>
              </div>
              <div className="flex items-center space-x-2">
                <RadioGroupItem value="query_and_selected_urls" id="reuse-selected" />
                <Label htmlFor="reuse-selected" className="text-sm cursor-pointer flex items-center gap-2">
                  검색어 + 선택한 URL
                  {reuseOption === "query_and_selected_urls" && selectedCount > 0 && (
                    <Badge variant="secondary" className="ml-1">
                      {selectedCount}개 선택
                    </Badge>
                  )}
                </Label>
              </div>
            </RadioGroup>
          </div>

          {/* URL Selection (only when selecting specific URLs) */}
          {reuseOption === "query_and_selected_urls" && (
            <div className="space-y-3">
              <div className="flex items-center justify-between">
                <Label className="text-sm font-medium flex items-center gap-2">
                  <LinkIcon className="h-4 w-4" />
                  URL 선택
                </Label>
                <div className="flex items-center gap-2">
                  <Button variant="ghost" size="sm" onClick={selectAllVisible} className="h-7 text-xs">
                    전체 선택
                  </Button>
                  <Button variant="ghost" size="sm" onClick={clearSelection} className="h-7 text-xs">
                    선택 해제
                  </Button>
                </div>
              </div>

              {/* URL Filter */}
              <div className="relative">
                <Filter className="absolute left-2.5 top-1/2 -translate-y-1/2 h-4 w-4 text-muted-foreground" />
                <Input
                  value={urlFilter}
                  onChange={(e) => setUrlFilter(e.target.value)}
                  placeholder="URL 필터링..."
                  className="pl-8 h-8 text-sm"
                />
              </div>

              {/* URL List */}
              {loading ? (
                <div className="text-center py-4 text-sm text-muted-foreground">
                  URL 목록을 불러오는 중...
                </div>
              ) : filteredUrls.length === 0 ? (
                <div className="text-center py-4 text-sm text-muted-foreground">
                  {urlFilter ? "필터와 일치하는 URL이 없습니다." : "재사용 가능한 URL이 없습니다."}
                </div>
              ) : (
                <ScrollArea className="h-[200px] border rounded-lg">
                  <div className="p-2 space-y-1">
                    {filteredUrls.map((url) => {
                      const isSelected = selectedUrlIds.has(url.id);
                      return (
                        <div
                          key={url.id}
                          className={`
                            flex items-center gap-2 p-2 rounded-md cursor-pointer
                            hover:bg-muted/50 transition-colors
                            ${isSelected ? "bg-primary/5" : ""}
                          `}
                          onClick={() => toggleUrl(url.id)}
                        >
                          <Checkbox
                            checked={isSelected}
                            onCheckedChange={() => toggleUrl(url.id)}
                            className="pointer-events-none"
                          />
                          <div className="flex-1 min-w-0">
                            <p className="text-sm font-medium truncate">{url.name}</p>
                            <p className="text-xs text-muted-foreground truncate">{url.url}</p>
                          </div>
                          {url.reliability && (
                            <Badge
                              variant="outline"
                              className={`text-xs shrink-0 ${
                                url.reliability === "high"
                                  ? "border-green-500 text-green-600"
                                  : url.reliability === "medium"
                                  ? "border-yellow-500 text-yellow-600"
                                  : "border-red-500 text-red-600"
                              }`}
                            >
                              {url.reliability === "high" ? "높음" : url.reliability === "medium" ? "보통" : "낮음"}
                            </Badge>
                          )}
                          <a
                            href={url.url}
                            target="_blank"
                            rel="noopener noreferrer"
                            className="p-1 rounded hover:bg-muted"
                            onClick={(e) => e.stopPropagation()}
                          >
                            <ExternalLink className="h-3.5 w-3.5 text-muted-foreground" />
                          </a>
                        </div>
                      );
                    })}
                  </div>
                </ScrollArea>
              )}
            </div>
          )}

          {/* Summary */}
          <div className="p-3 rounded-lg bg-muted/50 text-sm">
            <div className="flex items-center gap-2 text-muted-foreground">
              <CheckCircle2 className="h-4 w-4 text-green-600" />
              <span>
                <strong>{TARGET_PAGE_CONFIG[targetPage].label}</strong>로{" "}
                {reuseOption === "query_only"
                  ? "검색어만"
                  : reuseOption === "query_and_all_urls"
                  ? `검색어와 ${totalCount}개 URL`
                  : `검색어와 ${selectedCount}개 URL`}{" "}
                전달됩니다.
              </span>
            </div>
          </div>
        </div>

        <DialogFooter>
          <Button variant="outline" onClick={() => onOpenChange(false)}>
            취소
          </Button>
          <Button
            onClick={handleDerive}
            disabled={reuseOption === "query_and_selected_urls" && selectedCount === 0}
          >
            파생 검색 시작
          </Button>
        </DialogFooter>
      </DialogContent>
    </Dialog>
  );
}

export default DeriveSearchDialog;

```

---

## frontend/src/components/EnhancedMarkdownRenderer.tsx

```tsx
/**
 * EnhancedMarkdownRenderer - 고급 마크다운 렌더러
 * 
 * AI 분석 결과를 위한 고급 마크다운 렌더링 컴포넌트
 * - 섹션별 스타일링 (요약, 검증, 데이터 등)
 * - 테이블 고급 스타일링
 * - 코드 하이라이팅
 * - 인터랙티브 요소
 */

import { memo, useMemo } from "react";
import ReactMarkdown from "react-markdown";
import remarkGfm from "remark-gfm";
import { cn } from "@/lib/utils";
import { 
  ExternalLink, 
  CheckCircle2, 
  AlertTriangle, 
  Info, 
  FileText, 
  BarChart3,
  MessageSquare,
  AlertCircle,
  Lightbulb,
  BookOpen,
  Shield,
  TrendingUp,
  List,
  Quote
} from "lucide-react";
import { Badge } from "@/components/ui/badge";

interface EnhancedMarkdownRendererProps {
  content: string;
  className?: string;
  isStreaming?: boolean;
  variant?: 'default' | 'compact' | 'report';
}

// 섹션 헤더 아이콘 매핑
const SECTION_ICONS: Record<string, React.ComponentType<{ className?: string }>> = {
  '요약': FileText,
  '핵심 요약': FileText,
  '검증': CheckCircle2,
  '검증된 사실': CheckCircle2,
  '사실': CheckCircle2,
  '데이터': BarChart3,
  '주요 수치': BarChart3,
  '수치': TrendingUp,
  '관점': MessageSquare,
  '다양한 관점': MessageSquare,
  '주의': AlertTriangle,
  '주의사항': AlertTriangle,
  '한계': AlertCircle,
  '결론': Lightbulb,
  '배경': BookOpen,
  '배경 지식': BookOpen,
  '신뢰도': Shield,
  '목록': List,
  '인용': Quote,
};

// 섹션 스타일 매핑
const SECTION_STYLES: Record<string, { bg: string; border: string; icon: string }> = {
  '요약': { bg: 'bg-blue-50 dark:bg-blue-950/30', border: 'border-l-blue-500', icon: 'text-blue-600' },
  '핵심 요약': { bg: 'bg-blue-50 dark:bg-blue-950/30', border: 'border-l-blue-500', icon: 'text-blue-600' },
  '검증': { bg: 'bg-green-50 dark:bg-green-950/30', border: 'border-l-green-500', icon: 'text-green-600' },
  '검증된 사실': { bg: 'bg-green-50 dark:bg-green-950/30', border: 'border-l-green-500', icon: 'text-green-600' },
  '사실': { bg: 'bg-green-50 dark:bg-green-950/30', border: 'border-l-green-500', icon: 'text-green-600' },
  '데이터': { bg: 'bg-purple-50 dark:bg-purple-950/30', border: 'border-l-purple-500', icon: 'text-purple-600' },
  '주요 수치': { bg: 'bg-purple-50 dark:bg-purple-950/30', border: 'border-l-purple-500', icon: 'text-purple-600' },
  '관점': { bg: 'bg-orange-50 dark:bg-orange-950/30', border: 'border-l-orange-500', icon: 'text-orange-600' },
  '다양한 관점': { bg: 'bg-orange-50 dark:bg-orange-950/30', border: 'border-l-orange-500', icon: 'text-orange-600' },
  '주의': { bg: 'bg-amber-50 dark:bg-amber-950/30', border: 'border-l-amber-500', icon: 'text-amber-600' },
  '주의사항': { bg: 'bg-amber-50 dark:bg-amber-950/30', border: 'border-l-amber-500', icon: 'text-amber-600' },
  '결론': { bg: 'bg-indigo-50 dark:bg-indigo-950/30', border: 'border-l-indigo-500', icon: 'text-indigo-600' },
  '배경': { bg: 'bg-slate-50 dark:bg-slate-950/30', border: 'border-l-slate-500', icon: 'text-slate-600' },
};

// 검증 수준 배지 컴포넌트
const VerificationBadge = ({ level }: { level: string }) => {
  const normalized = level.toLowerCase();
  if (normalized.includes('높음') || normalized.includes('high')) {
    return <Badge className="bg-green-100 text-green-700 dark:bg-green-900 dark:text-green-300 text-xs">높음</Badge>;
  }
  if (normalized.includes('중간') || normalized.includes('medium')) {
    return <Badge className="bg-yellow-100 text-yellow-700 dark:bg-yellow-900 dark:text-yellow-300 text-xs">중간</Badge>;
  }
  if (normalized.includes('낮음') || normalized.includes('low')) {
    return <Badge className="bg-red-100 text-red-700 dark:bg-red-900 dark:text-red-300 text-xs">낮음</Badge>;
  }
  return <Badge variant="outline" className="text-xs">{level}</Badge>;
};

/**
 * 고급 마크다운 렌더러
 */
export const EnhancedMarkdownRenderer = memo(function EnhancedMarkdownRenderer({
  content,
  className,
  isStreaming = false,
  variant = 'default',
}: EnhancedMarkdownRendererProps) {
  
  // 섹션 헤더 텍스트에서 아이콘과 스타일 추출
  const getSectionInfo = (text: string) => {
    // [요약], [검증] 등의 패턴 감지
    const match = text.match(/\[([^\]]+)\]/);
    if (match) {
      const sectionName = match[1];
      return {
        name: sectionName,
        icon: SECTION_ICONS[sectionName],
        style: SECTION_STYLES[sectionName],
      };
    }
    
    // 패턴 없이 키워드로 감지
    for (const [keyword, icon] of Object.entries(SECTION_ICONS)) {
      if (text.includes(keyword)) {
        return {
          name: keyword,
          icon,
          style: SECTION_STYLES[keyword],
        };
      }
    }
    
    return null;
  };

  const variantStyles = useMemo(() => {
    switch (variant) {
      case 'compact':
        return 'text-sm';
      case 'report':
        return 'text-base leading-relaxed';
      default:
        return '';
    }
  }, [variant]);

  return (
    <div
      className={cn(
        // Base prose styles
        "prose prose-sm dark:prose-invert max-w-none",
        // Headings
        "prose-headings:font-semibold prose-headings:text-foreground",
        "prose-h1:text-xl prose-h1:mt-6 prose-h1:mb-3",
        "prose-h2:text-lg prose-h2:mt-5 prose-h2:mb-3",
        "prose-h3:text-base prose-h3:mt-4 prose-h3:mb-2",
        // Paragraphs
        "prose-p:my-2.5 prose-p:leading-relaxed prose-p:text-foreground/90",
        // Lists
        "prose-ul:my-3 prose-ul:pl-5",
        "prose-ol:my-3 prose-ol:pl-5",
        "prose-li:my-1 prose-li:marker:text-primary/70",
        // Strong/Bold
        "prose-strong:font-semibold prose-strong:text-foreground",
        // Links
        "prose-a:text-primary prose-a:no-underline prose-a:font-medium hover:prose-a:underline",
        // Blockquotes
        "prose-blockquote:border-l-4 prose-blockquote:border-primary/40",
        "prose-blockquote:pl-4 prose-blockquote:py-1 prose-blockquote:italic",
        "prose-blockquote:text-muted-foreground prose-blockquote:bg-muted/30 prose-blockquote:rounded-r-lg",
        // Code
        "prose-code:bg-muted prose-code:px-1.5 prose-code:py-0.5 prose-code:rounded-md",
        "prose-code:font-mono prose-code:text-sm prose-code:before:content-none prose-code:after:content-none",
        "prose-pre:bg-slate-900 dark:prose-pre:bg-slate-950 prose-pre:rounded-xl prose-pre:p-4 prose-pre:shadow-lg",
        // Horizontal rule
        "prose-hr:border-border prose-hr:my-6",
        variantStyles,
        className
      )}
    >
      <ReactMarkdown
        remarkPlugins={[remarkGfm]}
        components={{
          // 외부 링크 스타일링
          a: ({ href, children, ...props }) => {
            const isExternal = href?.startsWith("http");
            return (
              <a
                href={href}
                target={isExternal ? "_blank" : undefined}
                rel={isExternal ? "noopener noreferrer" : undefined}
                className="inline-flex items-center gap-1 text-primary hover:text-primary/80 transition-colors"
                {...props}
              >
                {children}
                {isExternal && <ExternalLink className="h-3 w-3 inline-block opacity-70" />}
              </a>
            );
          },
          
          // H2 - 주요 섹션 헤더 (색상 + 아이콘)
          h2: ({ children, ...props }) => {
            const text = String(children);
            const sectionInfo = getSectionInfo(text);
            const Icon = sectionInfo?.icon;
            const style = sectionInfo?.style;
            
            // 표시할 텍스트 ([] 패턴 제거)
            const displayText = text.replace(/\[([^\]]+)\]\s*/, '');
            
            return (
              <h2 
                className={cn(
                  "flex items-center gap-2 py-2 px-3 -mx-3 rounded-lg mt-6 mb-4",
                  style?.bg || "bg-muted/50",
                  "border-l-4",
                  style?.border || "border-l-primary"
                )} 
                {...props}
              >
                {Icon && <Icon className={cn("h-5 w-5", style?.icon || "text-primary")} />}
                <span className="font-semibold">{displayText}</span>
              </h2>
            );
          },
          
          // H3 - 서브 섹션 헤더
          h3: ({ children, ...props }) => {
            const text = String(children);
            const sectionInfo = getSectionInfo(text);
            const Icon = sectionInfo?.icon;
            const style = sectionInfo?.style;
            
            const displayText = text.replace(/\[([^\]]+)\]\s*/, '');
            
            return (
              <h3 
                className={cn(
                  "flex items-center gap-2 py-1.5 mt-4 mb-2",
                  "border-b border-border/50 pb-1"
                )} 
                {...props}
              >
                {Icon && <Icon className={cn("h-4 w-4", style?.icon || "text-muted-foreground")} />}
                <span className="font-medium">{displayText}</span>
              </h3>
            );
          },
          
          // 테이블 고급 스타일링
          table: ({ children, ...props }) => (
            <div className="my-4 overflow-x-auto rounded-lg border border-border shadow-sm">
              <table className="w-full border-collapse" {...props}>
                {children}
              </table>
            </div>
          ),
          
          thead: ({ children, ...props }) => (
            <thead className="bg-muted/70 dark:bg-muted/50" {...props}>
              {children}
            </thead>
          ),
          
          th: ({ children, ...props }) => (
            <th 
              className="px-4 py-3 text-left text-sm font-semibold text-foreground border-b border-border" 
              {...props}
            >
              {children}
            </th>
          ),
          
          td: ({ children, ...props }) => {
            const text = String(children);
            
            // 검증 수준 셀 감지 및 배지로 변환
            if (text.match(/^(높음|중간|낮음|high|medium|low)$/i)) {
              return (
                <td className="px-4 py-3 border-b border-border/50" {...props}>
                  <VerificationBadge level={text} />
                </td>
              );
            }
            
            return (
              <td 
                className="px-4 py-3 text-sm border-b border-border/50 text-foreground/90" 
                {...props}
              >
                {children}
              </td>
            );
          },
          
          tr: ({ children, ...props }) => (
            <tr 
              className="hover:bg-muted/30 transition-colors" 
              {...props}
            >
              {children}
            </tr>
          ),
          
          // 리스트 아이템 스타일링
          li: ({ children, ...props }) => (
            <li 
              className="my-1.5 pl-1 marker:text-primary/60" 
              {...props}
            >
              {children}
            </li>
          ),
          
          // 인용구 스타일링
          blockquote: ({ children, ...props }) => (
            <blockquote 
              className="my-4 border-l-4 border-primary/40 pl-4 py-2 bg-muted/20 rounded-r-lg italic text-muted-foreground"
              {...props}
            >
              {children}
            </blockquote>
          ),
          
          // 강조 텍스트
          strong: ({ children, ...props }) => (
            <strong className="font-semibold text-foreground" {...props}>
              {children}
            </strong>
          ),
          
          // 구분선
          hr: ({ ...props }) => (
            <hr className="my-6 border-t-2 border-dashed border-border/50" {...props} />
          ),
          
          // 코드 블록
          code: ({ className: codeClassName, children, ...props }) => {
            const isInline = !codeClassName;
            
            if (isInline) {
              return (
                <code 
                  className="bg-muted px-1.5 py-0.5 rounded-md text-sm font-mono text-primary"
                  {...props}
                >
                  {children}
                </code>
              );
            }
            
            return (
              <code className={cn(codeClassName, "block")} {...props}>
                {children}
              </code>
            );
          },
          
          // 이미지 스타일링
          img: ({ src, alt, ...props }) => (
            <figure className="my-4">
              <img 
                src={src} 
                alt={alt} 
                className="rounded-lg shadow-md max-w-full h-auto"
                {...props}
              />
              {alt && (
                <figcaption className="text-center text-sm text-muted-foreground mt-2">
                  {alt}
                </figcaption>
              )}
            </figure>
          ),
        }}
      >
        {content}
      </ReactMarkdown>
      
      {/* 스트리밍 커서 */}
      {isStreaming && (
        <span className="inline-block w-2 h-5 bg-primary animate-pulse ml-0.5 align-text-bottom rounded-sm" />
      )}
    </div>
  );
});

export default EnhancedMarkdownRenderer;

```

---

## frontend/src/components/ErrorState.tsx

```tsx
import * as React from "react";
import { AlertCircle, RefreshCw, XCircle, WifiOff, ServerCrash, FileWarning } from "lucide-react";
import { cn } from "@/lib/utils";
import { Button } from "@/components/ui/button";
import { Alert, AlertDescription, AlertTitle } from "@/components/ui/alert";

/**
 * 통합 에러 상태 컴포넌트
 * 
 * 다양한 에러 유형 지원:
 * - generic: 일반 에러
 * - network: 네트워크 에러
 * - server: 서버 에러
 * - notFound: 리소스 없음
 * - permission: 권한 에러
 */

export type ErrorType = "generic" | "network" | "server" | "notFound" | "permission";
export type ErrorVariant = "inline" | "card" | "fullPage";

interface ErrorStateProps {
  /** 에러 유형 */
  type?: ErrorType;
  /** 표시 스타일 */
  variant?: ErrorVariant;
  /** 에러 제목 */
  title?: string;
  /** 에러 상세 메시지 */
  message?: string;
  /** 재시도 콜백 */
  onRetry?: () => void;
  /** 재시도 버튼 텍스트 */
  retryText?: string;
  /** 재시도 중 상태 */
  isRetrying?: boolean;
  /** 취소/닫기 콜백 */
  onDismiss?: () => void;
  /** 추가 CSS 클래스 */
  className?: string;
  /** 자식 요소 (추가 액션 등) */
  children?: React.ReactNode;
}

const errorConfig: Record<ErrorType, { icon: typeof AlertCircle; defaultTitle: string; defaultMessage: string }> = {
  generic: {
    icon: AlertCircle,
    defaultTitle: "오류가 발생했습니다",
    defaultMessage: "요청을 처리하는 중 문제가 발생했습니다. 잠시 후 다시 시도해주세요.",
  },
  network: {
    icon: WifiOff,
    defaultTitle: "네트워크 연결 오류",
    defaultMessage: "인터넷 연결을 확인하고 다시 시도해주세요.",
  },
  server: {
    icon: ServerCrash,
    defaultTitle: "서버 오류",
    defaultMessage: "서버에서 오류가 발생했습니다. 잠시 후 다시 시도해주세요.",
  },
  notFound: {
    icon: FileWarning,
    defaultTitle: "찾을 수 없음",
    defaultMessage: "요청하신 리소스를 찾을 수 없습니다.",
  },
  permission: {
    icon: XCircle,
    defaultTitle: "접근 권한 없음",
    defaultMessage: "이 작업을 수행할 권한이 없습니다.",
  },
};

/** 인라인 에러 (Alert 형태) */
const InlineError = ({
  type = "generic",
  title,
  message,
  onRetry,
  retryText = "다시 시도",
  isRetrying,
  onDismiss,
  className,
  children,
}: ErrorStateProps) => {
  const config = errorConfig[type];
  const Icon = config.icon;

  return (
    <Alert variant="destructive" className={cn("relative", className)}>
      <Icon className="h-4 w-4" />
      <AlertTitle>{title || config.defaultTitle}</AlertTitle>
      <AlertDescription className="mt-2">
        <p>{message || config.defaultMessage}</p>
        {(onRetry || onDismiss || children) && (
          <div className="flex items-center gap-2 mt-3">
            {onRetry && (
              <Button
                variant="outline"
                size="sm"
                onClick={onRetry}
                disabled={isRetrying}
                className="gap-1"
              >
                <RefreshCw className={cn("h-3 w-3", isRetrying && "animate-spin")} />
                {retryText}
              </Button>
            )}
            {onDismiss && (
              <Button variant="ghost" size="sm" onClick={onDismiss}>
                닫기
              </Button>
            )}
            {children}
          </div>
        )}
      </AlertDescription>
    </Alert>
  );
};

/** 카드 형태 에러 */
const CardError = ({
  type = "generic",
  title,
  message,
  onRetry,
  retryText = "다시 시도",
  isRetrying,
  onDismiss,
  className,
  children,
}: ErrorStateProps) => {
  const config = errorConfig[type];
  const Icon = config.icon;

  return (
    <div
      className={cn(
        "flex flex-col items-center justify-center p-8 text-center rounded-lg border border-destructive/20 bg-destructive/5",
        className
      )}
    >
      <div className="p-3 rounded-full bg-destructive/10 mb-4">
        <Icon className="h-8 w-8 text-destructive" />
      </div>
      <h3 className="text-lg font-semibold text-foreground mb-2">{title || config.defaultTitle}</h3>
      <p className="text-sm text-muted-foreground max-w-md mb-4">{message || config.defaultMessage}</p>
      {(onRetry || onDismiss || children) && (
        <div className="flex items-center gap-3">
          {onRetry && (
            <Button onClick={onRetry} disabled={isRetrying} className="gap-2">
              <RefreshCw className={cn("h-4 w-4", isRetrying && "animate-spin")} />
              {retryText}
            </Button>
          )}
          {onDismiss && (
            <Button variant="outline" onClick={onDismiss}>
              닫기
            </Button>
          )}
          {children}
        </div>
      )}
    </div>
  );
};

/** 전체 페이지 에러 */
const FullPageError = ({
  type = "generic",
  title,
  message,
  onRetry,
  retryText = "다시 시도",
  isRetrying,
  className,
  children,
}: ErrorStateProps) => {
  const config = errorConfig[type];
  const Icon = config.icon;

  return (
    <div
      className={cn(
        "min-h-[400px] flex flex-col items-center justify-center p-8 text-center",
        className
      )}
    >
      <div className="p-4 rounded-full bg-destructive/10 mb-6">
        <Icon className="h-12 w-12 text-destructive" />
      </div>
      <h2 className="text-2xl font-bold text-foreground mb-3">{title || config.defaultTitle}</h2>
      <p className="text-muted-foreground max-w-lg mb-6">{message || config.defaultMessage}</p>
      {(onRetry || children) && (
        <div className="flex items-center gap-3">
          {onRetry && (
            <Button size="lg" onClick={onRetry} disabled={isRetrying} className="gap-2">
              <RefreshCw className={cn("h-5 w-5", isRetrying && "animate-spin")} />
              {retryText}
            </Button>
          )}
          {children}
        </div>
      )}
    </div>
  );
};

/** 메인 ErrorState 컴포넌트 */
export const ErrorState = ({ variant = "card", ...props }: ErrorStateProps) => {
  switch (variant) {
    case "inline":
      return <InlineError {...props} />;
    case "fullPage":
      return <FullPageError {...props} />;
    case "card":
    default:
      return <CardError {...props} />;
  }
};

/** 에러 바운더리 폴백 컴포넌트 */
export const ErrorBoundaryFallback = ({
  error,
  resetErrorBoundary,
}: {
  error: Error;
  resetErrorBoundary?: () => void;
}) => (
  <ErrorState
    type="generic"
    variant="fullPage"
    title="예기치 않은 오류"
    message={error.message || "애플리케이션에서 오류가 발생했습니다."}
    onRetry={resetErrorBoundary}
    retryText="새로고침"
  />
);

/** 빈 상태 컴포넌트 */
interface EmptyStateProps {
  icon?: React.ReactNode;
  title: string;
  description?: string;
  action?: React.ReactNode;
  className?: string;
}

export const EmptyState = ({ icon, title, description, action, className }: EmptyStateProps) => (
  <div className={cn("flex flex-col items-center justify-center p-8 text-center", className)}>
    {icon && <div className="mb-4 text-muted-foreground">{icon}</div>}
    <h3 className="text-lg font-semibold text-foreground mb-2">{title}</h3>
    {description && <p className="text-sm text-muted-foreground max-w-md mb-4">{description}</p>}
    {action}
  </div>
);

export default ErrorState;

```

---

## frontend/src/components/ExportButton.tsx

```tsx
import { useState } from "react";
import {
  Download,
  FileJson,
  FileText,
  FileSpreadsheet,
  Copy,
  Check,
  ChevronDown,
} from "lucide-react";
import { Button } from "@/components/ui/button";
import {
  DropdownMenu,
  DropdownMenuContent,
  DropdownMenuItem,
  DropdownMenuSeparator,
  DropdownMenuTrigger,
} from "@/components/ui/dropdown-menu";
import { useExport, type ExportFormat, type ExportableSearchResult, type ExportOptions } from "@/hooks/useExport";

interface ExportButtonProps {
  /** 내보낼 데이터 */
  data: ExportableSearchResult[];
  /** 내보내기 옵션 */
  options?: ExportOptions;
  /** 버튼 비활성화 */
  disabled?: boolean;
  /** 버튼 크기 */
  size?: "default" | "sm" | "lg" | "icon";
  /** 버튼 변형 */
  variant?: "default" | "outline" | "ghost" | "secondary";
  /** 아이콘만 표시 */
  iconOnly?: boolean;
  /** 추가 CSS 클래스 */
  className?: string;
}

/**
 * 검색 결과 내보내기 버튼 컴포넌트
 * 
 * @example
 * ``\`tsx
 * <ExportButton
 *   data={searchResults}
 *   options={{ filename: "search-results", title: "검색 결과" }}
 * />
 * ``\`
 */
export function ExportButton({
  data,
  options = {},
  disabled = false,
  size = "default",
  variant = "outline",
  iconOnly = false,
  className = "",
}: ExportButtonProps) {
  const { exportData, copyToClipboard } = useExport();
  const [copied, setCopied] = useState(false);

  const handleExport = (format: ExportFormat) => {
    exportData(data, format, options);
  };

  const handleCopy = async () => {
    const success = await copyToClipboard(data, "json");
    if (success) {
      setCopied(true);
      setTimeout(() => setCopied(false), 2000);
    }
  };

  const isDisabled = disabled || !data || data.length === 0;

  return (
    <DropdownMenu>
      <DropdownMenuTrigger asChild>
        <Button
          variant={variant}
          size={size}
          disabled={isDisabled}
          className={className}
          aria-label="내보내기"
        >
          <Download className="h-4 w-4" />
          {!iconOnly && (
            <>
              <span className="ml-2">내보내기</span>
              <ChevronDown className="ml-1 h-3 w-3" />
            </>
          )}
        </Button>
      </DropdownMenuTrigger>
      <DropdownMenuContent align="end" className="w-48">
        <DropdownMenuItem onClick={() => handleExport("json")} className="gap-2">
          <FileJson className="h-4 w-4 text-yellow-600" />
          <span>JSON으로 내보내기</span>
        </DropdownMenuItem>
        <DropdownMenuItem onClick={() => handleExport("csv")} className="gap-2">
          <FileSpreadsheet className="h-4 w-4 text-green-600" />
          <span>CSV로 내보내기</span>
        </DropdownMenuItem>
        <DropdownMenuItem onClick={() => handleExport("markdown")} className="gap-2">
          <FileText className="h-4 w-4 text-blue-600" />
          <span>Markdown으로 내보내기</span>
        </DropdownMenuItem>
        <DropdownMenuItem onClick={() => handleExport("txt")} className="gap-2">
          <FileText className="h-4 w-4 text-gray-600" />
          <span>텍스트로 내보내기</span>
        </DropdownMenuItem>
        <DropdownMenuSeparator />
        <DropdownMenuItem onClick={handleCopy} className="gap-2">
          {copied ? (
            <>
              <Check className="h-4 w-4 text-green-600" />
              <span className="text-green-600">복사됨!</span>
            </>
          ) : (
            <>
              <Copy className="h-4 w-4" />
              <span>클립보드에 복사</span>
            </>
          )}
        </DropdownMenuItem>
      </DropdownMenuContent>
    </DropdownMenu>
  );
}

export default ExportButton;

```

---

## frontend/src/components/FactCheckAnalyticsPanel.tsx

```tsx
import { useState } from "react";
import {
  BarChart3,
  ChevronDown,
  ChevronUp,
  Eye,
  FileText,
  Shield,
  AlertTriangle,
  CheckCircle2,
  XCircle,
  HelpCircle,
  Scale,
  TrendingUp,
  Info,
  Percent,
  Hash,
  Clock,
  Layers,
  Target,
  Lightbulb,
} from "lucide-react";
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from "@/components/ui/card";
import { Badge } from "@/components/ui/badge";
import { Progress } from "@/components/ui/progress";
import { Button } from "@/components/ui/button";
import { Collapsible, CollapsibleContent, CollapsibleTrigger } from "@/components/ui/collapsible";
import { Tabs, TabsContent, TabsList, TabsTrigger } from "@/components/ui/tabs";
import {
  Tooltip,
  TooltipContent,
  TooltipProvider,
  TooltipTrigger,
} from "@/components/ui/tooltip";

// Types for analytics data
export interface SourceCredibilityAnalysis {
  sourceName: string;
  isTrusted: boolean;
  trustScore: number; // 0-1
  trustLevel: "trusted" | "unknown" | "untrusted";
  reason: string;
  matchedTrustedSource?: string;
}

export interface ClickbaitAnalysis {
  isClickbait: boolean;
  score: number; // 0-1
  detectedPatterns: Array<{
    pattern: string;
    matchedText: string;
    severity: "low" | "medium" | "high";
  }>;
  totalPatternsChecked: number;
}

export interface MisinformationAnalysis {
  riskScore: number; // 0-1
  riskLevel: "low" | "medium" | "high";
  detectedPatterns: Array<{
    type: "misinformation" | "unverifiable";
    pattern: string;
    matchedText: string;
    severity: "low" | "medium" | "high";
  }>;
  unverifiableClaimCount: number;
}

export interface ClaimAnalysis {
  claimId: string;
  claimText: string;
  verdict: "verified" | "false" | "unverified" | "misleading" | "partially_true";
  confidence: number; // 0-1
  claimIndicator: string;
  analysisMethod: string;
  supportingFactors: string[];
  contradictingFactors: string[];
}

export interface ScoreBreakdown {
  sourceWeight: number; // 30%
  clickbaitWeight: number; // 20%
  misinfoWeight: number; // 20%
  verificationWeight: number; // 30%
  
  sourceContribution: number;
  clickbaitContribution: number;
  misinfoContribution: number;
  verificationContribution: number;
  
  totalScore: number;
  grade: "A" | "B" | "C" | "D" | "F";
}

export interface FactCheckAnalytics {
  // Source analysis
  sourceAnalysis: SourceCredibilityAnalysis;
  
  // Clickbait detection
  clickbaitAnalysis: ClickbaitAnalysis;
  
  // Misinformation risk
  misinfoAnalysis: MisinformationAnalysis;
  
  // Claims breakdown
  claimAnalyses: ClaimAnalysis[];
  
  // Final score breakdown
  scoreBreakdown: ScoreBreakdown;
  
  // Metadata
  analysisVersion: string;
  processingTimeMs: number;
  analyzedAt: string;
  
  // ML-specific metadata (optional, only when backend ML is used)
  mlModelsUsed?: string[];
  externalApisUsed?: string[];
}

interface FactCheckAnalyticsPanelProps {
  analytics: FactCheckAnalytics | null;
  isLoading?: boolean;
}

// Helper components
const ScoreBar = ({ 
  label, 
  score, 
  weight, 
  contribution,
  colorClass = "bg-blue-500"
}: { 
  label: string; 
  score: number; 
  weight: number;
  contribution: number;
  colorClass?: string;
}) => (
  <div className="space-y-1">
    <div className="flex items-center justify-between text-sm">
      <span className="text-muted-foreground">{label}</span>
      <div className="flex items-center gap-2">
        <Badge variant="outline" className="text-xs">
          가중치 {weight}%
        </Badge>
        <span className="font-medium">{Math.round(score * 100)}%</span>
      </div>
    </div>
    <Progress value={score * 100} className={`h-2 ${colorClass}`} />
    <div className="text-xs text-muted-foreground text-right">
      점수 기여: +{contribution.toFixed(1)}점
    </div>
  </div>
);

const PatternBadge = ({ 
  pattern, 
  severity 
}: { 
  pattern: string; 
  severity: "low" | "medium" | "high";
}) => {
  const severityColors = {
    low: "bg-yellow-100 text-yellow-800 border-yellow-200",
    medium: "bg-orange-100 text-orange-800 border-orange-200",
    high: "bg-red-100 text-red-800 border-red-200",
  };
  
  return (
    <Badge className={`${severityColors[severity]} border`}>
      {pattern}
    </Badge>
  );
};

const VerdictIcon = ({ verdict }: { verdict: ClaimAnalysis["verdict"] }) => {
  const icons = {
    verified: <CheckCircle2 className="h-4 w-4 text-green-500" />,
    false: <XCircle className="h-4 w-4 text-red-500" />,
    unverified: <HelpCircle className="h-4 w-4 text-gray-500" />,
    misleading: <AlertTriangle className="h-4 w-4 text-orange-500" />,
    partially_true: <Scale className="h-4 w-4 text-yellow-500" />,
  };
  return icons[verdict];
};

const GradeDisplay = ({ grade }: { grade: ScoreBreakdown["grade"] }) => {
  const gradeConfig = {
    A: { color: "bg-green-500", text: "text-green-600", label: "매우 신뢰" },
    B: { color: "bg-blue-500", text: "text-blue-600", label: "신뢰" },
    C: { color: "bg-yellow-500", text: "text-yellow-600", label: "주의 필요" },
    D: { color: "bg-orange-500", text: "text-orange-600", label: "신뢰 어려움" },
    F: { color: "bg-red-500", text: "text-red-600", label: "신뢰 불가" },
  };
  
  const config = gradeConfig[grade];
  
  return (
    <div className="flex items-center gap-2">
      <div className={`w-10 h-10 rounded-lg ${config.color} flex items-center justify-center`}>
        <span className="text-white font-bold text-lg">{grade}</span>
      </div>
      <span className={`text-sm font-medium ${config.text}`}>{config.label}</span>
    </div>
  );
};

export const FactCheckAnalyticsPanel = ({ 
  analytics, 
  isLoading = false 
}: FactCheckAnalyticsPanelProps) => {
  const [isExpanded, setIsExpanded] = useState(false);
  const [activeTab, setActiveTab] = useState("overview");
  
  if (isLoading) {
    return (
      <Card>
        <CardHeader>
          <CardTitle className="flex items-center gap-2">
            <BarChart3 className="h-5 w-5 animate-pulse" />
            분석 통계 로딩 중...
          </CardTitle>
        </CardHeader>
        <CardContent>
          <div className="space-y-4">
            <div className="h-4 bg-muted rounded animate-pulse" />
            <div className="h-4 bg-muted rounded animate-pulse w-3/4" />
            <div className="h-4 bg-muted rounded animate-pulse w-1/2" />
          </div>
        </CardContent>
      </Card>
    );
  }
  
  if (!analytics) {
    return null;
  }
  
  const { 
    sourceAnalysis, 
    clickbaitAnalysis, 
    misinfoAnalysis, 
    claimAnalyses, 
    scoreBreakdown 
  } = analytics;
  
  return (
    <Card className="border-2 border-dashed border-purple-200 dark:border-purple-800">
      <Collapsible open={isExpanded} onOpenChange={setIsExpanded}>
        <CardHeader className="pb-2">
          <div className="flex items-center justify-between">
            <div className="flex items-center gap-3">
              <div className="p-2 rounded-lg bg-purple-100 dark:bg-purple-900/30">
                <BarChart3 className="h-5 w-5 text-purple-600" />
              </div>
              <div>
                <CardTitle className="text-lg">분석 과정 세부 통계</CardTitle>
                <CardDescription>
                  신뢰도 {scoreBreakdown.totalScore}점 산출 과정을 확인합니다
                </CardDescription>
              </div>
            </div>
            <div className="flex items-center gap-2">
              <GradeDisplay grade={scoreBreakdown.grade} />
              <CollapsibleTrigger asChild>
                <Button variant="ghost" size="sm">
                  {isExpanded ? (
                    <ChevronUp className="h-4 w-4" />
                  ) : (
                    <ChevronDown className="h-4 w-4" />
                  )}
                </Button>
              </CollapsibleTrigger>
            </div>
          </div>
        </CardHeader>
        
        <CollapsibleContent>
          <CardContent className="pt-4">
            <Tabs value={activeTab} onValueChange={setActiveTab}>
              <TabsList className="grid w-full grid-cols-5 mb-4">
                <TabsTrigger value="overview" className="text-xs">
                  <TrendingUp className="h-3 w-3 mr-1" />
                  종합
                </TabsTrigger>
                <TabsTrigger value="source" className="text-xs">
                  <Shield className="h-3 w-3 mr-1" />
                  출처
                </TabsTrigger>
                <TabsTrigger value="clickbait" className="text-xs">
                  <AlertTriangle className="h-3 w-3 mr-1" />
                  낚시성
                </TabsTrigger>
                <TabsTrigger value="misinfo" className="text-xs">
                  <XCircle className="h-3 w-3 mr-1" />
                  허위정보
                </TabsTrigger>
                <TabsTrigger value="claims" className="text-xs">
                  <FileText className="h-3 w-3 mr-1" />
                  주장
                </TabsTrigger>
              </TabsList>
              
              {/* Overview Tab */}
              <TabsContent value="overview" className="space-y-6">
                {/* Score Formula Explanation */}
                <div className="p-4 rounded-lg bg-muted/50">
                  <div className="flex items-start gap-2 mb-3">
                    <Lightbulb className="h-5 w-5 text-yellow-500 shrink-0 mt-0.5" />
                    <div>
                      <h4 className="font-medium text-sm">신뢰도 점수 산출 공식</h4>
                      <p className="text-xs text-muted-foreground mt-1">
                        총점 = (출처 신뢰도 × 30%) + (낚시성 미탐지 × 20%) + (허위정보 미탐지 × 20%) + (주장 검증률 × 30%)
                      </p>
                    </div>
                  </div>
                  
                  <div className="grid grid-cols-2 md:grid-cols-4 gap-3 mt-4">
                    <div className="text-center p-2 rounded bg-background">
                      <div className="text-2xl font-bold text-blue-600">
                        {Math.round(sourceAnalysis.trustScore * 100)}%
                      </div>
                      <div className="text-xs text-muted-foreground">출처 신뢰도</div>
                    </div>
                    <div className="text-center p-2 rounded bg-background">
                      <div className="text-2xl font-bold text-green-600">
                        {clickbaitAnalysis.isClickbait ? "탐지" : "정상"}
                      </div>
                      <div className="text-xs text-muted-foreground">낚시성 여부</div>
                    </div>
                    <div className="text-center p-2 rounded bg-background">
                      <div className="text-2xl font-bold text-orange-600">
                        {misinfoAnalysis.riskLevel === "low" ? "낮음" : 
                         misinfoAnalysis.riskLevel === "medium" ? "중간" : "높음"}
                      </div>
                      <div className="text-xs text-muted-foreground">허위정보 위험</div>
                    </div>
                    <div className="text-center p-2 rounded bg-background">
                      <div className="text-2xl font-bold text-purple-600">
                        {claimAnalyses.filter(c => c.verdict === "verified").length}/{claimAnalyses.length}
                      </div>
                      <div className="text-xs text-muted-foreground">검증된 주장</div>
                    </div>
                  </div>
                </div>
                
                {/* Score Breakdown */}
                <div className="space-y-4">
                  <h4 className="font-medium flex items-center gap-2">
                    <Layers className="h-4 w-4" />
                    점수 구성 요소
                  </h4>
                  
                  <ScoreBar 
                    label="출처 신뢰도" 
                    score={sourceAnalysis.trustScore}
                    weight={scoreBreakdown.sourceWeight}
                    contribution={scoreBreakdown.sourceContribution}
                    colorClass="bg-blue-500"
                  />
                  
                  <ScoreBar 
                    label="낚시성 미탐지" 
                    score={clickbaitAnalysis.isClickbait ? 0.7 : 1}
                    weight={scoreBreakdown.clickbaitWeight}
                    contribution={scoreBreakdown.clickbaitContribution}
                    colorClass="bg-green-500"
                  />
                  
                  <ScoreBar 
                    label="허위정보 미탐지" 
                    score={1 - misinfoAnalysis.riskScore}
                    weight={scoreBreakdown.misinfoWeight}
                    contribution={scoreBreakdown.misinfoContribution}
                    colorClass="bg-orange-500"
                  />
                  
                  <ScoreBar 
                    label="주장 검증률" 
                    score={claimAnalyses.length > 0 
                      ? claimAnalyses.filter(c => c.verdict === "verified").length / claimAnalyses.length 
                      : 0}
                    weight={scoreBreakdown.verificationWeight}
                    contribution={scoreBreakdown.verificationContribution}
                    colorClass="bg-purple-500"
                  />
                  
                  <div className="pt-4 border-t">
                    <div className="flex items-center justify-between">
                      <span className="font-medium">최종 신뢰도 점수</span>
                      <div className="flex items-center gap-2">
                        <span className="text-2xl font-bold">{scoreBreakdown.totalScore}</span>
                        <span className="text-muted-foreground">/ 100</span>
                      </div>
                    </div>
                  </div>
                </div>
                
                {/* Metadata */}
                <div className="flex items-center gap-4 text-xs text-muted-foreground pt-4 border-t">
                  <div className="flex items-center gap-1">
                    <Clock className="h-3 w-3" />
                    처리시간: {analytics.processingTimeMs}ms
                  </div>
                  <div className="flex items-center gap-1">
                    <Info className="h-3 w-3" />
                    분석 버전: {analytics.analysisVersion}
                  </div>
                </div>
              </TabsContent>
              
              {/* Source Analysis Tab */}
              <TabsContent value="source" className="space-y-4">
                <div className={`p-4 rounded-lg border-2 ${
                  sourceAnalysis.isTrusted 
                    ? "border-green-200 bg-green-50 dark:bg-green-900/20" 
                    : "border-yellow-200 bg-yellow-50 dark:bg-yellow-900/20"
                }`}>
                  <div className="flex items-start gap-3">
                    <Shield className={`h-6 w-6 ${
                      sourceAnalysis.isTrusted ? "text-green-600" : "text-yellow-600"
                    }`} />
                    <div className="flex-1">
                      <div className="flex items-center gap-2 mb-1">
                        <h4 className="font-medium">{sourceAnalysis.sourceName || "알 수 없는 출처"}</h4>
                        <Badge variant={sourceAnalysis.isTrusted ? "default" : "secondary"}>
                          {sourceAnalysis.trustLevel === "trusted" ? "신뢰 매체" : 
                           sourceAnalysis.trustLevel === "unknown" ? "미확인" : "비신뢰"}
                        </Badge>
                      </div>
                      <p className="text-sm text-muted-foreground">{sourceAnalysis.reason}</p>
                      
                      <div className="mt-3 p-2 rounded bg-background/50">
                        <div className="flex items-center justify-between text-sm">
                          <span>출처 신뢰도 점수</span>
                          <span className="font-bold">{Math.round(sourceAnalysis.trustScore * 100)}%</span>
                        </div>
                        <Progress 
                          value={sourceAnalysis.trustScore * 100} 
                          className="h-2 mt-1" 
                        />
                      </div>
                      
                      {sourceAnalysis.matchedTrustedSource && (
                        <div className="mt-2 text-xs text-muted-foreground">
                          매칭된 신뢰 매체: <span className="font-medium">{sourceAnalysis.matchedTrustedSource}</span>
                        </div>
                      )}
                    </div>
                  </div>
                </div>
                
                <div className="p-4 rounded-lg bg-muted/50">
                  <h4 className="font-medium text-sm mb-2 flex items-center gap-2">
                    <Target className="h-4 w-4" />
                    출처 신뢰도 판별 기준
                  </h4>
                  <ul className="text-xs text-muted-foreground space-y-1">
                    <li>• 신뢰 매체 (90%): 연합뉴스, KBS, MBC, SBS, YTN, JTBC 등 17개</li>
                    <li>• 주요 신문 (80%): 조선일보, 중앙일보, 동아일보, 한겨레, 경향신문</li>
                    <li>• 인터넷 매체 (75%): 뉴시스, 뉴스1, 머니투데이, 이데일리</li>
                    <li>• 미확인 매체 (50%): 목록에 없는 출처</li>
                    <li>• 출처 없음 (30%): 출처 정보 미제공</li>
                  </ul>
                </div>
              </TabsContent>
              
              {/* Clickbait Analysis Tab */}
              <TabsContent value="clickbait" className="space-y-4">
                <div className={`p-4 rounded-lg border-2 ${
                  clickbaitAnalysis.isClickbait 
                    ? "border-red-200 bg-red-50 dark:bg-red-900/20" 
                    : "border-green-200 bg-green-50 dark:bg-green-900/20"
                }`}>
                  <div className="flex items-center gap-3 mb-3">
                    {clickbaitAnalysis.isClickbait ? (
                      <AlertTriangle className="h-6 w-6 text-red-600" />
                    ) : (
                      <CheckCircle2 className="h-6 w-6 text-green-600" />
                    )}
                    <div>
                      <h4 className="font-medium">
                        {clickbaitAnalysis.isClickbait ? "낚시성 콘텐츠 탐지됨" : "낚시성 콘텐츠 없음"}
                      </h4>
                      <p className="text-sm text-muted-foreground">
                        {clickbaitAnalysis.totalPatternsChecked}개 패턴 중 {clickbaitAnalysis.detectedPatterns.length}개 탐지
                      </p>
                    </div>
                  </div>
                  
                  <div className="flex items-center justify-between text-sm mb-2">
                    <span>낚시성 점수</span>
                    <span className="font-bold">{Math.round(clickbaitAnalysis.score * 100)}%</span>
                  </div>
                  <Progress value={clickbaitAnalysis.score * 100} className="h-2" />
                </div>
                
                {clickbaitAnalysis.detectedPatterns.length > 0 && (
                  <div className="space-y-2">
                    <h4 className="font-medium text-sm">탐지된 패턴</h4>
                    <div className="space-y-2">
                      {clickbaitAnalysis.detectedPatterns.map((pattern, idx) => (
                        <div key={idx} className="p-3 rounded-lg bg-muted/50 flex items-start gap-2">
                          <PatternBadge pattern={pattern.pattern} severity={pattern.severity} />
                          <div className="flex-1 min-w-0">
                            <p className="text-sm truncate">"{pattern.matchedText}"</p>
                          </div>
                        </div>
                      ))}
                    </div>
                  </div>
                )}
                
                <div className="p-4 rounded-lg bg-muted/50">
                  <h4 className="font-medium text-sm mb-2 flex items-center gap-2">
                    <Eye className="h-4 w-4" />
                    낚시성 탐지 패턴 목록
                  </h4>
                  <div className="flex flex-wrap gap-1 text-xs">
                    {["충격!", "경악!", "대박!", "헉!", "알고보니", "결국...", "드디어!", 
                      "...", "???", "!!!", "속보:", "단독:", "긴급:"].map(p => (
                      <Badge key={p} variant="outline" className="text-xs">{p}</Badge>
                    ))}
                  </div>
                </div>
              </TabsContent>
              
              {/* Misinformation Analysis Tab */}
              <TabsContent value="misinfo" className="space-y-4">
                <div className={`p-4 rounded-lg border-2 ${
                  misinfoAnalysis.riskLevel === "low" 
                    ? "border-green-200 bg-green-50 dark:bg-green-900/20" 
                    : misinfoAnalysis.riskLevel === "medium"
                    ? "border-yellow-200 bg-yellow-50 dark:bg-yellow-900/20"
                    : "border-red-200 bg-red-50 dark:bg-red-900/20"
                }`}>
                  <div className="flex items-center gap-3 mb-3">
                    {misinfoAnalysis.riskLevel === "low" ? (
                      <CheckCircle2 className="h-6 w-6 text-green-600" />
                    ) : misinfoAnalysis.riskLevel === "medium" ? (
                      <AlertTriangle className="h-6 w-6 text-yellow-600" />
                    ) : (
                      <XCircle className="h-6 w-6 text-red-600" />
                    )}
                    <div>
                      <h4 className="font-medium">
                        허위정보 위험도: {
                          misinfoAnalysis.riskLevel === "low" ? "낮음" :
                          misinfoAnalysis.riskLevel === "medium" ? "중간" : "높음"
                        }
                      </h4>
                      <p className="text-sm text-muted-foreground">
                        검증 불가 주장 {misinfoAnalysis.unverifiableClaimCount}개 발견
                      </p>
                    </div>
                  </div>
                  
                  <div className="flex items-center justify-between text-sm mb-2">
                    <span>위험도 점수</span>
                    <span className="font-bold">{Math.round(misinfoAnalysis.riskScore * 100)}%</span>
                  </div>
                  <Progress value={misinfoAnalysis.riskScore * 100} className="h-2" />
                </div>
                
                {misinfoAnalysis.detectedPatterns.length > 0 && (
                  <div className="space-y-2">
                    <h4 className="font-medium text-sm">탐지된 위험 패턴</h4>
                    <div className="space-y-2">
                      {misinfoAnalysis.detectedPatterns.map((pattern, idx) => (
                        <div key={idx} className="p-3 rounded-lg bg-muted/50">
                          <div className="flex items-center gap-2 mb-1">
                            <Badge variant={pattern.type === "misinformation" ? "destructive" : "secondary"}>
                              {pattern.type === "misinformation" ? "허위정보 패턴" : "검증 불가 표현"}
                            </Badge>
                            <PatternBadge pattern={pattern.pattern} severity={pattern.severity} />
                          </div>
                          <p className="text-sm text-muted-foreground">"{pattern.matchedText}"</p>
                        </div>
                      ))}
                    </div>
                  </div>
                )}
                
                <div className="grid grid-cols-2 gap-4">
                  <div className="p-4 rounded-lg bg-muted/50">
                    <h4 className="font-medium text-sm mb-2 flex items-center gap-2">
                      <AlertTriangle className="h-4 w-4 text-red-500" />
                      허위정보 패턴
                    </h4>
                    <div className="text-xs text-muted-foreground space-y-1">
                      <p>• "정부가 숨기"</p>
                      <p>• "언론이 보도하지 않는"</p>
                      <p>• "비밀리에"</p>
                      <p>• "충격 진실"</p>
                      <p>• "알려지지 않은 진실"</p>
                    </div>
                  </div>
                  
                  <div className="p-4 rounded-lg bg-muted/50">
                    <h4 className="font-medium text-sm mb-2 flex items-center gap-2">
                      <HelpCircle className="h-4 w-4 text-yellow-500" />
                      검증 불가 표현
                    </h4>
                    <div className="text-xs text-muted-foreground space-y-1">
                      <p>• "최초", "유일", "최고"</p>
                      <p>• "100%", "모든 사람"</p>
                      <p>• "아무도", "절대"</p>
                      <p>• "반드시"</p>
                    </div>
                  </div>
                </div>
              </TabsContent>
              
              {/* Claims Analysis Tab */}
              <TabsContent value="claims" className="space-y-4">
                <div className="grid grid-cols-5 gap-2 mb-4">
                  {[
                    { verdict: "verified", label: "검증됨", color: "bg-green-500" },
                    { verdict: "partially_true", label: "일부 사실", color: "bg-yellow-500" },
                    { verdict: "unverified", label: "미검증", color: "bg-gray-500" },
                    { verdict: "misleading", label: "오해 소지", color: "bg-orange-500" },
                    { verdict: "false", label: "거짓", color: "bg-red-500" },
                  ].map(({ verdict, label, color }) => (
                    <div key={verdict} className="text-center p-2 rounded bg-muted/50">
                      <div className={`w-4 h-4 rounded-full ${color} mx-auto mb-1`} />
                      <div className="text-lg font-bold">
                        {claimAnalyses.filter(c => c.verdict === verdict).length}
                      </div>
                      <div className="text-xs text-muted-foreground">{label}</div>
                    </div>
                  ))}
                </div>
                
                <div className="space-y-3">
                  {claimAnalyses.map((claim, idx) => (
                    <Collapsible key={claim.claimId}>
                      <div className="p-3 rounded-lg border bg-card">
                        <CollapsibleTrigger className="w-full">
                          <div className="flex items-start gap-3">
                            <div className="flex items-center gap-2">
                              <span className="text-xs text-muted-foreground">#{idx + 1}</span>
                              <VerdictIcon verdict={claim.verdict} />
                            </div>
                            <div className="flex-1 text-left">
                              <p className="text-sm line-clamp-2">{claim.claimText}</p>
                              <div className="flex items-center gap-2 mt-1">
                                <Badge variant="outline" className="text-xs">
                                  {claim.claimIndicator}
                                </Badge>
                                <span className="text-xs text-muted-foreground">
                                  신뢰도 {Math.round(claim.confidence * 100)}%
                                </span>
                              </div>
                            </div>
                            <ChevronDown className="h-4 w-4 text-muted-foreground" />
                          </div>
                        </CollapsibleTrigger>
                        
                        <CollapsibleContent className="mt-3 pt-3 border-t">
                          <div className="space-y-3">
                            <div>
                              <span className="text-xs font-medium">분석 방법</span>
                              <p className="text-xs text-muted-foreground">{claim.analysisMethod}</p>
                            </div>
                            
                            {claim.supportingFactors.length > 0 && (
                              <div>
                                <span className="text-xs font-medium text-green-600 flex items-center gap-1">
                                  <CheckCircle2 className="h-3 w-3" />
                                  지지 요소
                                </span>
                                <ul className="text-xs text-muted-foreground mt-1 space-y-1">
                                  {claim.supportingFactors.map((f, i) => (
                                    <li key={i}>• {f}</li>
                                  ))}
                                </ul>
                              </div>
                            )}
                            
                            {claim.contradictingFactors.length > 0 && (
                              <div>
                                <span className="text-xs font-medium text-red-600 flex items-center gap-1">
                                  <XCircle className="h-3 w-3" />
                                  반박 요소
                                </span>
                                <ul className="text-xs text-muted-foreground mt-1 space-y-1">
                                  {claim.contradictingFactors.map((f, i) => (
                                    <li key={i}>• {f}</li>
                                  ))}
                                </ul>
                              </div>
                            )}
                          </div>
                        </CollapsibleContent>
                      </div>
                    </Collapsible>
                  ))}
                </div>
                
                <div className="p-4 rounded-lg bg-muted/50">
                  <h4 className="font-medium text-sm mb-2 flex items-center gap-2">
                    <Hash className="h-4 w-4" />
                    주장 추출 기준 (Claim Indicators)
                  </h4>
                  <div className="flex flex-wrap gap-1 text-xs">
                    {["~라고 밝혔다", "~라고 주장했다", "~라고 전했다", 
                      "~에 따르면", "~것으로 알려졌다", "~것으로 확인됐다",
                      "관계자는", "전문가는", "소식통에 따르면"].map(indicator => (
                      <Badge key={indicator} variant="outline" className="text-xs">{indicator}</Badge>
                    ))}
                  </div>
                </div>
              </TabsContent>
            </Tabs>
          </CardContent>
        </CollapsibleContent>
      </Collapsible>
    </Card>
  );
};

export default FactCheckAnalyticsPanel;

```

---

## frontend/src/components/FactCheckChatbot.tsx

```tsx
import { useState, useRef, useEffect, useImperativeHandle, forwardRef, useCallback } from 'react';
import { Send, Loader2, Bot, User, AlertCircle, CheckCircle2, XCircle, Scale, Shield, Download, Copy, Check, FileText, FileCode, RefreshCw } from 'lucide-react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Input } from '@/components/ui/input';
import { ScrollArea } from '@/components/ui/scroll-area';
import { Badge } from '@/components/ui/badge';
import { Alert, AlertDescription } from '@/components/ui/alert';
import { MarkdownRenderer } from '@/components/MarkdownRenderer';
import { useFactCheckChat } from '@/hooks/useFactCheckChat';
import {
  DropdownMenu,
  DropdownMenuContent,
  DropdownMenuItem,
  DropdownMenuLabel,
  DropdownMenuSeparator,
  DropdownMenuTrigger,
} from '@/components/ui/dropdown-menu';
import { toast } from 'sonner';

interface Message {
  id: string;
  role: 'user' | 'assistant' | 'system';
  content: string;
  timestamp: number;
  type?: string;
  phase?: string;
  evidence?: any[];
  verificationResult?: any;
  credibility?: any;
}

interface FactCheckChatbotProps {
  /** Initial query to send when component mounts */
  initialQuery?: string;
  /** Initial claims to verify (will be combined into a query) */
  initialClaims?: string[];
  /** Compact mode for embedding in tabs */
  compact?: boolean;
  /** Custom height class (default: h-[calc(100vh-12rem)] or h-[500px] in compact mode) */
  heightClass?: string;
  /** Hide header in compact mode */
  hideHeader?: boolean;
}

export interface FactCheckChatbotRef {
  sendQuery: (query: string) => void;
  sendClaims: (claims: string[]) => void;
  clearMessages: () => void;
}

export const FactCheckChatbot = forwardRef<FactCheckChatbotRef, FactCheckChatbotProps>(({
  initialQuery,
  initialClaims,
  compact = false,
  heightClass,
  hideHeader = false,
}, ref) => {
  const [input, setInput] = useState('');
  const [messages, setMessages] = useState<Message[]>([]);
  const initialSentRef = useRef(false);
  const scrollRef = useRef<HTMLDivElement>(null);
  const inputRef = useRef<HTMLInputElement>(null);

  const { sendMessage, isConnected, isStreaming, sessionId, reconnect } = useFactCheckChat({
    onMessage: (event) => {
      setMessages((prev) => [...prev, {
        id: `${Date.now()}-${Math.random()}`,
        role: event.role as 'user' | 'assistant' | 'system',
        content: event.content || '',
        timestamp: event.timestamp || Date.now(),
        type: event.type,
        phase: event.phase,
        evidence: event.evidence,
        verificationResult: event.verificationResult,
        credibility: event.credibility,
      }]);
    },
    onError: (error) => {
      setMessages((prev) => [...prev, {
        id: `error-${Date.now()}`,
        role: 'system',
        content: `오류: ${error}`,
        timestamp: Date.now(),
        type: 'error',
      }]);
    },
  });

  // 세션 재연결 핸들러
  const handleReconnect = useCallback(() => {
    setMessages([]);
    reconnect();
  }, [reconnect]);

  // 자동 스크롤
  useEffect(() => {
    if (scrollRef.current) {
      scrollRef.current.scrollTop = scrollRef.current.scrollHeight;
    }
  }, [messages]);

  // Helper function to send a query
  const sendQueryInternal = async (query: string) => {
    if (!query.trim() || isStreaming) return;

    const userMessage: Message = {
      id: `user-${Date.now()}`,
      role: 'user',
      content: query,
      timestamp: Date.now(),
    };

    setMessages((prev) => [...prev, userMessage]);
    await sendMessage(query);
  };

  // Helper function to send claims
  const sendClaimsInternal = async (claims: string[]) => {
    const validClaims = claims.filter(c => c.trim());
    if (validClaims.length === 0) return;

    const query = validClaims.length === 1
      ? `다음 주장을 팩트체크해주세요: "${validClaims[0]}"`
      : `다음 주장들을 팩트체크해주세요:\n${validClaims.map((c, i) => `${i + 1}. ${c}`).join('\n')}`;

    await sendQueryInternal(query);
  };

  // Expose methods via ref for parent components
  useImperativeHandle(ref, () => ({
    sendQuery: (query: string) => {
      sendQueryInternal(query);
    },
    sendClaims: (claims: string[]) => {
      sendClaimsInternal(claims);
    },
    clearMessages: () => {
      setMessages([]);
    },
  }), [isStreaming, sendMessage]);

  // Handle initial query or claims on mount
  useEffect(() => {
    if (initialSentRef.current || !isConnected) return;

    if (initialClaims && initialClaims.length > 0) {
      initialSentRef.current = true;
      sendClaimsInternal(initialClaims);
    } else if (initialQuery) {
      initialSentRef.current = true;
      sendQueryInternal(initialQuery);
    }
  }, [isConnected, initialQuery, initialClaims]);

  const handleSend = async () => {
    if (!input.trim() || isStreaming) return;
    const query = input;
    setInput('');
    await sendQueryInternal(query);
  };

  const handleKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSend();
    }
  };

  // Export functionality
  const [copied, setCopied] = useState(false);

  const exportToMarkdown = useCallback(() => {
    if (messages.length === 0) return;
    
    const timestamp = new Date().toLocaleString('ko-KR');
    let md = `# 팩트체크 결과 보고서\n\n`;
    md += `**생성 시간**: ${timestamp}\n`;
    md += `**세션 ID**: ${sessionId || 'N/A'}\n\n`;
    md += `---\n\n`;

    messages.forEach((msg) => {
      if (msg.role === 'user') {
        md += `## 사용자 질문\n\n${msg.content}\n\n`;
      } else if (msg.role === 'assistant') {
        md += `## AI 응답\n\n${msg.content}\n\n`;
        
        if (msg.verificationResult) {
          const result = msg.verificationResult;
          md += `### 검증 결과\n\n`;
          md += `- **주장**: ${result.originalClaim}\n`;
          md += `- **판정**: ${getVerificationLabel(result.status)}\n`;
          md += `- **신뢰도**: ${Math.round((result.confidenceScore || 0) * 100)}%\n`;
          md += `- **요약**: ${result.verificationSummary}\n\n`;
        }
        
        if (msg.evidence && msg.evidence.length > 0) {
          md += `### 증거 자료\n\n`;
          msg.evidence.forEach((ev: any, idx: number) => {
            md += `${idx + 1}. **${ev.sourceName}**\n`;
            md += `   - ${ev.excerpt}\n`;
            if (ev.url) md += `   - URL: ${ev.url}\n`;
            md += `\n`;
          });
        }
      }
    });

    md += `---\n\n*이 보고서는 NewsInsight 팩트체크 챗봇에 의해 자동 생성되었습니다.*\n`;

    const blob = new Blob([md], { type: 'text/markdown;charset=utf-8' });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = `팩트체크_결과_${new Date().toISOString().slice(0, 10)}.md`;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    URL.revokeObjectURL(url);
    toast.success('Markdown 파일이 다운로드되었습니다.');
  }, [messages, sessionId]);

  const exportToText = useCallback(() => {
    if (messages.length === 0) return;
    
    const timestamp = new Date().toLocaleString('ko-KR');
    let text = `팩트체크 결과 보고서\n`;
    text += `========================================\n\n`;
    text += `생성 시간: ${timestamp}\n`;
    text += `세션 ID: ${sessionId || 'N/A'}\n\n`;
    text += `========================================\n\n`;

    messages.forEach((msg) => {
      if (msg.role === 'user') {
        text += `[사용자 질문]\n${msg.content}\n\n`;
      } else if (msg.role === 'assistant') {
        text += `[AI 응답]\n${msg.content}\n\n`;
        
        if (msg.verificationResult) {
          const result = msg.verificationResult;
          text += `[검증 결과]\n`;
          text += `- 주장: ${result.originalClaim}\n`;
          text += `- 판정: ${getVerificationLabel(result.status)}\n`;
          text += `- 신뢰도: ${Math.round((result.confidenceScore || 0) * 100)}%\n`;
          text += `- 요약: ${result.verificationSummary}\n\n`;
        }
      }
    });

    text += `========================================\n`;
    text += `이 보고서는 NewsInsight 팩트체크 챗봇에 의해 자동 생성되었습니다.\n`;

    const blob = new Blob([text], { type: 'text/plain;charset=utf-8' });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = `팩트체크_결과_${new Date().toISOString().slice(0, 10)}.txt`;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    URL.revokeObjectURL(url);
    toast.success('텍스트 파일이 다운로드되었습니다.');
  }, [messages, sessionId]);

  const exportToJson = useCallback(() => {
    if (messages.length === 0) return;
    
    const exportData = {
      exportedAt: new Date().toISOString(),
      sessionId: sessionId || null,
      messages: messages.map(msg => ({
        role: msg.role,
        content: msg.content,
        timestamp: msg.timestamp,
        type: msg.type,
        verificationResult: msg.verificationResult,
        evidence: msg.evidence,
      })),
    };

    const blob = new Blob([JSON.stringify(exportData, null, 2)], { type: 'application/json;charset=utf-8' });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = `팩트체크_결과_${new Date().toISOString().slice(0, 10)}.json`;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    URL.revokeObjectURL(url);
    toast.success('JSON 파일이 다운로드되었습니다.');
  }, [messages, sessionId]);

  const copyToClipboard = useCallback(async () => {
    if (messages.length === 0) return;
    
    const text = messages
      .filter(m => m.role !== 'system' || m.type !== 'status')
      .map(m => {
        if (m.role === 'user') return `사용자: ${m.content}`;
        if (m.role === 'assistant') return `AI: ${m.content}`;
        return m.content;
      })
      .join('\n\n');

    try {
      await navigator.clipboard.writeText(text);
      setCopied(true);
      toast.success('클립보드에 복사되었습니다.');
      setTimeout(() => setCopied(false), 2000);
    } catch {
      toast.error('복사에 실패했습니다.');
    }
  }, [messages]);

  // Determine height class
  const containerHeightClass = heightClass || (compact ? 'h-[500px]' : 'h-[calc(100vh-12rem)]');

  return (
    <div className={`flex flex-col ${containerHeightClass} ${compact ? '' : 'max-w-5xl mx-auto'}`}>
      <Card className="flex-1 flex flex-col">
        {!hideHeader && (
          <CardHeader className={`border-b ${compact ? 'py-3' : ''}`}>
            <div className="flex items-center gap-3">
              <div className={`${compact ? 'p-1.5' : 'p-2'} bg-primary/10 rounded-lg`}>
                <Shield className={`${compact ? 'h-5 w-5' : 'h-6 w-6'} text-primary`} />
              </div>
              <div>
                <CardTitle className={compact ? 'text-base' : ''}>팩트체크 챗봇</CardTitle>
                {!compact && (
                  <p className="text-sm text-muted-foreground mt-1">
                    궁금한 주장이나 뉴스를 입력하면 실시간으로 팩트체크 결과를 제공합니다
                  </p>
                )}
              </div>
              <div className="ml-auto flex items-center gap-2">
                {/* Export Menu */}
                {messages.length > 0 && (
                  <DropdownMenu>
                    <DropdownMenuTrigger asChild>
                      <Button variant="outline" size={compact ? 'sm' : 'default'}>
                        <Download className="h-4 w-4 mr-1" />
                        내보내기
                      </Button>
                    </DropdownMenuTrigger>
                    <DropdownMenuContent align="end">
                      <DropdownMenuLabel>내보내기 형식</DropdownMenuLabel>
                      <DropdownMenuSeparator />
                      <DropdownMenuItem onClick={exportToMarkdown}>
                        <FileCode className="h-4 w-4 mr-2 text-blue-600" />
                        Markdown (.md)
                      </DropdownMenuItem>
                      <DropdownMenuItem onClick={exportToText}>
                        <FileText className="h-4 w-4 mr-2 text-gray-600" />
                        텍스트 (.txt)
                      </DropdownMenuItem>
                      <DropdownMenuItem onClick={exportToJson}>
                        <FileText className="h-4 w-4 mr-2 text-yellow-600" />
                        JSON (.json)
                      </DropdownMenuItem>
                      <DropdownMenuSeparator />
                      <DropdownMenuItem onClick={copyToClipboard}>
                        {copied ? (
                          <Check className="h-4 w-4 mr-2 text-green-600" />
                        ) : (
                          <Copy className="h-4 w-4 mr-2" />
                        )}
                        클립보드 복사
                      </DropdownMenuItem>
                    </DropdownMenuContent>
                  </DropdownMenu>
                )}
                {isConnected && (
                  <Badge variant="outline">
                    <div className="w-2 h-2 bg-green-500 rounded-full mr-2 animate-pulse" />
                    연결됨
                  </Badge>
                )}
              </div>
            </div>
          </CardHeader>
        )}

        <CardContent className="flex-1 flex flex-col p-0 min-h-0">
          {/* 메시지 영역 */}
          <ScrollArea ref={scrollRef} className="flex-1 p-4">
            {/* 연결 오류 상태 */}
            {!isConnected && messages.length === 0 ? (
              <div className={`flex flex-col items-center justify-center h-full text-center ${compact ? 'p-4' : 'p-8'}`}>
                <AlertCircle className={`${compact ? 'h-12 w-12' : 'h-16 w-16'} text-destructive mb-4`} />
                <h3 className={`${compact ? 'text-base' : 'text-lg'} font-semibold mb-2`}>
                  세션 연결 중...
                </h3>
                <p className={`text-muted-foreground ${compact ? 'text-sm' : ''} max-w-md mb-4`}>
                  팩트체크 서버에 연결하고 있습니다. 잠시만 기다려주세요.
                </p>
                <Button onClick={handleReconnect} variant="outline" size="sm">
                  <RefreshCw className="h-4 w-4 mr-2" />
                  다시 연결
                </Button>
              </div>
            ) : messages.length === 0 ? (
              <div className={`flex flex-col items-center justify-center h-full text-center ${compact ? 'p-4' : 'p-8'}`}>
                <Bot className={`${compact ? 'h-12 w-12' : 'h-16 w-16'} text-muted-foreground mb-4`} />
                <h3 className={`${compact ? 'text-base' : 'text-lg'} font-semibold mb-2`}>
                  {compact ? '팩트체크를 시작하세요' : '팩트체크 챗봇에 오신 것을 환영합니다!'}
                </h3>
                <p className={`text-muted-foreground ${compact ? 'text-sm' : ''} max-w-md`}>
                  검증하고 싶은 주장이나 뉴스를 입력해주세요. 
                  {!compact && '신뢰할 수 있는 출처를 기반으로 실시간 팩트체크를 수행합니다.'}
                </p>
                <div className={`${compact ? 'mt-4' : 'mt-6'} grid grid-cols-1 gap-2 w-full max-w-md`}>
                  <Button
                    variant="outline"
                    className="justify-start"
                    onClick={() => setInput('메모리 반도체 가격이 상승하고 있다는 뉴스가 사실인가요?')}
                  >
                    💡 메모리 반도체 가격 상승 뉴스 검증
                  </Button>
                  <Button
                    variant="outline"
                    className="justify-start"
                    onClick={() => setInput('최근 발표된 경제 성장률 통계가 정확한가요?')}
                  >
                    📊 경제 통계 검증
                  </Button>
                  <Button
                    variant="outline"
                    className="justify-start"
                    onClick={() => setInput('이 정치인의 발언이 사실에 부합하나요?')}
                  >
                    🎤 정치인 발언 검증
                  </Button>
                </div>
              </div>
            ) : (
              <div className="space-y-4">
                {messages.map((message) => (
                  <MessageBubble key={message.id} message={message} />
                ))}
                {isStreaming && (
                  <div className="flex items-center gap-2 text-muted-foreground">
                    <Loader2 className="h-4 w-4 animate-spin" />
                    <span className="text-sm">분석 중...</span>
                  </div>
                )}
              </div>
            )}
          </ScrollArea>

          {/* 입력 영역 */}
          <div className="border-t p-4">
            <div className="flex gap-2">
              <Input
                ref={inputRef}
                value={input}
                onChange={(e) => setInput(e.target.value)}
                onKeyPress={handleKeyPress}
                placeholder="팩트체크할 내용을 입력하세요..."
                disabled={isStreaming}
                className="flex-1"
              />
              <Button
                onClick={handleSend}
                disabled={!input.trim() || isStreaming}
                size="icon"
              >
                {isStreaming ? (
                  <Loader2 className="h-4 w-4 animate-spin" />
                ) : (
                  <Send className="h-4 w-4" />
                )}
              </Button>
            </div>
            <p className="text-xs text-muted-foreground mt-2">
              Enter로 전송 • Shift+Enter로 줄바꿈
            </p>
          </div>
        </CardContent>
      </Card>
    </div>
  );
});

// 메시지 버블 컴포넌트
const MessageBubble = ({ message }: { message: Message }) => {
  const isUser = message.role === 'user';
  const isSystem = message.role === 'system';

  // 시스템 메시지 (상태 업데이트)
  if (isSystem && message.type === 'status') {
    return (
      <div className="flex justify-center">
        <Badge variant="secondary" className="text-xs">
          {message.content}
        </Badge>
      </div>
    );
  }

  // 증거 메시지
  if (message.type === 'evidence' && message.evidence) {
    return (
      <div className="flex gap-3">
        <div className="flex-shrink-0">
          <div className="w-8 h-8 rounded-full bg-blue-100 dark:bg-blue-900 flex items-center justify-center">
            <Shield className="h-4 w-4 text-blue-600 dark:text-blue-400" />
          </div>
        </div>
        <div className="flex-1">
          <Alert>
            <AlertDescription>
              <p className="font-medium mb-2">{message.content}</p>
              <div className="space-y-2 mt-3">
                {message.evidence.slice(0, 3).map((ev: any, idx: number) => (
                  <div key={idx} className="text-sm border-l-2 border-primary pl-3">
                    <p className="font-medium">{ev.sourceName}</p>
                    <p className="text-muted-foreground text-xs mt-1">{ev.excerpt}</p>
                  </div>
                ))}
              </div>
            </AlertDescription>
          </Alert>
        </div>
      </div>
    );
  }

  // 검증 결과 메시지
  if (message.type === 'verification' && message.verificationResult) {
    const result = message.verificationResult;
    const statusIcon = getVerificationIcon(result.status);
    
    return (
      <div className="flex gap-3">
        <div className="flex-shrink-0">
          <div className="w-8 h-8 rounded-full bg-purple-100 dark:bg-purple-900 flex items-center justify-center">
            {statusIcon}
          </div>
        </div>
        <div className="flex-1">
          <Card>
            <CardContent className="pt-4">
              <div className="flex items-start justify-between mb-2">
                <p className="font-medium">{result.originalClaim}</p>
                <Badge variant={getVerificationVariant(result.status)}>
                  {getVerificationLabel(result.status)}
                </Badge>
              </div>
              <p className="text-sm text-muted-foreground">{result.verificationSummary}</p>
              {result.confidenceScore && (
                <div className="mt-2">
                  <div className="flex items-center gap-2 text-xs text-muted-foreground">
                    <span>신뢰도</span>
                    <div className="flex-1 h-2 bg-muted rounded-full overflow-hidden">
                      <div
                        className="h-full bg-primary"
                        style={{ width: `${result.confidenceScore * 100}%` }}
                      />
                    </div>
                    <span>{Math.round(result.confidenceScore * 100)}%</span>
                  </div>
                </div>
              )}
            </CardContent>
          </Card>
        </div>
      </div>
    );
  }

  // AI 합성 메시지 (스트리밍)
  if (message.type === 'ai_synthesis') {
    return (
      <div className="flex gap-3">
        <div className="flex-shrink-0">
          <div className="w-8 h-8 rounded-full bg-gradient-to-br from-purple-500 to-pink-500 flex items-center justify-center">
            <Bot className="h-4 w-4 text-white" />
          </div>
        </div>
        <div className="flex-1 bg-muted/50 rounded-lg p-4">
          <MarkdownRenderer content={message.content} isStreaming={true} />
        </div>
      </div>
    );
  }

  // 완료 메시지
  if (message.type === 'complete') {
    return (
      <div className="flex justify-center">
        <Alert className="max-w-md">
          <CheckCircle2 className="h-4 w-4" />
          <AlertDescription>{message.content}</AlertDescription>
        </Alert>
      </div>
    );
  }

  // 에러 메시지
  if (message.type === 'error') {
    return (
      <div className="flex justify-center">
        <Alert variant="destructive" className="max-w-md">
          <AlertCircle className="h-4 w-4" />
          <AlertDescription>{message.content}</AlertDescription>
        </Alert>
      </div>
    );
  }

  // 일반 사용자/어시스턴트 메시지
  return (
    <div className={`flex gap-3 ${isUser ? 'flex-row-reverse' : ''}`}>
      <div className="flex-shrink-0">
        <div className={`w-8 h-8 rounded-full flex items-center justify-center ${
          isUser 
            ? 'bg-primary text-primary-foreground' 
            : 'bg-muted'
        }`}>
          {isUser ? <User className="h-4 w-4" /> : <Bot className="h-4 w-4" />}
        </div>
      </div>
      <div className={`flex-1 max-w-[80%] ${isUser ? 'text-right' : ''}`}>
        <div className={`inline-block rounded-lg p-3 ${
          isUser 
            ? 'bg-primary text-primary-foreground' 
            : 'bg-muted'
        }`}>
          {message.content.includes('\n') || message.content.length > 100 ? (
            <MarkdownRenderer content={message.content} isStreaming={false} />
          ) : (
            <p className="text-sm">{message.content}</p>
          )}
        </div>
        <p className="text-xs text-muted-foreground mt-1">
          {new Date(message.timestamp).toLocaleTimeString('ko-KR', {
            hour: '2-digit',
            minute: '2-digit',
          })}
        </p>
      </div>
    </div>
  );
};

// 헬퍼 함수들
const getVerificationIcon = (status: string) => {
  switch (status) {
    case 'VERIFIED':
      return <CheckCircle2 className="h-4 w-4 text-green-600" />;
    case 'FALSE':
      return <XCircle className="h-4 w-4 text-red-600" />;
    case 'DISPUTED':
      return <Scale className="h-4 w-4 text-orange-600" />;
    default:
      return <AlertCircle className="h-4 w-4 text-gray-600" />;
  }
};

const getVerificationVariant = (status: string): 'default' | 'destructive' | 'outline' | 'secondary' => {
  switch (status) {
    case 'VERIFIED':
      return 'default';
    case 'FALSE':
      return 'destructive';
    case 'DISPUTED':
      return 'secondary';
    default:
      return 'outline';
  }
};

const getVerificationLabel = (status: string) => {
  switch (status) {
    case 'VERIFIED':
      return '검증됨';
    case 'FALSE':
      return '거짓';
    case 'DISPUTED':
      return '논쟁 중';
    case 'UNVERIFIED':
      return '검증 불가';
    default:
      return status;
  }
};

// Set displayName for forwardRef
FactCheckChatbot.displayName = 'FactCheckChatbot';

```

---

## frontend/src/components/KeywordCloud.tsx

```tsx
import { Card } from "@/components/ui/card";
import type { KeywordData } from "@/types/api";

interface KeywordCloudProps {
  keywords: KeywordData[];
}

export function KeywordCloud({ keywords }: KeywordCloudProps) {
  const maxScore = Math.max(...keywords.map((k) => k.score), 1);
  
  const getFontSize = (score: number) => {
    const normalized = (score / maxScore) * 100;
    return Math.max(12, Math.min(48, normalized / 2));
  };

  const getColor = (index: number) => {
    const colors = [
      "hsl(217, 91%, 60%)",
      "hsl(217, 91%, 45%)",
      "hsl(217, 91%, 75%)",
      "hsl(142, 71%, 45%)",
      "hsl(217, 91%, 35%)",
    ];
    return colors[index % colors.length];
  };

  return (
    <Card className="p-6 shadow-elegant card-hover">
      <h2 className="text-xl font-bold mb-6">핵심 키워드</h2>
      <div className="min-h-[300px] flex flex-wrap items-center justify-center gap-4 p-6">
        {keywords.length > 0 ? (
          keywords.map((keyword, index) => (
            <span
              key={`${keyword.word}-${index}`}
              className="font-semibold transition-transform hover:scale-110 cursor-default"
              style={{
                fontSize: `${getFontSize(keyword.score)}px`,
                color: getColor(index),
                lineHeight: 1.5,
              }}
              title={`중요도: ${keyword.score.toFixed(2)}`}
            >
              {keyword.word}
            </span>
          ))
        ) : (
          <div className="text-center text-muted-foreground py-12">
            키워드 데이터가 없습니다.
          </div>
        )}
      </div>
    </Card>
  );
}

```

---

## frontend/src/components/LoadingState.tsx

```tsx
import * as React from "react";
import { Loader2 } from "lucide-react";
import { cn } from "@/lib/utils";
import { Skeleton } from "@/components/ui/skeleton";
import { Progress } from "@/components/ui/progress";

/**
 * 통합 로딩 상태 컴포넌트
 * 
 * 다양한 로딩 패턴을 지원:
 * - spinner: 기본 스피너
 * - skeleton: 콘텐츠 형태 스켈레톤
 * - progress: 진행률 바
 * - dots: 점 애니메이션
 */

export type LoadingVariant = "spinner" | "skeleton" | "progress" | "dots";
export type LoadingSize = "sm" | "md" | "lg" | "xl";

interface LoadingStateProps {
  /** 로딩 변형 */
  variant?: LoadingVariant;
  /** 크기 */
  size?: LoadingSize;
  /** 표시할 텍스트 */
  text?: string;
  /** 진행률 (progress 변형에서 사용) */
  progress?: number;
  /** 전체 화면 오버레이로 표시 */
  fullScreen?: boolean;
  /** 추가 CSS 클래스 */
  className?: string;
  /** 스켈레톤 변형에서의 줄 수 */
  skeletonLines?: number;
}

const sizeConfig: Record<LoadingSize, { spinner: string; text: string; container: string }> = {
  sm: { spinner: "h-4 w-4", text: "text-xs", container: "gap-2" },
  md: { spinner: "h-6 w-6", text: "text-sm", container: "gap-3" },
  lg: { spinner: "h-8 w-8", text: "text-base", container: "gap-4" },
  xl: { spinner: "h-12 w-12", text: "text-lg", container: "gap-5" },
};

/** 스피너 로딩 */
const SpinnerLoading = ({ size = "md", text, className }: Pick<LoadingStateProps, "size" | "text" | "className">) => {
  const config = sizeConfig[size];
  return (
    <div className={cn("flex flex-col items-center justify-center", config.container, className)}>
      <Loader2 className={cn("animate-spin text-primary", config.spinner)} />
      {text && <span className={cn("text-muted-foreground", config.text)}>{text}</span>}
    </div>
  );
};

/** 점 애니메이션 로딩 */
const DotsLoading = ({ size = "md", text, className }: Pick<LoadingStateProps, "size" | "text" | "className">) => {
  const config = sizeConfig[size];
  const dotSize = size === "sm" ? "h-1.5 w-1.5" : size === "md" ? "h-2 w-2" : size === "lg" ? "h-2.5 w-2.5" : "h-3 w-3";
  
  return (
    <div className={cn("flex flex-col items-center justify-center", config.container, className)}>
      <div className="flex items-center gap-1">
        {[0, 1, 2].map((i) => (
          <div
            key={i}
            className={cn(
              "rounded-full bg-primary animate-bounce",
              dotSize
            )}
            style={{ animationDelay: `${i * 0.15}s` }}
          />
        ))}
      </div>
      {text && <span className={cn("text-muted-foreground", config.text)}>{text}</span>}
    </div>
  );
};

/** 프로그레스 바 로딩 */
const ProgressLoading = ({
  size = "md",
  text,
  progress = 0,
  className,
}: Pick<LoadingStateProps, "size" | "text" | "progress" | "className">) => {
  const config = sizeConfig[size];
  const progressHeight = size === "sm" ? "h-1" : size === "md" ? "h-2" : size === "lg" ? "h-3" : "h-4";

  return (
    <div className={cn("flex flex-col w-full max-w-xs", config.container, className)}>
      <Progress value={progress} className={progressHeight} />
      <div className="flex justify-between items-center">
        {text && <span className={cn("text-muted-foreground", config.text)}>{text}</span>}
        <span className={cn("text-muted-foreground font-medium", config.text)}>{Math.round(progress)}%</span>
      </div>
    </div>
  );
};

/** 스켈레톤 로딩 */
const SkeletonLoading = ({
  size = "md",
  skeletonLines = 3,
  className,
}: Pick<LoadingStateProps, "size" | "skeletonLines" | "className">) => {
  const lineHeight = size === "sm" ? "h-3" : size === "md" ? "h-4" : size === "lg" ? "h-5" : "h-6";
  const gap = size === "sm" ? "gap-2" : size === "md" ? "gap-3" : "gap-4";

  return (
    <div className={cn("flex flex-col w-full", gap, className)}>
      {Array.from({ length: skeletonLines }).map((_, i) => (
        <Skeleton
          key={i}
          className={cn(lineHeight, i === skeletonLines - 1 ? "w-3/4" : "w-full")}
        />
      ))}
    </div>
  );
};

/** 카드 스켈레톤 */
export const CardSkeleton = ({ className }: { className?: string }) => (
  <div className={cn("rounded-lg border bg-card p-4 space-y-3", className)}>
    <Skeleton className="h-4 w-1/3" />
    <Skeleton className="h-3 w-full" />
    <Skeleton className="h-3 w-full" />
    <Skeleton className="h-3 w-2/3" />
    <div className="flex gap-2 pt-2">
      <Skeleton className="h-6 w-16 rounded-full" />
      <Skeleton className="h-6 w-16 rounded-full" />
    </div>
  </div>
);

/** 검색 결과 스켈레톤 */
export const SearchResultSkeleton = ({ count = 3, className }: { count?: number; className?: string }) => (
  <div className={cn("space-y-4", className)}>
    {Array.from({ length: count }).map((_, i) => (
      <CardSkeleton key={i} />
    ))}
  </div>
);

/** 테이블 스켈레톤 */
export const TableSkeleton = ({ rows = 5, cols = 4, className }: { rows?: number; cols?: number; className?: string }) => (
  <div className={cn("space-y-2", className)}>
    {/* Header */}
    <div className="flex gap-4 pb-2 border-b">
      {Array.from({ length: cols }).map((_, i) => (
        <Skeleton key={i} className="h-4 flex-1" />
      ))}
    </div>
    {/* Rows */}
    {Array.from({ length: rows }).map((_, rowIndex) => (
      <div key={rowIndex} className="flex gap-4 py-2">
        {Array.from({ length: cols }).map((_, colIndex) => (
          <Skeleton key={colIndex} className="h-4 flex-1" />
        ))}
      </div>
    ))}
  </div>
);

/** 인라인 로딩 (버튼, 텍스트 옆 등) */
export const InlineLoading = ({ text, className }: { text?: string; className?: string }) => (
  <span className={cn("inline-flex items-center gap-2", className)}>
    <Loader2 className="h-4 w-4 animate-spin" />
    {text && <span>{text}</span>}
  </span>
);

/** 메인 LoadingState 컴포넌트 */
export const LoadingState = ({
  variant = "spinner",
  size = "md",
  text,
  progress,
  fullScreen = false,
  className,
  skeletonLines,
}: LoadingStateProps) => {
  const content = React.useMemo(() => {
    switch (variant) {
      case "spinner":
        return <SpinnerLoading size={size} text={text} />;
      case "dots":
        return <DotsLoading size={size} text={text} />;
      case "progress":
        return <ProgressLoading size={size} text={text} progress={progress} />;
      case "skeleton":
        return <SkeletonLoading size={size} skeletonLines={skeletonLines} />;
      default:
        return <SpinnerLoading size={size} text={text} />;
    }
  }, [variant, size, text, progress, skeletonLines]);

  if (fullScreen) {
    return (
      <div className="fixed inset-0 z-50 flex items-center justify-center bg-background/80 backdrop-blur-sm">
        {content}
      </div>
    );
  }

  return <div className={cn("flex items-center justify-center p-4", className)}>{content}</div>;
};

export default LoadingState;

```

---

## frontend/src/components/MarkdownRenderer.tsx

```tsx
import { memo } from "react";
import ReactMarkdown from "react-markdown";
import remarkGfm from "remark-gfm";
import { cn } from "@/lib/utils";
import { ExternalLink } from "lucide-react";

interface MarkdownRendererProps {
  content: string;
  className?: string;
  isStreaming?: boolean;
}

/**
 * Markdown renderer component with GitHub Flavored Markdown support.
 * Used for rendering AI analysis results and other markdown content.
 */
export const MarkdownRenderer = memo(function MarkdownRenderer({
  content,
  className,
  isStreaming = false,
}: MarkdownRendererProps) {
  return (
    <div
      className={cn(
        // Base prose styles
        "prose prose-sm dark:prose-invert max-w-none",
        // Headings
        "prose-headings:font-semibold prose-headings:text-foreground",
        "prose-h1:text-xl prose-h1:mt-4 prose-h1:mb-2",
        "prose-h2:text-lg prose-h2:mt-4 prose-h2:mb-2",
        "prose-h3:text-base prose-h3:mt-3 prose-h3:mb-1",
        // Paragraphs
        "prose-p:my-2 prose-p:leading-relaxed",
        // Lists
        "prose-ul:my-2 prose-ul:pl-4",
        "prose-ol:my-2 prose-ol:pl-4",
        "prose-li:my-0.5 prose-li:marker:text-muted-foreground",
        // Strong/Bold
        "prose-strong:font-semibold prose-strong:text-foreground",
        // Links
        "prose-a:text-primary prose-a:underline prose-a:underline-offset-2 hover:prose-a:text-primary/80",
        // Blockquotes
        "prose-blockquote:border-l-4 prose-blockquote:border-primary/30",
        "prose-blockquote:pl-4 prose-blockquote:italic",
        "prose-blockquote:text-muted-foreground",
        // Code
        "prose-code:bg-muted prose-code:px-1.5 prose-code:py-0.5 prose-code:rounded",
        "prose-code:font-mono prose-code:text-sm",
        "prose-pre:bg-muted prose-pre:rounded-lg prose-pre:p-4",
        // Horizontal rule
        "prose-hr:border-border prose-hr:my-4",
        // Tables
        "prose-table:border prose-table:border-border",
        "prose-th:bg-muted prose-th:px-3 prose-th:py-2 prose-th:text-left",
        "prose-td:px-3 prose-td:py-2 prose-td:border-t prose-td:border-border",
        className
      )}
    >
      <ReactMarkdown
        remarkPlugins={[remarkGfm]}
        components={{
          // Custom link component with external link icon
          a: ({ href, children, ...props }) => {
            const isExternal = href?.startsWith("http");
            return (
              <a
                href={href}
                target={isExternal ? "_blank" : undefined}
                rel={isExternal ? "noopener noreferrer" : undefined}
                className="inline-flex items-center gap-1"
                {...props}
              >
                {children}
                {isExternal && <ExternalLink className="h-3 w-3 inline-block" />}
              </a>
            );
          },
          // Custom heading with anchor support
          h2: ({ children, ...props }) => (
            <h2 className="flex items-center gap-2 border-b border-border pb-1 mb-3" {...props}>
              {children}
            </h2>
          ),
          h3: ({ children, ...props }) => (
            <h3 className="flex items-center gap-1" {...props}>
              {children}
            </h3>
          ),
        }}
      >
        {content}
      </ReactMarkdown>
      {/* Streaming cursor */}
      {isStreaming && (
        <span className="inline-block w-2 h-4 bg-primary/60 animate-pulse ml-0.5 align-text-bottom" />
      )}
    </div>
  );
});

export default MarkdownRenderer;

```

---

## frontend/src/components/MobileNavDrawer.tsx

```tsx
import { useState, useCallback, useEffect } from "react";
import { Link, useLocation } from "react-router-dom";
import {
  Menu,
  X,
  Search,
  Bot,
  FolderOpen,
  History,
  Settings,
  Moon,
  Sun,
  Command,
  Database,
  Cpu,
  Home,
  LayoutDashboard,
  Wrench,
  FolderKanban,
  Activity,
  Gauge,
  Brain,
  Globe,
  ChevronDown,
  ChevronRight,
} from "lucide-react";
import { Button } from "@/components/ui/button";
import { Sheet, SheetContent, SheetTrigger, SheetTitle } from "@/components/ui/sheet";
import { Collapsible, CollapsibleContent, CollapsibleTrigger } from "@/components/ui/collapsible";
import { useTheme } from "@/contexts/ThemeContext";
import { cn } from "@/lib/utils";

interface NavSubItem {
  href: string;
  label: string;
  icon: typeof Search;
}

interface NavItem {
  id: string;
  href?: string;
  label: string;
  icon: typeof Search;
  color?: string;
  subItems?: NavSubItem[];
}

// 새로운 5탭 네비게이션 구조
const navItems: NavItem[] = [
  { 
    id: 'home',
    href: "/", 
    label: "홈", 
    icon: Home 
  },
  { 
    id: 'dashboard',
    label: "대시보드", 
    icon: LayoutDashboard,
    subItems: [
      { href: "/dashboard", label: "라이브 대시보드", icon: Activity },
      { href: "/operations", label: "운영 현황", icon: Gauge },
      { href: "/collected-data", label: "수집 데이터", icon: Database },
    ]
  },
  { 
    id: 'tools',
    href: "/tools",
    label: "도구", 
    icon: Wrench,
    color: "text-blue-600",
    subItems: [
      { href: "/search", label: "스마트 검색", icon: Search },
      { href: "/ml-addons", label: "ML Add-ons", icon: Cpu },
      { href: "/ai-agent", label: "브라우저 에이전트", icon: Bot },
      { href: "/ai-jobs", label: "AI Jobs", icon: Brain },
    ]
  },
  { 
    id: 'workspace',
    href: "/workspace",
    label: "내 작업", 
    icon: FolderKanban,
    color: "text-green-600",
    subItems: [
      { href: "/projects", label: "프로젝트", icon: FolderOpen },
      { href: "/history", label: "검색 기록", icon: History },
      { href: "/url-collections", label: "URL 컬렉션", icon: Globe },
    ]
  },
  { 
    id: 'settings',
    href: "/settings", 
    label: "설정", 
    icon: Settings 
  },
];

interface MobileNavDrawerProps {
  className?: string;
}

/**
 * 모바일 네비게이션 드로어 컴포넌트
 */
export function MobileNavDrawer({ className }: MobileNavDrawerProps) {
  const [open, setOpen] = useState(false);
  const [expandedSections, setExpandedSections] = useState<string[]>([]);
  const location = useLocation();
  const { theme, setTheme } = useTheme();

  // Auto-expand section if current path matches
  useEffect(() => {
    navItems.forEach(item => {
      if (item.subItems?.some(sub => location.pathname === sub.href)) {
        setExpandedSections(prev => 
          prev.includes(item.id) ? prev : [...prev, item.id]
        );
      }
    });
  }, [location.pathname]);

  // Close drawer on route change
  useEffect(() => {
    setOpen(false);
  }, [location.pathname]);

  const toggleTheme = useCallback(() => {
    setTheme(theme === "dark" ? "light" : "dark");
  }, [theme, setTheme]);

  const toggleSection = (id: string) => {
    setExpandedSections(prev =>
      prev.includes(id) ? prev.filter(s => s !== id) : [...prev, id]
    );
  };

  const isActive = (href: string) => location.pathname === href;
  const isSectionActive = (item: NavItem) => {
    if (item.href && location.pathname === item.href) return true;
    return item.subItems?.some(sub => location.pathname === sub.href) ?? false;
  };

  return (
    <Sheet open={open} onOpenChange={setOpen}>
      <SheetTrigger asChild>
        <Button
          variant="ghost"
          size="icon"
          className={cn("md:hidden", className)}
          aria-label="메뉴 열기"
        >
          <Menu className="h-5 w-5" />
        </Button>
      </SheetTrigger>
      <SheetContent side="left" className="w-72 p-0">
        <SheetTitle className="sr-only">네비게이션 메뉴</SheetTitle>
        <div className="flex flex-col h-full">
          {/* Header */}
          <div className="flex items-center justify-between p-4 border-b">
            <h2 className="font-bold text-lg bg-gradient-to-r from-blue-600 to-purple-600 bg-clip-text text-transparent">
              NewsInsight
            </h2>
            <Button
              variant="ghost"
              size="icon"
              onClick={() => setOpen(false)}
              aria-label="메뉴 닫기"
            >
              <X className="h-5 w-5" />
            </Button>
          </div>

          {/* Navigation Links */}
          <nav className="flex-1 p-4 overflow-y-auto">
            <ul className="space-y-1">
              {navItems.map((item) => {
                const Icon = item.icon;
                const active = isSectionActive(item);
                const isExpanded = expandedSections.includes(item.id);
                
                // Simple link (no submenu)
                if (!item.subItems) {
                  return (
                    <li key={item.id}>
                      <Link
                        to={item.href!}
                        className={cn(
                          "flex items-center gap-3 px-3 py-2.5 rounded-lg text-sm font-medium transition-colors",
                          active
                            ? "bg-primary/10 text-primary"
                            : "text-muted-foreground hover:bg-muted hover:text-foreground"
                        )}
                        onClick={() => setOpen(false)}
                      >
                        <Icon className={cn("h-5 w-5", item.color)} />
                        <span>{item.label}</span>
                      </Link>
                    </li>
                  );
                }

                // Collapsible section with submenu
                return (
                  <li key={item.id}>
                    <Collapsible open={isExpanded} onOpenChange={() => toggleSection(item.id)}>
                      <CollapsibleTrigger asChild>
                        <button
                          className={cn(
                            "w-full flex items-center gap-3 px-3 py-2.5 rounded-lg text-sm font-medium transition-colors",
                            active
                              ? "bg-primary/10 text-primary"
                              : "text-muted-foreground hover:bg-muted hover:text-foreground"
                          )}
                        >
                          <Icon className={cn("h-5 w-5", item.color)} />
                          <span className="flex-1 text-left">{item.label}</span>
                          {isExpanded ? (
                            <ChevronDown className="h-4 w-4" />
                          ) : (
                            <ChevronRight className="h-4 w-4" />
                          )}
                        </button>
                      </CollapsibleTrigger>
                      <CollapsibleContent>
                        <ul className="ml-4 mt-1 space-y-1 border-l-2 border-muted pl-3">
                          {item.subItems.map((subItem) => {
                            const SubIcon = subItem.icon;
                            return (
                              <li key={subItem.href}>
                                <Link
                                  to={subItem.href}
                                  className={cn(
                                    "flex items-center gap-3 px-3 py-2 rounded-lg text-sm transition-colors",
                                    isActive(subItem.href)
                                      ? "bg-primary/10 text-primary font-medium"
                                      : "text-muted-foreground hover:bg-muted hover:text-foreground"
                                  )}
                                  onClick={() => setOpen(false)}
                                >
                                  <SubIcon className="h-4 w-4" />
                                  <span>{subItem.label}</span>
                                </Link>
                              </li>
                            );
                          })}
                        </ul>
                      </CollapsibleContent>
                    </Collapsible>
                  </li>
                );
              })}
            </ul>
          </nav>

          {/* Footer Actions */}
          <div className="p-4 border-t space-y-2">
            {/* Command Palette Hint */}
            <div className="flex items-center justify-between px-3 py-2 rounded-lg bg-muted text-xs text-muted-foreground">
              <div className="flex items-center gap-2">
                <Command className="h-4 w-4" />
                <span>빠른 검색</span>
              </div>
              <kbd className="px-1.5 py-0.5 rounded bg-background text-xs">Ctrl+K</kbd>
            </div>

            {/* Theme Toggle */}
            <Button
              variant="outline"
              className="w-full justify-start gap-3"
              onClick={toggleTheme}
            >
              {theme === "dark" ? (
                <>
                  <Sun className="h-4 w-4" />
                  <span>라이트 모드</span>
                </>
              ) : (
                <>
                  <Moon className="h-4 w-4" />
                  <span>다크 모드</span>
                </>
              )}
            </Button>
          </div>
        </div>
      </SheetContent>
    </Sheet>
  );
}

export default MobileNavDrawer;

```

---

## frontend/src/components/NavLink.tsx

```tsx
import { NavLink as RouterNavLink, NavLinkProps } from "react-router-dom";
import { forwardRef } from "react";
import { cn } from "@/lib/utils";

interface NavLinkCompatProps extends Omit<NavLinkProps, "className"> {
  className?: string;
  activeClassName?: string;
  pendingClassName?: string;
}

const NavLink = forwardRef<HTMLAnchorElement, NavLinkCompatProps>(
  ({ className, activeClassName, pendingClassName, to, ...props }, ref) => {
    return (
      <RouterNavLink
        ref={ref}
        to={to}
        className={({ isActive, isPending }) =>
          cn(className, isActive && activeClassName, isPending && pendingClassName)
        }
        {...props}
      />
    );
  },
);

NavLink.displayName = "NavLink";

export { NavLink };

```

---

## frontend/src/components/PriorityUrlEditor.tsx

```tsx
import { useState, useCallback, useEffect } from "react";
import { Link } from "react-router-dom";
import {
  Plus,
  X,
  Link as LinkIcon,
  FolderOpen,
  Shield,
  AlertTriangle,
  ChevronDown,
  ChevronUp,
  GripVertical,
  ExternalLink,
} from "lucide-react";
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from "@/components/ui/card";
import { Button } from "@/components/ui/button";
import { Input } from "@/components/ui/input";
import { Badge } from "@/components/ui/badge";
import { Collapsible, CollapsibleContent, CollapsibleTrigger } from "@/components/ui/collapsible";
import {
  Tooltip,
  TooltipContent,
  TooltipProvider,
  TooltipTrigger,
} from "@/components/ui/tooltip";
import { useToast } from "@/hooks/use-toast";

// Types
export interface PriorityUrl {
  id: string;
  url: string;
  name: string;
  reliability?: "high" | "medium" | "low" | "unknown";
}

interface PriorityUrlEditorProps {
  /** Storage key for sessionStorage */
  storageKey: string;
  /** Current priority URLs */
  urls: PriorityUrl[];
  /** Callback when URLs change */
  onUrlsChange: (urls: PriorityUrl[]) => void;
  /** Whether the editor is disabled */
  disabled?: boolean;
  /** Maximum number of URLs allowed */
  maxUrls?: number;
  /** Title for the card */
  title?: string;
  /** Description for the card */
  description?: string;
  /** Whether to show in collapsed mode initially */
  defaultCollapsed?: boolean;
  /** Custom class name */
  className?: string;
}

// Known reliable domains
const HIGH_RELIABILITY_DOMAINS = [
  "wikipedia.org",
  "namu.wiki",
  "britannica.com",
  "scholar.google.com",
  "pubmed.ncbi.nlm.nih.gov",
  "nature.com",
  "science.org",
  "reuters.com",
  "apnews.com",
  "bbc.com",
  "bbc.co.uk",
  "nytimes.com",
  "washingtonpost.com",
  "theguardian.com",
  "gov.kr",
  "korea.kr",
  "bok.or.kr",
  "kosis.kr",
  "kostat.go.kr",
];

const MEDIUM_RELIABILITY_DOMAINS = [
  "yonhapnews.co.kr",
  "chosun.com",
  "donga.com",
  "joongang.co.kr",
  "hani.co.kr",
  "khan.co.kr",
  "kmib.co.kr",
  "mk.co.kr",
  "mt.co.kr",
  "hankyung.com",
  "yna.co.kr",
  "kbs.co.kr",
  "mbc.co.kr",
  "sbs.co.kr",
  "jtbc.co.kr",
  "cnn.com",
  "forbes.com",
  "bloomberg.com",
];

function getReliabilityFromUrl(url: string): PriorityUrl["reliability"] {
  try {
    const hostname = new URL(url).hostname.toLowerCase();
    
    // Check high reliability
    if (HIGH_RELIABILITY_DOMAINS.some((d) => hostname.includes(d))) {
      return "high";
    }
    
    // Check medium reliability
    if (MEDIUM_RELIABILITY_DOMAINS.some((d) => hostname.includes(d))) {
      return "medium";
    }
    
    // Government or educational domains
    if (hostname.endsWith(".gov") || hostname.endsWith(".edu") || hostname.endsWith(".ac.kr") || hostname.endsWith(".go.kr")) {
      return "high";
    }
    
    return "unknown";
  } catch {
    return "unknown";
  }
}

function generateUrlId(): string {
  return `url_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
}

function getHostname(url: string): string {
  try {
    return new URL(url).hostname;
  } catch {
    return url;
  }
}

const ReliabilityBadge = ({ reliability }: { reliability: PriorityUrl["reliability"] }) => {
  switch (reliability) {
    case "high":
      return (
        <TooltipProvider>
          <Tooltip>
            <TooltipTrigger asChild>
              <Badge variant="outline" className="bg-green-50 text-green-700 border-green-200 dark:bg-green-900/30 dark:text-green-400 dark:border-green-800">
                <Shield className="h-3 w-3 mr-1" />
                신뢰
              </Badge>
            </TooltipTrigger>
            <TooltipContent>
              <p>높은 신뢰도: 공식 기관, 학술 사이트</p>
            </TooltipContent>
          </Tooltip>
        </TooltipProvider>
      );
    case "medium":
      return (
        <TooltipProvider>
          <Tooltip>
            <TooltipTrigger asChild>
              <Badge variant="outline" className="bg-blue-50 text-blue-700 border-blue-200 dark:bg-blue-900/30 dark:text-blue-400 dark:border-blue-800">
                <Shield className="h-3 w-3 mr-1" />
                보통
              </Badge>
            </TooltipTrigger>
            <TooltipContent>
              <p>일반 신뢰도: 주요 언론사</p>
            </TooltipContent>
          </Tooltip>
        </TooltipProvider>
      );
    case "low":
      return (
        <TooltipProvider>
          <Tooltip>
            <TooltipTrigger asChild>
              <Badge variant="outline" className="bg-orange-50 text-orange-700 border-orange-200 dark:bg-orange-900/30 dark:text-orange-400 dark:border-orange-800">
                <AlertTriangle className="h-3 w-3 mr-1" />
                주의
              </Badge>
            </TooltipTrigger>
            <TooltipContent>
              <p>낮은 신뢰도: 검증 필요</p>
            </TooltipContent>
          </Tooltip>
        </TooltipProvider>
      );
    default:
      return null;
  }
};

export const PriorityUrlEditor = ({
  storageKey,
  urls,
  onUrlsChange,
  disabled = false,
  maxUrls = 10,
  title = "참고 URL",
  description = "분석 시 우선적으로 참고할 URL을 추가하세요.",
  defaultCollapsed = false,
  className = "",
}: PriorityUrlEditorProps) => {
  const { toast } = useToast();
  const [newUrl, setNewUrl] = useState("");
  const [isExpanded, setIsExpanded] = useState(!defaultCollapsed);
  const [isAdding, setIsAdding] = useState(false);

  // Persist to sessionStorage when URLs change
  useEffect(() => {
    if (urls.length > 0) {
      sessionStorage.setItem(storageKey, JSON.stringify(urls));
    } else {
      sessionStorage.removeItem(storageKey);
    }
  }, [urls, storageKey]);

  // Validate URL
  const isValidUrl = useCallback((url: string): boolean => {
    try {
      new URL(url);
      return true;
    } catch {
      return false;
    }
  }, []);

  // Add new URL
  const handleAddUrl = useCallback(() => {
    const trimmedUrl = newUrl.trim();
    
    if (!trimmedUrl) {
      toast({
        title: "URL을 입력하세요",
        variant: "destructive",
      });
      return;
    }

    // Add https:// if missing protocol
    let urlToAdd = trimmedUrl;
    if (!trimmedUrl.startsWith("http://") && !trimmedUrl.startsWith("https://")) {
      urlToAdd = `https://${trimmedUrl}`;
    }

    if (!isValidUrl(urlToAdd)) {
      toast({
        title: "유효하지 않은 URL입니다",
        description: "올바른 URL 형식을 입력하세요.",
        variant: "destructive",
      });
      return;
    }

    // Check for duplicates
    if (urls.some((u) => u.url === urlToAdd)) {
      toast({
        title: "이미 추가된 URL입니다",
        variant: "destructive",
      });
      return;
    }

    // Check max limit
    if (urls.length >= maxUrls) {
      toast({
        title: `최대 ${maxUrls}개까지 추가할 수 있습니다`,
        variant: "destructive",
      });
      return;
    }

    const hostname = getHostname(urlToAdd);
    const newPriorityUrl: PriorityUrl = {
      id: generateUrlId(),
      url: urlToAdd,
      name: hostname,
      reliability: getReliabilityFromUrl(urlToAdd),
    };

    onUrlsChange([...urls, newPriorityUrl]);
    setNewUrl("");
    setIsAdding(false);

    toast({
      title: "URL이 추가되었습니다",
      description: hostname,
    });
  }, [newUrl, urls, maxUrls, isValidUrl, onUrlsChange, toast]);

  // Remove URL
  const handleRemoveUrl = useCallback((id: string) => {
    onUrlsChange(urls.filter((u) => u.id !== id));
  }, [urls, onUrlsChange]);

  // Clear all URLs
  const handleClearAll = useCallback(() => {
    onUrlsChange([]);
    toast({
      title: "모든 URL이 제거되었습니다",
    });
  }, [onUrlsChange, toast]);

  // Handle Enter key
  const handleKeyDown = useCallback((e: React.KeyboardEvent) => {
    if (e.key === "Enter") {
      e.preventDefault();
      handleAddUrl();
    }
    if (e.key === "Escape") {
      setIsAdding(false);
      setNewUrl("");
    }
  }, [handleAddUrl]);

  // Empty state - show add button only
  if (urls.length === 0 && !isAdding) {
    return (
      <Card className={`border-dashed border-2 border-muted-foreground/20 ${className}`}>
        <CardContent className="py-6">
          <div className="text-center">
            <FolderOpen className="h-10 w-10 mx-auto text-muted-foreground/50 mb-3" />
            <p className="text-sm text-muted-foreground mb-4">{description}</p>
            <Button
              variant="outline"
              size="sm"
              onClick={() => setIsAdding(true)}
              disabled={disabled}
              className="gap-2"
            >
              <Plus className="h-4 w-4" />
              URL 추가
            </Button>
          </div>
          
          {isAdding && (
            <div className="mt-4 flex gap-2">
              <Input
                value={newUrl}
                onChange={(e) => setNewUrl(e.target.value)}
                onKeyDown={handleKeyDown}
                placeholder="https://example.com"
                autoFocus
                disabled={disabled}
                className="flex-1"
              />
              <Button
                size="sm"
                onClick={handleAddUrl}
                disabled={disabled || !newUrl.trim()}
              >
                추가
              </Button>
              <Button
                size="sm"
                variant="ghost"
                onClick={() => {
                  setIsAdding(false);
                  setNewUrl("");
                }}
              >
                취소
              </Button>
            </div>
          )}
        </CardContent>
      </Card>
    );
  }

  return (
    <Card className={`border-blue-200 dark:border-blue-800 bg-blue-50/50 dark:bg-blue-900/10 ${className}`}>
      <Collapsible open={isExpanded} onOpenChange={setIsExpanded}>
        <CardHeader className="pb-3">
          <div className="flex items-center justify-between">
            <div className="flex items-center gap-2">
              <FolderOpen className="h-5 w-5 text-blue-600" />
              <CardTitle className="text-lg">{title}</CardTitle>
              <Badge variant="secondary">{urls.length}개</Badge>
            </div>
            <div className="flex items-center gap-1">
              {urls.length > 0 && (
                <Button
                  variant="ghost"
                  size="sm"
                  onClick={handleClearAll}
                  disabled={disabled}
                  className="text-muted-foreground hover:text-destructive"
                >
                  <X className="h-4 w-4 mr-1" />
                  모두 제거
                </Button>
              )}
              <CollapsibleTrigger asChild>
                <Button variant="ghost" size="sm">
                  {isExpanded ? <ChevronUp className="h-4 w-4" /> : <ChevronDown className="h-4 w-4" />}
                </Button>
              </CollapsibleTrigger>
            </div>
          </div>
          <CardDescription>{description}</CardDescription>
        </CardHeader>

        <CollapsibleContent>
          <CardContent className="pt-0">
            {/* URL List */}
            <div className="space-y-2 mb-4">
              {urls.map((item) => (
                <div
                  key={item.id}
                  className="flex items-center gap-2 p-2 rounded-lg bg-white dark:bg-gray-800 border border-gray-200 dark:border-gray-700"
                >
                  <GripVertical className="h-4 w-4 text-muted-foreground/50 cursor-grab" />
                  <LinkIcon className="h-4 w-4 text-blue-500 shrink-0" />
                  <div className="flex-1 min-w-0">
                    <div className="flex items-center gap-2">
                      <span className="text-sm font-medium truncate" title={item.url}>
                        {item.name || getHostname(item.url)}
                      </span>
                      {item.reliability && <ReliabilityBadge reliability={item.reliability} />}
                    </div>
                    <a
                      href={item.url}
                      target="_blank"
                      rel="noopener noreferrer"
                      className="text-xs text-muted-foreground hover:text-blue-600 truncate block"
                    >
                      {item.url}
                    </a>
                  </div>
                  <a
                    href={item.url}
                    target="_blank"
                    rel="noopener noreferrer"
                    className="p-1 rounded hover:bg-muted transition-colors"
                    title="새 탭에서 열기"
                  >
                    <ExternalLink className="h-4 w-4 text-muted-foreground" />
                  </a>
                  <button
                    onClick={() => handleRemoveUrl(item.id)}
                    disabled={disabled}
                    className="p-1 rounded hover:bg-destructive/10 transition-colors"
                    title="제거"
                  >
                    <X className="h-4 w-4 text-muted-foreground hover:text-destructive" />
                  </button>
                </div>
              ))}
            </div>

            {/* Add URL Input */}
            {urls.length < maxUrls && (
              <div className="flex gap-2">
                <Input
                  value={newUrl}
                  onChange={(e) => setNewUrl(e.target.value)}
                  onKeyDown={handleKeyDown}
                  placeholder="URL을 입력하세요..."
                  disabled={disabled}
                  className="flex-1 bg-white dark:bg-gray-800"
                />
                <Button
                  size="sm"
                  onClick={handleAddUrl}
                  disabled={disabled || !newUrl.trim()}
                  className="gap-1"
                >
                  <Plus className="h-4 w-4" />
                  추가
                </Button>
              </div>
            )}

            {/* Helper text */}
            <div className="flex items-center justify-between mt-3 text-xs text-muted-foreground">
              <span>
                {urls.length}/{maxUrls}개 URL
              </span>
              <Link to="/url-collections" className="text-blue-600 hover:underline">
                URL 컬렉션에서 가져오기
              </Link>
            </div>
          </CardContent>
        </CollapsibleContent>
      </Collapsible>
    </Card>
  );
};

export default PriorityUrlEditor;

```

---

## frontend/src/components/ProtectedRoute.tsx

```tsx
import { Navigate, useLocation } from 'react-router-dom';
import { useAuth } from '@/contexts/AuthContext';
import { Loader2 } from 'lucide-react';

interface ProtectedRouteProps {
  children: React.ReactNode;
  requiredRole?: 'viewer' | 'operator' | 'admin';
  allowSetup?: boolean; // Allow access even when password change is required (for setup page)
}

export function ProtectedRoute({ children, requiredRole, allowSetup = false }: ProtectedRouteProps) {
  const { isAuthenticated, isLoading, user, passwordChangeRequired } = useAuth();
  const location = useLocation();

  if (isLoading) {
    return (
      <div className="min-h-screen flex items-center justify-center">
        <Loader2 className="h-8 w-8 animate-spin text-primary" />
      </div>
    );
  }

  if (!isAuthenticated) {
    // Redirect to login page, preserving the intended destination
    return <Navigate to="/admin/login" state={{ from: location }} replace />;
  }

  // Check if password change is required (initial setup)
  if (passwordChangeRequired && !allowSetup) {
    // Redirect to setup page
    return <Navigate to="/admin/setup" replace />;
  }

  // Check role if required
  if (requiredRole && user) {
    const roleHierarchy = ['viewer', 'operator', 'admin'];
    const userRoleIndex = roleHierarchy.indexOf(user.role);
    const requiredRoleIndex = roleHierarchy.indexOf(requiredRole);

    if (userRoleIndex < requiredRoleIndex) {
      // User doesn't have sufficient permissions
      return (
        <div className="min-h-screen flex items-center justify-center">
          <div className="text-center">
            <h1 className="text-2xl font-bold mb-2">접근 권한이 없습니다</h1>
            <p className="text-muted-foreground">
              이 페이지에 접근하려면 {requiredRole} 이상의 권한이 필요합니다.
            </p>
          </div>
        </div>
      );
    }
  }

  return <>{children}</>;
}

```

---

## frontend/src/components/QuickAccessPanel.tsx

```tsx
import { useState, useEffect } from 'react';
import { Link } from 'react-router-dom';
import {
  X,
  History,
  Bookmark,
  Search,
  Loader2,
  ChevronRight,
  Clock,
  TrendingUp,
  Zap,
  Brain,
} from 'lucide-react';
import { Button } from '@/components/ui/button';
import { Badge } from '@/components/ui/badge';
import { ScrollArea } from '@/components/ui/scroll-area';
import { Separator } from '@/components/ui/separator';
import { Input } from '@/components/ui/input';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { useSearchHistory } from '@/hooks/useSearchHistory';
import { formatDistanceToNow } from 'date-fns';
import { ko } from 'date-fns/locale';
import type { SearchHistoryRecord } from '@/lib/api';

interface QuickAccessPanelProps {
  isOpen: boolean;
  onClose: () => void;
  onSelectSearch?: (search: SearchHistoryRecord) => void;
}

export const QuickAccessPanel = ({ isOpen, onClose, onSelectSearch }: QuickAccessPanelProps) => {
  const [quickSearchQuery, setQuickSearchQuery] = useState('');
  const [activeTab, setActiveTab] = useState<'recent' | 'bookmarks' | 'ml'>('recent');
  
  const {
    history,
    loading,
    loadHistory,
    loadBookmarked,
  } = useSearchHistory({ pageSize: 5 });

  useEffect(() => {
    if (isOpen) {
      if (activeTab === 'recent') {
        loadHistory(0);
      } else if (activeTab === 'bookmarks') {
        loadBookmarked(0);
      }
    }
  }, [isOpen, activeTab, loadHistory, loadBookmarked]);

  if (!isOpen) return null;

  const handleQuickSearch = (e: React.FormEvent) => {
    e.preventDefault();
    if (quickSearchQuery.trim()) {
      window.location.href = `/search?q=${encodeURIComponent(quickSearchQuery)}`;
    }
  };

  const renderSearchItem = (item: SearchHistoryRecord) => (
    <div
      key={item.id}
      className="p-3 rounded-lg border border-border hover:bg-accent/50 cursor-pointer transition-colors group"
      onClick={() => {
        onSelectSearch?.(item);
        onClose();
      }}
    >
      <div className="flex items-start justify-between gap-2">
        <div className="flex-1 min-w-0">
          <p className="text-sm font-medium truncate">{item.query}</p>
          <div className="flex items-center gap-2 mt-1 text-xs text-muted-foreground">
            <Clock className="h-3 w-3" />
            <span>{formatDistanceToNow(new Date(item.createdAt), { addSuffix: true, locale: ko })}</span>
            {item.resultCount !== undefined && (
              <>
                <span>•</span>
                <span>{item.resultCount}건</span>
              </>
            )}
          </div>
        </div>
        <ChevronRight className="h-4 w-4 text-muted-foreground opacity-0 group-hover:opacity-100 transition-opacity" />
      </div>
    </div>
  );

  return (
    <>
      {/* Backdrop */}
      <div
        className="fixed inset-0 bg-black/20 backdrop-blur-sm z-[100]"
        onClick={onClose}
      />
      
      {/* Panel */}
      <div className="fixed right-0 top-0 h-full w-full sm:w-96 bg-background border-l border-border shadow-2xl z-[101] flex flex-col">
        {/* Header */}
        <div className="p-4 border-b border-border">
          <div className="flex items-center justify-between mb-4">
            <h2 className="text-lg font-semibold">빠른 접근</h2>
            <Button variant="ghost" size="icon" onClick={onClose}>
              <X className="h-4 w-4" />
            </Button>
          </div>

          {/* Quick Search */}
          <form onSubmit={handleQuickSearch}>
            <div className="relative">
              <Search className="absolute left-3 top-1/2 -translate-y-1/2 h-4 w-4 text-muted-foreground" />
              <Input
                value={quickSearchQuery}
                onChange={(e) => setQuickSearchQuery(e.target.value)}
                placeholder="빠른 검색..."
                className="pl-9"
              />
            </div>
          </form>
        </div>

        {/* Tabs */}
        <div className="flex gap-1 p-2 border-b border-border">
          <Button
            variant={activeTab === 'recent' ? 'secondary' : 'ghost'}
            size="sm"
            onClick={() => setActiveTab('recent')}
            className="flex-1"
          >
            <History className="h-4 w-4 mr-2" />
            최근 검색
          </Button>
          <Button
            variant={activeTab === 'bookmarks' ? 'secondary' : 'ghost'}
            size="sm"
            onClick={() => setActiveTab('bookmarks')}
            className="flex-1"
          >
            <Bookmark className="h-4 w-4 mr-2" />
            북마크
          </Button>
          <Button
            variant={activeTab === 'ml' ? 'secondary' : 'ghost'}
            size="sm"
            onClick={() => setActiveTab('ml')}
            className="flex-1"
          >
            <Brain className="h-4 w-4 mr-2" />
            ML
          </Button>
        </div>

        {/* Content */}
        <ScrollArea className="flex-1 p-4">
          {loading ? (
            <div className="flex items-center justify-center py-8">
              <Loader2 className="h-6 w-6 animate-spin text-muted-foreground" />
            </div>
          ) : activeTab === 'recent' || activeTab === 'bookmarks' ? (
            <div className="space-y-2">
              {history.length === 0 ? (
                <div className="text-center py-8 text-muted-foreground">
                  <p className="text-sm">
                    {activeTab === 'recent' ? '검색 기록이 없습니다' : '북마크가 없습니다'}
                  </p>
                </div>
              ) : (
                history.map(renderSearchItem)
              )}
              
              {history.length > 0 && (
                <Link
                  to="/history"
                  className="block text-center py-2 text-sm text-primary hover:underline"
                  onClick={onClose}
                >
                  전체 보기
                </Link>
              )}
            </div>
          ) : (
            <div className="space-y-3">
              {/* ML Training Quick Access */}
              <Card>
                <CardHeader className="pb-3">
                  <CardTitle className="text-sm flex items-center gap-2">
                    <Brain className="h-4 w-4" />
                    ML 학습
                  </CardTitle>
                </CardHeader>
                <CardContent className="space-y-2">
                  <Link to="/ml-training" onClick={onClose}>
                    <Button variant="outline" size="sm" className="w-full justify-start">
                      <Zap className="h-4 w-4 mr-2" />
                      학습 대시보드
                    </Button>
                  </Link>
                  <Link to="/ml-results" onClick={onClose}>
                    <Button variant="outline" size="sm" className="w-full justify-start">
                      <TrendingUp className="h-4 w-4 mr-2" />
                      분석 결과
                    </Button>
                  </Link>
                </CardContent>
              </Card>

              {/* ML Addons */}
              <Card>
                <CardHeader className="pb-3">
                  <CardTitle className="text-sm">ML Add-ons</CardTitle>
                </CardHeader>
                <CardContent>
                  <Link to="/ml-addons" onClick={onClose}>
                    <Button variant="outline" size="sm" className="w-full justify-start">
                      Add-on 관리
                    </Button>
                  </Link>
                </CardContent>
              </Card>
            </div>
          )}
        </ScrollArea>

        {/* Footer - Quick Links */}
        <div className="p-4 border-t border-border space-y-2">
          <div className="text-xs text-muted-foreground mb-2">빠른 링크</div>
          <div className="grid grid-cols-2 gap-2">
            <Link to="/search" onClick={onClose}>
              <Button variant="outline" size="sm" className="w-full">
                <Search className="h-3 w-3 mr-1" />
                검색
              </Button>
            </Link>
            <Link to="/history" onClick={onClose}>
              <Button variant="outline" size="sm" className="w-full">
                <History className="h-3 w-3 mr-1" />
                기록
              </Button>
            </Link>
            <Link to="/projects" onClick={onClose}>
              <Button variant="outline" size="sm" className="w-full">
                프로젝트
              </Button>
            </Link>
            <Link to="/settings" onClick={onClose}>
              <Button variant="outline" size="sm" className="w-full">
                설정
              </Button>
            </Link>
          </div>
        </div>
      </div>
    </>
  );
};

export default QuickAccessPanel;

```

---

## frontend/src/components/ReportExportButton.tsx

```tsx
import { useState, useCallback } from 'react';
import { FileText, Loader2 } from 'lucide-react';
import { Button } from '@/components/ui/button';
import {
  Dialog,
  DialogContent,
  DialogDescription,
  DialogFooter,
  DialogHeader,
  DialogTitle,
  DialogTrigger,
} from '@/components/ui/dialog';
import { Checkbox } from '@/components/ui/checkbox';
import { Label } from '@/components/ui/label';
import { toast } from 'sonner';
import {
  exportUnifiedSearchReport,
  exportDeepSearchReport,
  triggerPdfDownload,
  type ReportRequest,
  type ReportSection,
  type ReportType,
  DEFAULT_REPORT_SECTIONS,
} from '@/lib/api';
import type { ChartExportHandle } from '@/components/charts';

interface ReportExportButtonProps {
  /** Job ID for the search */
  jobId: string;
  /** Search query */
  query: string;
  /** Time window (1d, 7d, 30d) */
  timeWindow?: string;
  /** Report type */
  reportType?: ReportType;
  /** Chart refs for capturing chart images */
  chartRefs?: Record<string, React.RefObject<ChartExportHandle>>;
  /** Button variant */
  variant?: 'default' | 'outline' | 'ghost' | 'secondary';
  /** Button size */
  size?: 'default' | 'sm' | 'lg' | 'icon';
  /** Additional CSS classes */
  className?: string;
  /** Disable the button */
  disabled?: boolean;
}

interface SectionOption {
  id: ReportSection;
  label: string;
  description: string;
}

const ALL_SECTIONS: SectionOption[] = [
  { id: 'COVER', label: '표지', description: '보고서 표지 및 기본 정보' },
  { id: 'EXECUTIVE_SUMMARY', label: '요약', description: 'AI 분석 요약 및 핵심 인사이트' },
  { id: 'DATA_SOURCE', label: '데이터 소스', description: '검색 소스별 결과 분포' },
  { id: 'TREND_ANALYSIS', label: '트렌드 분석', description: '시간대별 기사 추이' },
  { id: 'KEYWORD_ANALYSIS', label: '키워드 분석', description: '주요 키워드 및 빈도' },
  { id: 'SENTIMENT_ANALYSIS', label: '감정 분석', description: '긍정/부정/중립 분포' },
  { id: 'RELIABILITY', label: '신뢰도 분석', description: '출처별 신뢰도 평가' },
  { id: 'BIAS_ANALYSIS', label: '편향성 분석', description: '정치적/이념적 편향 분석' },
  { id: 'FACTCHECK', label: '팩트체크', description: '주요 주장 검증 결과' },
  { id: 'EVIDENCE_LIST', label: '증거 목록', description: '수집된 증거 및 출처' },
  { id: 'DETAILED_RESULTS', label: '상세 결과', description: '개별 기사 상세 정보' },
];

/**
 * PDF 보고서 내보내기 버튼 컴포넌트
 * 
 * 차트 이미지를 캡처하고 PDF 보고서를 생성합니다.
 */
export function ReportExportButton({
  jobId,
  query,
  timeWindow = '7d',
  reportType = 'UNIFIED_SEARCH',
  chartRefs,
  variant = 'default',
  size = 'default',
  className,
  disabled = false,
}: ReportExportButtonProps) {
  const [isOpen, setIsOpen] = useState(false);
  const [isExporting, setIsExporting] = useState(false);
  const [selectedSections, setSelectedSections] = useState<ReportSection[]>(
    DEFAULT_REPORT_SECTIONS[reportType]
  );

  const captureChartImages = useCallback((): Record<string, string> => {
    const images: Record<string, string> = {};
    
    if (chartRefs) {
      for (const [key, ref] of Object.entries(chartRefs)) {
        if (ref.current) {
          const base64 = ref.current.toBase64();
          if (base64) {
            images[key] = base64;
          }
        }
      }
    }
    
    return images;
  }, [chartRefs]);

  const handleExport = async () => {
    setIsExporting(true);
    
    try {
      // Capture chart images
      const chartImages = captureChartImages();
      
      const request: ReportRequest = {
        reportType,
        targetId: jobId,
        query,
        timeWindow,
        includeSections: selectedSections,
        chartImages,
        language: 'ko',
      };

      let blob: Blob;
      
      if (reportType === 'DEEP_SEARCH') {
        blob = await exportDeepSearchReport(jobId, request);
      } else {
        blob = await exportUnifiedSearchReport(jobId, request);
      }

      // Generate filename
      const timestamp = new Date().toISOString().slice(0, 10).replace(/-/g, '');
      const safeQuery = query.replace(/[^가-힣a-zA-Z0-9]/g, '_').slice(0, 30);
      const typeLabel = reportType === 'DEEP_SEARCH' ? 'DeepSearch' : '통합검색';
      const filename = `NewsInsight_${typeLabel}_${safeQuery}_${timestamp}.pdf`;

      // Trigger download
      triggerPdfDownload(blob, filename);
      
      toast.success('PDF 보고서가 다운로드되었습니다.');
      setIsOpen(false);
    } catch (error) {
      console.error('Report export failed:', error);
      toast.error('보고서 생성에 실패했습니다. 다시 시도해주세요.');
    } finally {
      setIsExporting(false);
    }
  };

  const toggleSection = (sectionId: ReportSection) => {
    setSelectedSections((prev) =>
      prev.includes(sectionId)
        ? prev.filter((s) => s !== sectionId)
        : [...prev, sectionId]
    );
  };

  const selectAll = () => {
    setSelectedSections(ALL_SECTIONS.map((s) => s.id));
  };

  const selectDefault = () => {
    setSelectedSections(DEFAULT_REPORT_SECTIONS[reportType]);
  };

  const availableSections = ALL_SECTIONS.filter((section) => {
    // Filter sections based on report type
    if (reportType === 'UNIFIED_SEARCH') {
      return section.id !== 'EVIDENCE_LIST';
    }
    if (reportType === 'DEEP_SEARCH') {
      return section.id !== 'TREND_ANALYSIS' && section.id !== 'KEYWORD_ANALYSIS';
    }
    return true;
  });

  return (
    <Dialog open={isOpen} onOpenChange={setIsOpen}>
      <DialogTrigger asChild>
        <Button
          variant={variant}
          size={size}
          className={className}
          disabled={disabled || !jobId}
        >
          <FileText className="h-4 w-4 mr-2" />
          PDF 보고서
        </Button>
      </DialogTrigger>
      <DialogContent className="sm:max-w-[500px]">
        <DialogHeader>
          <DialogTitle>PDF 보고서 내보내기</DialogTitle>
          <DialogDescription>
            보고서에 포함할 섹션을 선택하세요.
          </DialogDescription>
        </DialogHeader>

        <div className="py-4">
          {/* Quick actions */}
          <div className="flex gap-2 mb-4">
            <Button variant="outline" size="sm" onClick={selectAll}>
              전체 선택
            </Button>
            <Button variant="outline" size="sm" onClick={selectDefault}>
              기본값
            </Button>
          </div>

          {/* Section selection */}
          <div className="space-y-3 max-h-[300px] overflow-y-auto pr-2">
            {availableSections.map((section) => (
              <div
                key={section.id}
                className="flex items-start space-x-3 p-2 rounded-lg hover:bg-muted/50 transition-colors"
              >
                <Checkbox
                  id={section.id}
                  checked={selectedSections.includes(section.id)}
                  onCheckedChange={() => toggleSection(section.id)}
                />
                <div className="flex-1">
                  <Label
                    htmlFor={section.id}
                    className="text-sm font-medium cursor-pointer"
                  >
                    {section.label}
                  </Label>
                  <p className="text-xs text-muted-foreground">
                    {section.description}
                  </p>
                </div>
              </div>
            ))}
          </div>

          {/* Summary */}
          <div className="mt-4 pt-4 border-t text-sm text-muted-foreground">
            {selectedSections.length}개 섹션 선택됨
          </div>
        </div>

        <DialogFooter>
          <Button variant="outline" onClick={() => setIsOpen(false)}>
            취소
          </Button>
          <Button
            onClick={handleExport}
            disabled={isExporting || selectedSections.length === 0}
          >
            {isExporting ? (
              <>
                <Loader2 className="h-4 w-4 mr-2 animate-spin" />
                생성 중...
              </>
            ) : (
              <>
                <FileText className="h-4 w-4 mr-2" />
                내보내기
              </>
            )}
          </Button>
        </DialogFooter>
      </DialogContent>
    </Dialog>
  );
}

export default ReportExportButton;

```

---

## frontend/src/components/SearchBar.tsx

```tsx
import { useState } from "react";
import { Search } from "lucide-react";
import { Button } from "@/components/ui/button";
import { Input } from "@/components/ui/input";
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from "@/components/ui/select";
import { Card } from "@/components/ui/card";

interface SearchBarProps {
  onSearch: (query: string, window: string) => void;
  isLoading?: boolean;
}

export function SearchBar({ onSearch, isLoading = false }: SearchBarProps) {
  const [query, setQuery] = useState("");
  const [window, setWindow] = useState("7d");

  const handleSubmit = (e: React.FormEvent) => {
    e.preventDefault();
    if (query.trim()) {
      onSearch(query.trim(), window);
    }
  };

  return (
    <Card className="p-6 shadow-elegant card-hover">
      <form onSubmit={handleSubmit} className="space-y-4">
        <div className="flex flex-col sm:flex-row gap-4">
          <div className="flex-1">
            <Input
              type="text"
              placeholder="분석하고 싶은 키워드를 입력하세요..."
              value={query}
              onChange={(e) => setQuery(e.target.value)}
              disabled={isLoading}
              className="h-12 text-base"
            />
          </div>
          <div className="w-full sm:w-40">
            <Select value={window} onValueChange={setWindow} disabled={isLoading}>
              <SelectTrigger className="h-12">
                <SelectValue />
              </SelectTrigger>
              <SelectContent className="bg-card z-50">
                <SelectItem value="1d">최근 1일</SelectItem>
                <SelectItem value="7d">최근 7일</SelectItem>
                <SelectItem value="30d">최근 30일</SelectItem>
              </SelectContent>
            </Select>
          </div>
          <Button
            type="submit"
            disabled={isLoading || !query.trim()}
            variant="gradient"
            size="lg"
            className="w-full sm:w-auto"
          >
            {isLoading ? (
              <>
                <div className="h-4 w-4 animate-spin rounded-full border-2 border-current border-t-transparent" />
                분석 중...
              </>
            ) : (
              <>
                <Search className="h-5 w-5" />
                분석하기
              </>
            )}
          </Button>
        </div>
      </form>
    </Card>
  );
}

```

---

## frontend/src/components/SearchHistoryPanel.tsx

```tsx
import { useState, useEffect, useCallback } from 'react';
import { useSearchHistory, useSearchHistorySSE } from '@/hooks/useSearchHistory';
import type { SearchHistoryRecord, SearchHistoryType } from '@/lib/api';
import { updateSearchNotes, getSearchHistoryById } from '@/lib/api';
import { formatDistanceToNow } from 'date-fns';
import { ko } from 'date-fns/locale';
import { toast } from 'sonner';

interface SearchHistoryPanelProps {
  onSelectSearch?: (search: SearchHistoryRecord) => void;
  onDeriveSearch?: (search: SearchHistoryRecord) => void;
  className?: string;
  enableRealtime?: boolean;
}

const searchTypeLabels: Record<SearchHistoryType, string> = {
  UNIFIED: '통합검색',
  DEEP_SEARCH: '딥서치',
  FACT_CHECK: '팩트체크',
  BROWSER_AGENT: '브라우저 에이전트',
};

const searchTypeColors: Record<SearchHistoryType, string> = {
  UNIFIED: 'bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200',
  DEEP_SEARCH: 'bg-purple-100 text-purple-800 dark:bg-purple-900 dark:text-purple-200',
  FACT_CHECK: 'bg-green-100 text-green-800 dark:bg-green-900 dark:text-green-200',
  BROWSER_AGENT: 'bg-orange-100 text-orange-800 dark:bg-orange-900 dark:text-orange-200',
};

export function SearchHistoryPanel({
  onSelectSearch,
  onDeriveSearch,
  className = '',
  enableRealtime = true,
}: SearchHistoryPanelProps) {
  const {
    history,
    loading,
    error,
    currentPage,
    totalPages,
    totalElements,
    loadHistory,
    loadBookmarked,
    searchHistory,
    toggleBookmark,
    deleteSearch,
    loadDerivedSearches,
  } = useSearchHistory({ pageSize: 10 });

  const [filter, setFilter] = useState<SearchHistoryType | 'all' | 'bookmarked'>('all');
  const [searchQuery, setSearchQuery] = useState('');
  const [expandedId, setExpandedId] = useState<number | null>(null);
  const [derivedSearches, setDerivedSearches] = useState<Record<number, SearchHistoryRecord[]>>({});
  const [localHistory, setLocalHistory] = useState<SearchHistoryRecord[]>([]);
  const [newItemIds, setNewItemIds] = useState<Set<number>>(new Set());
  
  // Notes editing state
  const [editingNotesId, setEditingNotesId] = useState<number | null>(null);
  const [notesValue, setNotesValue] = useState('');
  const [savingNotes, setSavingNotes] = useState(false);

  // Sync local history with server history
  useEffect(() => {
    setLocalHistory(history);
  }, [history]);

  // SSE real-time updates
  const { connected: sseConnected } = useSearchHistorySSE({
    enabled: enableRealtime,
    onNewSearch: useCallback((newSearch: SearchHistoryRecord) => {
      // Only add if we're on page 0 and filter matches
      if (currentPage === 0) {
        const matchesFilter = 
          filter === 'all' || 
          (filter === 'bookmarked' && newSearch.bookmarked) ||
          filter === newSearch.searchType;
        
        if (matchesFilter && !newSearch.parentSearchId) {
          setLocalHistory(prev => {
            // Prevent duplicates
            if (prev.some(item => item.id === newSearch.id)) {
              return prev;
            }
            // Add to the beginning
            return [newSearch, ...prev];
          });
          // Mark as new for highlight animation
          setNewItemIds(prev => new Set([...prev, newSearch.id]));
          // Remove highlight after animation
          setTimeout(() => {
            setNewItemIds(prev => {
              const next = new Set(prev);
              next.delete(newSearch.id);
              return next;
            });
          }, 3000);
        }
      }
    }, [currentPage, filter]),
    onUpdatedSearch: useCallback((updatedSearch: SearchHistoryRecord) => {
      setLocalHistory(prev => prev.map(item => 
        item.id === updatedSearch.id ? updatedSearch : item
      ));
    }, []),
    onDeletedSearch: useCallback((id: number) => {
      setLocalHistory(prev => prev.filter(item => item.id !== id));
    }, []),
  });

  // Load initial data
  useEffect(() => {
    loadHistory(0);
  }, [loadHistory]);

  // Handle filter change
  const handleFilterChange = useCallback((newFilter: SearchHistoryType | 'all' | 'bookmarked') => {
    setFilter(newFilter);
    setSearchQuery('');
    if (newFilter === 'bookmarked') {
      loadBookmarked(0);
    } else if (newFilter === 'all') {
      loadHistory(0);
    } else {
      loadHistory(0, newFilter);
    }
  }, [loadHistory, loadBookmarked]);

  // Handle search
  const handleSearch = useCallback((e: React.FormEvent) => {
    e.preventDefault();
    if (searchQuery.trim()) {
      searchHistory(searchQuery.trim(), 0);
    } else {
      loadHistory(0);
    }
  }, [searchQuery, searchHistory, loadHistory]);

  // Handle page change
  const handlePageChange = useCallback((page: number) => {
    if (searchQuery.trim()) {
      searchHistory(searchQuery.trim(), page);
    } else if (filter === 'bookmarked') {
      loadBookmarked(page);
    } else if (filter === 'all') {
      loadHistory(page);
    } else {
      loadHistory(page, filter);
    }
  }, [searchQuery, filter, searchHistory, loadBookmarked, loadHistory]);

  // Handle expand to show derived searches
  const handleExpand = useCallback(async (id: number) => {
    if (expandedId === id) {
      setExpandedId(null);
      return;
    }
    setExpandedId(id);
    if (!derivedSearches[id]) {
      const derived = await loadDerivedSearches(id);
      setDerivedSearches(prev => ({ ...prev, [id]: derived }));
    }
  }, [expandedId, derivedSearches, loadDerivedSearches]);

  // Handle bookmark toggle
  const handleToggleBookmark = useCallback(async (id: number, e: React.MouseEvent) => {
    e.stopPropagation();
    await toggleBookmark(id);
  }, [toggleBookmark]);

  // Handle delete
  const handleDelete = useCallback(async (id: number, e: React.MouseEvent) => {
    e.stopPropagation();
    if (window.confirm('이 검색 기록을 삭제하시겠습니까?')) {
      await deleteSearch(id);
    }
  }, [deleteSearch]);

  // Handle notes editing
  const handleStartEditNotes = useCallback((item: SearchHistoryRecord, e: React.MouseEvent) => {
    e.stopPropagation();
    setEditingNotesId(item.id);
    setNotesValue(item.notes || '');
  }, []);

  const handleSaveNotes = useCallback(async (id: number, e: React.MouseEvent) => {
    e.stopPropagation();
    setSavingNotes(true);
    try {
      const updated = await updateSearchNotes(id, notesValue);
      setLocalHistory(prev => prev.map(item => 
        item.id === id ? { ...item, notes: updated.notes } : item
      ));
      setEditingNotesId(null);
      setNotesValue('');
    } catch (err) {
      console.error('Failed to save notes:', err);
      alert('노트 저장에 실패했습니다.');
    } finally {
      setSavingNotes(false);
    }
  }, [notesValue]);

  const handleCancelEditNotes = useCallback((e: React.MouseEvent) => {
    e.stopPropagation();
    setEditingNotesId(null);
    setNotesValue('');
  }, []);

  // Export AI report from search history
  const handleExportAiReport = useCallback(async (item: SearchHistoryRecord, format: 'markdown' | 'html' | 'text', e: React.MouseEvent) => {
    e.stopPropagation();
    
    try {
      // Fetch full record with aiSummary if not already loaded
      let aiContent: string | undefined;
      
      if (item.aiSummary && typeof item.aiSummary === 'object') {
        const summary = item.aiSummary as Record<string, unknown>;
        aiContent = summary.content as string || summary.summary as string;
      }
      
      // If no content in the current item, fetch from server
      if (!aiContent && item.id) {
        const fullRecord = await getSearchHistoryById(item.id);
        if (fullRecord.aiSummary && typeof fullRecord.aiSummary === 'object') {
          const summary = fullRecord.aiSummary as Record<string, unknown>;
          aiContent = summary.content as string || summary.summary as string;
        }
      }
      
      if (!aiContent) {
        toast.error('내보낼 AI 분석 내용이 없습니다.');
        return;
      }
      
      const timestamp = new Date().toISOString().slice(0, 10).replace(/-/g, '');
      const safeQuery = item.query.replace(/[^가-힣a-zA-Z0-9]/g, '_').slice(0, 30);
      const baseFilename = `NewsInsight_${searchTypeLabels[item.searchType]}_${safeQuery}_${timestamp}`;
      
      let content: string;
      let mimeType: string;
      let extension: string;
      
      if (format === 'markdown') {
        content = `# NewsInsight AI 분석 보고서

**검색어**: ${item.query}  
**검색 유형**: ${searchTypeLabels[item.searchType]}  
**생성 시간**: ${new Date(item.createdAt).toLocaleString('ko-KR')}

---

${aiContent}

---

*이 보고서는 NewsInsight AI에 의해 자동 생성되었습니다.*
`;
        mimeType = 'text/markdown;charset=utf-8';
        extension = 'md';
      } else if (format === 'html') {
        content = `<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>NewsInsight AI 분석 - ${item.query}</title>
  <style>
    body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Noto Sans KR', sans-serif; max-width: 800px; margin: 0 auto; padding: 2rem; line-height: 1.6; }
    h1 { color: #7c3aed; border-bottom: 2px solid #7c3aed; padding-bottom: 0.5rem; }
    h2, h3 { color: #374151; margin-top: 1.5rem; }
    .meta { color: #6b7280; font-size: 0.9rem; margin-bottom: 1.5rem; }
    pre { background: #f3f4f6; padding: 1rem; border-radius: 0.5rem; overflow-x: auto; }
  </style>
</head>
<body>
  <h1>NewsInsight AI 분석 보고서</h1>
  <div class="meta">
    <p><strong>검색어:</strong> ${item.query}</p>
    <p><strong>검색 유형:</strong> ${searchTypeLabels[item.searchType]}</p>
    <p><strong>생성 시간:</strong> ${new Date(item.createdAt).toLocaleString('ko-KR')}</p>
  </div>
  <hr>
  <div class="content">
    ${aiContent.replace(/\n/g, '<br>')}
  </div>
  <hr>
  <footer style="color: #9ca3af; font-size: 0.8rem; text-align: center; margin-top: 2rem;">
    이 보고서는 NewsInsight AI에 의해 자동 생성되었습니다.
  </footer>
</body>
</html>`;
        mimeType = 'text/html;charset=utf-8';
        extension = 'html';
      } else {
        // Plain text
        content = `NewsInsight AI 분석 보고서
========================================

검색어: ${item.query}
검색 유형: ${searchTypeLabels[item.searchType]}
생성 시간: ${new Date(item.createdAt).toLocaleString('ko-KR')}

========================================

${aiContent.replace(/[#*`]/g, '')}

========================================

이 보고서는 NewsInsight AI에 의해 자동 생성되었습니다.
`;
        mimeType = 'text/plain;charset=utf-8';
        extension = 'txt';
      }
      
      // Download file
      const blob = new Blob([content], { type: mimeType });
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = `${baseFilename}.${extension}`;
      document.body.appendChild(a);
      a.click();
      document.body.removeChild(a);
      URL.revokeObjectURL(url);
      
      toast.success(`${format === 'markdown' ? 'Markdown' : format === 'html' ? 'HTML' : '텍스트'} 파일이 다운로드되었습니다.`);
    } catch (err) {
      console.error('Failed to export AI report:', err);
      toast.error('AI 보고서 내보내기에 실패했습니다.');
    }
  }, []);

  // Check if item has AI content
  const hasAiContent = useCallback((item: SearchHistoryRecord): boolean => {
    if (!item.aiSummary || typeof item.aiSummary !== 'object') return false;
    const summary = item.aiSummary as Record<string, unknown>;
    return !!(summary.content || summary.summary);
  }, []);

  // Render a single history item
  const renderHistoryItem = (item: SearchHistoryRecord, isChild = false) => {
    const isNew = newItemIds.has(item.id);
    
    return (
      <div
        key={item.id}
        className={`
          border rounded-lg p-3 cursor-pointer transition-all
          hover:border-blue-300 hover:shadow-sm
          ${isChild ? 'ml-6 border-l-4 border-l-purple-400' : ''}
          ${expandedId === item.id ? 'border-blue-500 bg-blue-50 dark:bg-blue-950' : 'border-gray-200 dark:border-gray-700'}
          ${isNew ? 'animate-pulse border-green-400 bg-green-50 dark:bg-green-950' : ''}
        `}
        onClick={() => onSelectSearch?.(item)}
      >
      <div className="flex items-start justify-between gap-2">
        <div className="flex-1 min-w-0">
          {/* Type badge and query */}
          <div className="flex items-center gap-2 mb-1">
            <span className={`text-xs px-2 py-0.5 rounded ${searchTypeColors[item.searchType]}`}>
              {searchTypeLabels[item.searchType]}
            </span>
            {item.depthLevel && item.depthLevel > 0 && (
              <span className="text-xs text-purple-600 dark:text-purple-400">
                드릴다운 Lv.{item.depthLevel}
              </span>
            )}
            {!item.success && (
              <span className="text-xs px-2 py-0.5 rounded bg-red-100 text-red-800 dark:bg-red-900 dark:text-red-200">
                실패
              </span>
            )}
          </div>
          
          {/* Query */}
          <p className="font-medium text-gray-900 dark:text-gray-100 truncate" title={item.query}>
            {item.query}
          </p>
          
          {/* Stats */}
          <div className="flex items-center gap-3 mt-1 text-xs text-gray-500 dark:text-gray-400">
            <span>결과: {item.resultCount ?? 0}건</span>
            {item.credibilityScore !== undefined && (
              <span>신뢰도: {Math.round(item.credibilityScore)}%</span>
            )}
            {item.durationMs !== undefined && (
              <span>{(item.durationMs / 1000).toFixed(1)}초</span>
            )}
            <span>
              {formatDistanceToNow(new Date(item.createdAt), { addSuffix: true, locale: ko })}
            </span>
          </div>
        </div>
        
        {/* Actions */}
        <div className="flex items-center gap-1">
          <button
            onClick={(e) => handleToggleBookmark(item.id, e)}
            className={`p-1.5 rounded hover:bg-gray-100 dark:hover:bg-gray-800 ${
              item.bookmarked ? 'text-yellow-500' : 'text-gray-400'
            }`}
            title={item.bookmarked ? '북마크 해제' : '북마크'}
          >
            <svg className="w-4 h-4" fill={item.bookmarked ? 'currentColor' : 'none'} stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M5 5a2 2 0 012-2h10a2 2 0 012 2v16l-7-3.5L5 21V5z" />
            </svg>
          </button>
          
          {/* Notes button */}
          <button
            onClick={(e) => handleStartEditNotes(item, e)}
            className={`p-1.5 rounded hover:bg-gray-100 dark:hover:bg-gray-800 ${
              item.notes ? 'text-amber-500' : 'text-gray-400'
            }`}
            title={item.notes ? '노트 편집' : '노트 추가'}
          >
            <svg className="w-4 h-4" fill={item.notes ? 'currentColor' : 'none'} stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M11 5H6a2 2 0 00-2 2v11a2 2 0 002 2h11a2 2 0 002-2v-5m-1.414-9.414a2 2 0 112.828 2.828L11.828 15H9v-2.828l8.586-8.586z" />
            </svg>
          </button>
          
          {/* Export AI Report dropdown */}
          {hasAiContent(item) && (
            <div className="relative group">
              <button
                onClick={(e) => e.stopPropagation()}
                className="p-1.5 rounded hover:bg-gray-100 dark:hover:bg-gray-800 text-green-500 hover:text-green-600"
                title="AI 보고서 내보내기"
              >
                <svg className="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M4 16v1a3 3 0 003 3h10a3 3 0 003-3v-1m-4-4l-4 4m0 0l-4-4m4 4V4" />
                </svg>
              </button>
              {/* Dropdown menu */}
              <div className="absolute right-0 top-full mt-1 w-40 bg-white dark:bg-gray-800 rounded-lg shadow-lg border border-gray-200 dark:border-gray-700 opacity-0 invisible group-hover:opacity-100 group-hover:visible transition-all z-10">
                <button
                  onClick={(e) => handleExportAiReport(item, 'markdown', e)}
                  className="w-full px-3 py-2 text-left text-sm hover:bg-gray-100 dark:hover:bg-gray-700 rounded-t-lg flex items-center gap-2"
                >
                  <svg className="w-4 h-4 text-blue-500" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z" />
                  </svg>
                  Markdown
                </button>
                <button
                  onClick={(e) => handleExportAiReport(item, 'html', e)}
                  className="w-full px-3 py-2 text-left text-sm hover:bg-gray-100 dark:hover:bg-gray-700 flex items-center gap-2"
                >
                  <svg className="w-4 h-4 text-orange-500" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M10 20l4-16m4 4l4 4-4 4M6 16l-4-4 4-4" />
                  </svg>
                  HTML
                </button>
                <button
                  onClick={(e) => handleExportAiReport(item, 'text', e)}
                  className="w-full px-3 py-2 text-left text-sm hover:bg-gray-100 dark:hover:bg-gray-700 rounded-b-lg flex items-center gap-2"
                >
                  <svg className="w-4 h-4 text-gray-500" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z" />
                  </svg>
                  텍스트
                </button>
              </div>
            </div>
          )}
          
          {onDeriveSearch && (
            <button
              onClick={(e) => {
                e.stopPropagation();
                onDeriveSearch(item);
              }}
              className="p-1.5 rounded hover:bg-gray-100 dark:hover:bg-gray-800 text-gray-400 hover:text-blue-500"
              title="파생 검색"
            >
              <svg className="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M13 7l5 5m0 0l-5 5m5-5H6" />
              </svg>
            </button>
          )}
          
          <button
            onClick={(e) => handleExpand(item.id)}
            className="p-1.5 rounded hover:bg-gray-100 dark:hover:bg-gray-800 text-gray-400"
            title="드릴다운 기록 보기"
          >
            <svg className={`w-4 h-4 transition-transform ${expandedId === item.id ? 'rotate-180' : ''}`} fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M19 9l-7 7-7-7" />
            </svg>
          </button>
          
          <button
            onClick={(e) => handleDelete(item.id, e)}
            className="p-1.5 rounded hover:bg-gray-100 dark:hover:bg-gray-800 text-gray-400 hover:text-red-500"
            title="삭제"
          >
            <svg className="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M19 7l-.867 12.142A2 2 0 0116.138 21H7.862a2 2 0 01-1.995-1.858L5 7m5 4v6m4-6v6m1-10V4a1 1 0 00-1-1h-4a1 1 0 00-1 1v3M4 7h16" />
            </svg>
          </button>
        </div>
      </div>
      
      {/* Notes display/edit section */}
      {(item.notes || editingNotesId === item.id) && (
        <div className="mt-2 pt-2 border-t border-gray-200 dark:border-gray-700" onClick={(e) => e.stopPropagation()}>
          {editingNotesId === item.id ? (
            <div className="space-y-2">
              <textarea
                value={notesValue}
                onChange={(e) => setNotesValue(e.target.value)}
                placeholder="검색에 대한 메모를 입력하세요..."
                className="w-full px-2 py-1.5 text-sm border border-gray-300 dark:border-gray-600 rounded bg-white dark:bg-gray-800 text-gray-900 dark:text-gray-100 resize-none"
                rows={3}
                autoFocus
              />
              <div className="flex justify-end gap-2">
                <button
                  onClick={handleCancelEditNotes}
                  className="px-2 py-1 text-xs rounded bg-gray-200 dark:bg-gray-700 text-gray-700 dark:text-gray-300 hover:bg-gray-300 dark:hover:bg-gray-600"
                >
                  취소
                </button>
                <button
                  onClick={(e) => handleSaveNotes(item.id, e)}
                  disabled={savingNotes}
                  className="px-2 py-1 text-xs rounded bg-blue-500 text-white hover:bg-blue-600 disabled:opacity-50"
                >
                  {savingNotes ? '저장 중...' : '저장'}
                </button>
              </div>
            </div>
          ) : (
            <div 
              className="text-xs text-gray-600 dark:text-gray-400 bg-amber-50 dark:bg-amber-900/20 p-2 rounded cursor-pointer hover:bg-amber-100 dark:hover:bg-amber-900/30"
              onClick={(e) => handleStartEditNotes(item, e)}
              title="클릭하여 편집"
            >
              <div className="flex items-start gap-1">
                <svg className="w-3 h-3 mt-0.5 flex-shrink-0 text-amber-500" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M11 5H6a2 2 0 00-2 2v11a2 2 0 002 2h11a2 2 0 002-2v-5m-1.414-9.414a2 2 0 112.828 2.828L11.828 15H9v-2.828l8.586-8.586z" />
                </svg>
                <span className="whitespace-pre-wrap">{item.notes}</span>
              </div>
            </div>
          )}
        </div>
      )}
      
      {/* Expanded: Show derived searches */}
      {expandedId === item.id && derivedSearches[item.id] && derivedSearches[item.id].length > 0 && (
        <div className="mt-3 pt-3 border-t border-gray-200 dark:border-gray-700 space-y-2">
          <p className="text-xs text-gray-500 dark:text-gray-400 mb-2">파생 검색 ({derivedSearches[item.id].length}건)</p>
          {derivedSearches[item.id].map(derived => renderHistoryItem(derived, true))}
        </div>
      )}
    </div>
  )};

  return (
    <div className={`flex flex-col h-full ${className}`}>
      {/* Header */}
      <div className="border-b border-gray-200 dark:border-gray-700 pb-3 mb-3">
        <div className="flex items-center justify-between mb-3">
          <h3 className="text-lg font-semibold text-gray-900 dark:text-gray-100">
            검색 기록
          </h3>
          {/* SSE connection status */}
          {enableRealtime && (
            <div className="flex items-center gap-1.5">
              <span 
                className={`w-2 h-2 rounded-full ${sseConnected ? 'bg-green-500' : 'bg-red-500'}`}
                title={sseConnected ? '실시간 연결됨' : '연결 끊김'}
              />
              <span className="text-xs text-gray-400">
                {sseConnected ? '실시간' : '오프라인'}
              </span>
            </div>
          )}
        </div>
        
        {/* Search input */}
        <form onSubmit={handleSearch} className="mb-3">
          <div className="relative">
            <input
              type="text"
              value={searchQuery}
              onChange={(e) => setSearchQuery(e.target.value)}
              placeholder="검색 기록 검색..."
              className="w-full px-3 py-2 pr-10 border border-gray-300 dark:border-gray-600 rounded-lg text-sm bg-white dark:bg-gray-800 text-gray-900 dark:text-gray-100"
            />
            <button
              type="submit"
              className="absolute right-2 top-1/2 -translate-y-1/2 text-gray-400 hover:text-gray-600"
            >
              <svg className="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z" />
              </svg>
            </button>
          </div>
        </form>
        
        {/* Filter buttons */}
        <div className="flex flex-wrap gap-1.5">
          {(['all', 'bookmarked', 'UNIFIED', 'DEEP_SEARCH', 'FACT_CHECK', 'BROWSER_AGENT'] as const).map((f) => (
            <button
              key={f}
              onClick={() => handleFilterChange(f)}
              className={`px-2.5 py-1 text-xs rounded-full transition-colors ${
                filter === f
                  ? 'bg-blue-500 text-white'
                  : 'bg-gray-100 dark:bg-gray-800 text-gray-600 dark:text-gray-400 hover:bg-gray-200 dark:hover:bg-gray-700'
              }`}
            >
              {f === 'all' ? '전체' : f === 'bookmarked' ? '북마크' : searchTypeLabels[f]}
            </button>
          ))}
        </div>
      </div>
      
      {/* Stats */}
      <div className="text-xs text-gray-500 dark:text-gray-400 mb-2">
        총 {totalElements}건 {localHistory.length > history.length && `(+${localHistory.length - history.length} 새 항목)`}
      </div>
      
      {/* History list */}
      <div className="flex-1 overflow-y-auto space-y-2">
        {loading ? (
          <div className="flex items-center justify-center py-8">
            <div className="animate-spin rounded-full h-6 w-6 border-b-2 border-blue-500"></div>
          </div>
        ) : error ? (
          <div className="text-center py-8 text-red-500">
            <p>{error}</p>
            <button
              onClick={() => loadHistory(0)}
              className="mt-2 text-sm text-blue-500 hover:underline"
            >
              다시 시도
            </button>
          </div>
        ) : localHistory.length === 0 ? (
          <div className="text-center py-8 text-gray-500 dark:text-gray-400">
            <p>검색 기록이 없습니다</p>
          </div>
        ) : (
          localHistory.filter(item => !item.parentSearchId).map(item => renderHistoryItem(item))
        )}
      </div>
      
      {/* Pagination */}
      {totalPages > 1 && (
        <div className="flex items-center justify-center gap-2 pt-3 border-t border-gray-200 dark:border-gray-700 mt-3">
          <button
            onClick={() => handlePageChange(currentPage - 1)}
            disabled={currentPage === 0}
            className="px-3 py-1 text-sm rounded border border-gray-300 dark:border-gray-600 disabled:opacity-50 disabled:cursor-not-allowed hover:bg-gray-100 dark:hover:bg-gray-800"
          >
            이전
          </button>
          <span className="text-sm text-gray-600 dark:text-gray-400">
            {currentPage + 1} / {totalPages}
          </span>
          <button
            onClick={() => handlePageChange(currentPage + 1)}
            disabled={currentPage >= totalPages - 1}
            className="px-3 py-1 text-sm rounded border border-gray-300 dark:border-gray-600 disabled:opacity-50 disabled:cursor-not-allowed hover:bg-gray-100 dark:hover:bg-gray-800"
          >
            다음
          </button>
        </div>
      )}
    </div>
  );
}

export default SearchHistoryPanel;

```

---

## frontend/src/components/SearchInputWithSuggestions.tsx

```tsx
import { useState, useRef, useEffect, useCallback, forwardRef } from "react";
import {
  Search,
  Clock,
  TrendingUp,
  X,
  Sparkles,
  Loader2,
} from "lucide-react";
import { Input } from "@/components/ui/input";
import { Button } from "@/components/ui/button";
import { Badge } from "@/components/ui/badge";
import {
  Command,
  CommandEmpty,
  CommandGroup,
  CommandItem,
  CommandList,
  CommandSeparator,
} from "@/components/ui/command";
import {
  Popover,
  PopoverContent,
  PopoverTrigger,
} from "@/components/ui/popover";
import { cn } from "@/lib/utils";
import { useSearchSuggestions, SearchSuggestion } from "@/hooks/useSearchSuggestions";

interface SearchInputWithSuggestionsProps {
  /** 현재 검색어 */
  value: string;
  /** 검색어 변경 핸들러 */
  onChange: (value: string) => void;
  /** 검색 실행 핸들러 */
  onSearch: (query: string) => void;
  /** 플레이스홀더 */
  placeholder?: string;
  /** 로딩 중 여부 */
  isLoading?: boolean;
  /** 비활성화 여부 */
  disabled?: boolean;
  /** 기본 제안 키워드 */
  defaultSuggestions?: string[];
  /** 트렌딩 키워드 */
  trendingKeywords?: string[];
  /** 추가 CSS 클래스 */
  className?: string;
  /** 입력 필드 크기 */
  size?: "sm" | "default" | "lg";
}

const typeConfig: Record<SearchSuggestion["type"], { icon: typeof Clock; label: string; color: string }> = {
  history: { icon: Clock, label: "최근", color: "text-muted-foreground" },
  trending: { icon: TrendingUp, label: "트렌딩", color: "text-orange-500" },
  suggestion: { icon: Sparkles, label: "추천", color: "text-blue-500" },
};

export const SearchInputWithSuggestions = forwardRef<HTMLInputElement, SearchInputWithSuggestionsProps>(
  (
    {
      value,
      onChange,
      onSearch,
      placeholder = "검색어를 입력하세요...",
      isLoading = false,
      disabled = false,
      defaultSuggestions = [
        "AI 기술 동향",
        "기후변화",
        "경제 전망",
        "의료 혁신",
        "우주 탐사",
        "사이버 보안",
        "전기차",
        "반도체",
      ],
      trendingKeywords = [],
      className,
      size = "default",
    },
    ref
  ) => {
    const [open, setOpen] = useState(false);
    const [inputFocused, setInputFocused] = useState(false);
    const inputRef = useRef<HTMLInputElement>(null);
    const containerRef = useRef<HTMLDivElement>(null);

    const {
      recentSearches,
      addToHistory,
      removeFromHistory,
      clearHistory,
      getSuggestions,
    } = useSearchSuggestions({
      defaultSuggestions,
      trendingKeywords,
    });

    const suggestions = getSuggestions(value);

    // 검색 실행
    const handleSearch = useCallback(
      (query: string) => {
        if (!query.trim()) return;
        addToHistory(query);
        onSearch(query);
        setOpen(false);
      },
      [addToHistory, onSearch]
    );

    // 엔터 키 핸들러
    const handleKeyDown = useCallback(
      (e: React.KeyboardEvent) => {
        if (e.key === "Enter" && value.trim()) {
          e.preventDefault();
          handleSearch(value);
        }
        if (e.key === "Escape") {
          setOpen(false);
          inputRef.current?.blur();
        }
        // 아래 화살표로 제안 목록 포커스
        if (e.key === "ArrowDown" && suggestions.length > 0) {
          e.preventDefault();
          setOpen(true);
        }
      },
      [value, handleSearch, suggestions.length]
    );

    // 제안 선택
    const handleSelect = useCallback(
      (suggestion: SearchSuggestion) => {
        onChange(suggestion.text);
        handleSearch(suggestion.text);
      },
      [onChange, handleSearch]
    );

    // 클릭 외부 감지
    useEffect(() => {
      const handleClickOutside = (e: MouseEvent) => {
        if (containerRef.current && !containerRef.current.contains(e.target as Node)) {
          setOpen(false);
        }
      };
      document.addEventListener("mousedown", handleClickOutside);
      return () => document.removeEventListener("mousedown", handleClickOutside);
    }, []);

    // 입력 포커스 시 열기
    useEffect(() => {
      if (inputFocused && (suggestions.length > 0 || recentSearches.length > 0)) {
        setOpen(true);
      }
    }, [inputFocused, suggestions.length, recentSearches.length]);

    const inputSizeClass = size === "sm" ? "h-9 text-sm" : size === "lg" ? "h-12 text-lg" : "h-10";
    const iconSizeClass = size === "sm" ? "h-4 w-4" : size === "lg" ? "h-6 w-6" : "h-5 w-5";

    return (
      <div ref={containerRef} className={cn("relative", className)}>
        <Popover open={open} onOpenChange={setOpen}>
          <PopoverTrigger asChild>
            <div className="relative">
              {/* 검색 아이콘 */}
              <Search
                className={cn(
                  "absolute left-3 top-1/2 -translate-y-1/2 text-muted-foreground",
                  iconSizeClass
                )}
              />

              {/* 입력 필드 */}
              <Input
                ref={ref || inputRef}
                type="text"
                value={value}
                onChange={(e) => onChange(e.target.value)}
                onFocus={() => setInputFocused(true)}
                onBlur={() => setInputFocused(false)}
                onKeyDown={handleKeyDown}
                placeholder={placeholder}
                disabled={disabled || isLoading}
                className={cn(
                  "pl-10 pr-20",
                  inputSizeClass,
                  open && "ring-2 ring-primary/20"
                )}
              />

              {/* 오른쪽 액션 버튼들 */}
              <div className="absolute right-2 top-1/2 -translate-y-1/2 flex items-center gap-1">
                {/* 클리어 버튼 */}
                {value && !isLoading && (
                  <Button
                    type="button"
                    variant="ghost"
                    size="icon"
                    className="h-6 w-6"
                    onClick={() => onChange("")}
                    tabIndex={-1}
                  >
                    <X className="h-4 w-4" />
                    <span className="sr-only">검색어 지우기</span>
                  </Button>
                )}

                {/* 검색 버튼 */}
                <Button
                  type="button"
                  size="sm"
                  disabled={!value.trim() || isLoading}
                  onClick={() => handleSearch(value)}
                  className="h-7"
                >
                  {isLoading ? (
                    <Loader2 className="h-4 w-4 animate-spin" />
                  ) : (
                    "검색"
                  )}
                </Button>
              </div>
            </div>
          </PopoverTrigger>

          <PopoverContent
            className="w-[var(--radix-popover-trigger-width)] p-0"
            align="start"
            sideOffset={4}
            onOpenAutoFocus={(e) => e.preventDefault()}
          >
            <Command>
              <CommandList>
                {/* 검색 결과 없음 */}
                {suggestions.length === 0 && recentSearches.length === 0 && (
                  <CommandEmpty>검색어를 입력하세요</CommandEmpty>
                )}

                {/* 제안 목록 */}
                {suggestions.length > 0 && (
                  <CommandGroup heading="검색 제안">
                    {suggestions.map((suggestion, index) => {
                      const config = typeConfig[suggestion.type];
                      const Icon = config.icon;
                      return (
                        <CommandItem
                          key={`${suggestion.type}-${suggestion.text}-${index}`}
                          value={suggestion.text}
                          onSelect={() => handleSelect(suggestion)}
                          className="flex items-center justify-between cursor-pointer"
                        >
                          <div className="flex items-center gap-2">
                            <Icon className={cn("h-4 w-4", config.color)} />
                            <span>{suggestion.text}</span>
                          </div>
                          {suggestion.type === "history" && (
                            <Button
                              variant="ghost"
                              size="icon"
                              className="h-5 w-5 opacity-0 group-hover:opacity-100"
                              onClick={(e) => {
                                e.stopPropagation();
                                removeFromHistory(suggestion.text);
                              }}
                            >
                              <X className="h-3 w-3" />
                            </Button>
                          )}
                          {suggestion.type === "trending" && (
                            <Badge variant="secondary" className="text-xs">
                              트렌딩
                            </Badge>
                          )}
                        </CommandItem>
                      );
                    })}
                  </CommandGroup>
                )}

                {/* 최근 검색어 (입력이 없을 때만) */}
                {!value && recentSearches.length > 0 && (
                  <>
                    <CommandSeparator />
                    <CommandGroup
                      heading={
                        <div className="flex items-center justify-between">
                          <span>최근 검색어</span>
                          <Button
                            variant="ghost"
                            size="sm"
                            className="h-auto py-0 px-1 text-xs text-muted-foreground"
                            onClick={(e) => {
                              e.preventDefault();
                              clearHistory();
                            }}
                          >
                            전체 삭제
                          </Button>
                        </div>
                      }
                    >
                      {recentSearches.map((item, index) => (
                        <CommandItem
                          key={`recent-${item.text}-${index}`}
                          value={item.text}
                          onSelect={() => handleSelect(item)}
                          className="flex items-center justify-between cursor-pointer group"
                        >
                          <div className="flex items-center gap-2">
                            <Clock className="h-4 w-4 text-muted-foreground" />
                            <span>{item.text}</span>
                          </div>
                          <Button
                            variant="ghost"
                            size="icon"
                            className="h-5 w-5 opacity-0 group-hover:opacity-100"
                            onClick={(e) => {
                              e.stopPropagation();
                              removeFromHistory(item.text);
                            }}
                          >
                            <X className="h-3 w-3" />
                          </Button>
                        </CommandItem>
                      ))}
                    </CommandGroup>
                  </>
                )}

                {/* 키보드 힌트 */}
                <div className="px-2 py-1.5 text-xs text-muted-foreground border-t flex items-center gap-4">
                  <span>
                    <kbd className="px-1.5 py-0.5 rounded bg-muted font-mono text-xs">Enter</kbd>{" "}
                    검색
                  </span>
                  <span>
                    <kbd className="px-1.5 py-0.5 rounded bg-muted font-mono text-xs">Esc</kbd>{" "}
                    닫기
                  </span>
                </div>
              </CommandList>
            </Command>
          </PopoverContent>
        </Popover>
      </div>
    );
  }
);

SearchInputWithSuggestions.displayName = "SearchInputWithSuggestions";

export default SearchInputWithSuggestions;

```

---

## frontend/src/components/SentimentChart.tsx

```tsx
import { Card } from "@/components/ui/card";
import type { SentimentData } from "@/types/api";

interface SentimentChartProps {
  data: SentimentData;
}

export function SentimentChart({ data }: SentimentChartProps) {
  const total = data.pos + data.neg + data.neu;
  const posPercent = total > 0 ? ((data.pos / total) * 100).toFixed(1) : "0";
  const negPercent = total > 0 ? ((data.neg / total) * 100).toFixed(1) : "0";
  const neuPercent = total > 0 ? ((data.neu / total) * 100).toFixed(1) : "0";

  return (
    <Card className="p-6 shadow-elegant card-hover">
      <h2 className="text-xl font-bold mb-6">감성 분석</h2>
      
      {/* Bar Chart */}
      <div className="space-y-6 mb-8">
        <div className="space-y-2">
          <div className="flex items-center justify-between text-sm">
            <span className="font-medium">긍정</span>
            <span className="text-muted-foreground">{data.pos}건 ({posPercent}%)</span>
          </div>
          <div className="h-8 bg-muted rounded-full overflow-hidden">
            <div 
              className="h-full bg-success transition-all duration-500"
              style={{ width: `${posPercent}%` }}
            />
          </div>
        </div>

        <div className="space-y-2">
          <div className="flex items-center justify-between text-sm">
            <span className="font-medium">부정</span>
            <span className="text-muted-foreground">{data.neg}건 ({negPercent}%)</span>
          </div>
          <div className="h-8 bg-muted rounded-full overflow-hidden">
            <div 
              className="h-full bg-destructive transition-all duration-500"
              style={{ width: `${negPercent}%` }}
            />
          </div>
        </div>

        <div className="space-y-2">
          <div className="flex items-center justify-between text-sm">
            <span className="font-medium">중립</span>
            <span className="text-muted-foreground">{data.neu}건 ({neuPercent}%)</span>
          </div>
          <div className="h-8 bg-muted rounded-full overflow-hidden">
            <div 
              className="h-full bg-muted-foreground transition-all duration-500"
              style={{ width: `${neuPercent}%` }}
            />
          </div>
        </div>
      </div>

      {/* Stats */}
      <div className="grid grid-cols-3 gap-4 pt-6 border-t">
        <div className="text-center">
          <div className="text-2xl font-bold text-success">{data.pos}</div>
          <div className="text-xs text-muted-foreground mt-1">긍정 ({posPercent}%)</div>
        </div>
        <div className="text-center">
          <div className="text-2xl font-bold text-destructive">{data.neg}</div>
          <div className="text-xs text-muted-foreground mt-1">부정 ({negPercent}%)</div>
        </div>
        <div className="text-center">
          <div className="text-2xl font-bold text-muted-foreground">{data.neu}</div>
          <div className="text-xs text-muted-foreground mt-1">중립 ({neuPercent}%)</div>
        </div>
      </div>
    </Card>
  );
}

```

---

## frontend/src/components/TaskTemplates.tsx

```tsx
import { useState, useCallback, useMemo } from "react";
import {
  Bookmark,
  BookmarkPlus,
  Trash2,
  Play,
  Edit,
  X,
  Search,
  Globe,
  FileText,
  Database,
  ShoppingCart,
  Newspaper,
  BarChart3,
  Loader2,
  ChevronDown,
  ChevronUp,
  Star,
  Copy,
} from "lucide-react";
import { Button } from "@/components/ui/button";
import { Input } from "@/components/ui/input";
import { Badge } from "@/components/ui/badge";
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from "@/components/ui/card";
import {
  Dialog,
  DialogContent,
  DialogDescription,
  DialogFooter,
  DialogHeader,
  DialogTitle,
  DialogTrigger,
} from "@/components/ui/dialog";
import { Label } from "@/components/ui/label";
import { Textarea } from "@/components/ui/textarea";
import {
  Select,
  SelectContent,
  SelectItem,
  SelectTrigger,
  SelectValue,
} from "@/components/ui/select";
import {
  Collapsible,
  CollapsibleContent,
  CollapsibleTrigger,
} from "@/components/ui/collapsible";
import { ScrollArea } from "@/components/ui/scroll-area";
import { cn } from "@/lib/utils";

export interface TaskTemplate {
  id: string;
  name: string;
  description: string;
  task: string;
  url?: string;
  maxSteps?: number;
  category: TaskCategory;
  icon?: string;
  isBuiltIn?: boolean;
  createdAt: string;
  usageCount?: number;
}

export type TaskCategory = 
  | "news"
  | "research"
  | "ecommerce"
  | "data"
  | "social"
  | "custom";

const CATEGORY_CONFIG: Record<TaskCategory, { label: string; icon: typeof Newspaper; color: string }> = {
  news: { label: "뉴스", icon: Newspaper, color: "text-blue-600" },
  research: { label: "연구", icon: Search, color: "text-purple-600" },
  ecommerce: { label: "쇼핑", icon: ShoppingCart, color: "text-green-600" },
  data: { label: "데이터", icon: BarChart3, color: "text-orange-600" },
  social: { label: "소셜", icon: Globe, color: "text-pink-600" },
  custom: { label: "사용자 정의", icon: FileText, color: "text-gray-600" },
};

/** 기본 제공 템플릿 */
const BUILT_IN_TEMPLATES: TaskTemplate[] = [
  {
    id: "builtin-1",
    name: "뉴스 헤드라인 수집",
    description: "뉴스 사이트에서 최신 헤드라인을 수집합니다",
    task: "Go to the news website and extract the top 10 headlines with their titles, summaries, and URLs. Format the output as a numbered list.",
    url: "",
    maxSteps: 15,
    category: "news",
    isBuiltIn: true,
    createdAt: "2024-01-01",
    usageCount: 0,
  },
  {
    id: "builtin-2",
    name: "Hacker News 인기글",
    description: "Hacker News 프론트페이지 인기글 추출",
    task: "Go to news.ycombinator.com and extract the top 10 stories with their titles, points, comment counts, and URLs.",
    url: "https://news.ycombinator.com",
    maxSteps: 10,
    category: "news",
    isBuiltIn: true,
    createdAt: "2024-01-01",
    usageCount: 0,
  },
  {
    id: "builtin-3",
    name: "Wikipedia 정보 추출",
    description: "Wikipedia에서 특정 주제 정보 수집",
    task: "Search Wikipedia for the given topic and extract the main summary, key facts, and related topics.",
    url: "https://wikipedia.org",
    maxSteps: 15,
    category: "research",
    isBuiltIn: true,
    createdAt: "2024-01-01",
    usageCount: 0,
  },
  {
    id: "builtin-4",
    name: "상품 정보 수집",
    description: "이커머스 사이트에서 상품 정보 추출",
    task: "Find product information including name, price, ratings, and reviews from the given product page or search results.",
    url: "",
    maxSteps: 20,
    category: "ecommerce",
    isBuiltIn: true,
    createdAt: "2024-01-01",
    usageCount: 0,
  },
  {
    id: "builtin-5",
    name: "트렌드 데이터 수집",
    description: "트렌드/통계 데이터 추출",
    task: "Extract trending topics, statistics, or data points from the given page. Format as structured data with dates and values.",
    url: "",
    maxSteps: 20,
    category: "data",
    isBuiltIn: true,
    createdAt: "2024-01-01",
    usageCount: 0,
  },
];

const STORAGE_KEY = "newsinsight-task-templates";

interface TaskTemplatesProps {
  /** 템플릿 선택 시 콜백 */
  onSelectTemplate: (template: TaskTemplate) => void;
  /** 현재 작업이 실행 중인지 */
  disabled?: boolean;
  /** 추가 CSS 클래스 */
  className?: string;
}

/** 로컬 스토리지에서 템플릿 로드 */
const loadTemplates = (): TaskTemplate[] => {
  try {
    const stored = localStorage.getItem(STORAGE_KEY);
    if (stored) {
      const userTemplates = JSON.parse(stored) as TaskTemplate[];
      return [...BUILT_IN_TEMPLATES, ...userTemplates];
    }
  } catch (e) {
    console.error("Failed to load templates:", e);
  }
  return BUILT_IN_TEMPLATES;
};

/** 사용자 템플릿만 저장 */
const saveTemplates = (templates: TaskTemplate[]) => {
  const userTemplates = templates.filter((t) => !t.isBuiltIn);
  localStorage.setItem(STORAGE_KEY, JSON.stringify(userTemplates));
};

export function TaskTemplates({
  onSelectTemplate,
  disabled = false,
  className,
}: TaskTemplatesProps) {
  const [templates, setTemplates] = useState<TaskTemplate[]>(loadTemplates);
  const [isOpen, setIsOpen] = useState(false);
  const [searchQuery, setSearchQuery] = useState("");
  const [selectedCategory, setSelectedCategory] = useState<TaskCategory | "all">("all");
  const [editDialogOpen, setEditDialogOpen] = useState(false);
  const [editingTemplate, setEditingTemplate] = useState<TaskTemplate | null>(null);

  // 새 템플릿 기본값
  const [newTemplate, setNewTemplate] = useState<Partial<TaskTemplate>>({
    name: "",
    description: "",
    task: "",
    url: "",
    maxSteps: 25,
    category: "custom",
  });

  // 필터링된 템플릿
  const filteredTemplates = useMemo(() => {
    return templates.filter((t) => {
      const matchesSearch =
        !searchQuery ||
        t.name.toLowerCase().includes(searchQuery.toLowerCase()) ||
        t.description.toLowerCase().includes(searchQuery.toLowerCase()) ||
        t.task.toLowerCase().includes(searchQuery.toLowerCase());
      
      const matchesCategory =
        selectedCategory === "all" || t.category === selectedCategory;
      
      return matchesSearch && matchesCategory;
    });
  }, [templates, searchQuery, selectedCategory]);

  // 카테고리별 그룹화
  const groupedTemplates = useMemo(() => {
    const groups: Record<string, TaskTemplate[]> = {};
    filteredTemplates.forEach((t) => {
      const key = t.isBuiltIn ? "기본 제공" : "내 템플릿";
      if (!groups[key]) groups[key] = [];
      groups[key].push(t);
    });
    return groups;
  }, [filteredTemplates]);

  // 템플릿 선택
  const handleSelect = useCallback((template: TaskTemplate) => {
    // 사용 횟수 증가
    setTemplates((prev) => {
      const updated = prev.map((t) =>
        t.id === template.id
          ? { ...t, usageCount: (t.usageCount || 0) + 1 }
          : t
      );
      saveTemplates(updated);
      return updated;
    });
    
    onSelectTemplate(template);
    setIsOpen(false);
  }, [onSelectTemplate]);

  // 템플릿 저장
  const handleSave = useCallback(() => {
    if (!newTemplate.name?.trim() || !newTemplate.task?.trim()) return;

    const template: TaskTemplate = {
      id: editingTemplate?.id || `user-${Date.now()}`,
      name: newTemplate.name.trim(),
      description: newTemplate.description?.trim() || "",
      task: newTemplate.task.trim(),
      url: newTemplate.url?.trim() || undefined,
      maxSteps: newTemplate.maxSteps || 25,
      category: newTemplate.category as TaskCategory || "custom",
      isBuiltIn: false,
      createdAt: editingTemplate?.createdAt || new Date().toISOString(),
      usageCount: editingTemplate?.usageCount || 0,
    };

    setTemplates((prev) => {
      let updated: TaskTemplate[];
      if (editingTemplate) {
        updated = prev.map((t) => (t.id === template.id ? template : t));
      } else {
        updated = [...prev, template];
      }
      saveTemplates(updated);
      return updated;
    });

    setEditDialogOpen(false);
    setEditingTemplate(null);
    setNewTemplate({
      name: "",
      description: "",
      task: "",
      url: "",
      maxSteps: 25,
      category: "custom",
    });
  }, [newTemplate, editingTemplate]);

  // 템플릿 삭제
  const handleDelete = useCallback((id: string) => {
    setTemplates((prev) => {
      const updated = prev.filter((t) => t.id !== id);
      saveTemplates(updated);
      return updated;
    });
  }, []);

  // 편집 모드 시작
  const startEdit = useCallback((template: TaskTemplate) => {
    setEditingTemplate(template);
    setNewTemplate({
      name: template.name,
      description: template.description,
      task: template.task,
      url: template.url,
      maxSteps: template.maxSteps,
      category: template.category,
    });
    setEditDialogOpen(true);
  }, []);

  return (
    <Collapsible open={isOpen} onOpenChange={setIsOpen} className={className}>
      <CollapsibleTrigger asChild>
        <Button
          variant="outline"
          className="w-full justify-between"
          disabled={disabled}
        >
          <div className="flex items-center gap-2">
            <Bookmark className="h-4 w-4" />
            <span>작업 템플릿</span>
            <Badge variant="secondary" className="ml-1">
              {templates.length}
            </Badge>
          </div>
          {isOpen ? (
            <ChevronUp className="h-4 w-4" />
          ) : (
            <ChevronDown className="h-4 w-4" />
          )}
        </Button>
      </CollapsibleTrigger>

      <CollapsibleContent className="mt-3 space-y-3">
        {/* 검색 및 필터 */}
        <div className="flex gap-2">
          <div className="relative flex-1">
            <Search className="absolute left-3 top-1/2 -translate-y-1/2 h-4 w-4 text-muted-foreground" />
            <Input
              value={searchQuery}
              onChange={(e) => setSearchQuery(e.target.value)}
              placeholder="템플릿 검색..."
              className="pl-9"
            />
          </div>
          <Select
            value={selectedCategory}
            onValueChange={(v) => setSelectedCategory(v as TaskCategory | "all")}
          >
            <SelectTrigger className="w-[120px]">
              <SelectValue />
            </SelectTrigger>
            <SelectContent>
              <SelectItem value="all">전체</SelectItem>
              {Object.entries(CATEGORY_CONFIG).map(([key, config]) => (
                <SelectItem key={key} value={key}>
                  {config.label}
                </SelectItem>
              ))}
            </SelectContent>
          </Select>
          
          {/* 새 템플릿 추가 */}
          <Dialog open={editDialogOpen} onOpenChange={setEditDialogOpen}>
            <DialogTrigger asChild>
              <Button
                variant="outline"
                size="icon"
                onClick={() => {
                  setEditingTemplate(null);
                  setNewTemplate({
                    name: "",
                    description: "",
                    task: "",
                    url: "",
                    maxSteps: 25,
                    category: "custom",
                  });
                }}
              >
                <BookmarkPlus className="h-4 w-4" />
              </Button>
            </DialogTrigger>
            <DialogContent className="sm:max-w-[500px]">
              <DialogHeader>
                <DialogTitle>
                  {editingTemplate ? "템플릿 수정" : "새 템플릿 만들기"}
                </DialogTitle>
                <DialogDescription>
                  자주 사용하는 작업을 템플릿으로 저장하여 빠르게 재사용하세요.
                </DialogDescription>
              </DialogHeader>
              <div className="space-y-4 py-4">
                <div className="space-y-2">
                  <Label htmlFor="name">템플릿 이름 *</Label>
                  <Input
                    id="name"
                    value={newTemplate.name}
                    onChange={(e) =>
                      setNewTemplate((p) => ({ ...p, name: e.target.value }))
                    }
                    placeholder="예: 뉴스 헤드라인 수집"
                  />
                </div>
                <div className="space-y-2">
                  <Label htmlFor="description">설명</Label>
                  <Input
                    id="description"
                    value={newTemplate.description}
                    onChange={(e) =>
                      setNewTemplate((p) => ({ ...p, description: e.target.value }))
                    }
                    placeholder="템플릿에 대한 간단한 설명"
                  />
                </div>
                <div className="space-y-2">
                  <Label htmlFor="task">작업 내용 *</Label>
                  <Textarea
                    id="task"
                    value={newTemplate.task}
                    onChange={(e) =>
                      setNewTemplate((p) => ({ ...p, task: e.target.value }))
                    }
                    placeholder="AI 에이전트가 수행할 작업을 자세히 설명하세요"
                    rows={4}
                  />
                </div>
                <div className="grid grid-cols-2 gap-4">
                  <div className="space-y-2">
                    <Label htmlFor="url">시작 URL</Label>
                    <Input
                      id="url"
                      value={newTemplate.url}
                      onChange={(e) =>
                        setNewTemplate((p) => ({ ...p, url: e.target.value }))
                      }
                      placeholder="https://..."
                    />
                  </div>
                  <div className="space-y-2">
                    <Label htmlFor="maxSteps">최대 단계</Label>
                    <Input
                      id="maxSteps"
                      type="number"
                      value={newTemplate.maxSteps}
                      onChange={(e) =>
                        setNewTemplate((p) => ({
                          ...p,
                          maxSteps: parseInt(e.target.value) || 25,
                        }))
                      }
                      min={1}
                      max={100}
                    />
                  </div>
                </div>
                <div className="space-y-2">
                  <Label>카테고리</Label>
                  <Select
                    value={newTemplate.category}
                    onValueChange={(v) =>
                      setNewTemplate((p) => ({ ...p, category: v as TaskCategory }))
                    }
                  >
                    <SelectTrigger>
                      <SelectValue />
                    </SelectTrigger>
                    <SelectContent>
                      {Object.entries(CATEGORY_CONFIG).map(([key, config]) => {
                        const Icon = config.icon;
                        return (
                          <SelectItem key={key} value={key}>
                            <div className="flex items-center gap-2">
                              <Icon className={cn("h-4 w-4", config.color)} />
                              {config.label}
                            </div>
                          </SelectItem>
                        );
                      })}
                    </SelectContent>
                  </Select>
                </div>
              </div>
              <DialogFooter>
                <Button variant="outline" onClick={() => setEditDialogOpen(false)}>
                  취소
                </Button>
                <Button
                  onClick={handleSave}
                  disabled={!newTemplate.name?.trim() || !newTemplate.task?.trim()}
                >
                  {editingTemplate ? "수정" : "저장"}
                </Button>
              </DialogFooter>
            </DialogContent>
          </Dialog>
        </div>

        {/* 템플릿 목록 */}
        <ScrollArea className="h-[300px] pr-2">
          {filteredTemplates.length === 0 ? (
            <div className="text-center py-8 text-muted-foreground">
              <Bookmark className="h-8 w-8 mx-auto mb-2 opacity-50" />
              <p>검색 결과가 없습니다</p>
            </div>
          ) : (
            <div className="space-y-4">
              {Object.entries(groupedTemplates).map(([group, items]) => (
                <div key={group}>
                  <h4 className="text-sm font-medium text-muted-foreground mb-2">
                    {group}
                  </h4>
                  <div className="space-y-2">
                    {items.map((template) => {
                      const categoryConfig = CATEGORY_CONFIG[template.category];
                      const Icon = categoryConfig.icon;
                      
                      return (
                        <div
                          key={template.id}
                          className="flex items-start gap-3 p-3 rounded-lg border bg-card hover:bg-muted/50 transition-colors"
                        >
                          <div className={cn("p-2 rounded-lg bg-muted", categoryConfig.color)}>
                            <Icon className="h-4 w-4" />
                          </div>
                          <div className="flex-1 min-w-0">
                            <div className="flex items-center gap-2">
                              <h5 className="font-medium text-sm truncate">
                                {template.name}
                              </h5>
                              {template.isBuiltIn && (
                                <Badge variant="secondary" className="text-xs shrink-0">
                                  기본
                                </Badge>
                              )}
                            </div>
                            <p className="text-xs text-muted-foreground line-clamp-1 mt-0.5">
                              {template.description || template.task}
                            </p>
                            {template.url && (
                              <p className="text-xs text-blue-600 truncate mt-0.5">
                                {template.url}
                              </p>
                            )}
                          </div>
                          <div className="flex items-center gap-1 shrink-0">
                            {/* 사용하기 */}
                            <Button
                              variant="ghost"
                              size="icon"
                              className="h-8 w-8"
                              onClick={() => handleSelect(template)}
                              title="이 템플릿 사용"
                            >
                              <Play className="h-4 w-4" />
                            </Button>
                            
                            {/* 편집 (사용자 템플릿만) */}
                            {!template.isBuiltIn && (
                              <Button
                                variant="ghost"
                                size="icon"
                                className="h-8 w-8"
                                onClick={() => startEdit(template)}
                                title="수정"
                              >
                                <Edit className="h-4 w-4" />
                              </Button>
                            )}
                            
                            {/* 삭제 (사용자 템플릿만) */}
                            {!template.isBuiltIn && (
                              <Button
                                variant="ghost"
                                size="icon"
                                className="h-8 w-8 text-destructive hover:text-destructive"
                                onClick={() => handleDelete(template.id)}
                                title="삭제"
                              >
                                <Trash2 className="h-4 w-4" />
                              </Button>
                            )}
                          </div>
                        </div>
                      );
                    })}
                  </div>
                </div>
              ))}
            </div>
          )}
        </ScrollArea>
      </CollapsibleContent>
    </Collapsible>
  );
}

export default TaskTemplates;

```

---

## frontend/src/components/ThemeToggle.tsx

```tsx
import { Moon, Sun, Monitor } from "lucide-react";
import { Button } from "@/components/ui/button";
import {
  DropdownMenu,
  DropdownMenuContent,
  DropdownMenuItem,
  DropdownMenuTrigger,
} from "@/components/ui/dropdown-menu";
import {
  Tooltip,
  TooltipContent,
  TooltipTrigger,
} from "@/components/ui/tooltip";
import { useTheme } from "@/contexts/ThemeContext";
import { cn } from "@/lib/utils";

interface ThemeToggleProps {
  /** 버튼 변형 */
  variant?: "icon" | "dropdown" | "switch";
  /** 크기 */
  size?: "sm" | "default" | "lg";
  /** 추가 CSS 클래스 */
  className?: string;
}

/** 아이콘만 있는 간단한 토글 버튼 */
const IconToggle = ({ size = "default", className }: Pick<ThemeToggleProps, "size" | "className">) => {
  const { resolvedTheme, toggleTheme, theme } = useTheme();

  const iconSize = size === "sm" ? "h-4 w-4" : size === "lg" ? "h-6 w-6" : "h-5 w-5";
  const buttonSize = size === "sm" ? "h-8 w-8" : size === "lg" ? "h-12 w-12" : "h-10 w-10";

  const getTooltipText = () => {
    if (theme === "light") return "다크 모드로 전환";
    if (theme === "dark") return "시스템 설정 사용";
    return "라이트 모드로 전환";
  };

  return (
    <Tooltip>
      <TooltipTrigger asChild>
        <Button
          variant="ghost"
          size="icon"
          onClick={toggleTheme}
          className={cn(buttonSize, "relative", className)}
          aria-label="테마 전환"
        >
          {theme === "system" ? (
            <Monitor className={cn(iconSize, "text-muted-foreground")} />
          ) : resolvedTheme === "dark" ? (
            <Moon className={cn(iconSize, "text-blue-400")} />
          ) : (
            <Sun className={cn(iconSize, "text-yellow-500")} />
          )}
        </Button>
      </TooltipTrigger>
      <TooltipContent>
        <p>{getTooltipText()}</p>
      </TooltipContent>
    </Tooltip>
  );
};

/** 드롭다운 메뉴 형태의 테마 선택 */
const DropdownToggle = ({ size = "default", className }: Pick<ThemeToggleProps, "size" | "className">) => {
  const { theme, setTheme, resolvedTheme } = useTheme();

  const iconSize = size === "sm" ? "h-4 w-4" : size === "lg" ? "h-6 w-6" : "h-5 w-5";

  return (
    <DropdownMenu>
      <DropdownMenuTrigger asChild>
        <Button variant="ghost" size="icon" className={className}>
          {theme === "system" ? (
            <Monitor className={cn(iconSize, "text-muted-foreground")} />
          ) : resolvedTheme === "dark" ? (
            <Moon className={cn(iconSize, "text-blue-400")} />
          ) : (
            <Sun className={cn(iconSize, "text-yellow-500")} />
          )}
          <span className="sr-only">테마 선택</span>
        </Button>
      </DropdownMenuTrigger>
      <DropdownMenuContent align="end">
        <DropdownMenuItem
          onClick={() => setTheme("light")}
          className={cn(theme === "light" && "bg-accent")}
        >
          <Sun className="h-4 w-4 mr-2 text-yellow-500" />
          라이트
        </DropdownMenuItem>
        <DropdownMenuItem
          onClick={() => setTheme("dark")}
          className={cn(theme === "dark" && "bg-accent")}
        >
          <Moon className="h-4 w-4 mr-2 text-blue-400" />
          다크
        </DropdownMenuItem>
        <DropdownMenuItem
          onClick={() => setTheme("system")}
          className={cn(theme === "system" && "bg-accent")}
        >
          <Monitor className="h-4 w-4 mr-2" />
          시스템
        </DropdownMenuItem>
      </DropdownMenuContent>
    </DropdownMenu>
  );
};

/** 스위치 형태의 토글 (라이트/다크만) */
const SwitchToggle = ({ className }: Pick<ThemeToggleProps, "className">) => {
  const { resolvedTheme, setTheme } = useTheme();
  const isDark = resolvedTheme === "dark";

  const handleToggle = () => {
    setTheme(isDark ? "light" : "dark");
  };

  return (
    <button
      role="switch"
      aria-checked={isDark}
      onClick={handleToggle}
      className={cn(
        "relative inline-flex h-6 w-11 items-center rounded-full transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2",
        isDark ? "bg-blue-600" : "bg-yellow-400",
        className
      )}
    >
      <span className="sr-only">다크 모드 {isDark ? "끄기" : "켜기"}</span>
      <span
        className={cn(
          "pointer-events-none inline-flex h-5 w-5 transform items-center justify-center rounded-full bg-white shadow-lg ring-0 transition-transform",
          isDark ? "translate-x-5" : "translate-x-0.5"
        )}
      >
        {isDark ? (
          <Moon className="h-3 w-3 text-blue-600" />
        ) : (
          <Sun className="h-3 w-3 text-yellow-500" />
        )}
      </span>
    </button>
  );
};

/** 메인 ThemeToggle 컴포넌트 */
export const ThemeToggle = ({ variant = "icon", size = "default", className }: ThemeToggleProps) => {
  switch (variant) {
    case "dropdown":
      return <DropdownToggle size={size} className={className} />;
    case "switch":
      return <SwitchToggle className={className} />;
    case "icon":
    default:
      return <IconToggle size={size} className={className} />;
  }
};

export default ThemeToggle;

```

---

## frontend/src/components/UnifiedExportMenu.tsx

```tsx
/**
 * UnifiedExportMenu - 통합 내보내기 메뉴
 * 
 * PDF 보고서, AI 분석 내보내기, 데이터 내보내기를 하나의 드롭다운으로 통합
 */

import { useState, useCallback } from 'react';
import {
  Download,
  FileText,
  FileJson,
  FileSpreadsheet,
  FileCode,
  FileType2,
  Copy,
  Check,
  ChevronDown,
  Loader2,
  Settings2,
} from 'lucide-react';
import { Button } from '@/components/ui/button';
import {
  DropdownMenu,
  DropdownMenuContent,
  DropdownMenuItem,
  DropdownMenuLabel,
  DropdownMenuSeparator,
  DropdownMenuSub,
  DropdownMenuSubContent,
  DropdownMenuSubTrigger,
  DropdownMenuTrigger,
} from '@/components/ui/dropdown-menu';
import {
  Dialog,
  DialogContent,
  DialogDescription,
  DialogFooter,
  DialogHeader,
  DialogTitle,
} from '@/components/ui/dialog';
import { Checkbox } from '@/components/ui/checkbox';
import { Label } from '@/components/ui/label';
import { toast } from 'sonner';
import {
  exportUnifiedSearchReport,
  exportDeepSearchReport,
  triggerPdfDownload,
  type ReportRequest,
  type ReportSection,
  type ReportType,
  DEFAULT_REPORT_SECTIONS,
} from '@/lib/api';
import { useExport, type ExportFormat, type ExportableSearchResult, type ExportOptions } from '@/hooks/useExport';
import type { ChartExportHandle } from '@/components/charts';

// ============================================
// Types
// ============================================

interface UnifiedExportMenuProps {
  /** Job ID for PDF report generation */
  jobId?: string;
  /** Search query */
  query: string;
  /** Report type */
  reportType?: ReportType;
  /** Time window */
  timeWindow?: string;
  /** AI analysis content (markdown) for analysis export */
  aiContent?: string;
  /** Structured data for JSON/CSV export */
  data?: ExportableSearchResult[];
  /** Chart refs for capturing chart images */
  chartRefs?: Record<string, React.RefObject<ChartExportHandle>>;
  /** Export options */
  exportOptions?: ExportOptions;
  /** Button variant */
  variant?: 'default' | 'outline' | 'ghost' | 'secondary';
  /** Button size */
  size?: 'default' | 'sm' | 'lg' | 'icon';
  /** Additional CSS classes */
  className?: string;
  /** Disable the button */
  disabled?: boolean;
  /** Show icon only */
  iconOnly?: boolean;
}

interface SectionOption {
  id: ReportSection;
  label: string;
  description: string;
}

// ============================================
// Constants
// ============================================

const ALL_SECTIONS: SectionOption[] = [
  { id: 'COVER', label: '표지', description: '보고서 표지 및 기본 정보' },
  { id: 'EXECUTIVE_SUMMARY', label: '요약', description: 'AI 분석 요약 및 핵심 인사이트' },
  { id: 'DATA_SOURCE', label: '데이터 소스', description: '검색 소스별 결과 분포' },
  { id: 'TREND_ANALYSIS', label: '트렌드 분석', description: '시간대별 기사 추이' },
  { id: 'KEYWORD_ANALYSIS', label: '키워드 분석', description: '주요 키워드 및 빈도' },
  { id: 'SENTIMENT_ANALYSIS', label: '감정 분석', description: '긍정/부정/중립 분포' },
  { id: 'RELIABILITY', label: '신뢰도 분석', description: '출처별 신뢰도 평가' },
  { id: 'BIAS_ANALYSIS', label: '편향성 분석', description: '정치적/이념적 편향 분석' },
  { id: 'FACTCHECK', label: '팩트체크', description: '주요 주장 검증 결과' },
  { id: 'EVIDENCE_LIST', label: '증거 목록', description: '수집된 증거 및 출처' },
  { id: 'DETAILED_RESULTS', label: '상세 결과', description: '개별 기사 상세 정보' },
];

// ============================================
// Utility Functions
// ============================================

/**
 * Generate HTML report from markdown content
 */
const generateHtmlReport = (content: string, query: string): string => {
  const timestamp = new Date().toLocaleString('ko-KR');
  
  return `<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>NewsInsight AI 분석 - ${query}</title>
  <style>
    :root {
      --primary: #7c3aed;
      --primary-light: #a78bfa;
      --bg: #ffffff;
      --text: #1f2937;
      --text-muted: #6b7280;
      --border: #e5e7eb;
    }
    
    @media (prefers-color-scheme: dark) {
      :root {
        --bg: #111827;
        --text: #f9fafb;
        --text-muted: #9ca3af;
        --border: #374151;
      }
    }
    
    * { box-sizing: border-box; margin: 0; padding: 0; }
    
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Noto Sans KR', sans-serif;
      line-height: 1.7;
      color: var(--text);
      background: var(--bg);
      max-width: 900px;
      margin: 0 auto;
      padding: 2rem;
    }
    
    header {
      text-align: center;
      padding-bottom: 2rem;
      margin-bottom: 2rem;
      border-bottom: 2px solid var(--primary);
    }
    
    header h1 {
      color: var(--primary);
      font-size: 1.5rem;
      margin-bottom: 0.5rem;
    }
    
    header .query {
      font-size: 1.25rem;
      font-weight: 600;
      margin-bottom: 0.5rem;
    }
    
    header .meta {
      color: var(--text-muted);
      font-size: 0.875rem;
    }
    
    h2, h3 {
      margin: 1.5rem 0 1rem;
      border-left: 4px solid var(--primary);
      padding-left: 1rem;
    }
    
    h2 { font-size: 1.25rem; }
    h3 { font-size: 1rem; }
    
    p { margin: 0.75rem 0; }
    
    ul, ol { padding-left: 1.5rem; margin: 0.75rem 0; }
    li { margin: 0.5rem 0; }
    
    strong { font-weight: 600; }
    
    a { color: var(--primary); text-decoration: none; }
    a:hover { text-decoration: underline; }
    
    table {
      width: 100%;
      border-collapse: collapse;
      margin: 1rem 0;
      font-size: 0.9rem;
    }
    
    th, td {
      padding: 0.75rem 1rem;
      text-align: left;
      border-bottom: 1px solid var(--border);
    }
    
    th { background: var(--border); font-weight: 600; }
    
    blockquote {
      margin: 1rem 0;
      padding: 0.75rem 1rem;
      border-left: 4px solid var(--primary-light);
      background: rgba(124, 58, 237, 0.05);
      font-style: italic;
    }
    
    code {
      background: var(--border);
      padding: 0.125rem 0.375rem;
      border-radius: 0.25rem;
      font-size: 0.875em;
    }
    
    hr {
      border: none;
      border-top: 2px dashed var(--border);
      margin: 2rem 0;
    }
    
    footer {
      margin-top: 3rem;
      padding-top: 1.5rem;
      border-top: 1px solid var(--border);
      text-align: center;
      color: var(--text-muted);
      font-size: 0.875rem;
    }
    
    @media print {
      body { padding: 1rem; }
      h2 { break-after: avoid; }
      table { break-inside: avoid; }
    }
  </style>
</head>
<body>
  <header>
    <h1>NewsInsight AI 분석 보고서</h1>
    <div class="query">"${query}"</div>
    <div class="meta">생성 시간: ${timestamp}</div>
  </header>
  
  <main>
    ${markdownToHtml(content)}
  </main>
  
  <footer>
    <p>이 보고서는 NewsInsight AI에 의해 자동 생성되었습니다.</p>
    <p>모든 정보는 참고용이며, 최종 판단은 사용자의 몫입니다.</p>
  </footer>
</body>
</html>`;
};

/**
 * Simple markdown to HTML conversion
 */
const markdownToHtml = (md: string): string => {
  return md
    .replace(/^### \[([^\]]+)\] (.+)$/gm, '<h3>$1: $2</h3>')
    .replace(/^### (.+)$/gm, '<h3>$1</h3>')
    .replace(/^## \[([^\]]+)\] (.+)$/gm, '<h2>$1: $2</h2>')
    .replace(/^## (.+)$/gm, '<h2>$1</h2>')
    .replace(/\*\*(.+?)\*\*/g, '<strong>$1</strong>')
    .replace(/\*(.+?)\*/g, '<em>$1</em>')
    .replace(/\[([^\]]+)\]\(([^)]+)\)/g, '<a href="$2" target="_blank">$1</a>')
    .replace(/^- (.+)$/gm, '<li>$1</li>')
    .replace(/(<li>.*<\/li>\n?)+/gs, '<ul>$&</ul>')
    .replace(/^> (.+)$/gm, '<blockquote>$1</blockquote>')
    .replace(/`([^`]+)`/g, '<code>$1</code>')
    .replace(/^---$/gm, '<hr>')
    .replace(/^(?!<[a-z])(.*[^\n])$/gm, '<p>$1</p>')
    .replace(/<p>\s*<\/p>/g, '');
};

/**
 * Download file utility
 */
const downloadFile = (content: string, filename: string, mimeType: string) => {
  const blob = new Blob([content], { type: mimeType });
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url;
  a.download = filename;
  document.body.appendChild(a);
  a.click();
  document.body.removeChild(a);
  URL.revokeObjectURL(url);
};

// ============================================
// Component
// ============================================

/**
 * Unified Export Menu Component
 * 
 * Combines PDF report, AI analysis export, and data export into a single dropdown.
 */
export function UnifiedExportMenu({
  jobId,
  query,
  reportType = 'UNIFIED_SEARCH',
  timeWindow = '7d',
  aiContent,
  data,
  chartRefs,
  exportOptions = {},
  variant = 'outline',
  size = 'default',
  className,
  disabled = false,
  iconOnly = false,
}: UnifiedExportMenuProps) {
  const [isExporting, setIsExporting] = useState(false);
  const [copied, setCopied] = useState(false);
  const [pdfDialogOpen, setPdfDialogOpen] = useState(false);
  const [selectedSections, setSelectedSections] = useState<ReportSection[]>(
    DEFAULT_REPORT_SECTIONS[reportType]
  );
  
  const { exportData, copyToClipboard } = useExport();
  
  // Generate base filename
  const timestamp = new Date().toISOString().slice(0, 10).replace(/-/g, '');
  const safeQuery = query.replace(/[^가-힣a-zA-Z0-9]/g, '_').slice(0, 30);
  const typeLabel = reportType === 'DEEP_SEARCH' ? 'DeepSearch' : '통합검색';
  const baseFilename = `NewsInsight_${typeLabel}_${safeQuery}_${timestamp}`;

  // Capture chart images for PDF
  const captureChartImages = useCallback((): Record<string, string> => {
    const images: Record<string, string> = {};
    if (chartRefs) {
      for (const [key, ref] of Object.entries(chartRefs)) {
        if (ref.current) {
          const base64 = ref.current.toBase64();
          if (base64) {
            images[key] = base64;
          }
        }
      }
    }
    return images;
  }, [chartRefs]);

  // PDF Export with dialog
  const handlePdfExport = async () => {
    if (!jobId) {
      toast.error('PDF 내보내기는 검색 작업 ID가 필요합니다.');
      return;
    }
    
    setIsExporting(true);
    try {
      const chartImages = captureChartImages();
      
      const request: ReportRequest = {
        reportType,
        targetId: jobId,
        query,
        timeWindow,
        includeSections: selectedSections,
        chartImages,
        language: 'ko',
      };

      let blob: Blob;
      if (reportType === 'DEEP_SEARCH') {
        blob = await exportDeepSearchReport(jobId, request);
      } else {
        blob = await exportUnifiedSearchReport(jobId, request);
      }

      triggerPdfDownload(blob, `${baseFilename}.pdf`);
      toast.success('PDF 보고서가 다운로드되었습니다.');
      setPdfDialogOpen(false);
    } catch (error) {
      console.error('PDF export failed:', error);
      toast.error('PDF 보고서 생성에 실패했습니다.');
    } finally {
      setIsExporting(false);
    }
  };

  // AI Content exports
  const handleMarkdownExport = useCallback(() => {
    if (!aiContent) {
      toast.error('내보낼 AI 분석 내용이 없습니다.');
      return;
    }
    
    const mdContent = `# NewsInsight AI 분석 보고서

**검색어**: ${query}  
**생성 시간**: ${new Date().toLocaleString('ko-KR')}

---

${aiContent}

---

*이 보고서는 NewsInsight AI에 의해 자동 생성되었습니다.*
`;
    downloadFile(mdContent, `${baseFilename}_AI분석.md`, 'text/markdown;charset=utf-8');
    toast.success('Markdown 파일이 다운로드되었습니다.');
  }, [aiContent, query, baseFilename]);

  const handleHtmlExport = useCallback(() => {
    if (!aiContent) {
      toast.error('내보낼 AI 분석 내용이 없습니다.');
      return;
    }
    
    const htmlContent = generateHtmlReport(aiContent, query);
    downloadFile(htmlContent, `${baseFilename}_AI분석.html`, 'text/html;charset=utf-8');
    toast.success('HTML 파일이 다운로드되었습니다.');
  }, [aiContent, query, baseFilename]);

  const handleTextExport = useCallback(() => {
    if (!aiContent) {
      toast.error('내보낼 AI 분석 내용이 없습니다.');
      return;
    }
    
    const plainText = aiContent
      .replace(/#{1,6}\s/g, '')
      .replace(/\*\*(.+?)\*\*/g, '$1')
      .replace(/\*(.+?)\*/g, '$1')
      .replace(/\[([^\]]+)\]\([^)]+\)/g, '$1')
      .replace(/`([^`]+)`/g, '$1')
      .replace(/\|/g, ' | ');
    
    const textContent = `NewsInsight AI 분석 보고서
========================================

검색어: ${query}
생성 시간: ${new Date().toLocaleString('ko-KR')}

========================================

${plainText}

========================================

이 보고서는 NewsInsight AI에 의해 자동 생성되었습니다.
`;
    downloadFile(textContent, `${baseFilename}_AI분석.txt`, 'text/plain;charset=utf-8');
    toast.success('텍스트 파일이 다운로드되었습니다.');
  }, [aiContent, query, baseFilename]);

  // Data exports (JSON/CSV)
  const handleDataExport = (format: ExportFormat) => {
    if (!data || data.length === 0) {
      toast.error('내보낼 데이터가 없습니다.');
      return;
    }
    exportData(data, format, { ...exportOptions, filename: baseFilename });
  };

  // Clipboard
  const handleCopy = async (type: 'ai' | 'data') => {
    try {
      if (type === 'ai' && aiContent) {
        await navigator.clipboard.writeText(aiContent);
      } else if (type === 'data' && data) {
        await copyToClipboard(data, 'json');
      } else {
        toast.error('복사할 내용이 없습니다.');
        return;
      }
      setCopied(true);
      toast.success('클립보드에 복사되었습니다.');
      setTimeout(() => setCopied(false), 2000);
    } catch {
      toast.error('복사에 실패했습니다.');
    }
  };

  // Section selection for PDF
  const toggleSection = (sectionId: ReportSection) => {
    setSelectedSections((prev) =>
      prev.includes(sectionId)
        ? prev.filter((s) => s !== sectionId)
        : [...prev, sectionId]
    );
  };

  const selectAllSections = () => {
    setSelectedSections(ALL_SECTIONS.map((s) => s.id));
  };

  const selectDefaultSections = () => {
    setSelectedSections(DEFAULT_REPORT_SECTIONS[reportType]);
  };

  const availableSections = ALL_SECTIONS.filter((section) => {
    if (reportType === 'UNIFIED_SEARCH') {
      return section.id !== 'EVIDENCE_LIST';
    }
    if (reportType === 'DEEP_SEARCH') {
      return section.id !== 'TREND_ANALYSIS' && section.id !== 'KEYWORD_ANALYSIS';
    }
    return true;
  });

  const hasAnyContent = jobId || aiContent || (data && data.length > 0);
  const isDisabled = disabled || !hasAnyContent;

  return (
    <>
      <DropdownMenu>
        <DropdownMenuTrigger asChild>
          <Button
            variant={variant}
            size={size}
            disabled={isDisabled || isExporting}
            className={className}
            aria-label="내보내기"
          >
            {isExporting ? (
              <Loader2 className="h-4 w-4 animate-spin" />
            ) : (
              <Download className="h-4 w-4" />
            )}
            {!iconOnly && (
              <>
                <span className="ml-2">내보내기</span>
                <ChevronDown className="ml-1 h-3 w-3" />
              </>
            )}
          </Button>
        </DropdownMenuTrigger>
        <DropdownMenuContent align="end" className="w-56">
          {/* PDF Report Section */}
          {jobId && (
            <>
              <DropdownMenuLabel className="flex items-center gap-2">
                <FileText className="h-4 w-4 text-red-600" />
                PDF 보고서
              </DropdownMenuLabel>
              <DropdownMenuItem onClick={() => setPdfDialogOpen(true)}>
                <Settings2 className="h-4 w-4 mr-2" />
                PDF 보고서 생성...
              </DropdownMenuItem>
              <DropdownMenuSeparator />
            </>
          )}

          {/* AI Analysis Export Section */}
          {aiContent && (
            <>
              <DropdownMenuLabel className="flex items-center gap-2">
                <FileCode className="h-4 w-4 text-purple-600" />
                AI 분석 내보내기
              </DropdownMenuLabel>
              <DropdownMenuItem onClick={handleMarkdownExport}>
                <FileCode className="h-4 w-4 mr-2 text-blue-600" />
                Markdown (.md)
              </DropdownMenuItem>
              <DropdownMenuItem onClick={handleHtmlExport}>
                <FileType2 className="h-4 w-4 mr-2 text-orange-600" />
                HTML 웹페이지
              </DropdownMenuItem>
              <DropdownMenuItem onClick={handleTextExport}>
                <FileText className="h-4 w-4 mr-2 text-gray-600" />
                텍스트 (.txt)
              </DropdownMenuItem>
              <DropdownMenuItem onClick={() => handleCopy('ai')}>
                {copied ? (
                  <Check className="h-4 w-4 mr-2 text-green-600" />
                ) : (
                  <Copy className="h-4 w-4 mr-2" />
                )}
                AI 분석 복사
              </DropdownMenuItem>
              <DropdownMenuSeparator />
            </>
          )}

          {/* Data Export Section */}
          {data && data.length > 0 && (
            <>
              <DropdownMenuLabel className="flex items-center gap-2">
                <FileJson className="h-4 w-4 text-yellow-600" />
                데이터 내보내기
              </DropdownMenuLabel>
              <DropdownMenuItem onClick={() => handleDataExport('json')}>
                <FileJson className="h-4 w-4 mr-2 text-yellow-600" />
                JSON으로 내보내기
              </DropdownMenuItem>
              <DropdownMenuItem onClick={() => handleDataExport('csv')}>
                <FileSpreadsheet className="h-4 w-4 mr-2 text-green-600" />
                CSV로 내보내기
              </DropdownMenuItem>
              <DropdownMenuItem onClick={() => handleDataExport('markdown')}>
                <FileCode className="h-4 w-4 mr-2 text-blue-600" />
                Markdown 테이블
              </DropdownMenuItem>
              <DropdownMenuSeparator />
              <DropdownMenuItem onClick={() => handleCopy('data')}>
                {copied ? (
                  <Check className="h-4 w-4 mr-2 text-green-600" />
                ) : (
                  <Copy className="h-4 w-4 mr-2" />
                )}
                데이터 복사 (JSON)
              </DropdownMenuItem>
            </>
          )}

          {/* Fallback if nothing is available */}
          {!hasAnyContent && (
            <DropdownMenuItem disabled>
              내보낼 내용이 없습니다
            </DropdownMenuItem>
          )}
        </DropdownMenuContent>
      </DropdownMenu>

      {/* PDF Section Selection Dialog */}
      <Dialog open={pdfDialogOpen} onOpenChange={setPdfDialogOpen}>
        <DialogContent className="sm:max-w-[500px]">
          <DialogHeader>
            <DialogTitle>PDF 보고서 내보내기</DialogTitle>
            <DialogDescription>
              보고서에 포함할 섹션을 선택하세요.
            </DialogDescription>
          </DialogHeader>

          <div className="py-4">
            {/* Quick actions */}
            <div className="flex gap-2 mb-4">
              <Button variant="outline" size="sm" onClick={selectAllSections}>
                전체 선택
              </Button>
              <Button variant="outline" size="sm" onClick={selectDefaultSections}>
                기본값
              </Button>
            </div>

            {/* Section selection */}
            <div className="space-y-3 max-h-[300px] overflow-y-auto pr-2">
              {availableSections.map((section) => (
                <div
                  key={section.id}
                  className="flex items-start space-x-3 p-2 rounded-lg hover:bg-muted/50 transition-colors"
                >
                  <Checkbox
                    id={section.id}
                    checked={selectedSections.includes(section.id)}
                    onCheckedChange={() => toggleSection(section.id)}
                  />
                  <div className="flex-1">
                    <Label
                      htmlFor={section.id}
                      className="text-sm font-medium cursor-pointer"
                    >
                      {section.label}
                    </Label>
                    <p className="text-xs text-muted-foreground">
                      {section.description}
                    </p>
                  </div>
                </div>
              ))}
            </div>

            {/* Summary */}
            <div className="mt-4 pt-4 border-t text-sm text-muted-foreground">
              {selectedSections.length}개 섹션 선택됨
            </div>
          </div>

          <DialogFooter>
            <Button variant="outline" onClick={() => setPdfDialogOpen(false)}>
              취소
            </Button>
            <Button
              onClick={handlePdfExport}
              disabled={isExporting || selectedSections.length === 0}
            >
              {isExporting ? (
                <>
                  <Loader2 className="h-4 w-4 mr-2 animate-spin" />
                  생성 중...
                </>
              ) : (
                <>
                  <FileText className="h-4 w-4 mr-2" />
                  내보내기
                </>
              )}
            </Button>
          </DialogFooter>
        </DialogContent>
      </Dialog>
    </>
  );
}

export default UnifiedExportMenu;

```

---

## frontend/src/components/UrlClaimExtractor.tsx

```tsx
import { useState, useCallback } from "react";
import {
  Link as LinkIcon,
  Loader2,
  AlertCircle,
  X,
  Sparkles,
  FileText,
  Globe,
  ArrowRight,
} from "lucide-react";
import { Button } from "@/components/ui/button";
import { Input } from "@/components/ui/input";
import { Badge } from "@/components/ui/badge";
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from "@/components/ui/card";
import { Alert, AlertDescription } from "@/components/ui/alert";
import { Checkbox } from "@/components/ui/checkbox";
import { cn } from "@/lib/utils";
import { extractClaimsFromUrl } from "@/lib/api";

interface ExtractedClaim {
  id: string;
  text: string;
  confidence: number;
  context?: string;
  selected: boolean;
}

interface UrlClaimExtractorProps {
  /** URL 추출 후 선택된 주장들을 전달하는 콜백 */
  onClaimsExtracted: (claims: string[]) => void;
  /** 현재 분석 중인지 여부 */
  disabled?: boolean;
  /** 추가 CSS 클래스 */
  className?: string;
}

/** URL 유효성 검사 */
const isValidUrl = (url: string): boolean => {
  try {
    const parsed = new URL(url);
    return parsed.protocol === "http:" || parsed.protocol === "https:";
  } catch {
    return false;
  }
};

/** 신뢰도에 따른 색상 */
const getConfidenceColor = (confidence: number): string => {
  if (confidence >= 0.8) return "text-green-600";
  if (confidence >= 0.5) return "text-yellow-600";
  return "text-orange-600";
};

export function UrlClaimExtractor({
  onClaimsExtracted,
  disabled = false,
  className,
}: UrlClaimExtractorProps) {
  const [url, setUrl] = useState("");
  const [isExtracting, setIsExtracting] = useState(false);
  const [extractedClaims, setExtractedClaims] = useState<ExtractedClaim[]>([]);
  const [error, setError] = useState<string | null>(null);
  const [pageTitle, setPageTitle] = useState<string | null>(null);

  // URL에서 주장 추출 - 실제 백엔드 API 호출
  const extractClaims = useCallback(async () => {
    if (!url.trim() || !isValidUrl(url)) {
      setError("올바른 URL을 입력해주세요.");
      return;
    }

    setIsExtracting(true);
    setError(null);
    setExtractedClaims([]);
    setPageTitle(null);

    try {
      // 실제 백엔드 API 호출
      const response = await extractClaimsFromUrl({ 
        url: url.trim(),
        maxClaims: 10,
        minConfidence: 0.5
      });
      
      if (response.message && response.claims.length === 0) {
        setError(response.message);
        return;
      }

      if (response.claims && Array.isArray(response.claims)) {
        setExtractedClaims(
          response.claims.map((claim) => ({
            id: claim.id,
            text: claim.text,
            confidence: claim.confidence || 0.7,
            context: claim.context,
            selected: true, // 기본적으로 모두 선택
          }))
        );
        setPageTitle(response.pageTitle || null);
      } else {
        setError("주장을 추출할 수 없습니다.");
      }
    } catch (err) {
      console.error("Claim extraction failed:", err);
      const errorMessage = err instanceof Error ? err.message : "알 수 없는 오류가 발생했습니다.";
      setError(`주장 추출 실패: ${errorMessage}`);
    } finally {
      setIsExtracting(false);
    }
  }, [url]);

  // 주장 선택 토글
  const toggleClaim = useCallback((id: string) => {
    setExtractedClaims((prev) =>
      prev.map((claim) =>
        claim.id === id ? { ...claim, selected: !claim.selected } : claim
      )
    );
  }, []);

  // 모두 선택/해제
  const toggleAll = useCallback((selected: boolean) => {
    setExtractedClaims((prev) =>
      prev.map((claim) => ({ ...claim, selected }))
    );
  }, []);

  // 선택된 주장 적용
  const applyClaims = useCallback(() => {
    const selectedClaims = extractedClaims
      .filter((c) => c.selected)
      .map((c) => c.text);
    
    if (selectedClaims.length === 0) {
      setError("최소 1개 이상의 주장을 선택해주세요.");
      return;
    }

    onClaimsExtracted(selectedClaims);
    
    // 초기화
    setUrl("");
    setExtractedClaims([]);
    setPageTitle(null);
  }, [extractedClaims, onClaimsExtracted]);

  // 취소/초기화
  const handleReset = useCallback(() => {
    setUrl("");
    setExtractedClaims([]);
    setError(null);
    setPageTitle(null);
  }, []);

  const selectedCount = extractedClaims.filter((c) => c.selected).length;
  const hasResults = extractedClaims.length > 0;

  return (
    <Card className={cn("border-dashed border-2 border-muted-foreground/25", className)}>
      <CardHeader className="pb-3">
        <div className="flex items-center gap-2">
          <Globe className="h-5 w-5 text-blue-600" />
          <CardTitle className="text-lg">URL에서 주장 추출</CardTitle>
          <Badge variant="secondary" className="text-xs">AI 자동 추출</Badge>
        </div>
        <CardDescription>
          뉴스 기사나 웹페이지 URL을 입력하면 AI가 자동으로 검증할 수 있는 주장들을 추출합니다.
        </CardDescription>
      </CardHeader>

      <CardContent className="space-y-4">
        {/* URL 입력 */}
        {!hasResults && (
          <div className="flex gap-2">
            <div className="relative flex-1">
              <LinkIcon className="absolute left-3 top-1/2 -translate-y-1/2 h-4 w-4 text-muted-foreground" />
              <Input
                value={url}
                onChange={(e) => {
                  setUrl(e.target.value);
                  setError(null);
                }}
                placeholder="https://news.example.com/article/..."
                disabled={disabled || isExtracting}
                className="pl-10"
              />
            </div>
            <Button
              onClick={extractClaims}
              disabled={disabled || isExtracting || !url.trim()}
            >
              {isExtracting ? (
                <>
                  <Loader2 className="h-4 w-4 mr-2 animate-spin" />
                  추출 중...
                </>
              ) : (
                <>
                  <Sparkles className="h-4 w-4 mr-2" />
                  추출
                </>
              )}
            </Button>
          </div>
        )}

        {/* 에러 메시지 */}
        {error && (
          <Alert variant="destructive">
            <AlertCircle className="h-4 w-4" />
            <AlertDescription>{error}</AlertDescription>
          </Alert>
        )}

        {/* 추출 중 상태 */}
        {isExtracting && (
          <div className="flex items-center justify-center py-8 text-muted-foreground">
            <div className="text-center space-y-3">
              <Loader2 className="h-8 w-8 animate-spin mx-auto text-primary" />
              <div>
                <p className="font-medium">URL 분석 중...</p>
                <p className="text-sm">페이지에서 검증 가능한 주장을 찾고 있습니다.</p>
              </div>
            </div>
          </div>
        )}

        {/* 추출 결과 */}
        {hasResults && !isExtracting && (
          <div className="space-y-4">
            {/* 페이지 정보 */}
            {pageTitle && (
              <div className="flex items-center gap-2 p-3 rounded-lg bg-muted/50">
                <FileText className="h-4 w-4 text-muted-foreground" />
                <span className="text-sm font-medium truncate">{pageTitle}</span>
                <Badge variant="outline" className="ml-auto shrink-0">
                  {extractedClaims.length}개 주장 발견
                </Badge>
              </div>
            )}

            {/* 선택 컨트롤 */}
            <div className="flex items-center justify-between">
              <div className="flex items-center gap-4">
                <Button
                  variant="ghost"
                  size="sm"
                  onClick={() => toggleAll(true)}
                  disabled={selectedCount === extractedClaims.length}
                >
                  모두 선택
                </Button>
                <Button
                  variant="ghost"
                  size="sm"
                  onClick={() => toggleAll(false)}
                  disabled={selectedCount === 0}
                >
                  모두 해제
                </Button>
              </div>
              <span className="text-sm text-muted-foreground">
                {selectedCount}개 선택됨
              </span>
            </div>

            {/* 주장 목록 */}
            <div className="space-y-2 max-h-[300px] overflow-y-auto pr-2">
              {extractedClaims.map((claim) => (
                <div
                  key={claim.id}
                  className={cn(
                    "p-3 rounded-lg border transition-colors cursor-pointer",
                    claim.selected
                      ? "border-primary bg-primary/5"
                      : "border-muted hover:border-muted-foreground/50"
                  )}
                  onClick={() => toggleClaim(claim.id)}
                >
                  <div className="flex items-start gap-3">
                    <Checkbox
                      checked={claim.selected}
                      onCheckedChange={() => toggleClaim(claim.id)}
                      className="mt-0.5"
                    />
                    <div className="flex-1 min-w-0">
                      <p className="text-sm">{claim.text}</p>
                      <div className="flex items-center gap-2 mt-1">
                        <span className={cn("text-xs", getConfidenceColor(claim.confidence))}>
                          신뢰도: {Math.round(claim.confidence * 100)}%
                        </span>
                        {claim.context && (
                          <span className="text-xs text-muted-foreground">
                            • {claim.context}
                          </span>
                        )}
                      </div>
                    </div>
                  </div>
                </div>
              ))}
            </div>

            {/* 액션 버튼 */}
            <div className="flex gap-2 pt-2">
              <Button
                variant="outline"
                onClick={handleReset}
                className="flex-1"
              >
                <X className="h-4 w-4 mr-2" />
                취소
              </Button>
              <Button
                onClick={applyClaims}
                disabled={selectedCount === 0}
                className="flex-1"
              >
                <ArrowRight className="h-4 w-4 mr-2" />
                {selectedCount}개 주장 적용
              </Button>
            </div>
          </div>
        )}

        {/* 빈 상태 안내 */}
        {!hasResults && !isExtracting && !error && (
          <p className="text-xs text-muted-foreground text-center py-2">
            URL을 입력하고 "추출" 버튼을 클릭하세요. AI가 자동으로 사실 확인이 필요한 주장들을 찾아냅니다.
          </p>
        )}
      </CardContent>
    </Card>
  );
}

export default UrlClaimExtractor;

```

---

## frontend/src/components/UrlTree.tsx

```tsx
import React, { useState, useCallback, useMemo, useRef } from 'react';
import {
  Folder,
  FolderOpen,
  File,
  Link,
  ChevronRight,
  ChevronDown,
  MoreHorizontal,
  Trash2,
  Edit,
  FolderPlus,
  Plus,
  Check,
  X,
  GripVertical,
  ExternalLink,
  Clock,
} from 'lucide-react';
import { cn } from '@/lib/utils';
import { Button } from '@/components/ui/button';
import { Input } from '@/components/ui/input';
import { Checkbox } from '@/components/ui/checkbox';
import { Badge } from '@/components/ui/badge';
import {
  DropdownMenu,
  DropdownMenuContent,
  DropdownMenuItem,
  DropdownMenuSeparator,
  DropdownMenuTrigger,
} from '@/components/ui/dropdown-menu';
import {
  Tooltip,
  TooltipContent,
  TooltipTrigger,
} from '@/components/ui/tooltip';
import type { TreeItem, FolderItem, UrlItem, SelectedItems } from '@/hooks/useUrlCollection';

// ============================================
// Drag & Drop Context
// ============================================

interface DragState {
  draggedItemId: string | null;
  draggedItemType: 'folder' | 'url' | null;
  dropTargetId: string | null;
  dropPosition: 'before' | 'inside' | 'after' | null;
}

// ============================================
// Tree Item Component
// ============================================

interface TreeNodeProps {
  item: TreeItem;
  depth: number;
  selectedItems: SelectedItems;
  onToggleFolder: (id: string) => void;
  onToggleSelection: (id: string, type: 'folder' | 'url') => void;
  onDelete: (id: string) => void;
  onUpdate: (id: string, updates: Partial<UrlItem | FolderItem>) => void;
  onAddFolder: (parentId: string) => void;
  onAddUrl: (parentId: string) => void;
  onSelectAll: (folderId: string) => void;
  onMoveItem?: (itemId: string, targetFolderId: string) => void;
  dragState: DragState;
  onDragStart: (id: string, type: 'folder' | 'url') => void;
  onDragEnd: () => void;
  onDragOver: (id: string, position: 'before' | 'inside' | 'after') => void;
  onDrop: (targetId: string) => void;
}

const TreeNode: React.FC<TreeNodeProps> = ({
  item,
  depth,
  selectedItems,
  onToggleFolder,
  onToggleSelection,
  onDelete,
  onUpdate,
  onAddFolder,
  onAddUrl,
  onSelectAll,
  onMoveItem,
  dragState,
  onDragStart,
  onDragEnd,
  onDragOver,
  onDrop,
}) => {
  const [isEditing, setIsEditing] = useState(false);
  const [editName, setEditName] = useState(item.name);
  const nodeRef = useRef<HTMLDivElement>(null);

  const isSelected = item.type === 'folder' 
    ? selectedItems.folders.has(item.id)
    : selectedItems.urls.has(item.id);

  const isDragging = dragState.draggedItemId === item.id;
  const isDropTarget = dragState.dropTargetId === item.id;
  const dropPosition = isDropTarget ? dragState.dropPosition : null;

  const handleDragStart = (e: React.DragEvent) => {
    e.stopPropagation();
    e.dataTransfer.effectAllowed = 'move';
    e.dataTransfer.setData('text/plain', item.id);
    onDragStart(item.id, item.type);
  };

  const handleDragEnd = (e: React.DragEvent) => {
    e.preventDefault();
    onDragEnd();
  };

  const handleDragOver = (e: React.DragEvent) => {
    e.preventDefault();
    e.stopPropagation();
    
    if (dragState.draggedItemId === item.id) return;
    
    // Don't allow dropping a folder into itself or its children
    if (dragState.draggedItemType === 'folder' && item.type === 'folder') {
      // This is a simplified check - a full check would verify ancestry
    }

    const rect = nodeRef.current?.getBoundingClientRect();
    if (!rect) return;

    const y = e.clientY - rect.top;
    const height = rect.height;

    // For folders, allow dropping inside
    if (item.type === 'folder') {
      if (y < height * 0.25) {
        onDragOver(item.id, 'before');
      } else if (y > height * 0.75) {
        onDragOver(item.id, 'after');
      } else {
        onDragOver(item.id, 'inside');
      }
    } else {
      // For URLs, only allow before/after
      if (y < height * 0.5) {
        onDragOver(item.id, 'before');
      } else {
        onDragOver(item.id, 'after');
      }
    }
  };

  const handleDrop = (e: React.DragEvent) => {
    e.preventDefault();
    e.stopPropagation();
    onDrop(item.id);
  };

  const handleDragLeave = (e: React.DragEvent) => {
    e.preventDefault();
  };

  const handleSaveEdit = () => {
    if (editName.trim()) {
      onUpdate(item.id, { name: editName.trim() });
    }
    setIsEditing(false);
  };

  const handleCancelEdit = () => {
    setEditName(item.name);
    setIsEditing(false);
  };

  const handleKeyDown = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter') {
      handleSaveEdit();
    } else if (e.key === 'Escape') {
      handleCancelEdit();
    }
  };

  if (item.type === 'folder') {
    const folder = item as FolderItem;
    return (
      <div>
        <div
          ref={nodeRef}
          draggable={!isEditing}
          onDragStart={handleDragStart}
          onDragEnd={handleDragEnd}
          onDragOver={handleDragOver}
          onDrop={handleDrop}
          onDragLeave={handleDragLeave}
          className={cn(
            'group flex items-center gap-1 py-1.5 px-2 rounded-md hover:bg-muted/50 cursor-pointer transition-colors',
            isSelected && 'bg-primary/10 hover:bg-primary/20',
            isDragging && 'opacity-50 bg-muted',
            isDropTarget && dropPosition === 'inside' && 'ring-2 ring-primary ring-inset bg-primary/5',
            isDropTarget && dropPosition === 'before' && 'border-t-2 border-primary',
            isDropTarget && dropPosition === 'after' && 'border-b-2 border-primary'
          )}
          style={{ paddingLeft: `${depth * 16 + 8}px` }}
        >
          {/* Drag Handle */}
          <GripVertical className="h-4 w-4 text-muted-foreground/50 shrink-0 cursor-grab active:cursor-grabbing opacity-0 group-hover:opacity-100 transition-opacity" />

          {/* Expand/Collapse */}
          <button
            onClick={() => onToggleFolder(folder.id)}
            className="p-0.5 hover:bg-muted rounded"
          >
            {folder.isExpanded ? (
              <ChevronDown className="h-4 w-4 text-muted-foreground" />
            ) : (
              <ChevronRight className="h-4 w-4 text-muted-foreground" />
            )}
          </button>

          {/* Checkbox */}
          <Checkbox
            checked={isSelected}
            onCheckedChange={() => onToggleSelection(folder.id, 'folder')}
            className="mr-1"
          />

          {/* Icon */}
          {folder.isExpanded ? (
            <FolderOpen className="h-4 w-4 text-yellow-600 shrink-0" />
          ) : (
            <Folder className="h-4 w-4 text-yellow-600 shrink-0" />
          )}

          {/* Name */}
          {isEditing ? (
            <div className="flex items-center gap-1 flex-1">
              <Input
                value={editName}
                onChange={(e) => setEditName(e.target.value)}
                onKeyDown={handleKeyDown}
                className="h-6 text-sm py-0"
                autoFocus
              />
              <Button size="icon" variant="ghost" className="h-6 w-6" onClick={handleSaveEdit}>
                <Check className="h-3 w-3" />
              </Button>
              <Button size="icon" variant="ghost" className="h-6 w-6" onClick={handleCancelEdit}>
                <X className="h-3 w-3" />
              </Button>
            </div>
          ) : (
            <span
              className="flex-1 text-sm font-medium truncate"
              onDoubleClick={() => setIsEditing(true)}
            >
              {folder.name}
            </span>
          )}

          {/* Item count */}
          <Badge variant="secondary" className="text-xs h-5 px-1.5">
            {folder.children.length}
          </Badge>

          {/* Actions */}
          <DropdownMenu>
            <DropdownMenuTrigger asChild>
              <Button
                size="icon"
                variant="ghost"
                className="h-6 w-6 opacity-0 group-hover:opacity-100 transition-opacity"
              >
                <MoreHorizontal className="h-4 w-4" />
              </Button>
            </DropdownMenuTrigger>
            <DropdownMenuContent align="end">
              <DropdownMenuItem onClick={() => onAddFolder(folder.id)}>
                <FolderPlus className="h-4 w-4 mr-2" />
                하위 폴더 추가
              </DropdownMenuItem>
              <DropdownMenuItem onClick={() => onAddUrl(folder.id)}>
                <Plus className="h-4 w-4 mr-2" />
                URL 추가
              </DropdownMenuItem>
              <DropdownMenuItem onClick={() => onSelectAll(folder.id)}>
                <Check className="h-4 w-4 mr-2" />
                전체 선택
              </DropdownMenuItem>
              <DropdownMenuSeparator />
              <DropdownMenuItem onClick={() => setIsEditing(true)}>
                <Edit className="h-4 w-4 mr-2" />
                이름 변경
              </DropdownMenuItem>
              <DropdownMenuItem
                onClick={() => onDelete(folder.id)}
                className="text-destructive focus:text-destructive"
              >
                <Trash2 className="h-4 w-4 mr-2" />
                삭제
              </DropdownMenuItem>
            </DropdownMenuContent>
          </DropdownMenu>
        </div>

        {/* Children */}
        {folder.isExpanded && (
          <div>
            {folder.children.map((child) => (
              <TreeNode
                key={child.id}
                item={child}
                depth={depth + 1}
                selectedItems={selectedItems}
                onToggleFolder={onToggleFolder}
                onToggleSelection={onToggleSelection}
                onDelete={onDelete}
                onUpdate={onUpdate}
                onAddFolder={onAddFolder}
                onAddUrl={onAddUrl}
                onSelectAll={onSelectAll}
                onMoveItem={onMoveItem}
                dragState={dragState}
                onDragStart={onDragStart}
                onDragEnd={onDragEnd}
                onDragOver={onDragOver}
                onDrop={onDrop}
              />
            ))}
          </div>
        )}
      </div>
    );
  }

  // URL item
  const url = item as UrlItem;
  return (
    <div
      ref={nodeRef}
      draggable={!isEditing}
      onDragStart={handleDragStart}
      onDragEnd={handleDragEnd}
      onDragOver={handleDragOver}
      onDrop={handleDrop}
      onDragLeave={handleDragLeave}
      className={cn(
        'group flex items-center gap-1 py-1.5 px-2 rounded-md hover:bg-muted/50 cursor-pointer transition-colors',
        isSelected && 'bg-primary/10 hover:bg-primary/20',
        isDragging && 'opacity-50 bg-muted',
        isDropTarget && dropPosition === 'before' && 'border-t-2 border-primary',
        isDropTarget && dropPosition === 'after' && 'border-b-2 border-primary'
      )}
      style={{ paddingLeft: `${depth * 16 + 28}px` }}
    >
      {/* Drag Handle */}
      <GripVertical className="h-4 w-4 text-muted-foreground/50 shrink-0 cursor-grab active:cursor-grabbing opacity-0 group-hover:opacity-100 transition-opacity" />

      {/* Checkbox */}
      <Checkbox
        checked={isSelected}
        onCheckedChange={() => onToggleSelection(url.id, 'url')}
        className="mr-1"
      />

      {/* Icon */}
      <Link className="h-4 w-4 text-blue-600 shrink-0" />

      {/* Name & URL */}
      {isEditing ? (
        <div className="flex items-center gap-1 flex-1">
          <Input
            value={editName}
            onChange={(e) => setEditName(e.target.value)}
            onKeyDown={handleKeyDown}
            className="h-6 text-sm py-0"
            autoFocus
          />
          <Button size="icon" variant="ghost" className="h-6 w-6" onClick={handleSaveEdit}>
            <Check className="h-3 w-3" />
          </Button>
          <Button size="icon" variant="ghost" className="h-6 w-6" onClick={handleCancelEdit}>
            <X className="h-3 w-3" />
          </Button>
        </div>
      ) : (
        <Tooltip>
          <TooltipTrigger asChild>
            <span
              className="flex-1 text-sm truncate"
              onDoubleClick={() => setIsEditing(true)}
            >
              {url.name}
            </span>
          </TooltipTrigger>
          <TooltipContent side="right" className="max-w-xs">
            <p className="text-xs break-all">{url.url}</p>
            {url.description && (
              <p className="text-xs text-muted-foreground mt-1">{url.description}</p>
            )}
          </TooltipContent>
        </Tooltip>
      )}

      {/* Tags */}
      {url.tags && url.tags.length > 0 && (
        <div className="hidden sm:flex gap-1">
          {url.tags.slice(0, 2).map((tag) => (
            <Badge key={tag} variant="outline" className="text-xs h-5 px-1">
              {tag}
            </Badge>
          ))}
        </div>
      )}

      {/* Last analyzed indicator */}
      {url.lastAnalyzedAt && (
        <Tooltip>
          <TooltipTrigger>
            <Clock className="h-3 w-3 text-green-600" />
          </TooltipTrigger>
          <TooltipContent>
            마지막 분석: {new Date(url.lastAnalyzedAt).toLocaleString('ko-KR')}
          </TooltipContent>
        </Tooltip>
      )}

      {/* External link */}
      <a
        href={url.url}
        target="_blank"
        rel="noopener noreferrer"
        onClick={(e) => e.stopPropagation()}
        className="opacity-0 group-hover:opacity-100 transition-opacity"
      >
        <ExternalLink className="h-3.5 w-3.5 text-muted-foreground hover:text-foreground" />
      </a>

      {/* Actions */}
      <DropdownMenu>
        <DropdownMenuTrigger asChild>
          <Button
            size="icon"
            variant="ghost"
            className="h-6 w-6 opacity-0 group-hover:opacity-100 transition-opacity"
          >
            <MoreHorizontal className="h-4 w-4" />
          </Button>
        </DropdownMenuTrigger>
        <DropdownMenuContent align="end">
          <DropdownMenuItem onClick={() => setIsEditing(true)}>
            <Edit className="h-4 w-4 mr-2" />
            이름 변경
          </DropdownMenuItem>
          <DropdownMenuItem
            onClick={() => {
              navigator.clipboard.writeText(url.url);
            }}
          >
            <Link className="h-4 w-4 mr-2" />
            URL 복사
          </DropdownMenuItem>
          <DropdownMenuSeparator />
          <DropdownMenuItem
            onClick={() => onDelete(url.id)}
            className="text-destructive focus:text-destructive"
          >
            <Trash2 className="h-4 w-4 mr-2" />
            삭제
          </DropdownMenuItem>
        </DropdownMenuContent>
      </DropdownMenu>
    </div>
  );
};

// ============================================
// URL Tree Component
// ============================================

interface UrlTreeProps {
  root: FolderItem;
  selectedItems: SelectedItems;
  onToggleFolder: (id: string) => void;
  onToggleSelection: (id: string, type: 'folder' | 'url') => void;
  onDelete: (id: string) => void;
  onUpdate: (id: string, updates: Partial<UrlItem | FolderItem>) => void;
  onAddFolder: (parentId: string) => void;
  onAddUrl: (parentId: string) => void;
  onSelectAll: (folderId: string) => void;
  onMoveItem?: (itemId: string, targetFolderId: string) => void;
}

export const UrlTree: React.FC<UrlTreeProps> = ({
  root,
  selectedItems,
  onToggleFolder,
  onToggleSelection,
  onDelete,
  onUpdate,
  onAddFolder,
  onAddUrl,
  onSelectAll,
  onMoveItem,
}) => {
  // Drag & Drop state management
  const [dragState, setDragState] = useState<DragState>({
    draggedItemId: null,
    draggedItemType: null,
    dropTargetId: null,
    dropPosition: null,
  });

  const handleDragStart = useCallback((id: string, type: 'folder' | 'url') => {
    setDragState({
      draggedItemId: id,
      draggedItemType: type,
      dropTargetId: null,
      dropPosition: null,
    });
  }, []);

  const handleDragEnd = useCallback(() => {
    setDragState({
      draggedItemId: null,
      draggedItemType: null,
      dropTargetId: null,
      dropPosition: null,
    });
  }, []);

  const handleDragOver = useCallback((id: string, position: 'before' | 'inside' | 'after') => {
    setDragState(prev => ({
      ...prev,
      dropTargetId: id,
      dropPosition: position,
    }));
  }, []);

  // Find parent folder of an item
  const findParentFolder = useCallback((itemId: string, items: (UrlItem | FolderItem)[], parentId: string = 'root'): string | null => {
    for (const item of items) {
      if (item.id === itemId) {
        return parentId;
      }
      if (item.type === 'folder') {
        const found = findParentFolder(itemId, item.children, item.id);
        if (found) return found;
      }
    }
    return null;
  }, []);

  const handleDrop = useCallback((targetId: string) => {
    if (!dragState.draggedItemId || !onMoveItem) {
      handleDragEnd();
      return;
    }

    const { draggedItemId, dropPosition } = dragState;

    // Prevent dropping an item onto itself
    if (draggedItemId === targetId) {
      handleDragEnd();
      return;
    }

    // Find the target item to determine its parent
    const findItem = (items: (UrlItem | FolderItem)[]): (UrlItem | FolderItem) | null => {
      for (const item of items) {
        if (item.id === targetId) return item;
        if (item.type === 'folder') {
          const found = findItem(item.children);
          if (found) return found;
        }
      }
      return null;
    };

    const targetItem = findItem(root.children);

    if (targetItem) {
      if (dropPosition === 'inside' && targetItem.type === 'folder') {
        // Drop inside folder
        onMoveItem(draggedItemId, targetId);
      } else {
        // Drop before/after - move to parent folder
        const parentId = findParentFolder(targetId, root.children);
        if (parentId) {
          onMoveItem(draggedItemId, parentId);
        }
      }
    }

    handleDragEnd();
  }, [dragState, onMoveItem, handleDragEnd, root.children, findParentFolder]);

  if (root.children.length === 0) {
    return (
      <div className="text-center py-8 text-muted-foreground">
        <Folder className="h-12 w-12 mx-auto mb-3 opacity-50" />
        <p className="text-sm">URL이 없습니다</p>
        <p className="text-xs mt-1">폴더나 URL을 추가하세요</p>
      </div>
    );
  }

  return (
    <div className="space-y-0.5">
      {root.children.map((item) => (
        <TreeNode
          key={item.id}
          item={item}
          depth={0}
          selectedItems={selectedItems}
          onToggleFolder={onToggleFolder}
          onToggleSelection={onToggleSelection}
          onDelete={onDelete}
          onUpdate={onUpdate}
          onAddFolder={onAddFolder}
          onAddUrl={onAddUrl}
          onSelectAll={onSelectAll}
          onMoveItem={onMoveItem}
          dragState={dragState}
          onDragStart={handleDragStart}
          onDragEnd={handleDragEnd}
          onDragOver={handleDragOver}
          onDrop={handleDrop}
        />
      ))}
    </div>
  );
};

export default UrlTree;

```

---

## frontend/src/components/VirtualList.tsx

```tsx
import { useState, useRef, useCallback, useEffect, useMemo } from "react";
import { cn } from "@/lib/utils";

interface VirtualListProps<T> {
  /** 렌더링할 아이템 배열 */
  items: T[];
  /** 각 아이템의 예상 높이 (픽셀) */
  itemHeight: number;
  /** 컨테이너 높이 (픽셀 또는 CSS 값) */
  containerHeight: number | string;
  /** 오버스캔 - 화면 밖에 추가로 렌더링할 아이템 수 */
  overscan?: number;
  /** 아이템 렌더 함수 */
  renderItem: (item: T, index: number, style: React.CSSProperties) => React.ReactNode;
  /** 아이템 키 추출 함수 */
  getItemKey: (item: T, index: number) => string | number;
  /** 추가 CSS 클래스 */
  className?: string;
  /** 빈 상태 렌더링 */
  emptyState?: React.ReactNode;
  /** 로딩 상태 */
  loading?: boolean;
  /** 로딩 상태 렌더링 */
  loadingState?: React.ReactNode;
}

/**
 * 가상화된 리스트 컴포넌트
 * 대량의 데이터를 효율적으로 렌더링
 * 
 * @example
 * ``\`tsx
 * <VirtualList
 *   items={searchResults}
 *   itemHeight={80}
 *   containerHeight={600}
 *   getItemKey={(item) => item.id}
 *   renderItem={(item, index, style) => (
 *     <div style={style}>
 *       <SearchResultCard result={item} />
 *     </div>
 *   )}
 * />
 * ``\`
 */
export function VirtualList<T>({
  items,
  itemHeight,
  containerHeight,
  overscan = 3,
  renderItem,
  getItemKey,
  className,
  emptyState,
  loading,
  loadingState,
}: VirtualListProps<T>) {
  const containerRef = useRef<HTMLDivElement>(null);
  const [scrollTop, setScrollTop] = useState(0);

  // 컨테이너 높이를 픽셀로 계산
  const [containerHeightPx, setContainerHeightPx] = useState(
    typeof containerHeight === "number" ? containerHeight : 400
  );

  // 컨테이너 크기 관찰
  useEffect(() => {
    if (typeof containerHeight === "number") {
      setContainerHeightPx(containerHeight);
      return;
    }

    const container = containerRef.current;
    if (!container) return;

    const observer = new ResizeObserver((entries) => {
      for (const entry of entries) {
        setContainerHeightPx(entry.contentRect.height);
      }
    });

    observer.observe(container);
    return () => observer.disconnect();
  }, [containerHeight]);

  // 스크롤 핸들러
  const handleScroll = useCallback((event: React.UIEvent<HTMLDivElement>) => {
    setScrollTop(event.currentTarget.scrollTop);
  }, []);

  // 가상화 계산
  const virtualData = useMemo(() => {
    const totalHeight = items.length * itemHeight;
    const startIndex = Math.max(0, Math.floor(scrollTop / itemHeight) - overscan);
    const endIndex = Math.min(
      items.length - 1,
      Math.floor((scrollTop + containerHeightPx) / itemHeight) + overscan
    );

    const visibleItems = items.slice(startIndex, endIndex + 1).map((item, i) => ({
      item,
      index: startIndex + i,
      style: {
        position: "absolute" as const,
        top: (startIndex + i) * itemHeight,
        left: 0,
        right: 0,
        height: itemHeight,
      },
    }));

    return {
      totalHeight,
      startIndex,
      endIndex,
      visibleItems,
    };
  }, [items, itemHeight, containerHeightPx, scrollTop, overscan]);

  // 빈 상태 또는 로딩 상태
  if (loading) {
    return (
      <div
        className={cn("flex items-center justify-center", className)}
        style={{ height: containerHeight }}
      >
        {loadingState || <div className="text-muted-foreground">로딩 중...</div>}
      </div>
    );
  }

  if (items.length === 0) {
    return (
      <div
        className={cn("flex items-center justify-center", className)}
        style={{ height: containerHeight }}
      >
        {emptyState || <div className="text-muted-foreground">데이터가 없습니다</div>}
      </div>
    );
  }

  return (
    <div
      ref={containerRef}
      className={cn("overflow-auto relative", className)}
      style={{ height: containerHeight }}
      onScroll={handleScroll}
    >
      <div
        style={{
          height: virtualData.totalHeight,
          position: "relative",
        }}
      >
        {virtualData.visibleItems.map(({ item, index, style }) => (
          <div key={getItemKey(item, index)} style={style}>
            {renderItem(item, index, style)}
          </div>
        ))}
      </div>
    </div>
  );
}

/**
 * 무한 스크롤 훅
 * 
 * @example
 * ``\`tsx
 * const { loadMoreRef, isLoading } = useInfiniteScroll({
 *   hasMore: data?.hasNextPage,
 *   onLoadMore: () => fetchNextPage(),
 * });
 * 
 * return (
 *   <div>
 *     {items.map(item => <Item key={item.id} />)}
 *     <div ref={loadMoreRef}>
 *       {isLoading && <Spinner />}
 *     </div>
 *   </div>
 * );
 * ``\`
 */
export function useInfiniteScroll(options: {
  hasMore: boolean;
  onLoadMore: () => void;
  threshold?: number;
  rootMargin?: string;
}) {
  const { hasMore, onLoadMore, threshold = 0.1, rootMargin = "100px" } = options;
  const loadMoreRef = useRef<HTMLDivElement>(null);
  const [isLoading, setIsLoading] = useState(false);

  useEffect(() => {
    const element = loadMoreRef.current;
    if (!element || !hasMore) return;

    const observer = new IntersectionObserver(
      async (entries) => {
        const [entry] = entries;
        if (entry.isIntersecting && hasMore && !isLoading) {
          setIsLoading(true);
          try {
            await onLoadMore();
          } finally {
            setIsLoading(false);
          }
        }
      },
      { threshold, rootMargin }
    );

    observer.observe(element);
    return () => observer.disconnect();
  }, [hasMore, onLoadMore, threshold, rootMargin, isLoading]);

  return { loadMoreRef, isLoading };
}

/**
 * 지연 로딩 이미지 컴포넌트
 * 
 * @example
 * ``\`tsx
 * <LazyImage
 *   src="/image.jpg"
 *   alt="Description"
 *   className="w-full h-48 object-cover"
 * />
 * ``\`
 */
interface LazyImageProps extends React.ImgHTMLAttributes<HTMLImageElement> {
  /** 로딩 중 표시할 플레이스홀더 */
  placeholder?: React.ReactNode;
  /** 에러 시 표시할 콘텐츠 */
  fallback?: React.ReactNode;
}

export function LazyImage({
  src,
  alt,
  className,
  placeholder,
  fallback,
  ...props
}: LazyImageProps) {
  const [isLoaded, setIsLoaded] = useState(false);
  const [hasError, setHasError] = useState(false);
  const imgRef = useRef<HTMLImageElement>(null);

  useEffect(() => {
    const img = imgRef.current;
    if (!img) return;

    const observer = new IntersectionObserver(
      (entries) => {
        const [entry] = entries;
        if (entry.isIntersecting) {
          // 실제 src 설정
          img.src = src || "";
          observer.disconnect();
        }
      },
      { rootMargin: "100px" }
    );

    observer.observe(img);
    return () => observer.disconnect();
  }, [src]);

  if (hasError && fallback) {
    return <>{fallback}</>;
  }

  return (
    <div className={cn("relative", className)}>
      {!isLoaded && !hasError && (
        <div className="absolute inset-0 flex items-center justify-center bg-muted animate-pulse">
          {placeholder || <div className="w-8 h-8 rounded-full bg-muted-foreground/20" />}
        </div>
      )}
      <img
        ref={imgRef}
        alt={alt}
        className={cn(
          "transition-opacity duration-300",
          isLoaded ? "opacity-100" : "opacity-0",
          className
        )}
        onLoad={() => setIsLoaded(true)}
        onError={() => setHasError(true)}
        {...props}
      />
    </div>
  );
}

/**
 * 디바운스 훅
 * 
 * @example
 * ``\`tsx
 * const debouncedSearch = useDebouncedCallback((query: string) => {
 *   search(query);
 * }, 300);
 * ``\`
 */
export function useDebouncedCallback<T extends (...args: any[]) => any>(
  callback: T,
  delay: number
): T {
  const timeoutRef = useRef<NodeJS.Timeout | null>(null);

  const debouncedCallback = useCallback(
    (...args: Parameters<T>) => {
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current);
      }
      timeoutRef.current = setTimeout(() => {
        callback(...args);
      }, delay);
    },
    [callback, delay]
  ) as T;

  // 클린업
  useEffect(() => {
    return () => {
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current);
      }
    };
  }, []);

  return debouncedCallback;
}

/**
 * 쓰로틀 훅
 * 
 * @example
 * ``\`tsx
 * const throttledScroll = useThrottledCallback((event) => {
 *   handleScroll(event);
 * }, 100);
 * ``\`
 */
export function useThrottledCallback<T extends (...args: any[]) => any>(
  callback: T,
  delay: number
): T {
  const lastCall = useRef(0);
  const timeoutRef = useRef<NodeJS.Timeout | null>(null);

  const throttledCallback = useCallback(
    (...args: Parameters<T>) => {
      const now = Date.now();
      const timeSinceLastCall = now - lastCall.current;

      if (timeSinceLastCall >= delay) {
        lastCall.current = now;
        callback(...args);
      } else {
        // 마지막 호출 예약
        if (timeoutRef.current) {
          clearTimeout(timeoutRef.current);
        }
        timeoutRef.current = setTimeout(() => {
          lastCall.current = Date.now();
          callback(...args);
        }, delay - timeSinceLastCall);
      }
    },
    [callback, delay]
  ) as T;

  // 클린업
  useEffect(() => {
    return () => {
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current);
      }
    };
  }, []);

  return throttledCallback;
}

export default VirtualList;

```

---

## frontend/src/components/admin/JobStatusBadge.tsx

```tsx
import { cn } from '@/lib/utils';
import { Badge } from '@/components/ui/badge';
import {
  CheckCircle2,
  AlertCircle,
  Clock,
  Loader2,
  XCircle,
} from 'lucide-react';
import type { CollectionJobStatus } from '@/lib/api/collection';

interface JobStatusBadgeProps {
  status: CollectionJobStatus;
  /** 추가 텍스트 */
  label?: string;
  /** 사이즈 */
  size?: 'sm' | 'default';
  /** 클래스명 */
  className?: string;
}

const statusConfig: Record<CollectionJobStatus, {
  icon: React.ReactNode;
  label: string;
  variant: 'default' | 'secondary' | 'destructive' | 'outline';
  className: string;
}> = {
  PENDING: {
    icon: <Clock className="h-3 w-3" />,
    label: '대기 중',
    variant: 'secondary',
    className: 'bg-yellow-100 text-yellow-700 dark:bg-yellow-900 dark:text-yellow-300 border-yellow-200',
  },
  RUNNING: {
    icon: <Loader2 className="h-3 w-3 animate-spin" />,
    label: '수집 중',
    variant: 'default',
    className: 'bg-blue-100 text-blue-700 dark:bg-blue-900 dark:text-blue-300 border-blue-200',
  },
  COMPLETED: {
    icon: <CheckCircle2 className="h-3 w-3" />,
    label: '완료',
    variant: 'secondary',
    className: 'bg-green-100 text-green-700 dark:bg-green-900 dark:text-green-300 border-green-200',
  },
  FAILED: {
    icon: <AlertCircle className="h-3 w-3" />,
    label: '실패',
    variant: 'destructive',
    className: 'bg-red-100 text-red-700 dark:bg-red-900 dark:text-red-300 border-red-200',
  },
  CANCELLED: {
    icon: <XCircle className="h-3 w-3" />,
    label: '취소됨',
    variant: 'outline',
    className: 'bg-gray-100 text-gray-700 dark:bg-gray-800 dark:text-gray-300 border-gray-200',
  },
};

/**
 * 수집 작업 상태 배지 컴포넌트
 */
export function JobStatusBadge({
  status,
  label,
  size = 'default',
  className,
}: JobStatusBadgeProps) {
  const config = statusConfig[status];
  
  return (
    <Badge
      variant={config.variant}
      className={cn(
        'flex items-center gap-1',
        config.className,
        size === 'sm' && 'text-xs px-1.5 py-0',
        className
      )}
    >
      {config.icon}
      {label || config.label}
    </Badge>
  );
}

export default JobStatusBadge;

```

---

## frontend/src/components/admin/LiveCounter.tsx

```tsx
import { useEffect, useRef, useState } from 'react';
import { cn } from '@/lib/utils';
import { TrendingUp, TrendingDown, Minus } from 'lucide-react';

interface LiveCounterProps {
  /** 현재 값 */
  value: number;
  /** 이전 값 (변화량 계산용) */
  previousValue?: number;
  /** 라벨 */
  label: string;
  /** 아이콘 */
  icon?: React.ReactNode;
  /** 서브 텍스트 */
  subtitle?: string;
  /** 변화량 표시 여부 */
  showChange?: boolean;
  /** 로딩 상태 */
  isLoading?: boolean;
  /** 숫자 포맷 함수 */
  formatValue?: (value: number) => string;
  /** 클래스명 */
  className?: string;
}

/**
 * 실시간 카운터 컴포넌트
 * 값이 변경될 때 롤링 애니메이션 효과 적용
 */
export function LiveCounter({
  value,
  previousValue,
  label,
  icon,
  subtitle,
  showChange = true,
  isLoading = false,
  formatValue = (v) => v.toLocaleString(),
  className,
}: LiveCounterProps) {
  const [displayValue, setDisplayValue] = useState(value);
  const [isAnimating, setIsAnimating] = useState(false);
  const prevValueRef = useRef(value);

  // 값 변경 시 롤링 애니메이션
  useEffect(() => {
    if (value === prevValueRef.current) return;

    setIsAnimating(true);
    const startValue = prevValueRef.current;
    const endValue = value;
    const duration = 500; // ms
    const startTime = Date.now();

    const animate = () => {
      const elapsed = Date.now() - startTime;
      const progress = Math.min(elapsed / duration, 1);
      
      // easeOutQuad
      const eased = 1 - (1 - progress) * (1 - progress);
      const current = Math.round(startValue + (endValue - startValue) * eased);
      
      setDisplayValue(current);

      if (progress < 1) {
        requestAnimationFrame(animate);
      } else {
        setIsAnimating(false);
        prevValueRef.current = value;
      }
    };

    requestAnimationFrame(animate);
  }, [value]);

  const change = previousValue !== undefined ? value - previousValue : 0;
  const changePercent = previousValue && previousValue !== 0
    ? ((value - previousValue) / previousValue * 100).toFixed(1)
    : null;

  return (
    <div className={cn(
      'rounded-xl border bg-card p-6 shadow-sm transition-all duration-300',
      isAnimating && 'ring-2 ring-primary/20',
      className
    )}>
      <div className="flex flex-row items-center justify-between space-y-0 pb-2">
        <div className="tracking-tight text-sm font-medium text-muted-foreground">
          {label}
        </div>
        {icon && <div className="text-muted-foreground">{icon}</div>}
      </div>
      
      <div className="flex items-baseline gap-2">
        {isLoading ? (
          <div className="h-8 w-24 animate-pulse rounded bg-muted" />
        ) : (
          <div className={cn(
            'text-2xl font-bold transition-colors duration-300',
            isAnimating && 'text-primary'
          )}>
            {formatValue(displayValue)}
          </div>
        )}
        
        {showChange && change !== 0 && !isLoading && (
          <div className={cn(
            'flex items-center text-xs font-medium',
            change > 0 ? 'text-green-600' : 'text-red-600'
          )}>
            {change > 0 ? (
              <TrendingUp className="h-3 w-3 mr-0.5" />
            ) : (
              <TrendingDown className="h-3 w-3 mr-0.5" />
            )}
            {change > 0 ? '+' : ''}{change.toLocaleString()}
            {changePercent && ` (${changePercent}%)`}
          </div>
        )}
        
        {showChange && change === 0 && previousValue !== undefined && !isLoading && (
          <div className="flex items-center text-xs font-medium text-muted-foreground">
            <Minus className="h-3 w-3 mr-0.5" />
            변화 없음
          </div>
        )}
      </div>
      
      {subtitle && (
        <p className="text-xs text-muted-foreground mt-1">{subtitle}</p>
      )}
    </div>
  );
}

export default LiveCounter;

```

---

## frontend/src/components/admin/LiveStream.tsx

```tsx
import { useEffect, useRef } from 'react';
import { cn } from '@/lib/utils';
import { 
  FileText, 
  RefreshCw, 
  AlertCircle, 
  CheckCircle2, 
  Clock,
  Zap,
  Database,
  Activity
} from 'lucide-react';
import type { ActivityLogEntry, DashboardEventType } from '@/hooks/useDashboardEvents';
import { ScrollArea } from '@/components/ui/scroll-area';

interface LiveStreamProps {
  /** 활동 로그 목록 */
  logs: ActivityLogEntry[];
  /** 연결 상태 */
  status: 'connecting' | 'connected' | 'disconnected' | 'error';
  /** 최대 표시 개수 */
  maxVisible?: number;
  /** 제목 */
  title?: string;
  /** 클래스명 */
  className?: string;
  /** 로그 클리어 핸들러 */
  onClear?: () => void;
}

const eventTypeConfig: Record<DashboardEventType, {
  icon: React.ReactNode;
  color: string;
  bgColor: string;
}> = {
  HEARTBEAT: {
    icon: <Activity className="h-3 w-3" />,
    color: 'text-gray-500',
    bgColor: 'bg-gray-50 dark:bg-gray-900',
  },
  NEW_DATA: {
    icon: <FileText className="h-3 w-3" />,
    color: 'text-blue-600',
    bgColor: 'bg-blue-50 dark:bg-blue-950',
  },
  SOURCE_UPDATED: {
    icon: <RefreshCw className="h-3 w-3" />,
    color: 'text-purple-600',
    bgColor: 'bg-purple-50 dark:bg-purple-950',
  },
  STATS_UPDATED: {
    icon: <Database className="h-3 w-3" />,
    color: 'text-green-600',
    bgColor: 'bg-green-50 dark:bg-green-950',
  },
  COLLECTION_STARTED: {
    icon: <Zap className="h-3 w-3" />,
    color: 'text-yellow-600',
    bgColor: 'bg-yellow-50 dark:bg-yellow-950',
  },
  COLLECTION_COMPLETED: {
    icon: <CheckCircle2 className="h-3 w-3" />,
    color: 'text-green-600',
    bgColor: 'bg-green-50 dark:bg-green-950',
  },
  ERROR: {
    icon: <AlertCircle className="h-3 w-3" />,
    color: 'text-red-600',
    bgColor: 'bg-red-50 dark:bg-red-950',
  },
};

function formatRelativeTime(date: Date): string {
  const now = new Date();
  const diff = now.getTime() - date.getTime();
  
  if (diff < 5000) return '방금';
  if (diff < 60000) return `${Math.floor(diff / 1000)}초 전`;
  if (diff < 3600000) return `${Math.floor(diff / 60000)}분 전`;
  if (diff < 86400000) return `${Math.floor(diff / 3600000)}시간 전`;
  return date.toLocaleDateString('ko-KR');
}

function LogEntry({ log }: { log: ActivityLogEntry }) {
  const config = eventTypeConfig[log.eventType] || eventTypeConfig.NEW_DATA;
  
  return (
    <div className={cn(
      'flex items-start gap-3 p-3 rounded-lg transition-all duration-300',
      'animate-in slide-in-from-top-2 fade-in',
      config.bgColor
    )}>
      <div className={cn('mt-0.5', config.color)}>
        {config.icon}
      </div>
      <div className="flex-1 min-w-0">
        <p className="text-sm text-foreground leading-snug">
          {log.message}
        </p>
        {log.data && Object.keys(log.data).length > 0 && (
          <div className="mt-1 text-xs text-muted-foreground">
            {Object.entries(log.data).slice(0, 3).map(([key, value]) => (
              <span key={key} className="mr-2">
                <span className="font-medium">{key}:</span>{' '}
                {typeof value === 'object' ? JSON.stringify(value) : String(value)}
              </span>
            ))}
          </div>
        )}
      </div>
      <div className="text-xs text-muted-foreground whitespace-nowrap flex items-center gap-1">
        <Clock className="h-3 w-3" />
        {formatRelativeTime(log.timestamp)}
      </div>
    </div>
  );
}

function ConnectionStatus({ status }: { status: LiveStreamProps['status'] }) {
  const statusConfig = {
    connecting: { color: 'bg-yellow-500', label: '연결 중...', animate: true },
    connected: { color: 'bg-green-500', label: '실시간 연결됨', animate: false },
    disconnected: { color: 'bg-gray-500', label: '연결 끊김', animate: false },
    error: { color: 'bg-red-500', label: '연결 오류', animate: false },
  };
  
  const config = statusConfig[status];
  
  return (
    <div className="flex items-center gap-2 text-xs text-muted-foreground">
      <span className={cn(
        'h-2 w-2 rounded-full',
        config.color,
        config.animate && 'animate-pulse'
      )} />
      {config.label}
    </div>
  );
}

/**
 * 실시간 활동 스트림 컴포넌트
 * 터미널 로그 스타일의 실시간 활동 피드
 */
export function LiveStream({
  logs,
  status,
  maxVisible = 20,
  title = '실시간 활동',
  className,
  onClear,
}: LiveStreamProps) {
  const scrollRef = useRef<HTMLDivElement>(null);
  
  // 새 로그가 추가되면 스크롤을 상단으로
  useEffect(() => {
    if (scrollRef.current) {
      scrollRef.current.scrollTop = 0;
    }
  }, [logs.length]);

  const visibleLogs = logs.slice(0, maxVisible);

  return (
    <div className={cn(
      'rounded-xl border bg-card shadow-sm flex flex-col',
      className
    )}>
      {/* Header */}
      <div className="flex items-center justify-between p-4 border-b">
        <div className="flex items-center gap-2">
          <Activity className="h-4 w-4 text-primary" />
          <h3 className="font-semibold">{title}</h3>
          {logs.length > 0 && (
            <span className="text-xs text-muted-foreground bg-muted px-2 py-0.5 rounded-full">
              {logs.length}
            </span>
          )}
        </div>
        <div className="flex items-center gap-3">
          <ConnectionStatus status={status} />
          {onClear && logs.length > 0 && (
            <button
              onClick={onClear}
              className="text-xs text-muted-foreground hover:text-foreground transition-colors"
            >
              지우기
            </button>
          )}
        </div>
      </div>
      
      {/* Log Stream */}
      <ScrollArea className="flex-1" ref={scrollRef}>
        <div className="p-3 space-y-2">
          {visibleLogs.length === 0 ? (
            <div className="flex flex-col items-center justify-center py-8 text-muted-foreground">
              {status === 'connected' ? (
                <>
                  <Activity className="h-8 w-8 mb-2 animate-pulse" />
                  <p className="text-sm">이벤트 대기 중...</p>
                </>
              ) : (
                <>
                  <AlertCircle className="h-8 w-8 mb-2" />
                  <p className="text-sm">연결 대기 중...</p>
                </>
              )}
            </div>
          ) : (
            visibleLogs.map((log) => (
              <LogEntry key={log.id} log={log} />
            ))
          )}
        </div>
      </ScrollArea>
      
      {/* Footer - 더 보기 */}
      {logs.length > maxVisible && (
        <div className="p-3 border-t text-center">
          <span className="text-xs text-muted-foreground">
            + {logs.length - maxVisible}개 더 있음
          </span>
        </div>
      )}
    </div>
  );
}

export default LiveStream;

```

---

## frontend/src/components/admin/SourceCard.tsx

```tsx
import { useState } from 'react';
import { cn } from '@/lib/utils';
import { Button } from '@/components/ui/button';
import { Badge } from '@/components/ui/badge';
import {
  Play,
  Pause,
  RefreshCw,
  Clock,
  CheckCircle2,
  AlertCircle,
  Loader2,
  ExternalLink,
  MoreVertical,
} from 'lucide-react';
import {
  DropdownMenu,
  DropdownMenuContent,
  DropdownMenuItem,
  DropdownMenuTrigger,
} from '@/components/ui/dropdown-menu';
import { startCollectionForSource } from '@/lib/api/collection';
import { toast } from 'sonner';

export interface SourceInfo {
  id: number;
  name: string;
  url: string;
  sourceType: 'RSS' | 'WEB' | 'API' | 'WEBHOOK';
  active: boolean;
  lastCollectedAt?: string;
  lastError?: string;
  itemsCollectedToday?: number;
  totalItemsCollected?: number;
}

interface SourceCardProps {
  source: SourceInfo;
  /** 수집 실행 중 여부 */
  isCollecting?: boolean;
  /** 상태 변경 콜백 */
  onToggleActive?: (id: number, active: boolean) => Promise<void>;
  /** 수집 완료 콜백 */
  onCollectionComplete?: () => void;
  /** 클래스명 */
  className?: string;
}

function formatRelativeTime(dateString: string | undefined): string {
  if (!dateString) return '없음';
  
  const date = new Date(dateString);
  const now = new Date();
  const diff = now.getTime() - date.getTime();
  
  if (diff < 60000) return '방금 전';
  if (diff < 3600000) return `${Math.floor(diff / 60000)}분 전`;
  if (diff < 86400000) return `${Math.floor(diff / 3600000)}시간 전`;
  return `${Math.floor(diff / 86400000)}일 전`;
}

function getSourceTypeColor(type: SourceInfo['sourceType']): string {
  const colors: Record<SourceInfo['sourceType'], string> = {
    RSS: 'bg-orange-100 text-orange-700 dark:bg-orange-900 dark:text-orange-300',
    WEB: 'bg-blue-100 text-blue-700 dark:bg-blue-900 dark:text-blue-300',
    API: 'bg-purple-100 text-purple-700 dark:bg-purple-900 dark:text-purple-300',
    WEBHOOK: 'bg-green-100 text-green-700 dark:bg-green-900 dark:text-green-300',
  };
  return colors[type];
}

/**
 * 뉴스 소스 제어 카드
 * 소스 상태 표시 및 수집 트리거 버튼 제공
 */
export function SourceCard({
  source,
  isCollecting = false,
  onToggleActive,
  onCollectionComplete,
  className,
}: SourceCardProps) {
  const [isRunning, setIsRunning] = useState(false);
  const [isToggling, setIsToggling] = useState(false);

  const handleRunNow = async () => {
    if (isRunning || isCollecting) return;
    
    setIsRunning(true);
    try {
      await startCollectionForSource(source.id);
      toast.success(`${source.name} 수집이 시작되었습니다`);
      onCollectionComplete?.();
    } catch (e) {
      const message = e instanceof Error ? e.message : '수집 시작 실패';
      toast.error(message);
    } finally {
      setIsRunning(false);
    }
  };

  const handleToggleActive = async () => {
    if (!onToggleActive || isToggling) return;
    
    setIsToggling(true);
    try {
      await onToggleActive(source.id, !source.active);
      toast.success(source.active ? `${source.name} 비활성화됨` : `${source.name} 활성화됨`);
    } catch (e) {
      const message = e instanceof Error ? e.message : '상태 변경 실패';
      toast.error(message);
    } finally {
      setIsToggling(false);
    }
  };

  const hasError = !!source.lastError;
  const isHealthy = source.active && !hasError;

  return (
    <div className={cn(
      'rounded-lg border bg-card p-4 shadow-sm transition-all hover:shadow-md',
      !source.active && 'opacity-60',
      hasError && 'border-red-200 dark:border-red-800',
      className
    )}>
      {/* Header */}
      <div className="flex items-start justify-between gap-2">
        <div className="flex-1 min-w-0">
          <div className="flex items-center gap-2">
            <h4 className="font-medium text-sm truncate">{source.name}</h4>
            <Badge variant="secondary" className={cn('text-xs', getSourceTypeColor(source.sourceType))}>
              {source.sourceType}
            </Badge>
          </div>
          <a
            href={source.url}
            target="_blank"
            rel="noopener noreferrer"
            className="text-xs text-muted-foreground hover:text-primary flex items-center gap-1 mt-1 truncate"
          >
            {new URL(source.url).hostname}
            <ExternalLink className="h-3 w-3 flex-shrink-0" />
          </a>
        </div>
        
        <DropdownMenu>
          <DropdownMenuTrigger asChild>
            <Button variant="ghost" size="icon" className="h-8 w-8">
              <MoreVertical className="h-4 w-4" />
            </Button>
          </DropdownMenuTrigger>
          <DropdownMenuContent align="end">
            <DropdownMenuItem onClick={handleToggleActive} disabled={isToggling}>
              {source.active ? (
                <>
                  <Pause className="h-4 w-4 mr-2" />
                  비활성화
                </>
              ) : (
                <>
                  <Play className="h-4 w-4 mr-2" />
                  활성화
                </>
              )}
            </DropdownMenuItem>
            <DropdownMenuItem asChild>
              <a href={source.url} target="_blank" rel="noopener noreferrer">
                <ExternalLink className="h-4 w-4 mr-2" />
                사이트 열기
              </a>
            </DropdownMenuItem>
          </DropdownMenuContent>
        </DropdownMenu>
      </div>

      {/* Status */}
      <div className="mt-3 space-y-2">
        <div className="flex items-center justify-between text-xs">
          <span className="text-muted-foreground flex items-center gap-1">
            <Clock className="h-3 w-3" />
            마지막 수집
          </span>
          <span className={cn(
            'font-medium',
            source.lastCollectedAt ? 'text-foreground' : 'text-muted-foreground'
          )}>
            {formatRelativeTime(source.lastCollectedAt)}
          </span>
        </div>
        
        <div className="flex items-center justify-between text-xs">
          <span className="text-muted-foreground">상태</span>
          <div className="flex items-center gap-1">
            {isHealthy ? (
              <>
                <CheckCircle2 className="h-3 w-3 text-green-600" />
                <span className="text-green-600 font-medium">정상</span>
              </>
            ) : hasError ? (
              <>
                <AlertCircle className="h-3 w-3 text-red-600" />
                <span className="text-red-600 font-medium" title={source.lastError}>
                  오류
                </span>
              </>
            ) : (
              <>
                <Pause className="h-3 w-3 text-gray-500" />
                <span className="text-gray-500 font-medium">비활성</span>
              </>
            )}
          </div>
        </div>

        {source.itemsCollectedToday !== undefined && (
          <div className="flex items-center justify-between text-xs">
            <span className="text-muted-foreground">오늘 수집</span>
            <span className="font-medium">{source.itemsCollectedToday.toLocaleString()}건</span>
          </div>
        )}
      </div>

      {/* Error Message */}
      {hasError && (
        <div className="mt-2 p-2 rounded bg-red-50 dark:bg-red-950 text-xs text-red-600 dark:text-red-400 line-clamp-2">
          {source.lastError}
        </div>
      )}

      {/* Action Button */}
      <div className="mt-3">
        <Button
          variant="outline"
          size="sm"
          className="w-full"
          onClick={handleRunNow}
          disabled={!source.active || isRunning || isCollecting}
        >
          {isRunning || isCollecting ? (
            <>
              <Loader2 className="h-4 w-4 mr-2 animate-spin" />
              수집 중...
            </>
          ) : (
            <>
              <RefreshCw className="h-4 w-4 mr-2" />
              지금 수집
            </>
          )}
        </Button>
      </div>
    </div>
  );
}

export default SourceCard;

```

---

## frontend/src/components/charts/KeywordBarChart.tsx

```tsx
import { useRef, forwardRef, useImperativeHandle } from 'react';
import { Bar } from 'react-chartjs-2';
import {
  Chart as ChartJS,
  CategoryScale,
  LinearScale,
  BarElement,
  Tooltip,
  Legend,
  type ChartOptions,
} from 'chart.js';

// Register Chart.js components
ChartJS.register(CategoryScale, LinearScale, BarElement, Tooltip, Legend);

export interface KeywordBarChartProps {
  keywords: Array<{ keyword: string; count: number }>;
  title?: string;
  maxItems?: number;
  horizontal?: boolean;
  className?: string;
}

export interface ChartExportHandle {
  toBase64: () => string | null;
}

export const KeywordBarChart = forwardRef<ChartExportHandle, KeywordBarChartProps>(
  ({ keywords, title = '주요 키워드', maxItems = 10, horizontal = true, className }, ref) => {
    const chartRef = useRef<ChartJS<'bar'>>(null);

    useImperativeHandle(ref, () => ({
      toBase64: () => {
        if (chartRef.current) {
          return chartRef.current.toBase64Image();
        }
        return null;
      },
    }));

    // Sort and limit keywords
    const sortedKeywords = [...keywords]
      .sort((a, b) => b.count - a.count)
      .slice(0, maxItems);

    const data = {
      labels: sortedKeywords.map((k) => k.keyword),
      datasets: [
        {
          label: '언급 횟수',
          data: sortedKeywords.map((k) => k.count),
          backgroundColor: 'rgba(59, 130, 246, 0.7)',
          borderColor: 'rgba(59, 130, 246, 1)',
          borderWidth: 1,
          borderRadius: 4,
        },
      ],
    };

    const options: ChartOptions<'bar'> = {
      responsive: true,
      maintainAspectRatio: true,
      indexAxis: horizontal ? 'y' : 'x',
      plugins: {
        legend: {
          display: false,
        },
        title: {
          display: !!title,
          text: title,
          font: {
            size: 16,
            weight: 'bold',
          },
          padding: {
            bottom: 20,
          },
        },
        tooltip: {
          callbacks: {
            label: (context) => `${context.parsed.x || context.parsed.y}건`,
          },
        },
      },
      scales: {
        x: {
          beginAtZero: true,
          grid: {
            display: !horizontal,
          },
          ticks: {
            precision: 0,
          },
        },
        y: {
          grid: {
            display: horizontal,
          },
          ticks: {
            font: {
              size: 11,
            },
          },
        },
      },
    };

    return (
      <div className={className}>
        <Bar ref={chartRef} data={data} options={options} />
      </div>
    );
  }
);

KeywordBarChart.displayName = 'KeywordBarChart';

```

---

## frontend/src/components/charts/ReliabilityGauge.tsx

```tsx
import { useRef, forwardRef, useImperativeHandle } from 'react';
import { Doughnut } from 'react-chartjs-2';
import {
  Chart as ChartJS,
  ArcElement,
  Tooltip,
  Legend,
  type ChartOptions,
} from 'chart.js';

// Register Chart.js components
ChartJS.register(ArcElement, Tooltip, Legend);

export interface ReliabilityGaugeProps {
  score: number;  // 0-100
  title?: string;
  showLabel?: boolean;
  className?: string;
}

export interface ChartExportHandle {
  toBase64: () => string | null;
}

const getGradeInfo = (score: number) => {
  if (score >= 80) return { label: '높음', color: 'rgba(34, 197, 94, 0.8)', borderColor: 'rgba(34, 197, 94, 1)' };
  if (score >= 50) return { label: '중간', color: 'rgba(234, 179, 8, 0.8)', borderColor: 'rgba(234, 179, 8, 1)' };
  return { label: '낮음', color: 'rgba(239, 68, 68, 0.8)', borderColor: 'rgba(239, 68, 68, 1)' };
};

export const ReliabilityGauge = forwardRef<ChartExportHandle, ReliabilityGaugeProps>(
  ({ score, title = '신뢰도', showLabel = true, className }, ref) => {
    const chartRef = useRef<ChartJS<'doughnut'>>(null);

    useImperativeHandle(ref, () => ({
      toBase64: () => {
        if (chartRef.current) {
          return chartRef.current.toBase64Image();
        }
        return null;
      },
    }));

    const gradeInfo = getGradeInfo(score);
    const remaining = 100 - score;

    const data = {
      labels: ['신뢰도', ''],
      datasets: [
        {
          data: [score, remaining],
          backgroundColor: [gradeInfo.color, 'rgba(229, 231, 235, 0.5)'],
          borderColor: [gradeInfo.borderColor, 'rgba(229, 231, 235, 0.8)'],
          borderWidth: 2,
          circumference: 270,
          rotation: 225,
        },
      ],
    };

    const options: ChartOptions<'doughnut'> = {
      responsive: true,
      maintainAspectRatio: true,
      cutout: '70%',
      plugins: {
        legend: {
          display: false,
        },
        title: {
          display: !!title,
          text: title,
          font: {
            size: 16,
            weight: 'bold',
          },
          padding: {
            bottom: 10,
          },
        },
        tooltip: {
          enabled: false,
        },
      },
    };

    return (
      <div className={`relative ${className}`}>
        <Doughnut ref={chartRef} data={data} options={options} />
        {showLabel && (
          <div className="absolute inset-0 flex flex-col items-center justify-center pointer-events-none">
            <div className="text-3xl font-bold" style={{ color: gradeInfo.borderColor }}>
              {score}
            </div>
            <div className="text-sm text-muted-foreground">{gradeInfo.label}</div>
          </div>
        )}
      </div>
    );
  }
);

ReliabilityGauge.displayName = 'ReliabilityGauge';

```

---

## frontend/src/components/charts/SentimentPieChart.tsx

```tsx
import { useRef, forwardRef, useImperativeHandle } from 'react';
import { Pie } from 'react-chartjs-2';
import {
  Chart as ChartJS,
  ArcElement,
  Tooltip,
  Legend,
  type ChartOptions,
} from 'chart.js';

// Register Chart.js components
ChartJS.register(ArcElement, Tooltip, Legend);

export interface SentimentPieChartProps {
  positive: number;
  negative: number;
  neutral: number;
  title?: string;
  showLegend?: boolean;
  className?: string;
}

export interface ChartExportHandle {
  toBase64: () => string | null;
}

export const SentimentPieChart = forwardRef<ChartExportHandle, SentimentPieChartProps>(
  ({ positive, negative, neutral, title = '감성 분포', showLegend = true, className }, ref) => {
    const chartRef = useRef<ChartJS<'pie'>>(null);

    useImperativeHandle(ref, () => ({
      toBase64: () => {
        if (chartRef.current) {
          return chartRef.current.toBase64Image();
        }
        return null;
      },
    }));

    const data = {
      labels: ['긍정', '부정', '중립'],
      datasets: [
        {
          data: [positive, negative, neutral],
          backgroundColor: [
            'rgba(34, 197, 94, 0.8)',   // Green
            'rgba(239, 68, 68, 0.8)',    // Red
            'rgba(156, 163, 175, 0.8)',  // Gray
          ],
          borderColor: [
            'rgba(34, 197, 94, 1)',
            'rgba(239, 68, 68, 1)',
            'rgba(156, 163, 175, 1)',
          ],
          borderWidth: 2,
        },
      ],
    };

    const options: ChartOptions<'pie'> = {
      responsive: true,
      maintainAspectRatio: true,
      plugins: {
        legend: {
          display: showLegend,
          position: 'bottom',
          labels: {
            padding: 20,
            usePointStyle: true,
            font: {
              size: 12,
            },
          },
        },
        title: {
          display: !!title,
          text: title,
          font: {
            size: 16,
            weight: 'bold',
          },
          padding: {
            bottom: 20,
          },
        },
        tooltip: {
          callbacks: {
            label: (context) => {
              const total = positive + negative + neutral;
              const value = context.parsed;
              const percentage = total > 0 ? ((value / total) * 100).toFixed(1) : '0';
              return `${context.label}: ${value}건 (${percentage}%)`;
            },
          },
        },
      },
    };

    return (
      <div className={className}>
        <Pie ref={chartRef} data={data} options={options} />
      </div>
    );
  }
);

SentimentPieChart.displayName = 'SentimentPieChart';

```

---

## frontend/src/components/charts/SourceDistributionChart.tsx

```tsx
import { useRef, forwardRef, useImperativeHandle } from 'react';
import { Doughnut } from 'react-chartjs-2';
import {
  Chart as ChartJS,
  ArcElement,
  Tooltip,
  Legend,
  type ChartOptions,
} from 'chart.js';

// Register Chart.js components
ChartJS.register(ArcElement, Tooltip, Legend);

export interface SourceDistributionChartProps {
  sources: Array<{ source: string; count: number }>;
  title?: string;
  maxItems?: number;
  className?: string;
}

export interface ChartExportHandle {
  toBase64: () => string | null;
}

const COLORS = [
  'rgba(59, 130, 246, 0.8)',   // Blue
  'rgba(34, 197, 94, 0.8)',    // Green
  'rgba(234, 179, 8, 0.8)',    // Yellow
  'rgba(239, 68, 68, 0.8)',    // Red
  'rgba(168, 85, 247, 0.8)',   // Purple
  'rgba(20, 184, 166, 0.8)',   // Teal
  'rgba(249, 115, 22, 0.8)',   // Orange
  'rgba(236, 72, 153, 0.8)',   // Pink
  'rgba(107, 114, 128, 0.8)',  // Gray
  'rgba(139, 92, 246, 0.8)',   // Violet
];

const BORDER_COLORS = [
  'rgba(59, 130, 246, 1)',
  'rgba(34, 197, 94, 1)',
  'rgba(234, 179, 8, 1)',
  'rgba(239, 68, 68, 1)',
  'rgba(168, 85, 247, 1)',
  'rgba(20, 184, 166, 1)',
  'rgba(249, 115, 22, 1)',
  'rgba(236, 72, 153, 1)',
  'rgba(107, 114, 128, 1)',
  'rgba(139, 92, 246, 1)',
];

export const SourceDistributionChart = forwardRef<ChartExportHandle, SourceDistributionChartProps>(
  ({ sources, title = '출처별 분포', maxItems = 8, className }, ref) => {
    const chartRef = useRef<ChartJS<'doughnut'>>(null);

    useImperativeHandle(ref, () => ({
      toBase64: () => {
        if (chartRef.current) {
          return chartRef.current.toBase64Image();
        }
        return null;
      },
    }));

    // Sort and limit sources
    const sortedSources = [...sources]
      .sort((a, b) => b.count - a.count)
      .slice(0, maxItems);

    // Group remaining sources as "기타"
    if (sources.length > maxItems) {
      const otherCount = sources
        .sort((a, b) => b.count - a.count)
        .slice(maxItems)
        .reduce((sum, s) => sum + s.count, 0);
      if (otherCount > 0) {
        sortedSources.push({ source: '기타', count: otherCount });
      }
    }

    const data = {
      labels: sortedSources.map((s) => s.source),
      datasets: [
        {
          data: sortedSources.map((s) => s.count),
          backgroundColor: sortedSources.map((_, i) => COLORS[i % COLORS.length]),
          borderColor: sortedSources.map((_, i) => BORDER_COLORS[i % BORDER_COLORS.length]),
          borderWidth: 2,
        },
      ],
    };

    const options: ChartOptions<'doughnut'> = {
      responsive: true,
      maintainAspectRatio: true,
      cutout: '50%',
      plugins: {
        legend: {
          display: true,
          position: 'right',
          labels: {
            padding: 15,
            usePointStyle: true,
            font: {
              size: 11,
            },
          },
        },
        title: {
          display: !!title,
          text: title,
          font: {
            size: 16,
            weight: 'bold',
          },
          padding: {
            bottom: 20,
          },
        },
        tooltip: {
          callbacks: {
            label: (context) => {
              const total = sortedSources.reduce((sum, s) => sum + s.count, 0);
              const percentage = total > 0 ? ((context.parsed / total) * 100).toFixed(1) : '0';
              return `${context.label}: ${context.parsed}건 (${percentage}%)`;
            },
          },
        },
      },
    };

    return (
      <div className={className}>
        <Doughnut ref={chartRef} data={data} options={options} />
      </div>
    );
  }
);

SourceDistributionChart.displayName = 'SourceDistributionChart';

```

---

## frontend/src/components/charts/TrendLineChart.tsx

```tsx
import { useRef, forwardRef, useImperativeHandle } from 'react';
import { Line } from 'react-chartjs-2';
import {
  Chart as ChartJS,
  CategoryScale,
  LinearScale,
  PointElement,
  LineElement,
  Tooltip,
  Legend,
  Filler,
  type ChartOptions,
} from 'chart.js';

// Register Chart.js components
ChartJS.register(
  CategoryScale,
  LinearScale,
  PointElement,
  LineElement,
  Tooltip,
  Legend,
  Filler
);

export interface TrendDataPoint {
  date: string;
  count: number;
}

export interface TrendLineChartProps {
  data: TrendDataPoint[];
  title?: string;
  showArea?: boolean;
  color?: string;
  className?: string;
}

export interface ChartExportHandle {
  toBase64: () => string | null;
}

export const TrendLineChart = forwardRef<ChartExportHandle, TrendLineChartProps>(
  ({ data, title = '시간대별 트렌드', showArea = true, color = 'rgb(59, 130, 246)', className }, ref) => {
    const chartRef = useRef<ChartJS<'line'>>(null);

    useImperativeHandle(ref, () => ({
      toBase64: () => {
        if (chartRef.current) {
          return chartRef.current.toBase64Image();
        }
        return null;
      },
    }));

    const chartData = {
      labels: data.map((d) => d.date),
      datasets: [
        {
          label: '기사 수',
          data: data.map((d) => d.count),
          borderColor: color,
          backgroundColor: showArea ? `${color}33` : 'transparent',
          fill: showArea,
          tension: 0.4,
          pointBackgroundColor: color,
          pointBorderColor: '#fff',
          pointBorderWidth: 2,
          pointRadius: 4,
          pointHoverRadius: 6,
        },
      ],
    };

    const options: ChartOptions<'line'> = {
      responsive: true,
      maintainAspectRatio: true,
      plugins: {
        legend: {
          display: false,
        },
        title: {
          display: !!title,
          text: title,
          font: {
            size: 16,
            weight: 'bold',
          },
          padding: {
            bottom: 20,
          },
        },
        tooltip: {
          mode: 'index',
          intersect: false,
          callbacks: {
            label: (context) => `${context.parsed.y}건`,
          },
        },
      },
      scales: {
        x: {
          grid: {
            display: false,
          },
          ticks: {
            maxRotation: 45,
            minRotation: 0,
          },
        },
        y: {
          beginAtZero: true,
          grid: {
            color: 'rgba(0, 0, 0, 0.1)',
          },
          ticks: {
            precision: 0,
          },
        },
      },
      interaction: {
        mode: 'nearest',
        axis: 'x',
        intersect: false,
      },
    };

    return (
      <div className={className}>
        <Line ref={chartRef} data={chartData} options={options} />
      </div>
    );
  }
);

TrendLineChart.displayName = 'TrendLineChart';

```

---

## frontend/src/components/charts/index.ts

```ts
/**
 * Chart components for PDF report generation
 * These components use Chart.js and provide a toBase64() method
 * for exporting chart images to be included in PDF reports.
 */

export { SentimentPieChart, type SentimentPieChartProps } from './SentimentPieChart';
export { KeywordBarChart, type KeywordBarChartProps } from './KeywordBarChart';
export { TrendLineChart, type TrendLineChartProps, type TrendDataPoint } from './TrendLineChart';
export { ReliabilityGauge, type ReliabilityGaugeProps } from './ReliabilityGauge';
export { SourceDistributionChart, type SourceDistributionChartProps } from './SourceDistributionChart';

// Common export handle interface
export type { ChartExportHandle } from './SentimentPieChart';

```

---

## frontend/src/components/dashboard/LiveNewsTicker.tsx

```tsx
import { useEffect, useState, useCallback } from "react";
import { Card, CardContent, CardHeader, CardTitle } from "@/components/ui/card";
import { Badge } from "@/components/ui/badge";
import { ExternalLink, TrendingUp, Clock, RefreshCw, AlertCircle } from "lucide-react";
import { ScrollArea } from "@/components/ui/scroll-area";
import { Button } from "@/components/ui/button";
import { Skeleton } from "@/components/ui/skeleton";
import { listCollectedData, type CollectedDataDTO } from "@/lib/api/data";

interface NewsItem {
  id: string;
  title: string;
  source: string;
  time: string;
  url: string;
  category: string;
  originalData?: CollectedDataDTO;
}

/**
 * 수집된 데이터를 뉴스 아이템으로 변환
 */
const transformToNewsItem = (data: CollectedDataDTO): NewsItem => {
  // metadata에서 source 이름 추출 (API returns snake_case: source_name)
  const sourceName = (data.metadata?.source_name as string) || 
                     (data.metadata?.sourceName as string) || 
                     (data.metadata?.source as string) || 
                     `Source #${data.sourceId}`;
  
  // metadata에서 카테고리 추출 (tags 배열 또는 category)
  const tags = data.metadata?.tags as string[] | undefined;
  const category = (tags && tags.length > 0 ? tags[0] : null) ||
                   (data.metadata?.category as string) || 
                   (data.metadata?.section as string) || 
                   '일반';
  
  // 시간 포맷팅
  const time = data.publishedDate 
    ? new Date(data.publishedDate).toLocaleTimeString('ko-KR', { hour: '2-digit', minute: '2-digit' })
    : new Date(data.collectedAt).toLocaleTimeString('ko-KR', { hour: '2-digit', minute: '2-digit' });

  return {
    id: data.id.toString(),
    title: data.title || '제목 없음',
    source: sourceName,
    time,
    url: data.url || '#',
    category,
    originalData: data,
  };
};

export function LiveNewsTicker() {
  const [news, setNews] = useState<NewsItem[]>([]);
  const [isLoading, setIsLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);
  const [lastFetchTime, setLastFetchTime] = useState<Date | null>(null);

  // 데이터 로드 함수
  const fetchNews = useCallback(async (showLoading = true) => {
    if (showLoading) setIsLoading(true);
    setError(null);
    
    try {
      // 최근 수집된 데이터 20개 조회
      const result = await listCollectedData(0, 20);
      const newsItems = result.content.map(transformToNewsItem);
      setNews(newsItems);
      setLastFetchTime(new Date());
    } catch (e) {
      console.error('Failed to fetch news:', e);
      setError('뉴스를 불러오는데 실패했습니다.');
    } finally {
      setIsLoading(false);
    }
  }, []);

  // 초기 로드
  useEffect(() => {
    fetchNews();
  }, [fetchNews]);

  // 30초마다 자동 새로고침
  useEffect(() => {
    const interval = setInterval(() => {
      fetchNews(false); // 로딩 표시 없이 백그라운드 업데이트
    }, 30000);

    return () => clearInterval(interval);
  }, [fetchNews]);

  // 뉴스 클릭 핸들러
  const handleNewsClick = (item: NewsItem, e: React.MouseEvent) => {
    if (!item.url || item.url === '#') {
      e.preventDefault();
      // URL이 없으면 상세 페이지로 이동하거나 모달 표시
      // 추후 상세 보기 기능 추가 가능
      return;
    }
    // 외부 URL은 새 탭에서 열기
  };

  // 로딩 상태
  if (isLoading && news.length === 0) {
    return (
      <Card className="h-full">
        <CardHeader className="pb-2">
          <CardTitle className="text-lg font-bold flex items-center gap-2">
            <TrendingUp className="h-5 w-5 text-red-500" />
            실시간 뉴스 브리핑
          </CardTitle>
        </CardHeader>
        <CardContent>
          <div className="space-y-4">
            {[1, 2, 3, 4, 5].map(i => (
              <div key={i} className="p-3 rounded-lg border">
                <Skeleton className="h-4 w-24 mb-2" />
                <Skeleton className="h-5 w-full" />
              </div>
            ))}
          </div>
        </CardContent>
      </Card>
    );
  }

  // 에러 상태
  if (error && news.length === 0) {
    return (
      <Card className="h-full">
        <CardHeader className="pb-2">
          <CardTitle className="text-lg font-bold flex items-center gap-2">
            <TrendingUp className="h-5 w-5 text-red-500" />
            실시간 뉴스 브리핑
          </CardTitle>
        </CardHeader>
        <CardContent className="flex flex-col items-center justify-center h-[300px] gap-4">
          <AlertCircle className="h-12 w-12 text-muted-foreground" />
          <p className="text-muted-foreground">{error}</p>
          <Button variant="outline" size="sm" onClick={() => fetchNews()}>
            <RefreshCw className="h-4 w-4 mr-2" />
            다시 시도
          </Button>
        </CardContent>
      </Card>
    );
  }

  // 데이터 없음 상태
  if (news.length === 0) {
    return (
      <Card className="h-full">
        <CardHeader className="pb-2">
          <CardTitle className="text-lg font-bold flex items-center gap-2">
            <TrendingUp className="h-5 w-5 text-red-500" />
            실시간 뉴스 브리핑
          </CardTitle>
        </CardHeader>
        <CardContent className="flex flex-col items-center justify-center h-[300px] gap-4">
          <p className="text-muted-foreground">수집된 뉴스가 없습니다.</p>
          <Button variant="outline" size="sm" onClick={() => fetchNews()}>
            <RefreshCw className="h-4 w-4 mr-2" />
            새로고침
          </Button>
        </CardContent>
      </Card>
    );
  }

  return (
    <Card className="h-full">
      <CardHeader className="pb-2">
        <div className="flex items-center justify-between">
          <CardTitle className="text-lg font-bold flex items-center gap-2">
            <TrendingUp className="h-5 w-5 text-red-500" />
            실시간 뉴스 브리핑
          </CardTitle>
          <div className="flex items-center gap-2">
            {lastFetchTime && (
              <span className="text-xs text-muted-foreground">
                {lastFetchTime.toLocaleTimeString('ko-KR', { hour: '2-digit', minute: '2-digit' })} 업데이트
              </span>
            )}
            <Badge variant="outline" className="animate-pulse text-red-500 border-red-200 bg-red-50 dark:bg-red-950 dark:border-red-800">
              LIVE
            </Badge>
          </div>
        </div>
      </CardHeader>
      <CardContent>
        <ScrollArea className="h-[380px] pr-4">
          <div className="space-y-3">
            {news.map((item, index) => (
              <a
                key={item.id}
                href={item.url}
                target="_blank"
                rel="noopener noreferrer"
                onClick={(e) => handleNewsClick(item, e)}
                className={`
                  block p-3 rounded-lg border bg-card transition-all cursor-pointer
                  hover:bg-accent/50 hover:border-primary/30 hover:shadow-sm
                  ${index === 0 ? 'border-l-4 border-l-red-500 shadow-sm' : ''}
                `}
              >
                <div className="flex items-center justify-between text-xs text-muted-foreground mb-1">
                  <div className="flex items-center gap-2">
                    <Badge variant="secondary" className="text-[10px] h-5">
                      {item.category}
                    </Badge>
                    <span className="font-medium text-primary/80">{item.source}</span>
                  </div>
                  <div className="flex items-center gap-1">
                    <Clock className="h-3 w-3" />
                    {item.time}
                  </div>
                </div>
                <div className="font-medium flex items-start gap-1 text-sm leading-snug">
                  <span className="flex-1 line-clamp-2">{item.title}</span>
                  {item.url && item.url !== '#' && (
                    <ExternalLink className="h-3 w-3 mt-0.5 opacity-50 flex-shrink-0" />
                  )}
                </div>
              </a>
            ))}
          </div>
        </ScrollArea>
      </CardContent>
    </Card>
  );
}

```
