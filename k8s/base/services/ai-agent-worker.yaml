# AI Agent Worker Deployment
# Consumes Kafka messages for AI processing (newsinsight.ai.requests)
# Source: backend/AI_agent_server/go-proxy-admin
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-agent-worker
  namespace: newsinsight
  labels:
    app: ai-agent-worker
    app.kubernetes.io/name: ai-agent-worker
    app.kubernetes.io/component: worker
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ai-agent-worker
  template:
    metadata:
      labels:
        app: ai-agent-worker
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "7080"
    spec:
      serviceAccountName: newsinsight-sa
      containers:
        - name: ai-agent-worker
          image: ai-agent-worker:latest
          ports:
            - containerPort: 7080
              name: http
          env:
            # Admin Server Configuration
            - name: ADMIN_PORT
              value: "7080"
            - name: ADMIN_JWT_SECRET
              valueFrom:
                secretKeyRef:
                  name: newsinsight-secrets
                  key: JWT_SECRET_KEY
            - name: ADMIN_DB_PATH
              value: "/data/proxy-admin.db"
            - name: ADMIN_EMAIL
              value: "admin@newsinsight.nodove.com"
            - name: ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: newsinsight-secrets
                  key: AI_AGENT_ADMIN_PASSWORD
                  optional: true
            # Kafka Configuration
            - name: KAFKA_BROKERS
              valueFrom:
                configMapKeyRef:
                  name: newsinsight-config
                  key: KAFKA_BOOTSTRAP_SERVERS
            - name: KAFKA_GROUP_ID
              value: "ai-agent-worker"
            - name: KAFKA_REQUEST_TOPIC
              value: "newsinsight.ai.requests"
            - name: KAFKA_RESPONSE_TOPIC
              value: "newsinsight.ai.responses"
            # Upstream LLM Configuration
            - name: OPENCODE_BASE
              value: "http://opencode:7012"
            # Optional: Override default upstream if using external LLM
            - name: DEFAULT_UPSTREAM
              value: "http://opencode:7012"
          resources:
            requests:
              memory: "256Mi"
              cpu: "100m"
            limits:
              memory: "512Mi"
              cpu: "500m"
          volumeMounts:
            - name: data
              mountPath: /data
          livenessProbe:
            httpGet:
              path: /admin/health
              port: 7080
            initialDelaySeconds: 30
            periodSeconds: 30
            timeoutSeconds: 5
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /admin/health
              port: 7080
            initialDelaySeconds: 15
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
      volumes:
        - name: data
          emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: ai-agent-worker
  namespace: newsinsight
  labels:
    app: ai-agent-worker
spec:
  selector:
    app: ai-agent-worker
  ports:
    - port: 7080
      targetPort: 7080
      name: http
  type: ClusterIP
